- en: Chapter 2\. Getting Started with Amazon Redshift
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章。开始使用Amazon Redshift
- en: Amazon Redshift enables you to run analytics for your business without having
    to provision servers or infrastructure, making it easy to get started. It includes
    a web-based query editor in the AWS console to start loading and analyzing your
    data without having to install software. Amazon Redshift is also compatible with
    your favorite query editors like DBeaver, SQL WorkbenchJ, and Toad using *Java
    Database Connectivity* (JDBC) or *Open Database Connectivity* (ODBC) drivers provided.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift使您能够运行业务分析，无需预置服务器或基础设施，使得开始变得轻松。它包括AWS控制台中的基于Web的查询编辑器，可以开始加载和分析数据，无需安装软件。Amazon
    Redshift还兼容您喜爱的查询编辑器，如DBeaver、SQL WorkbenchJ和Toad，使用提供的*Java数据库连接*（JDBC）或*开放数据库连接*（ODBC）驱动程序。
- en: In this chapter, we will provide an Amazon Redshift architecture overview, describing
    the key components of the platform. Next, we’ll provide steps on how you can [“Get
    Started with Amazon Redshift Serverless”](#redshift_serverless) and begin querying
    [“Sample Data”](#sample_data) with a few button clicks. We’ll also describe [“When
    to Use a Provisioned Cluster?”](#redshift_provisioned) and how you can [“Estimate
    Your Amazon Redshift Cost”](#cost_estimation) for both serverless and provisioned
    data warehouses. Then, we’ll talk about [“AWS Account Management”](#accounts_organizations),
    describing how you can create a single account or manage multiple accounts in
    your organization. Lastly, we’ll cover some options for [“Connecting to Your Amazon
    Redshift Data Warehouse”](#connecting) and how to manage user access.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将提供Amazon Redshift架构概述，描述平台的关键组件。接下来，我们将提供有关如何[“开始使用Amazon Redshift无服务器”](#redshift_serverless)并开始查询[“样本数据”](#sample_data)的步骤，只需点击几下按钮。我们还将描述[“何时使用预置集群？”](#redshift_provisioned)以及如何为无服务器和预置数据仓库[“估算您的Amazon
    Redshift成本”](#cost_estimation)。然后，我们将讨论[“AWS账户管理”](#accounts_organizations)，描述如何在您的组织中创建单个账户或管理多个账户。最后，我们将介绍[“连接到您的Amazon
    Redshift数据仓库”](#connecting)的一些选项以及如何管理用户访问。
- en: Amazon Redshift Architecture Overview
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon Redshift架构概述
- en: What’s in a name? That which we call a rose by any other name would smell just
    as sweet.
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 名字有什么关系呢？我们可以用任何其他名字来称呼一朵玫瑰，它依然会一样芳香。
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Romeo and Juliet*'
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*罗密欧与朱丽叶*'
- en: William Shakespeare uses this line in his play *Romeo and Juliet* to convey
    that the naming of things is irrelevant.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 威廉·莎士比亚在他的剧作*罗密欧与朱丽叶*中使用这句话来表达，事物的命名是无关紧要的。
- en: There are many theories about how and why the name *Redshift*. We discovered
    that the term was coined based on the astronomical phenomenon Red Shift, which
    is a concept in physics for astronomers. It means the wavelength of light is stretched
    as it expands, so the light is shifted toward red, the color at the longest wavelength
    end of the visible spectrum of light.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 关于名为*Redshift*的原因和含义有许多理论。我们发现这个术语是基于天文学现象红移而创造的，红移是天文学中的一个概念，指的是光的波长在扩展时被拉长，因此光线向红色移动，这是可见光谱中最长波长端的颜色。
- en: Because data is ever expanding, Amazon Redshift provides a platform to store
    and analyze data and scale it seamlessly. Being the first fully managed, PB-scale
    cloud data warehouse, Amazon Redshift is an architectural shift from on-premises
    data warehousing solutions, which require upfront capital investment, effort to
    scale, and full-time resources to operate.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 因为数据不断扩展，Amazon Redshift提供了一个平台来存储和分析数据，并实现无缝扩展。作为第一个完全托管的PB级云数据仓库，Amazon Redshift是从本地数据仓库解决方案转型而来的架构，后者需要前期资本投入、扩展工作和全职资源来操作。
- en: Amazon Redshift data warehouse service is ANSI SQL compatible and built for
    OLAP workloads that store your data in compressed columnar format. This service
    is available as a provisioned or serverless data warehouse.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift数据仓库服务兼容ANSI SQL，专为OLAP工作负载设计，以压缩的列式存储格式存储数据。此服务可作为预置或无服务器数据仓库使用。
- en: '[Figure 2-1](#redshift_architecture_2_1_1) illustrates a *provisioned* cluster.
    With the newest generation of node type [RA3](https://oreil.ly/m-WgQ), you can
    scale compute and storage independently based on your workloads. The storage for
    this node type is *Amazon Redshift Managed Storage* (RMS), which is backed by
    Amazon S3.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-1](#redshift_architecture_2_1_1)展示了一个*预置*集群。使用最新一代节点类型[RA3](https://oreil.ly/m-WgQ)，您可以根据工作负载独立扩展计算和存储。该节点类型的存储为*Amazon
    Redshift Managed Storage*（RMS），由Amazon S3支持。'
- en: '![Amazon Redshift architecture](assets/ardg_0201.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift架构](assets/ardg_0201.png)'
- en: Figure 2-1\. Amazon Redshift architecture
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1。Amazon Redshift架构
- en: The *serverless* architecture (see [Figure 2-2](#redshift_serverless_architecture))
    automates many of the operational activities to monitor and scale Amazon Redshift.
    Amazon Redshift serverless leverages a machine learning-based workload monitoring
    system to automatically scale compute resources to meet the demands of your workload.
    Also, as your demand evolves with more concurrent users and new workloads, your
    data warehouse scales automatically to provide consistent query execution times.
    Finally, the getting started experience with Amazon Redshift serverless is also
    simpler; you’re charged only when it is in use. Coupled with the data-sharing
    capabilities of RMS, a department can use serverless to start analyzing data in
    an isolated data warehouse with zero impact to that shared data. Since you are
    not paying for idleness, your team does not need to reach out to an administrator
    to pause or resume your data warehouse.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*无服务器*架构（见 [图 2-2](#redshift_serverless_architecture)）自动化了许多监视和扩展 Amazon Redshift
    的操作活动。Amazon Redshift 无服务器利用基于机器学习的工作负载监控系统，自动扩展计算资源以满足工作负载的需求。随着需求随着更多并发用户和新工作负载的进展而变化，您的数据仓库会自动扩展，以提供一致的查询执行时间。最后，使用
    Amazon Redshift 无服务器开始的体验也更简单；仅在使用时收费。结合 RMS 的数据共享能力，一个部门可以使用无服务器开始分析隔离的数据仓库中的数据，而不影响共享数据。由于不必支付闲置费用，您的团队无需联系管理员来暂停或恢复数据仓库。'
- en: '![Amazon Redshift serverless architecture](assets/ardg_0202.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift 无服务器架构](assets/ardg_0202.png)'
- en: Figure 2-2\. Amazon Redshift serverless architecture
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-2\. Amazon Redshift 无服务器架构
- en: Both provisioned and serverless Amazon Redshift are based on an MPP framework
    consisting of multiple [Elastic Compute Cloud (EC2)](https://oreil.ly/2816C) nodes
    including a leader node and one or more compute nodes. Amazon Redshift also includes
    additional components for code compilation, query plans caching, results caching,
    data lake access, Concurrency Scaling (CS), machine learning, federated query,
    and data sharing. We will cover these in detail in subsequent chapters.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 预置和无服务器都基于包括领导节点和一个或多个计算节点的 MPP 框架。Amazon Redshift 还包括用于代码编译、查询计划缓存、结果缓存、数据湖访问、并发扩展（CS）、机器学习、联合查询和数据共享的额外组件。我们将在随后的章节详细介绍这些内容。
- en: With Amazon Redshift, you can get started in minutes and analyze your data using
    either a serverless or a provisioned data warehouse. We will start with how you
    can create a serverless data warehouse and work with a sample dataset to run queries.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Amazon Redshift，您可以在几分钟内开始分析数据，使用无服务器或预置数据仓库。我们将从如何创建一个无服务器数据仓库并使用样例数据集运行查询开始。
- en: Get Started with Amazon Redshift Serverless
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用 Amazon Redshift 无服务器
- en: Both Amazon Redshift serverless and provisioned have many of the same functional
    capabilities like loading and querying structured and semistructured data, federating
    to operational databases in PostgreSQL and MySQL, and querying data in your data
    lake. In addition, both serverless and RA3 provisioned data warehouses are built
    on top of RMS, allowing both to access data that was produced in other Amazon
    Redshift data warehouses whether they are provisioned or serverless. While there
    are considerations for when you may choose one over the other for your workload,
    it’s clear that serverless is the easiest way to get started with Amazon Redshift.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 无服务器和预置两者在功能上有很多相同的能力，比如加载和查询结构化和半结构化数据，向 PostgreSQL 和 MySQL
    中的运行数据库联邦化，以及在数据湖中查询数据。此外，无服务器和 RA3 预置数据仓库都构建在 RMS 之上，使两者都能访问其他 Amazon Redshift
    数据仓库中生成的数据，无论是预置还是无服务器。尽管在选择工作负载时可能需要考虑某一种方式，但很明显，无服务器是开始使用 Amazon Redshift 的最简单方式。
- en: Creating an Amazon Redshift Serverless Data Warehouse
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 Amazon Redshift 无服务器数据仓库
- en: Amazon Redshift serverless is separated into workgroups and namespaces to manage
    storage and compute resources separately. The namespace is a collection of database
    objects that include databases, schemas, tables, users, user permissions, and
    AWS Key Management Service keys for encrypting data. Other resources grouped under
    namespaces include datashares, recovery points, and usage limits. The workgroup
    is a collection of compute resources and include Amazon RPU base capacity, virtual
    private clouds (VPC) subnet groups, security groups, and limits.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 无服务器分为工作组和命名空间，以单独管理存储和计算资源。命名空间是包含数据库对象的集合，包括数据库、模式、表、用户、用户权限以及用于加密数据的
    AWS 密钥管理服务密钥。命名空间下分组的其他资源包括数据共享、恢复点和使用限制。工作组是包含计算资源的集合，包括亚马逊 RPU 基础容量、虚拟私有云（VPC）子网组、安全组和限制。
- en: To get started with Amazon Redshift serverless, you can configure the storage
    (namespace) and compute (workgroup) properties using the AWS console, the AWS
    CLI, or Amazon Redshift serverless APIs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用亚马逊 Redshift 无服务器，您可以使用 AWS 控制台、AWS CLI 或亚马逊 Redshift 无服务器 API 配置存储（命名空间）和计算（工作组）属性。
- en: To deploy an Amazon Redshift serverless data warehouse using the AWS console,
    navigate to the [Create Workgroup](https://oreil.ly/fDs-g) page and choose your
    configuration options. In the first section, you will choose the workgroup name.
    Next, you will decide the initial compute capacity by choosing the base RPU capacity.
    This is the compute capacity used when Amazon Redshift serverless starts processing
    your workload, but it can scale up automatically based on your workload needs.
    You can choose a little as 8 RPUs or as many as 512 RPUs with a default of 128\.
    For more details on determining the best RPU size for your use case, see [“Amazon
    Redshift Serverless Compute Cost”](#serverless_size_estimate).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 AWS 控制台部署亚马逊 Redshift 无服务器数据仓库，请导航到 [创建工作组](https://oreil.ly/fDs-g) 页面，并选择您的配置选项。在第一部分，您将选择工作组名称。接下来，您将通过选择基础
    RPU 容量来确定初始计算能力。这是亚马逊 Redshift 无服务器在开始处理您的工作负载时使用的计算能力，但它可以根据您的工作负载需求自动扩展。您可以选择至少
    8 个 RPUs 或多达 512 个 RPUs，默认为 128 个。有关确定您用例的最佳 RPU 大小的详细信息，请参阅 [“亚马逊 Redshift 无服务器计算成本”](#serverless_size_estimate)。
- en: Finally, you will select the security configuration (see [Figure 2-3](#workgroup_name_security)).
    This determines where your data warehouse will be deployed in the context of your
    network configuration. By default, the serverless data warehouse will be deployed
    in the default VPC, subnets, and security group. You can use the default settings
    or customize each one. For a more detailed discussion on considerations on network
    configuration, see [“Private/Public VPC and Secure Access”](#network_configuration).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您将选择安全配置（参见 [Figure 2-3](#workgroup_name_security)）。这将确定数据仓库将在哪个网络配置上部署。默认情况下，无服务器数据仓库将部署在默认
    VPC、子网和安全组中。您可以使用默认设置或自定义每个设置。有关网络配置考虑事项的详细讨论，请参阅 [“私有/公共 VPC 和安全访问”](#network_configuration)。
- en: '![Workgroup Name and Security Configuration](assets/ardg_0203.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![工作组名称和安全配置](assets/ardg_0203.png)'
- en: Figure 2-3\. Workgroup name and security configuration
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 2-3\. 工作组名称和安全配置
- en: Next, create a new namespace ([Figure 2-4](#workgroup_namespace)) or attach
    your workgroup to an existing namespace. The namespace will contain your database
    objects.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个新的命名空间（参见 [Figure 2-4](#workgroup_namespace)）或将您的工作组附加到现有的命名空间。命名空间将包含您的数据库对象。
- en: '![Namespace](assets/ardg_0204.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![命名空间](assets/ardg_0204.png)'
- en: Figure 2-4\. Namespace
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 2-4\. 命名空间
- en: If creating a new namespace, you will be prompted to specify the permissions
    and admin credentials ([Figure 2-5](#workgroup_permissions_creds)). Similar to
    a provisioned cluster, permissions are defined via Identity and Access Management
    (IAM) roles the workgroup can assume to access other resources within your AWS
    environment. In the next example, we created an IAM role `RedshiftRole`, assigned
    it the `AmazonRedshiftAllCommandsFullAccess` policy, and made it the `default`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果创建新的命名空间，系统将提示您指定权限和管理员凭据（参见 [Figure 2-5](#workgroup_permissions_creds)）。与预配置的集群类似，权限是通过工作组可以假定的身份和访问管理（IAM）角色定义的，以访问
    AWS 环境中的其他资源。在下一个示例中，我们创建了一个名为 `RedshiftRole` 的 IAM 角色，为其分配了 `AmazonRedshiftAllCommandsFullAccess`
    策略，并将其设置为默认角色。
- en: The permissions defined in the IAM role associated to your Redshift data warehouse
    affect which AWS services the Amazon Redshift service can access, such as reading
    and writing to Amazon S3\. This should not be confused with permissions assigned
    to a database user, database group, or database role.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: IAM 角色中定义的权限将影响 Amazon Redshift 数据仓库可以访问的 AWS 服务，例如读取和写入 Amazon S3。这不应与分配给数据库用户、数据库组或数据库角色的权限混淆。
- en: '![Permissions and Admin Credentials](assets/ardg_0205.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![权限和管理员凭据](assets/ardg_0205.png)'
- en: Figure 2-5\. Permissions and admin credentials
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-5\. 权限和管理员凭据
- en: Finally, for your new namespace, specify if you would like to customize the
    encryption and logging ([Figure 2-6](#workgroup_encryption)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在您的新命名空间中，指定是否要自定义加密和日志记录（[图 2-6](#workgroup_encryption)）。
- en: '![Encryption and Logging](assets/ardg_0206.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![加密和日志记录](assets/ardg_0206.png)'
- en: Figure 2-6\. Encryption and logging
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-6\. 加密和日志记录
- en: Once complete, your workgroup list ([Figure 2-7](#workgroup_list)) can be retrieved
    by navigating to the [Redshift Workgroups](https://oreil.ly/G8Mdn) page, where
    you can retrieve information such as the workgroup endpoint and JDBC and ODBC
    URL. For options to connect to your workgroup, see [“Connecting to Your Amazon
    Redshift Data Warehouse”](#connecting).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您可以通过导航到 [Redshift 工作组](https://oreil.ly/G8Mdn) 页面来检索您的工作组列表（[图 2-7](#workgroup_list)），在该页面上您可以检索工作组端点、JDBC
    和 ODBC URL 等信息。有关连接到您的工作组的选项，请参见 [“连接到您的 Amazon Redshift 数据仓库”](#connecting)。
- en: '![Workgroup List](assets/ardg_0207.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![工作组列表](assets/ardg_0207.png)'
- en: Figure 2-7\. Workgroup list
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-7\. 工作组列表
- en: Configurations of 8 or 16 RPU support Amazon RMS capacity of up to 128 TB. If
    you’re using more than 128 terabytes (TB) of managed storage, you can’t downgrade
    to less than 32 RPU.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 配置为 8 或 16 RPU 支持最多 128 TB 的 Amazon RMS 容量。如果您使用的托管存储超过 128 TB，则无法降级到少于 32 RPU。
- en: Sample Data
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例数据
- en: Once you have Amazon Redshift up and running, whether you’re using serverless
    or provisioned, you can start creating the data models required to build your
    data warehouse solution.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您启动了 Amazon Redshift，无论是使用无服务器还是预配，您可以开始创建所需的数据模型，以构建数据仓库解决方案。
- en: 'When you create an Amazon Redshift serverless data warehouse, three sample
    datasets are available for you to start interacting with. The first dataset, `tickit`,
    consists of seven tables: two fact tables and five dimensions, as shown in [Figure 2-8](#tickit_sample_datamodel).
    This sample database application helps analysts track sales activity for the fictional
    Tickit website, where users buy and sell tickets online for sporting events, shows,
    and concerts. In particular, analysts can identify ticket movement over time,
    success rates for sellers, and the best-selling events, venues, and seasons. Analysts
    can use this information to provide incentives to buyers and sellers who frequent
    the site, attract new users, and drive advertising and promotions.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当您创建 Amazon Redshift 无服务器数据仓库时，您可以开始与三个示例数据集互动。第一个数据集 `tickit` 包含七张表：两个事实表和五个维度，如
    [图 2-8](#tickit_sample_datamodel) 所示。这个示例数据库应用帮助分析人员跟踪虚构的 Tickit 网站上的销售活动，用户在此购买和出售体育赛事、演出和音乐会的门票。特别是，分析人员可以识别随时间变化的票务流动情况，卖家的成功率，以及最畅销的事件、场馆和季节。分析人员可以利用这些信息来激励经常访问该网站的买家和卖家，吸引新用户，并推动广告和促销活动。
- en: '![Tickit sample data model](assets/ardg_0208.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![Tickit 示例数据模型](assets/ardg_0208.png)'
- en: Figure 2-8\. Tickit sample data model
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-8\. Tickit 示例数据模型
- en: Activate Sample Data Models and Query Using the Query Editor
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 激活示例数据模型并使用查询编辑器进行查询
- en: You can use the Amazon Redshift Query Editor V2 to activate the sample datasets
    and start querying. See [“Querying a Database Using the Query Editor V2”](#using_qev2)
    for more details on how to get started using the Query Editor V2\. Once authenticated,
    expand the `sample_data_dev` database. Then click on the folder icon next to each
    schema to open sample notebooks ([Figure 2-9](#activate_sample_data)). This will
    create the sample data model tables, data, and the queries relevant to the sample
    data models. Query Editor V2 supports a notebook as well as an editor interface.
    When you activate the dataset, the sample queries will also be opened in the notebook
    interface, and you can query the data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用亚马逊 Redshift 查询编辑器 V2 来激活示例数据集并开始查询。有关如何开始使用查询编辑器 V2 的详细信息，请参阅“使用查询编辑器
    V2 查询数据库”。认证后，展开 `sample_data_dev` 数据库。然后点击每个模式名称旁边的文件夹图标以打开示例笔记本（参见 [Figure 2-9](#activate_sample_data)）。这将创建示例数据模型表、数据和与示例数据模型相关的查询。查询编辑器
    V2 支持笔记本和编辑器界面。激活数据集后，示例查询也将在笔记本界面中打开，您可以查询数据。
- en: '![Start querying tickit dataset](assets/ardg_0209.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![开始查询 tickit 数据集](assets/ardg_0209.png)'
- en: Figure 2-9\. Query `tickit` sample dataset
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-9\. 查询 `tickit` 示例数据集
- en: Once you activate the sample dataset, you can start querying the data. From
    the queries provided in the notebook, try the following sample queries using the
    `tickit` data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦激活示例数据集，您可以开始查询数据。从笔记本提供的查询中，尝试使用 `tickit` 数据的以下示例查询。
- en: The first query ([Example 2-1](#query_sample1)) finds the total sales revenue
    per event.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个查询 ([Example 2-1](#query_sample1)) 查找每个事件的总销售收入。
- en: Example 2-1\. Total sales revenue per event
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-1\. 每个事件的总销售收入
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The second query ([Example 2-2](#query_sample2)) retrieves total sales quantity
    for a date.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个查询 ([Example 2-2](#query_sample2)) 检索特定日期的总销售数量。
- en: Example 2-2\. Total sales quantity for a date
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-2\. 特定日期的总销售数量
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can also open the query editor interface by clicking the + button and choosing
    the “Editor” menu option (see [Figure 2-10](#query_sample_data_editor)).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以通过点击 + 按钮并选择“编辑器”菜单选项来打开查询编辑器界面（参见 [Figure 2-10](#query_sample_data_editor)）。
- en: '![Query tickit sample dataset in Editor mode](assets/ardg_0210.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![在编辑器模式下查询 tickit 示例数据集](assets/ardg_0210.png)'
- en: Figure 2-10\. Query `tickit` sample dataset in editor mode
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-10\. 在编辑器模式下查询 `tickit` 示例数据集
- en: Try entering the following queries in the editor and run it to see the result.
    This query ([Example 2-3](#query_sample3)) retrieves total sales quantity for
    the top 10 buyers.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试在编辑器中输入以下查询并运行以查看结果。这个查询 ([Example 2-3](#query_sample3)) 检索前十个买家的总销售数量。
- en: Example 2-3\. Total sales quantity for top 10 buyers
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-3\. 前十大买家的总销售数量
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This query ([Example 2-4](#query_sample4)) finds events in the 99.9 percentile
    in terms of all time gross sales.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询 ([Example 2-4](#query_sample4)) 查找在所有时间总销售中位于99.9百分位数的事件。
- en: Example 2-4\. Events in the 99.9% of sales
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 2-4\. 销售额的99.9%事件
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The other two datasets are `tpch`, and `tpcds`, which are standard benchmark
    datasets from [tpc.org](https://www.tpc.org). The [TPC-H](https://www.tpc.org/tpch)
    and [TPC-DS](https://www.tpc.org/tpcds) datasets are decision support benchmarks.
    These consist of a suite of business-oriented ad hoc queries and concurrent data
    modifications. The queries and the data populating the database have been chosen
    to have broad industry-wide relevance. The benchmark provides a representative
    evaluation of performance as a general-purpose decision support system.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两个数据集是 `tpch` 和 `tpcds`，这些都是来自 [tpc.org](https://www.tpc.org) 的标准基准数据集。[TPC-H](https://www.tpc.org/tpch)
    和 [TPC-DS](https://www.tpc.org/tpcds) 数据集是决策支持基准测试。这些包括一套面向业务的即席查询和并发数据修改。所选的查询和数据库中的数据具有广泛的行业相关性。这些基准测试提供了作为通用决策支持系统性能的代表性评估。
- en: These data models are available in the `sample_data_dev` database with respective
    schemas `tpch` and `tpcds`. You can activate these data models and access the
    related objects for each schema by clicking on the folder icon next to the schema
    names as you did earlier for the `tickit` schema. This will open all the queries
    in a notebook interface ([Figure 2-11](#tpch_sample_query_returns_notebook)).
    Now you can try running the sample queries. The first query returns the amount
    of business that was billed, shipped, and returned.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据模型位于 `sample_data_dev` 数据库中，具有各自的 `tpch` 和 `tpcds` 模式。您可以激活这些数据模型，并通过点击模式名称旁边的文件夹图标来访问每个模式的相关对象，就像您之前为
    `tickit` 模式所做的那样。这将在一个笔记本界面中打开所有查询（参见 [Figure 2-11](#tpch_sample_query_returns_notebook)）。现在您可以尝试运行示例查询。第一个查询返回已开票、已发货和已退货的业务金额。
- en: '![Try sample queries on tpch dataset](assets/ardg_0211.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![在 tpch 数据集上尝试示例查询](assets/ardg_0211.png)'
- en: Figure 2-11\. Query `tpch` sample dataset
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-11\. 查询 `tpch` 样本数据集
- en: When to Use a Provisioned Cluster?
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用预置集群？
- en: Amazon Redshift provides a second deployment option where you can have additional
    controls over your data warehouse. The key consideration when setting up your
    Amazon Redshift data warehouse is to choose a configuration and architecture that
    is best suited for your workload to give you the the best out-of-the-box performance.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 提供了第二种部署选项，您可以对数据仓库具有更多控制。设置亚马逊 Redshift 数据仓库时的关键考虑因素是选择最适合您工作负载的配置和架构，以获得最佳的开箱即用性能。
- en: 'According to an article from Jeff Bezos, the founder of Amazon, from November
    23, 2020:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 根据来自亚马逊创始人杰夫·贝索斯于2020年11月23日的一篇文章：
- en: 'There are two types of decisions. There are decisions that are irreversible
    and highly consequential; we call them one-way doors […​] They need to be made
    slowly and carefully. I often find myself at Amazon acting as the chief slowdown
    officer: “Whoa, I want to see that decision analyzed seventeen more ways because
    it’s highly consequential and irreversible.” The problem is that most decisions
    aren’t like that. Most decisions are two-way doors.'
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有两种类型的决策。有些决策是不可逆转且影响深远的；我们称之为单向门 […​] 它们需要慢慢和仔细地作出。在亚马逊，我经常扮演首席减速官的角色：“哇，我想看到这个决策再分析十七种方式，因为它具有高度重大且不可逆的影响。”
    问题在于大多数决策不是这样的。大多数决策是双向门。
- en: As mentioned by Bezos, choosing between serverless and provisioned is a two-way
    door decision, and even if you do not choose the optimal configuration, because
    Amazon Redshift is a pay-as-you-go cloud-based solution, capacity can be added
    or removed in minutes. The design of your analytics architecture can and should
    be based on quick experimentation and validation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 正如贝索斯所述，选择无服务器和预置之间是一个双向门决策，即使您没有选择最佳配置，因为亚马逊 Redshift 是按使用付费的云解决方案，可以在几分钟内增加或删除容量。您的分析架构设计应基于快速实验和验证。
- en: A provisioned cluster provides capabilities to fine-tune your data warehouse.
    With a provisioned cluster you are in control of when and how you resize your
    cluster, have the ability to manually configure workload management, and determine
    when you pause/resume your data warehouse. While a provisioned cluster may require
    more management, it provides more options to tune predicable workloads and optimize
    for costs. If you have a very consistent and constant workload, leveraging a provisioned
    cluster and purchasing reserved instances can be a more cost-optimized option.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 预置集群提供了调整数据仓库性能的能力。使用预置集群，您可以控制何时以及如何调整集群大小，有能力手动配置工作负载管理，并确定何时暂停/恢复数据仓库。虽然预置集群可能需要更多的管理，但它提供了更多调整可预见工作负载和优化成本的选项。如果您有非常一致和恒定的工作负载，利用预置集群和购买预留实例可能是更为成本优化的选择。
- en: When designing the architecture of your production data warehouse, you have
    many options. You will want to decide if it makes sense to run your workload in
    one Amazon Redshift data warehouse or split/isolate your workload in multiple
    Amazon Redshift data warehouses. You will also want to decide for the one or many
    data warehouses if it makes sense to use provisioned or serverless. In the following
    example, two different strategies are illustrated to support the same workload
    ([Figure 2-12](#redshift_deployment_options)).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计生产数据仓库的架构时，您有许多选择。您需要决定是否有意义在一个亚马逊 Redshift 数据仓库中运行工作负载，还是将工作负载拆分/隔离到多个亚马逊
    Redshift 数据仓库中。您还需要决定在一个或多个数据仓库中使用预置还是无服务器是否有意义。在下面的示例中，展示了支持相同工作负载的两种不同策略（[图2-12](#redshift_deployment_options)）。
- en: '![Redshift Deployment Options](assets/ardg_0212.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![Redshift 部署选项](assets/ardg_0212.png)'
- en: Figure 2-12\. Amazon Redshift deployment options
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-12\. 亚马逊 Redshift 部署选项
- en: In [Chapter 1, “AWS for Data”](ch01.html#AR_TGD_CH1), you learned how a modern
    data architecture encourages distributed teams to own and architect their domain-oriented
    solution independently. In the following Amazon Redshift data mesh architecture
    ([Figure 2-13](#redshift_datamesh_serverless)), you can see an architecture that
    takes advantage of both a provisioned data warehouse and multiple serverless data
    warehouses. In this environment, you use a provisioned data warehouse (1) for
    data ingestion from multiple sources because the workload profile is consistent
    and runs during a large portion of the day. You can purchase reserved instances
    and have full control over predictable costs. In addition, you set up a serverless
    data warehouse (2), which can read from the data in the provisioned data warehouse
    using data sharing. Users in this serverless data warehouse read from the shared
    data as well and curate new datasets by loading their own data, joining to the
    shared data and aggregating data as needed. The users of this serverless data
    warehouse become the shepherds of data specific to their domain or department.
    Any data outside of their domain is accessible, but they are not dependent on
    that organization’s processing needs. Finally, you set up another serverless data
    warehouse (3), which also reads from the provisioned data warehouse the curated
    datasets from the other serverless data warehouse (2) using data sharing. Each
    of these workloads have different profiles in terms of how much compute they need,
    when they run, and how long they need to be active.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章“用于数据的AWS”](ch01.html#AR_TGD_CH1)中，您学习了现代数据架构如何鼓励分布式团队独立拥有和设计其面向领域的解决方案。在以下的亚马逊Redshift数据网格架构（[图2-13](#redshift_datamesh_serverless)）中，您可以看到一种既利用了配置的数据仓库，又利用了多个无服务器数据仓库的架构。在这种环境中，您使用配置的数据仓库（1）从多个来源进行数据摄取，因为工作负载配置是一致的，并且在大部分时间内运行。您可以购买预留实例，并完全控制可预测的成本。此外，您设置了一个无服务器数据仓库（2），它可以使用数据共享从配置的数据仓库中读取数据。此服务器无服务器数据仓库的用户也从共享数据中读取数据，并通过加载自己的数据、连接到共享数据并根据需要聚合数据来整理新的数据集。这些无服务器数据仓库的用户成为其领域或部门特定数据的管理者。他们可以访问其领域之外的任何数据，但不依赖于该组织的处理需求。最后，您设置了另一个无服务器数据仓库（3），它也使用数据共享从配置的数据仓库中读取来自另一个无服务器数据仓库（2）的整理数据集。这些工作负载在计算需求、运行时间以及活动时间长度等方面各不相同。
- en: '![Redshift Data Mesh Architecture](assets/ardg_0213.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![Redshift数据网格架构](assets/ardg_0213.png)'
- en: Figure 2-13\. Redshift data mesh architecture
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-13\. Redshift数据网格架构
- en: Regardless of the deployment option you choose, to switch from one to the other
    you can use the snapshot/restore processs. For more details on how to restore
    a snapshot from a provisioned cluster to serverless data warehouse, see the [online
    documentation](https://oreil.ly/a66BT).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您选择哪种部署选项，都可以使用快照/恢复过程切换。有关如何将快照从配置的集群恢复到无服务器数据仓库的详细信息，请参阅[在线文档](https://oreil.ly/a66BT)。
- en: Creating an Amazon Redshift Provisioned Cluster
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建Amazon Redshift配置集群
- en: Deploying Amazon Redshift using the provisioned option means you’ll be deploying
    a certain number of compute nodes of a certain node type, forming a cluster. To
    deploy an Amazon Redshift provisioned cluster, navigate to the [Create Cluster](https://oreil.ly/2xS0U)
    page and chose your configuration options. You can also follow the steps described
    in the AWS documentation to [create a sample Amazon Redshift cluster](https://oreil.ly/ptbqk).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用配置选项部署Amazon Redshift意味着您将部署特定节点类型的一定数量的计算节点，形成一个集群。要部署Amazon Redshift配置集群，请导航至[创建集群](https://oreil.ly/2xS0U)页面并选择您的配置选项。您还可以按照AWS文档中描述的步骤来[创建样例Amazon
    Redshift集群](https://oreil.ly/ptbqk)。
- en: In the first section, you will be choosing the cluster name and size ([Figure 2-14](#cluster_name_size)).
    For more details on determining the best cluster size for your use case, see [“Amazon
    Redshift Provisioned Compute Cost”](#provisioned_size_estimate).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一部分中，您将选择集群名称和大小（[图2-14](#cluster_name_size)）。有关确定适用于您用例的最佳集群大小的详细信息，请参阅[“Amazon
    Redshift配置计算成本”](#provisioned_size_estimate)。
- en: '![Cluster Name and Size](assets/ardg_0214.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![集群名称和大小](assets/ardg_0214.png)'
- en: Figure 2-14\. Cluster name and size
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-14\. 集群名称和大小
- en: Next, you will decide if you want to load sample data (optional) and set admin
    credentials ([Figure 2-15](#cluster_data_creds)).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将决定是否加载样例数据（可选）并设置管理员凭据（[图2-15](#cluster_data_creds)）。
- en: '![Cluster Load Sample Data and Set Admin Credentials](assets/ardg_0215.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![集群载入示例数据并设置管理员凭证](assets/ardg_0215.png)'
- en: Figure 2-15\. Load sample data and set admin credentials
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-15\. 载入示例数据并设置管理员凭证
- en: Next, specify the cluster permissions ([Figure 2-16](#cluster_permissions))
    by assigning IAM roles that your Amazon Redshift cluster can assume to access
    other resources within your AWS environment. These permissions are required if
    you intend to perform actions like bulk loading data from Amazon S3 into Amazon
    Redshift. A managed policy, `AmazonRedshiftAllCommandsFullAccess`, is available
    to associate to your role containing the common services you may use. In the next
    example, we created an IAM role `RedshiftRole`, assigned it the `AmazonRedshiftAllCommandsFullAccess`
    policy, and made it the `default`. For more details on authorizing Amazon Redshift
    to access other Amazon services on your behalf, see the [online documentation](https://oreil.ly/zjIDn).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，指定集群权限（[图 2-16](#cluster_permissions)）通过为您的亚马逊 Redshift 集群分配 IAM 角色，以访问
    AWS 环境中的其他资源。如果您打算执行诸如从 Amazon S3 批量加载数据到 Amazon Redshift 的操作，则需要这些权限。提供了一个名为
    `AmazonRedshiftAllCommandsFullAccess` 的托管策略，可用于关联到包含您可能使用的常见服务的角色。在下一个示例中，我们创建了一个
    IAM 角色 `RedshiftRole`，分配了 `AmazonRedshiftAllCommandsFullAccess` 策略，并将其设为默认角色。有关授权亚马逊
    Redshift 代表您访问其他亚马逊服务的更多详细信息，请参阅[在线文档](https://oreil.ly/zjIDn)。
- en: '![Cluster Permissions](assets/ardg_0216.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![集群权限](assets/ardg_0216.png)'
- en: Figure 2-16\. Cluster permissions
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-16\. 集群权限
- en: Lastly, set up the cluster additional configurations ([Figure 2-17](#cluster_configurations)).
    These determine where your cluster will be deployed in the context of your network
    configuration. By default, the cluster will be deployed in the default VPC, subnets,
    and security group. You can use the default settings or customize each one. For
    a more detailed discussion on considerations on network configuration, see [“Private/Public
    VPC and Secure Access”](#network_configuration).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，设置集群的附加配置（[图 2-17](#cluster_configurations)）。这些配置决定了您的集群将在您网络配置的上下文中部署的位置。默认情况下，集群将部署在默认的
    VPC、子网和安全组中。您可以使用默认设置或自定义每个设置。有关网络配置考虑事项的详细讨论，请参阅[“私有/公共 VPC 和安全访问”](#network_configuration)。
- en: '![Cluster Additional Configurations](assets/ardg_0217.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![集群附加配置](assets/ardg_0217.png)'
- en: Figure 2-17\. Cluster additional configurations
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-17\. 集群附加配置
- en: From the [Redshift Clusters](https://oreil.ly/Sgl51) page, you can see your
    cluster list ([Figure 2-18](#cluster_list)). Clicking on the cluster, you get
    to general information such as the cluster endpoint and JDBC and ODBC URL. For
    options to connect to your cluster, see [“Connecting to Your Amazon Redshift Data
    Warehouse”](#connecting).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[Redshift 集群](https://oreil.ly/Sgl51)页面查看您的集群列表（[图 2-18](#cluster_list)）。单击集群，您可以获取一般信息，如集群终端节点以及
    JDBC 和 ODBC URL。有关连接到集群的选项，请参阅[“连接到您的亚马逊 Redshift 数据仓库”](#connecting)。
- en: '![Cluster List](assets/ardg_0218.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![集群列表](assets/ardg_0218.png)'
- en: Figure 2-18\. Cluster list
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-18\. 集群列表
- en: Estimate Your Amazon Redshift Cost
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估算您的亚马逊 Redshift 成本
- en: When estimating the cost of Amazon Redshift, the two main factors to consider
    are storage and compute. For the case of the RA3 node type and serverless, you
    must consider the managed storage separate from the serverless compute cost or
    the provisioned compute cost. If, however, you are using the DC2 node type, you
    need to consider only the provisioned compute cost, as all storage is local to
    the compute nodes.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当估算亚马逊 Redshift 的成本时，需要考虑的两个主要因素是存储和计算。对于 RA3 节点类型和无服务器的情况，您必须单独考虑托管存储成本，而不是无服务器计算成本或预置计算成本。然而，如果您使用
    DC2 节点类型，则只需考虑预置计算成本，因为所有存储都是局部存储在计算节点上。
- en: Amazon Redshift Managed Storage
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 托管存储
- en: 'Amazon RMS is a compressed and columnar formatted data structure designed for
    optimal performance on analytics workloads. The storage is separated from the
    compute and is elastic in nature. You can scale from TB to PB of data. It can
    be shared between Amazon Redshift data warehouses whether they are RA3 provisioned
    or serverless. The shared data is available to consumers even if the Amazon Redshift
    data warehouse is not active. For example, if the primary owner of the data is
    a provisioned cluster, a consumer can access that data even if the provisioned
    cluster is paused. This functionality allows you to choose the appropriate compute
    for the workload without needing to move or transform the data. It also ensures
    the data is not duplicated, reducing maintenance and storage costs. Because you
    can easily move between different compute options and the storage is available
    even if the compute is not running, storage is priced independently. To estimate
    the cost of your storage when using an RA3 cluster or a serverless data warehouse,
    you can estimate the compressed storage needs multiplied by the storage prices
    per month. For example, let’s say your storage usage is 10 TB. Based on the pricing
    of $0.024/GB month, your charge for storage would be $240:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon RMS是一种压缩且列格式化的数据结构，专为分析工作负载的最佳性能而设计。存储与计算分离，并且具有弹性。您可以将数据从TB扩展到PB。无论Amazon
    Redshift数据仓库是RA3预配还是无服务器，它都可以共享。即使Amazon Redshift数据仓库处于非活动状态，共享数据也对消费者可用。例如，如果数据的主要所有者是预配集群，则消费者可以访问该数据，即使预配集群暂停。此功能使您可以选择适合工作负载的计算而无需移动或转换数据。它还确保数据不会重复，从而减少维护和存储成本。由于您可以轻松地在不同的计算选项之间移动，并且即使计算未运行，存储也可用，因此存储的定价是独立的。要估算使用RA3集群或无服务器数据仓库时的存储成本，您可以估算压缩存储需求乘以每月的存储价格。例如，假设您的存储使用量为10
    TB。基于每GB每月$0.024的定价，您的存储费用将为$240：
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: For the most up-to-date details on Amazon Redshift Managed Storage pricing,
    see the [online documentation](https://oreil.ly/QsZE6).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 获取关于亚马逊Redshift托管存储定价的最新详细信息，请参阅[在线文档](https://oreil.ly/QsZE6)。
- en: Amazon Redshift Serverless Compute Cost
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊Redshift无服务器计算成本
- en: 'For Amazon Redshift serverless, in addition to the RMS cost, there is one other
    key cost to consider: the compute. To facilitate Amazon Redshift billing, a unit
    of measurement called RPU was created ([Figure 2-19](#redshift_serverless_rpu))
    and represents the compute capacity that is used in a given time period. When
    you set up your workgroup, it is configured with a base capacity of 128 RPUs.
    This base is used when Amazon Redshift serverless wakes up from an idle state
    and will scale up when more compute is needed. You can modify the base capacity
    for your workgroup by editing the Amazon Redshift serverless configuration and
    modifying the `Limits`.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于亚马逊Redshift无服务器，除了RMS成本外，还有一个关键成本需要考虑：计算成本。为了便于亚马逊Redshift计费，创建了一种称为RPU的计量单位（[图2-19](#redshift_serverless_rpu)），表示在给定时间段内使用的计算能力。设置工作组时，会配置128个RPUs的基础容量。当亚马逊Redshift无服务器从空闲状态唤醒并需要更多计算时，将会扩展此基础。您可以通过编辑亚马逊Redshift无服务器配置并修改`Limits`来修改工作组的基础容量。
- en: '![Amazon Redshift serverless base capacity](assets/ardg_0219.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![亚马逊Redshift无服务器基础容量](assets/ardg_0219.png)'
- en: Figure 2-19\. Amazon Redshift serverless base capacity
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-19\. 亚马逊Redshift无服务器基础容量
- en: 'Each query is logged in the system, and you are charged only for the time period
    the serverless workgroup is running queries (with a 60-second minimum charge for
    transactions). For example, let’s say you’ve used the default of 128 RPUs and
    within the hour you submit only 1 query, which runs for 90 seconds. Based on the
    us-west-2 pricing of $0.45/RPU hour, your charge for that query would be $1.44:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 每个查询都会在系统中记录，只有在服务器无服务器工作组运行查询的时间段内才会收费（交易的最低计费时间为60秒）。例如，假设您使用了默认的128 RPUs，并且在一个小时内只提交了1个运行90秒的查询。根据us-west-2地区的定价$0.45/RPU小时，您的查询费用将为$1.44：
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s say this was actually a scheduled dashboard that triggers the execution
    of 3 simultaneous queries (15s, 30s, and 90s), the longest of which completes
    in 90 seconds. Let’s also assume this is the only workload on the workgroup for
    the hour. You would still be charged only $1.44 because the workgroup was only
    up for those 90 seconds and the serverless workgroup was able to finish the job
    using the base capacity of 128 RPUs:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这实际上是一个按计划触发执行3个同时查询（15秒、30秒和90秒）的仪表板，其中最长的查询在90秒内完成。还假设这是该小时工作组的唯一工作负载。您仍将仅收取$1.44，因为工作组仅在这90秒内运行，而无服务器工作组能够使用128
    RPUs的基本容量完成作业：
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Setting a different value for the base capacity
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置不同的基本容量值
- en: 'Let’s say instead of 128 RPUs, you configure the workgroup to have the base
    capacity of 8 RPUs or 1/16 the compute. In all likelihood, that workload that
    completed in 90 seconds will take 16 times as long (1440 seconds) and the price
    would still be $1.44:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您配置工作组的基本容量为8 RPUs或1/16的计算能力而不是128 RPUs。很可能，90秒完成的工作量将需要长达16倍的时间（1440秒），但价格仍将为$1.44：
- en: '[PRE7]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With a small base capacity configuration like 8 RPUs, workloads may take longer
    than 1440 seconds if the query uses a lot of memory because less will be available
    and you will have paging to disk. However, in some cases, the workload may take
    less time because the original 90 seconds may have contained overhead that doesn’t
    need to be extrapolated.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果像8 RPUs这样的小基本容量配置，如果查询使用了大量内存，工作负载可能会比1440秒更长，因为可用内存更少，您将进行磁盘分页。但是，在某些情况下，工作负载可能需要的时间较短，因为原始90秒可能包含了不需要推算的开销。
- en: Another consideration on choosing the base capacity is the minimum charge of
    60 seconds. If you have a lot of queries that are less than 60 seconds and you
    have idle time between queries, the charge per query will be less on a smaller
    base capacity configuration.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择基本容量时的另一个考虑因素是最低收费60秒。如果您有很多少于60秒的查询，并且在查询之间有空闲时间，则较小的基本容量配置上的每个查询费用将较低。
- en: 'In the following example, let’s say you have a query that runs in 1 second
    on a 128 RPU base capacity configuration and 16 seconds on a 8 RPU base capacity
    configuration. If that is the only query run in the minute, they will each be
    subject to their respective minimum charge, resulting in 16 times difference in
    price:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，假设您有一个查询，在128 RPU基本容量配置上运行1秒钟，在8 RPU基本容量配置上运行16秒钟。如果这是该分钟内唯一运行的查询，则它们各自将按其各自的最低收费标准收费，导致价格相差16倍：
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: High/frequent usage
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高/频繁使用
- en: In another example, let’s say you have a streaming application that loads into
    your data warehouse at one minute intervals but the loads take only 5 seconds
    each ([Figure 2-20](#streaming_usage)). Because each transaction on the serverless
    workgroup is billed with a minimum of 60 seconds, even though each query finishes
    in 5 seconds, each is billed based on the 60 second minimum.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个例子中，假设您有一个流媒体应用程序，每分钟加载到您的数据仓库，但每个加载只需5秒钟（[图2-20](#streaming_usage)）。因为无服务器工作组上的每个事务都按照最低60秒计费，即使每个查询只需5秒完成，也将基于60秒的最低收费计费。
- en: '![Streaming Usage Timeline](assets/ardg_0220.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![流媒体使用时间轴](assets/ardg_0220.png)'
- en: Figure 2-20\. Streaming usage timeline
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-20\. 流媒体使用时间轴
- en: 'In this example, while the total query execution time was `5*60=300` seconds,
    the billed usage will be `60*60=3600` seconds when the 60 second minimum charge
    is applied. Based on the us-west-2 pricing of $0.45/RPU hour, your charge for
    this workload would be $57.60:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，虽然总的查询执行时间是`5*60=300`秒，但应用了60秒的最低收费时，计费使用时间为`60*60=3600`秒。基于us-west-2地区的价格为$0.45/RPU小时，您的这个工作负载的费用将为$57.60：
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In each of these cases, it’s a good idea to experiment on a base capacity configuration
    that meets your query service level agreements (SLAs) and budget requirements,
    keeping in mind that you are being charged only for the compute you are using.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况中，建议在满足查询服务水平协议（SLAs）和预算要求的基本容量配置上进行实验，记住您只需支付您使用的计算费用。
- en: For the most up-to-date details on Amazon Redshift pricing, including how much
    you can save with reserved capacity, see the [online documentation](https://oreil.ly/9kwzy).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Amazon Redshift定价的最新详细信息，包括使用预留容量可以节省多少费用，请查看[在线文档](https://oreil.ly/9kwzy)。
- en: Amazon Redshift Provisioned Compute Cost
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Redshift预留计算成本
- en: For an RA3 provisioned cluster, in addition to the storage cost, the key additional
    cost comes from the cluster size. The first step in planning your provisioned
    data warehouse is to determine the node type and the number of nodes you will
    need. When determining the size of your Amazon Redshift provisioned cluster, consider
    the steady-state compute that will satisfy the performance SLAs of your analytical
    processing needs. Each type of node is defined by a compute profile and gets progressively
    larger and more expensive so you can choose the node type and number of nodes
    best suited to meet your needs. The following table ([Table 2-1](#ra3_node_types))
    summarizes the allocated resources for each node for each node type as of 2023\.
    You can get the latest compute profiles and read more about the different node
    types in the [online documentation](https://oreil.ly/hDesT).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于RA3预留集群，除了存储成本外，主要额外成本来自集群大小。规划预留数据仓库的第一步是确定节点类型和您所需的节点数。在确定Amazon Redshift预留集群大小时，请考虑能够满足您分析处理需求性能SLA的稳态计算。每种节点类型由一个计算配置文件定义，并且随着节点类型的选择越来越大和更昂贵，您可以选择最适合满足您需求的节点类型和节点数量。下表（[表 2-1](#ra3_node_types)）总结了每种节点类型的分配资源，截至2023年。您可以获取最新的计算配置文件，并在[在线文档](https://oreil.ly/hDesT)中了解更多有关不同节点类型的信息。
- en: Table 2-1\. RA3 node types
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2-1\. RA3节点类型
- en: '| Node type | RMS | Memory | vCPUs |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 节点类型 | RMS | 内存 | vCPU |'
- en: '| --- | --- | --- | --- |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| ra3.xlplus | 32 TB | 32 GB | 4 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| ra3.xlplus | 32 TB | 32 GB | 4 |'
- en: '| ra3.4xlarge | 128 TB | 96 GB | 12 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| ra3.4xlarge | 128 TB | 96 GB | 12 |'
- en: '| ra3.16xlarge | 128 TB | 384 GB | 48 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| ra3.16xlarge | 128 TB | 384 GB | 48 |'
- en: When determining the node size and the number of nodes needed in your cluster,
    consider your processing needs. Start with the largest node size and consider
    the smaller node sizes when you are exceeding your performance SLAs. This strategy
    helps reduce network traffic when data shuffles between the nodes. For example,
    2 nodes of the ra3.16xl is equivalent to 8 nodes of the ra3.4xlarge and 24 nodes
    of the ra3.xlplus node types in terms of vCPU and memory. If you start with the
    ra3.16xlarge node type and find that you are far exceeding your performance SLAs
    and your cluster CPU utilization is low, you can can resize your cluster to a
    smaller node type by leveraging the resize option. For more information on the
    resize option, see the [online documentation](https://oreil.ly/sRQdC).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定集群中需要的节点大小和节点数时，请考虑您的处理需求。从最大的节点大小开始，当您超出性能SLA时考虑更小的节点大小。这种策略有助于减少节点之间数据洗牌时的网络流量。例如，ra3.16xl的2个节点在vCPU和内存方面等效于ra3.4xlarge的8个节点和ra3.xlplus节点类型的24个节点。如果您从ra3.16xlarge节点类型开始，并发现您远远超过了性能SLA，并且集群CPU利用率低，您可以利用调整选项将集群调整为较小的节点类型。有关调整选项的更多信息，请参阅[在线文档](https://oreil.ly/sRQdC)。
- en: If you have not run your workload yet and need an initial cluster size, the
    Amazon Redshift console provides a tool ([Figure 2-21](#redshift_provisioned_helpmechoose))
    to help you choose the size of your cluster taking into consideration parameters
    such as the amount of storage needed as well as your workload.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您尚未运行工作负载并需要初始集群大小，则Amazon Redshift控制台提供了一个工具（[图 2-21](#redshift_provisioned_helpmechoose)），帮助您选择集群大小，考虑参数如所需存储量及工作负载。
- en: '![Help me choose](assets/ardg_0221.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![帮助我选择](assets/ardg_0221.png)'
- en: Figure 2-21\. Help me choose
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-21\. 帮助我选择
- en: A key aspect of Amazon Redshift pricing for a provisioned cluster is that it
    can either be billed on-demand, or you can purchase reserved instances, which
    give you a fixed cost and a deep discount. In the Help Me Choose tool, a summary
    of the cost for the compute is given ([Figure 2-22](#redshift_provisioned_choosesummary)).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift提供的预留集群的关键方面是，可以按需计费，也可以购买预留实例，这样您就可以获得固定成本和深度折扣。在“帮助我选择”工具中，提供了计算成本摘要（[图 2-22](#redshift_provisioned_choosesummary)）。
- en: You receive a 33% discount committing to a 1-year reservation and a 61% discount
    when committing to a 3-year reservation.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 承诺1年预订可获得33%的折扣，承诺3年预订可获得61%的折扣。
- en: '![Sample cost estimate](assets/ardg_0222.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![样本成本估算](assets/ardg_0222.png)'
- en: Figure 2-22\. Sample cost estimate
  id: totrans-145
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-22\. 样本成本估算
- en: For an Amazon Redshift provisioned cluster, there are a few features that will
    result in an additional variable cost which, in contrast, are bundled as RPUs
    in Amazon Redshift serverless. First is a feature called *Concurrency Scaling*,
    which causes your data warehouse to automatically provision transient clusters
    during periods of bursty activity. Second is a feature called *Amazon Redshift
    Spectrum*, which leverages a separate fleet of compute to query data in your Amazon
    S3 data lake. In [Chapter 5, “Scaling and Performance Optimizations”](ch05.html#AR_TGD_CH5),
    we will discuss Concurrency Scaling in more detail, and in [Chapter 3, “Setting
    Up Your Data Models and Ingesting Data”](ch03.html#AR_TGD_CH3), and [Chapter 4,
    “Data Transformation Strategies”](ch04.html#AR_TGD_CH4), we will discuss how to
    query external data in more detail. We bring them up now to highlight how you
    have the ability to control these features and have a more predictable cost structure.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Amazon Redshift 提供的集群，有一些功能会导致额外的变动成本，相比之下，在 Amazon Redshift 无服务器中作为 RPUs
    打包。首先是名为*并发扩展*的功能，在高峰活动期间，会自动为您的数据仓库提供临时集群。其次是名为*Amazon Redshift Spectrum*的功能，利用一个独立的计算机群来查询
    Amazon S3 数据湖中的数据。在[第 5 章，“扩展和性能优化”](ch05.html#AR_TGD_CH5)中，我们将详细讨论并发扩展，在[第 3
    章，“设置数据模型和数据摄入”](ch03.html#AR_TGD_CH3)和[第 4 章，“数据转换策略”](ch04.html#AR_TGD_CH4)中，我们将详细讨论如何查询外部数据。现在我们提到它们是为了强调您如何能够控制这些功能并拥有更可预测的成本结构。
- en: AWS Account Management
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS 账户管理
- en: You will need an AWS account to launch any of the AWS services, including Amazon
    Redshift. An AWS account is owned by the root user that was used to create the
    account. Once you create your AWS account, you can create additional users using
    the *Identity and Access Management* (IAM) service and allocate permission to
    IAM users. We mention AWS accounts because like any other AWS service you launch,
    for Amazon Redshift you can establish boundaries by launching your data warehouse
    in different accounts; e.g., development versus production (see [Figure 2-23](#control_tower_2_2_5)).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要一个 AWS 账户来启动任何 AWS 服务，包括 Amazon Redshift。AWS 账户由创建该账户的根用户拥有。创建 AWS 账户后，您可以使用*身份和访问管理*（IAM）服务创建额外的用户并分配权限给
    IAM 用户。我们提到 AWS 账户，因为与您启动的任何其他 AWS 服务一样，对于 Amazon Redshift，您可以通过在不同的账户中启动数据仓库来设立边界，例如开发与生产（见[图
    2-23](#control_tower_2_2_5)）。
- en: '![AWS Control Tower, AWS Organizations and AWS Accounts](assets/ardg_0223.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![AWS 控制塔，AWS 组织和 AWS 账户](assets/ardg_0223.png)'
- en: Figure 2-23\. AWS Control Tower, AWS Organizations, and AWS accounts
  id: totrans-150
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-23\. AWS 控制塔，AWS 组织和 AWS 账户
- en: AWS Organizations helps you collectively manage multiple AWS accounts, allocate
    resources, group accounts into organizational units (OUs), apply governance and
    security policies on OUs, and simplify billing for your organization by designating
    a management account for taking advantage of quantity discounts with a single
    bill. Other AWS accounts are member accounts.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 组织（[AWS Organizations](https://oreil.ly/tvrqD)）帮助您集体管理多个 AWS 账户，分配资源，将账户分组为组织单位（OUs），在这些单位上应用治理和安全策略，并通过指定一个管理账户简化您的组织计费，以便利用单一账单的数量折扣。其他
    AWS 账户是成员账户。
- en: Having a designated security OU with an isolated account for audit will allow
    your security team to quickly review all accesses across your entire organization.
    A separate logging account will allow you to centralize all log files, and troubleshooting
    end-to-end application problems is easy when you can correlate all your data together.
    Refer to [“Set up a multi-account AWS environment using best practices for AWS
    Organizations”](https://oreil.ly/tvrqD) for a short video.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设置一个指定的安全 OU，并为审计单独设置一个隔离账户，将使您的安全团队能够快速审核整个组织中的所有访问。单独的日志记录账户将允许您集中所有日志文件，当您能够将所有数据关联在一起时，可以轻松地排除端到端应用程序问题。请参阅[“使用
    AWS 组织的最佳实践设置多账户 AWS 环境”](https://oreil.ly/tvrqD)观看短视频。
- en: Instead of designing your AWS Organizations and AWS accounts manually, you can
    leverage the AWS Control Tower service. The AWS Control Tower is a separate service
    that provides a prescriptive experience that automatically sets up your AWS Organizations
    and AWS accounts based on best-practice blueprints. It also uses prepackaged service
    control policies (SCP) and governance rules for security, operations, and compliance.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 不必手动设计 AWS 组织和 AWS 账户，您可以利用 AWS 控制塔服务。AWS 控制塔是一个独立的服务，提供预设体验，根据最佳实践蓝图自动设置您的
    AWS 组织和 AWS 账户。它还使用预打包的服务控制策略（SCP）和治理规则，用于安全、运营和合规性。
- en: You can use AWS Control Tower irrespective of whether you are starting new on
    AWS or have an existing multiaccount AWS environment. AWS Control Tower automates
    the setup of landings zone for the external files to be brought into your analytics
    environment, applies guardrails for ongoing governance, automates provisioning
    workflow, and also provides prepackaged dashboards for visibility across your
    OU, accounts, and guardrails. For more details, here’s a short YouTube video,
    [“What Is AWS Control Tower?”](https://oreil.ly/7zyKO).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是在AWS上全新启动还是已有现有的多账户AWS环境，都可以使用AWS Control Tower。AWS Control Tower自动设置着陆区，以便将外部文件引入到您的分析环境中，为持续治理应用保护栏杆，自动化供应工作流程，并为OU、账户和保护栏杆提供预打包仪表板以实现可见性。有关更多详情，请参阅短视频[“什么是AWS
    Control Tower？”](https://oreil.ly/7zyKO)。
- en: Connecting to Your Amazon Redshift Data Warehouse
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接到您的亚马逊Redshift数据仓库
- en: Once you’ve determined your deployment architecture, the next question you should
    ask yourself is how to control access to your data to meet your security requirements.
    The inherent challenge IT organizations face today is to ensure that access to
    your data platform is secure while also flexible and easy to manage. Administrators
    need the ability to provision access and tooling for everyone who needs access,
    but do so in a way that is in line with corporate policies and accessible via
    approved network pathways. Depending on the number of users you need to manage
    and whether you have existing infrastructure in place for user administration,
    authentication, and authorization, you may choose one strategy over another. Once
    connected, the identity of the user is stored within the Amazon Redshift metadata.
    That identity can be assigned to one or more groups, and roles for authorization
    and activity by that user will be logged for traceability. Amazon Redshift contains
    different features that enable secure and flexible access, and there are many
    considerations for choosing which options to leverage. In addition, there are
    multiple tools provided by AWS to access your Amazon Redshift data warehouse,
    with multiple options for how to leverage those security features.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了部署架构，接下来您应该问自己的问题是如何控制访问以满足安全需求。今天IT组织面临的固有挑战是确保数据平台的访问既安全又灵活且易于管理。管理员需要能够为所有需要访问的人提供访问和工具，但必须符合公司政策并通过批准的网络途径进行访问。根据您需要管理的用户数量以及是否已有用于用户管理、身份验证和授权的现有基础设施，您可以选择一种策略而非另一种。一旦连接，用户的身份将存储在Amazon
    Redshift元数据中。该身份可以分配给一个或多个组，并且将为该用户的授权和活动记录日志以进行追踪。Amazon Redshift包含不同的功能，可以实现安全和灵活的访问，有许多考虑因素可供选择哪些选项进行利用。此外，AWS提供了多种工具来访问您的Amazon
    Redshift数据仓库，以及如何利用这些安全功能的多种选项。
- en: Private/Public VPC and Secure Access
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 私有/公有VPC和安全访问
- en: Whether you choose serverless or provisioned, Amazon Redshift is always deployed
    within a VPC and subnet. Depending on that choice, the data warehouse can be accessible
    by only internal resources or can be accessible by resources in the public internet.
    For more details on determining the best VPC strategy for your organization, read
    about VPC scenarios in the [online documentation](https://oreil.ly/TKM1N). Furthermore,
    when you connect to an Amazon Redshift data warehouse using tools based on JDBC
    or ODBC drivers, you are connecting via TCP/IP to a specific hostname and port
    number. Like any AWS service that is deployed to a VPC, you can control network
    traffic to Amazon Redshift by customizing inbound rules to the security group
    attached to your data warehouse. For more details on understanding security groups
    and setting inbound rules, see the [online documentation](https://oreil.ly/EArzG).
    Finally, you may have a scenario where Amazon Redshift needs connectivity to an
    AWS service that runs outside your VPC or in another AWS account altogether. For
    these scenarios, a VPC endpoint may be suitable. Learn more about VPC endpoints
    in the [online documentation](https://oreil.ly/Rw5gK).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您选择无服务器或预置，Amazon Redshift 始终部署在 VPC 和子网中。根据这一选择，数据仓库只能由内部资源访问，或者可以由公共互联网上的资源访问。有关为您的组织确定最佳
    VPC 策略的更多详细信息，请阅读[在线文档](https://oreil.ly/TKM1N)中关于 VPC 场景的内容。此外，当您使用基于 JDBC 或
    ODBC 驱动程序的工具连接到 Amazon Redshift 数据仓库时，您是通过 TCP/IP 连接到特定的主机名和端口号。与部署到 VPC 的任何 AWS
    服务一样，您可以通过自定义入站规则来控制到 Amazon Redshift 的网络流量，以适配与您的数据仓库关联的安全组。有关理解安全组和设置入站规则的更多详细信息，请参阅[在线文档](https://oreil.ly/EArzG)。最后，您可能会遇到
    Amazon Redshift 需要连接到运行在您的 VPC 外部或另一个 AWS 帐户中的 AWS 服务的情况。对于这些场景，VPC 端点可能是合适的选择。有关
    VPC 端点的更多信息，请参阅[在线文档](https://oreil.ly/Rw5gK)。
- en: The following sample architecture containing a private subnet with AWS Direct
    Connect ([Figure 2-24](#privatesubnet_directconnect)) is commonly used by enterprise
    users because it contains controls that limit access to people within the corporate
    infrastructure or outside the infrastructure using a VPN service. To ensure a
    high-bandwidth and secure connection to the AWS cloud, the architecture leverages
    AWS Direct Connect. The virtual private gateway ensures that the data transferred
    is secure and encrypted. When set up correctly, resources within the AWS cloud
    such as the Amazon Redshift data warehouse and analytical tools are addressable
    via private IP addresses whether the user is on an internal or external client
    machine.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 包含带有 AWS Direct Connect 的私有子网的以下示例架构（[图 2-24](#privatesubnet_directconnect)）通常由企业用户使用，因为它包含限制只允许企业基础设施内部人员或通过
    VPN 服务外部访问的控制措施。为确保与 AWS 云的高带宽和安全连接，该架构利用 AWS Direct Connect。虚拟私有网关确保传输的数据安全且加密。正确设置后，AWS
    云内的资源（如 Amazon Redshift 数据仓库和分析工具）可通过私有 IP 地址访问，无论用户是否在内部或外部客户端机器上。
- en: Within AWS, Amazon Redshift is deployed in a private subnet, which means it
    does not have direct internet connectivity and any access to the environment would
    have to originate from within the VPC or through the virtual private gateway.
    However, there are some AWS services that do not run within your AWS VPC. A key
    service used for `COPY` and `UNLOAD` commands in Amazon Redshift is the Amazon
    S3 service. To ensure that data transferred from Amazon S3 to Amazon Redshift
    goes through your VPC, the enhanced VPC routing feature is enabled and the private
    subnet is configured with a route table referencing a VPC endpoint to Amazon S3\.
    To learn more about how to configure enhanced VPC routing, see the [online documentation](https://oreil.ly/yRMs-).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AWS 中，Amazon Redshift 部署在私有子网中，这意味着它没有直接的互联网连接，对环境的任何访问都必须起源于 VPC 内部或通过虚拟私有网关。然而，有一些
    AWS 服务并不在您的 AWS VPC 内运行。Amazon Redshift 中用于 `COPY` 和 `UNLOAD` 命令的关键服务是 Amazon
    S3 服务。为确保从 Amazon S3 传输到 Amazon Redshift 的数据通过您的 VPC，已启用增强型 VPC 路由功能，并配置了私有子网，该子网引用了指向
    Amazon S3 的 VPC 端点的路由表。有关如何配置增强型 VPC 路由的详细信息，请参阅[在线文档](https://oreil.ly/yRMs-)。
- en: '![Private Subnet DirectConnect](assets/ardg_0224.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![Private Subnet DirectConnect](assets/ardg_0224.png)'
- en: Figure 2-24\. Private subnet with AWS Direct Connect
  id: totrans-162
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-24\. 带有 AWS Direct Connect 的私有子网
- en: Stored Password
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储密码
- en: 'The easiest mechanism for maintaining users within your Amazon Redshift data
    warehouse is by creating a local user and storing a password within the Amazon
    Redshift metadata. This strategy is common to almost any database platform and
    can be done simply using the [`CREATE USER`](https://oreil.ly/Qmq49) command.
    For example:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在Amazon Redshift数据仓库中维护用户的最简单机制是创建一个本地用户并在Amazon Redshift元数据中存储密码。这种策略几乎适用于任何数据库平台，并且可以简单地使用[`CREATE
    USER`](https://oreil.ly/Qmq49)命令来完成。例如：
- en: '[PRE10]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This strategy is typically used when you have very few users to maintain, but
    it can result in administrative overhead as your user population increases.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 当您要维护的用户非常少时，通常会使用此策略，但是随着用户群体的增加，可能会产生管理开销。
- en: Temporary Credentials
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 临时凭证
- en: The next concept to consider, which is only available for Amazon Redshift provisioned
    clusters, is temporary credentials. This strategy is possible based on the API
    function [`GetClusterCredentials`](https://oreil.ly/ABhoZ). The API call will
    take as an input parameter, a `DbUser` and `DbGroups` parameter allowing you to
    join one or many database groups for authorization purposes. The API call also
    takes an `AutoCreate` parameter that, when set, will create a user if it doesn’t
    already exist in the database. The API will return a temporary password for the
    user provided. Once the temporary password is retrieved, you can log in using
    that combination of username and temporary password.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要考虑的下一个概念，仅适用于Amazon Redshift预置集群的是临时凭证。这种策略是基于API函数[`GetClusterCredentials`](https://oreil.ly/ABhoZ)的。API调用将以`DbUser`和`DbGroups`参数作为输入参数，允许您加入一个或多个数据库组进行授权。API调用还接受一个`AutoCreate`参数，当设置时，如果数据库中不存在用户，则会创建一个用户。API将返回一个用户提供的临时密码。一旦检索到临时密码，您可以使用用户名和临时密码组合登录。
- en: 'To use the temporary credentials strategy for a provisioned data warehouse,
    a user needs to first be authenticated and associated to an IAM identity, either
    an IAM user or be logged in as an IAM role. That identity needs to have an IAM
    policy that allows the user to use the `redshift:GetClusterCredentials` action.
    To enable features such as creating new users and dynamically joining groups,
    you may add the `redshift:CreateUser` and `redshift:JoinGroup` privileges. To
    ensure that a user can’t get a temporary password for any user or join a database
    group they shouldn’t join, it is a good idea to scope down the policy and add
    a condition that ensures the username they are getting the temporary credentials
    for matches their identity. Here is a sample policy that grants a user access
    to the `dev` database and to join the `marketing` group. It also has a condition
    to ensure the `aws:userid` matches the `DbUser`, which is passed into the `GetClusterCredentials`
    API command:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 要为预置数据仓库使用临时凭证策略，用户需要首先进行身份验证并关联到IAM身份，可以是IAM用户或作为IAM角色登录。该身份需要具有允许用户使用`redshift:GetClusterCredentials`操作的IAM策略。要启用创建新用户和动态加入组等功能，可以添加`redshift:CreateUser`和`redshift:JoinGroup`权限。为了确保用户不能为任何用户获取临时密码或加入他们不应该加入的数据库组，建议缩小策略范围并添加一个条件，确保他们获取临时凭证的用户名与其身份匹配。以下是授予用户访问`dev`数据库和加入`marketing`组的示例策略。还有一个条件，确保`aws:userid`与传递给`GetClusterCredentials`
    API命令的`DbUser`匹配：
- en: '[PRE11]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In addition to allowing users who are already logged into AWS via their IAM
    identity to query Amazon Redshift, this strategy has also been built into the
    JDBC and ODBC drivers. You simply indicate to the driver that you will use IAM
    to authenticate and pass it your IAM identity. Read more about how to configure
    a JDBC or ODBC connection to use IAM credentials in the [online documentation](https://oreil.ly/2nkuO).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 除了允许已通过IAM身份登录到AWS的用户查询Amazon Redshift外，该策略还内置于JDBC和ODBC驱动程序中。您只需向驱动程序指示将使用IAM进行身份验证并将其IAM身份传递给它即可。更多关于如何配置JDBC或ODBC连接以使用IAM凭证的信息，请参阅[在线文档](https://oreil.ly/2nkuO)。
- en: 'A simple way to pass the IAM identity is by passing an `AccessKeyID` and `SecretAccessKey`.
    See the following example JDBC URL:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 通过传递`AccessKeyID`和`SecretAccessKey`来传递IAM身份的简单方法。请参阅以下示例JDBC URL：
- en: '[PRE12]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Federated User
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 联合用户
- en: The next concept to consider is a *federated user*. This strategy is possible
    based on the API functions [`GetClusterCredentialsWithIAM`](https://oreil.ly/Ygkg1)
    for provisioned and [`GetCredentials`](https://oreil.ly/dlVqQ) for serverless.
    Similar to the the API call `GetClusterCredentials`, these APIs will retrieve
    a temporary password for a user; however, instead of passing these APIs parameters
    for authorization, the API will read values based on the logged-in identity. In
    the case of serverless, it will retrieve the username from `aws:userid` and will
    retrieve the database roles from the principal tags `RedshiftDbRoles` to authorize
    the session. In the case of provisioned, it will only retrieve the username stored
    in the `aws:userid`. In both cases, by default it will create a user if one doesn’t
    exist. Once the temporary password is retrieved, the user can login using that
    combination of username and temporary password.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个需要考虑的概念是*联合用户*。此策略基于API函数[`GetClusterCredentialsWithIAM`](https://oreil.ly/Ygkg1)（针对预配）和[`GetCredentials`](https://oreil.ly/dlVqQ)（针对无服务器）实现。类似于API调用`GetClusterCredentials`，这些API将获取用户的临时密码；不过，与传递这些API的授权参数不同，API将根据登录的身份读取值。在无服务器情况下，它将从`aws:userid`检索用户名，并将从主体标签`RedshiftDbRoles`中检索数据库角色以授权会话。在预配情况下，它仅检索存储在`aws:userid`中的用户名。在两种情况下，默认情况下，如果用户不存在，将创建用户。一旦获取临时密码，用户可以使用用户名和临时密码组合登录。
- en: 'Similar to `GetClusterCredentials`, to use the federated user, a user needs
    to first be authenticated and associated to an IAM identity, either an IAM user
    or be logged in as an IAM role. That identity needs to have an IAM policy that
    allows the user to use the `redshift:GetClusterCredentialsWithIAM` action for
    provisioned and `redshift-serverless:GetCredentials` action for serverless. Using
    the `Federated User` option, you do not need to have any additional permissions.
    In the case of serverless, you will need to ensure the IAM identity you use has
    the `RedshiftDbRoles` principal tag set if you want to enable role-based authorization.
    Here is a sample policy that grants a user access to the `dev` database:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`GetClusterCredentials`，要使用联合用户，用户首先需要进行身份验证，并关联到IAM身份，可以是IAM用户或作为IAM角色登录。该身份需要具有IAM策略，允许用户对预配执行`redshift:GetClusterCredentialsWithIAM`操作和对无服务器执行`redshift-serverless:GetCredentials`操作。使用`联合用户`选项时，您无需任何额外权限。在无服务器情况下，如果要启用基于角色的授权，则需要确保使用的IAM身份具有设置`RedshiftDbRoles`主体标签。以下是授予用户访问`dev`数据库的示例策略：
- en: '[PRE13]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Similar to the `GetClusterCredentials` API, the federated user functionality
    is built into the JDBC and ODBC drivers and is used by default when connecting
    to a serverless data warehouse when you indicate in the driver that you will use
    IAM to authenticate. Read more about how to configure a JDBC or ODBC connection
    to use IAM credentials in the [online documentation](https://oreil.ly/2nkuO).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`GetClusterCredentials` API，联合用户功能已经内置于JDBC和ODBC驱动程序中，并且在连接到无服务器数据仓库时默认使用，只要在驱动程序中指定将使用IAM进行身份验证。了解如何配置JDBC或ODBC连接以使用IAM凭据，请参阅[在线文档](https://oreil.ly/2nkuO)。
- en: SAML-Based Authentication from an Identity Provider
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于身份提供者的基于SAML的身份验证
- en: Typically for enterprises and large-scale Amazon Redshift deployments, your
    user identities are not stored in IAM but instead in an identity provider (IdP)
    such as Okta, Azure Ad, or PingFederate. If that is the case, maintaining a separate
    directory in IAM or within the Amazon Redshift metadata is not a scalable solution.
    Also, there may be multiple groups a user can be a member of, and maintaining
    separate IAM roles for each group combination would be unmanageable. Native to
    the AWS platform is the ability to establish an IAM identity from an IdP using
    the [`AssumeRoleWithSAML`](https://oreil.ly/WUg3v) API command. When you leverage
    this strategy, an IAM role can be assumed that contains privileges to `GetClusterCredentials`.
    This functionality is built into the Amazon Redshift JDBC and ODBC drivers. In
    [Figure 2-25](#saml), you can see how your SQL client will interact with your
    IdP and AWS services like AWS Security Token Service (AWS STS) and IAM prior to
    establishing a connection to Amazon Redshift.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，对于企业和大规模的Amazon Redshift部署，您的用户身份不会存储在IAM中，而是存储在身份提供者（IdP）如Okta、Azure
    Ad或PingFederate中。如果是这种情况，将IAM或Amazon Redshift元数据中的单独目录保持一致并非可扩展的解决方案。此外，用户可能属于多个组，并为每个组合维护单独的IAM角色将变得难以管理。AWS平台本地支持使用[`AssumeRoleWithSAML`](https://oreil.ly/WUg3v)
    API命令从IdP建立IAM身份。通过利用这一策略，可以假定包含执行`GetClusterCredentials`权限的IAM角色。此功能已内置于Amazon
    Redshift JDBC和ODBC驱动程序中。在[图2-25](#saml)中，您可以看到SQL客户端如何与IdP和AWS服务（如AWS安全令牌服务（AWS
    STS）和IAM）交互，然后才能连接到Amazon Redshift。
- en: '![SAML Authentication](assets/ardg_0225.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![SAML认证](assets/ardg_0225.png)'
- en: Figure 2-25\. Security Assertion Markup Language (SAML) authentication
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-25\. 安全断言标记语言（SAML）认证
- en: See the [online documentation](https://oreil.ly/RqO_P) for a detailed look at
    the different IdPs and features supported, such as multifactored authentication.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[在线文档](https://oreil.ly/RqO_P)以详细了解不同的IdP和支持的功能，如多因素身份验证。
- en: For a step-by-step guide on how to set up an Okta IdP, see this [blog post](https://oreil.ly/mTqC3)
    that uses the `OktaCredentialsProvider` plug-in. For scenarios where multifactor
    authentication is required, see this [blog post](https://oreil.ly/pQPST) that
    also uses an Okta IdP, but leverages the `BrowserSamlCredentialsProvider` plug-in.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 想要设置Okta IdP的逐步指南，请参阅使用`OktaCredentialsProvider`插件的[博客文章](https://oreil.ly/mTqC3)。对于需要多因素身份验证的场景，请参阅同样使用Okta
    IdP但利用`BrowserSamlCredentialsProvider`插件的[博客文章](https://oreil.ly/pQPST)。
- en: 'Whether you use Okta or another IdP, the steps required are:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用Okta还是其他IdP，所需的步骤包括：
- en: Create a SAML application accessible to your users in your IdP.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的IdP中创建一个供用户访问的SAML应用程序。
- en: Configure the application to reference the IAM role and pass the user and group
    information.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置应用程序引用IAM角色并传递用户和组信息。
- en: Download the application metadata from your IdP.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从您的IdP下载应用程序元数据。
- en: Establish an IdP within the AWS console using the metadata you just downloaded.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS控制台内使用刚刚下载的元数据建立一个IdP。
- en: Native IdP Integration
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本地IdP集成
- en: When applications have a way to establish a trust relationship via an OAuth
    token, Amazon Redshift has additional plug-ins, such as the `BrowserAzureOAuth2CredentialsProvider`.
    Instead of leveraging API commands or IAM to establish the trust relationship,
    the Amazon Redshift driver will make the initial request to the identity provider
    to validate the credentials and pop up a multifactor authentication prompt (if
    required) and receive the OAuth token. Next, the Amazon Redshift service will
    use the OAuth token to make further calls to the IdP to gather group authorization
    information. The native IdP architecture ([Figure 2-26](#native_idp)) outlines
    the flow with Microsoft Power BI and indicates how the native integration would
    work when using Azure Active Directory as the identity provider.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用程序通过OAuth令牌建立信任关系时，Amazon Redshift具有额外的插件，例如`BrowserAzureOAuth2CredentialsProvider`。与利用API命令或IAM建立信任关系不同，Amazon
    Redshift驱动程序将发起初始请求到身份提供者以验证凭据，并弹出多因素认证提示（如果需要），并接收OAuth令牌。接下来，Amazon Redshift服务将使用OAuth令牌向IdP发起进一步调用以获取组授权信息。本地IdP架构（[图2-26](#native_idp)）概述了在使用Azure
    Active Directory作为身份提供者时，Microsoft Power BI如何集成以及本地集成的工作原理。
- en: '![Native IdP Architecture](assets/ardg_0226.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![本地IdP架构](assets/ardg_0226.png)'
- en: Figure 2-26\. Native IdP architecture
  id: totrans-193
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-26\. 本地IdP架构
- en: For a detailed look at setting up native IdP integration with Power BI and active
    directory, see this [blog post](https://oreil.ly/fJFvP).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 若要详细了解如何设置与 Power BI 和活动目录的本地 IdP 集成，请参阅此 [博客文章](https://oreil.ly/fJFvP)。
- en: Amazon Redshift Data API
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 数据 API
- en: Another way to connect to Amazon Redshift and query data is by using the Amazon
    Redshift Data API ([Figure 2-27](#data_api)). Using this strategy, a user does
    not connect directly to Amazon Redshift but instead connects to a secure HTTP
    endpoint. You can use the endpoint to run SQL statements without managing connections.
    Calls to the Data API are asynchronous. Using this strategy, an application needs
    access to the internet, or if you are running an application from a private VPC,
    you can set up a VPC endpoint. See this [online documentation](https://oreil.ly/jaqge)
    for more details on setting up a VPC endpoint.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 连接到亚马逊 Redshift 并查询数据的另一种方法是使用亚马逊 Redshift 数据 API（[图 2-27](#data_api)）。使用此策略，用户不直接连接到亚马逊
    Redshift，而是连接到安全的 HTTP 端点。您可以使用端点运行 SQL 语句，而无需管理连接。Data API 的调用是异步的。使用此策略，应用程序需要访问互联网，或者如果您正在从私有
    VPC 运行应用程序，则可以设置 VPC 端点。有关设置 VPC 端点的详细信息，请参阅此 [在线文档](https://oreil.ly/jaqge)。
- en: '![Amazon Redshift Data API](assets/ardg_0227.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![亚马逊 Redshift 数据 API](assets/ardg_0227.png)'
- en: Figure 2-27\. Amazon Redshift Data API
  id: totrans-198
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-27\. 亚马逊 Redshift 数据 API
- en: To use the Amazon Redshift Data API, users need to first be authenticated into
    AWS and be associated to an IAM identity, either an IAM user or be logged in as
    an IAM role. That role will need permissions to use the Amazon Redshift Data API.
    The permissions are prefixed with `redshift-data:` and include metadata queries
    such as `ListTables` and `ListSchemas`, execution commands such as `ExecuteStatement`
    and `GetStatementResults`, and monitoring queries such as `DescribeStatement`.
    A detailed list of command are available in the [online documentation](https://oreil.ly/PnVAL).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用亚马逊 Redshift 数据 API，用户需要首先通过 AWS 进行身份验证，并与 IAM 身份相关联，可以是 IAM 用户或以 IAM 角色身份登录。该角色将需要权限来使用亚马逊
    Redshift 数据 API。权限以 `redshift-data:` 为前缀，包括元数据查询如 `ListTables` 和 `ListSchemas`，执行命令如
    `ExecuteStatement` 和 `GetStatementResults`，以及监控查询如 `DescribeStatement`。可在 [在线文档](https://oreil.ly/PnVAL)
    中查看详细的命令列表。
- en: When using the Amazon Redshift Data API, you have two options to authenticate.
    The first is by using temporary credentials where you call the API and pass the
    `DbUser` parameter and do not pass the `SecretArn` parameter. To learn more about
    using temporary credentials, see [“Temporary Credentials”](#temporary_credentials).
    Conversely, you may authenticate using a stored password by passing the `SecretArn`
    parameter but do not pass the `DbUser`. To learn more about using a stored password,
    see [“Stored Password”](#stored_password).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用亚马逊 Redshift 数据 API 时，您有两种身份验证选项。首先是使用临时凭证，在调用 API 时传递 `DbUser` 参数，但不传递 `SecretArn`
    参数。要了解更多关于使用临时凭证的信息，请参见 [“临时凭证”](#temporary_credentials)。相反，您可以通过传递 `SecretArn`
    参数而不传递 `DbUser` 参数来使用存储的密码进行身份验证。要了解更多关于使用存储密码的信息，请参见 [“存储的密码”](#stored_password)。
- en: 'In the following example, you can see how to leverage the Amazon Redshift Data
    API to execute a simple `CREATE SCHEMA` command using credentials stored within
    a secret:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，您可以看到如何利用亚马逊 Redshift 数据 API 执行一个简单的 `CREATE SCHEMA` 命令，使用存储在密钥中的凭证：
- en: '[PRE14]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: For a more detailed guide on how you can use the Amazon Redshift Data API, see
    this [blog post](https://oreil.ly/qsFf6).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 要详细了解如何使用亚马逊 Redshift 数据 API，请参阅此 [博客文章](https://oreil.ly/qsFf6)。
- en: Querying a Database Using the Query Editor V2
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用查询编辑器 V2 查询数据库
- en: After you have established your authentication strategy, the next step is to
    query your data. Amazon Redshift offers two versions of query editor—the legacy
    query editor and Query Editor V2 ([Figure 2-28](#query_editor_v2)) that you can
    use to author and run queries on your Amazon Redshift data warehouse. While the
    legacy query editor is still available to use, we recommend using Query Editor
    V2 as it has additional features allowing you to manage database objects, visualize
    results, and share your work with your team in addition to editing and running
    queries. It shows databases, schemas, and all objects in a tree-view panel for
    easy access of database objects.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定了身份验证策略之后，下一步是查询您的数据。亚马逊 Redshift 提供两个版本的查询编辑器——传统查询编辑器和查询编辑器 V2（[图 2-28](#query_editor_v2)）。您可以使用它们来编写和运行对亚马逊
    Redshift 数据仓库的查询。虽然传统查询编辑器仍然可用，但我们建议使用查询编辑器 V2，因为它具有额外的功能，允许您管理数据库对象、可视化结果，并与团队共享工作，除了编辑和运行查询。它显示数据库、模式和树形视图面板中的所有对象，便于访问数据库对象。
- en: '![Query Editor V2](assets/ardg_0228.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![查询编辑器 V2](assets/ardg_0228.png)'
- en: Figure 2-28\. Query Editor V2
  id: totrans-207
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 2-28\. 查询编辑器 V2
- en: Query Editor V2 has two tab types ([Figure 2-29](#query_editor_tab_types)),
    an Editor tab and a Notebook tab. The Editor tab will allow you to consolidate
    all queries in one page and trigger execution at the same time. The Editor will
    execute all the queries in sequence and produce the results in different result
    tabs. The SQL Notebook tab contains SQL and markdown cells, which you can use
    to organize, annotate, and share multiple SQL commands in a single document. Both
    editor scripts and notebooks can be saved and shared with your team for collaboration.
    In this book, we will use Query Editor V2 as this is the future direction for
    querying data in Amazon Redshift.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 查询编辑器 V2 有两种标签类型（[Figure 2-29](#query_editor_tab_types)）：编辑器标签和笔记本标签。编辑器标签允许您在一个页面中整理所有查询，并同时触发执行。编辑器将按顺序执行所有查询，并在不同的结果标签中生成结果。SQL
    笔记本标签包含 SQL 和 Markdown 单元格，您可以在单个文档中组织、注释和共享多个 SQL 命令。编辑器脚本和笔记本均可保存并与团队共享，以便进行协作。在本书中，我们将使用查询编辑器
    V2，因为这是在 Amazon Redshift 中查询数据的未来方向。
- en: '![Query Editor V2 tab types](assets/ardg_0229.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![查询编辑器 V2 标签类型](assets/ardg_0229.png)'
- en: Figure 2-29\. Query Editor V2 tab types
  id: totrans-210
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 2-29\. 查询编辑器 V2 标签类型
- en: To access Query Editor V2 within the AWS console, click the link below the Query
    data button ([Figure 2-30](#query_data)).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 AWS 控制台内访问查询编辑器 V2，请单击查询数据按钮下方的链接（[Figure 2-30](#query_data)）。
- en: '![Query data](assets/ardg_0230.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![查询数据](assets/ardg_0230.png)'
- en: Figure 2-30\. Query data
  id: totrans-213
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 2-30\. 查询数据
- en: To enable users to access Query Editor V2, you can attach one of the AWS-managed
    Query Editor V2 policies ([Table 2-2](#query_editor_policies)) to the IAM user
    or role. These managed policies also give access to other required services. You
    can also create a user-managed policy if you want to customize permissions for
    your end users.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 要允许用户访问查询编辑器 V2，您可以将 AWS 管理的查询编辑器 V2 策略之一（[Table 2-2](#query_editor_policies)）附加到
    IAM 用户或角色上。这些托管策略还提供对其他所需服务的访问。如果您希望为最终用户自定义权限，也可以创建用户管理的策略。
- en: Table 2-2\. Query Editor V2 policies
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Table 2-2\. 查询编辑器 V2 策略
- en: '| Policy | Description |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 策略 | 描述 |'
- en: '| --- | --- |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| AmazonRedshiftQueryEditorV2FullAccess | Grants full access to Query Editor
    V2 operations and resources. This is primarily intended for administrators. |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| AmazonRedshiftQueryEditorV2FullAccess | 授予对查询编辑器 V2 操作和资源的完全访问权限。这主要用于管理员。
    |'
- en: '| AmazonRedshiftQueryEditorV2NoSharing | Grants the ability to work with Query
    Editor V2 without sharing resources. Users can’t share their queries with their
    team members. |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| AmazonRedshiftQueryEditorV2NoSharing | 允许在不共享资源的情况下使用查询编辑器 V2。用户不能与团队成员共享他们的查询。
    |'
- en: '| AmazonRedshiftQueryEditorV2ReadSharing | Grants the ability to work with
    Query Editor V2 with limited sharing of resources. The granted principal can read
    the saved queries shared with their team but can’t update them. |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| AmazonRedshiftQueryEditorV2ReadSharing | 允许在有限共享资源的情况下使用查询编辑器 V2。授权的主体可以读取与团队共享的保存查询，但不能更新它们。
    |'
- en: '| AmazonRedshiftQueryEditorV2ReadWriteSharing | Grants the ability to work
    with Query Editor V2 with sharing of resources. The granted principal can read
    and update the shared resources with their team. |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| AmazonRedshiftQueryEditorV2ReadWriteSharing | 允许在共享资源的情况下使用查询编辑器 V2。授权的主体可以读取和更新团队共享的资源。
    |'
- en: To enable collaboration of queries between team members, you can tag the IAM
    principal. For example, if you have a group of users as a part of `marketing_group`,
    and you want them to collaborate between themselves by sharing their queries,
    you ensure their IAM role, `marketing_role`, is assigned the `AmazonRedshiftQueryEditorV2ReadSharing`
    policy. You can also tag the role with the tag `sqlworkbench-team` having the
    value of `marketing_group`. Now the end users logged in with the `marketing_role`
    can access Query Editor V2 with the ability to share their queries.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现团队成员之间的查询协作，您可以对 IAM 主体进行标记。例如，如果您有一组用户作为`marketing_group`的一部分，并且希望他们通过共享他们的查询进行协作，您需确保他们的
    IAM 角色`marketing_role`被分配了`AmazonRedshiftQueryEditorV2ReadSharing`策略。您还可以使用标签`sqlworkbench-team`为角色打标签，其值为`marketing_group`。现在，使用`marketing_role`登录的最终用户可以访问查询编辑器
    V2，并具有共享其查询的能力。
- en: When using the query editor to connect to your Amazon Redshift data warehouse,
    you are prompted with a few options. You can connect as a [“Federated user”](#qev2_fed_user),
    use [“Temporary credentials”](#qev2_temp_creds), with a [“Database username and
    password”](#qev2_password), or through [“AWS Secrets Manager”](#qev2_secret).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用查询编辑器连接到您的 Amazon Redshift 数据仓库时，您将看到几个选项。您可以作为[“联合用户”](#qev2_fed_user)连接，使用[“临时凭证”](#qev2_temp_creds)，通过[“数据库用户名和密码”](#qev2_password)，或通过[“AWS
    Secrets Manager”](#qev2_secret)连接。
- en: The temporary credentials option in the Query Editor V2 is available only when
    connecting to a provisioned cluster.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 查询编辑器 V2 中的临时凭证选项仅在连接到已配置的集群时可用。
- en: Federated user
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 联合用户
- en: When using the Query Editor V2 and the federated user option ([Figure 2-31](#query_editor_federated))
    is chosen, it will operate differently for a provisioned versus serverless data
    warehouse. For provisioned, Query Editor V2 will depend on the `GetClusterCredentials`
    used in the temporary credentials authentication method. However, instead of prompting
    for the user and group information, it will look for these values from two principal
    tags, `RedshiftDbUser` and `RedshiftDbGroups`, and will pass the values in those
    tags to the API call. Those principal tags can be set either directly in IAM or
    they can be passed from an IdP. To use this strategy, the IAM role passed from
    the IdP will also need to have permissions to use temporary credentials, as discussed
    previously. Using this strategy is both scalable and easy to use because the only
    input required from the end user is the database name. For a detailed walkthrough
    of how to set up federated user login with Okta, see this [blog post](https://oreil.ly/70qK6).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用查询编辑器 V2 并选择联合用户选项（[图 2-31](#query_editor_federated)）时，对于已配置与无服务器数据仓库不同。对于已配置，查询编辑器
    V2 将依赖于临时凭证认证方法中使用的 `GetClusterCredentials`。然而，与其要求用户和组信息不同，它将从两个主体标签 `RedshiftDbUser`
    和 `RedshiftDbGroups` 中查找这些值，并将这些标签中的值传递给 API 调用。这些主体标签可以直接在 IAM 中设置，也可以从 IdP 传递。要使用此策略，从
    IdP 传递的 IAM 角色还需要具有使用临时凭证的权限，如前所述。使用此策略既具有可扩展性又易于使用，因为终端用户唯一需要输入的是数据库名称。有关如何设置
    Okta 联合用户登录的详细步骤，请参阅此[博客文章](https://oreil.ly/70qK6)。
- en: '![Query Editor V2 federated user](assets/ardg_0231.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![查询编辑器 V2 联合用户](assets/ardg_0231.png)'
- en: Figure 2-31\. Query Editor V2 federated user
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-31\. 查询编辑器 V2 联合用户
- en: In contrast, when federated user ([Figure 2-31](#query_editor_federated)) is
    chosen for a serverless data warehouse, Query Editor V2 will leverage the `GetCredentials`
    API call used in the federated user authentication method. Similarly, the database
    username will be retrieved from the `aws:userid`, and the database roles will
    be retrieved from the `RedshiftDbRoles` principal tags.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，当选择联合用户（[图 2-31](#query_editor_federated)）用于无服务器数据仓库时，查询编辑器 V2 将利用联合用户认证方法中使用的
    `GetCredentials` API 调用。类似地，数据库用户名将从 `aws:userid` 中检索，数据库角色将从 `RedshiftDbRoles`
    主体标签中检索。
- en: Temporary credentials
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 临时凭证
- en: The temporary credentials option ([Figure 2-32](#query_editor_temp)) is similar
    to the federated user option in that the IAM identity will need to have permissions
    to use temporary credentials. One notable difference is that it is not dependent
    on principal tags, so in addition to the `Database` parameter, a user must enter
    the username and will not be automatically added to groups.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 临时凭证选项（[图 2-32](#query_editor_temp)）与联合用户选项类似，即 IAM 身份需要具有使用临时凭证的权限。一个显著的区别是它不依赖于主体标签，因此除了
    `Database` 参数外，用户还必须输入用户名，并且不会自动添加到组中。
- en: '![Query Editor V2 temporary credentials](assets/ardg_0232.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![查询编辑器 V2 临时凭证](assets/ardg_0232.png)'
- en: Figure 2-32\. Query Editor V2 temporary credentials
  id: totrans-233
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-32\. 查询编辑器 V2 临时凭证
- en: Database username and password
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据库用户名和密码
- en: With the password option ([Figure 2-33](#query_editor_pass)), in addition to
    the `Database` and `User name` parameters, a user must supply a password. To make
    it easier in subsequent sessions, the password is saved within the Secrets Manager
    service and the IAM identity using the query editor will need to have permissions
    to read and write to Secrets Manager.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 使用密码选项（[图 2-33](#query_editor_pass)）时，除了 `Database` 和 `User name` 参数外，用户还必须提供密码。为了在后续会话中更容易使用，密码将保存在
    Secrets Manager 服务中，并且使用查询编辑器的 IAM 身份需要具有读写 Secrets Manager 的权限。
- en: '![Query Editor V2 stored password](assets/ardg_0233.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![查询编辑器 V2 存储密码](assets/ardg_0233.png)'
- en: Figure 2-33\. Query Editor V2 stored password
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-33\. 查询编辑器 V2 存储密码
- en: AWS Secrets Manager
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS Secrets Manager
- en: With the AWS Secrets Manager option ([Figure 2-34](#query_editor_secret)), the
    user only needs to specify a predefined AWS secret. In this scenario, the secret
    would have been precreated by an administrator so the IAM identity using the query
    editor does *not* need permissions to write to Secrets Manager.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AWS Secrets Manager选项（[图 2-34](#query_editor_secret)），用户只需指定预定义的AWS秘密。在这种情况下，该秘密将由管理员预先创建，因此使用查询编辑器的IAM身份*不*需要权限写入Secrets
    Manager。
- en: '![Query Editor V2 AWS Secrets Manager](assets/ardg_0234.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![Query Editor V2 AWS Secrets Manager](assets/ardg_0234.png)'
- en: Figure 2-34\. Query Editor V2 AWS Secrets Manager
  id: totrans-241
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-34\. 查询编辑器V2 AWS Secrets Manager
- en: 'For more examples of using the Query Editor V2, see the following blog posts:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 若要了解更多有关查询编辑器V2的示例，请参阅以下博客文章：
- en: '[“Simplify Your Data Analysis with Amazon Redshift Query Editor V2”](https://oreil.ly/wBMv-)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“使用Amazon Redshift Query Editor V2简化数据分析”](https://oreil.ly/wBMv-)'
- en: '[“Introducing Amazon Redshift Query Editor V2, a Free Web-based Query Authoring
    Tool for Data Analysts”](https://oreil.ly/spxKw)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“介绍Amazon Redshift Query Editor V2，一款供数据分析师使用的免费Web查询创作工具”](https://oreil.ly/spxKw)'
- en: '[“Federate Access to Amazon Redshift Query Editor V2 with Active Directory
    Federation Services (AD FS): Part 3”](https://oreil.ly/ihsKQ)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“使用Active Directory联合服务（AD FS）将Amazon Redshift Query Editor V2联合访问”：第3部分](https://oreil.ly/ihsKQ)'
- en: Business Intelligence Using Amazon QuickSight
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Amazon QuickSight进行商业智能分析
- en: BI platforms of your choice can connect to Amazon Redshift using JDBC and ODBC
    drivers either packaged with those applications or that can be downloaded. Popular
    BI platforms that integrate with Amazon Redshift include [MicroStrategy](https://www.microstrategy.com),
    [Power BI](https://powerbi.microsoft.com), [Tableau](https://www.tableau.com),
    and [Looker](https://www.looker.com). For more information on connecting to Amazon
    Redshift using these drivers see [“Connecting to Amazon Redshift Using JDBC/ODBC”](#connecting_jdbc_odbc).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用BI平台通过JDBC和ODBC驱动程序连接到Amazon Redshift，这些驱动程序可以作为这些应用程序的一部分打包或下载。与Amazon
    Redshift集成的流行BI平台包括[MicroStrategy](https://www.microstrategy.com)，[Power BI](https://powerbi.microsoft.com)，[Tableau](https://www.tableau.com)和[Looker](https://www.looker.com)。有关使用这些驱动程序连接到Amazon
    Redshift的更多信息，请参阅[“使用JDBC/ODBC连接到Amazon Redshift”](#connecting_jdbc_odbc)。
- en: AWS also provides a cloud native serverless BI service, [Amazon QuickSight](https://aws.amazon.com/quicksight),
    which is tightly integrated with Amazon Redshift and does not require a driver
    to be set up. Amazon QuickSight has a pay-per-user pricing model, automatic scaling,
    and no servers to maintain. There are a number of live example dashboards available
    on the [Amazon QuickSight Gallery](https://oreil.ly/PX_nz) for you to explore
    that demonstrate various features available in the tool.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: AWS还提供一种原生云服务器无服务BI服务，[Amazon QuickSight](https://aws.amazon.com/quicksight)，与Amazon
    Redshift紧密集成，无需设置驱动程序。 Amazon QuickSight采用按用户付费的定价模型，自动扩展，无需维护服务器。您可以在[Amazon
    QuickSight Gallery](https://oreil.ly/PX_nz)上探索许多实时示例仪表板，演示该工具中提供的各种功能。
- en: In the following retail analytics example dashboard ([Figure 2-35](#quicksight_dashboard)),
    you can see a number of key features of QuickSight. A few of these features include
    built-in machine learning algorithms to forecast and detect anomalies, customized
    narratives, and rich visualizations.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下零售分析示例仪表板中（[图 2-35](#quicksight_dashboard)），您可以看到QuickSight的许多关键功能。其中一些功能包括内置的机器学习算法用于预测和检测异常，定制的叙述内容以及丰富的可视化效果。
- en: '![QuickSight Example](assets/ardg_0235.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![QuickSight 示例](assets/ardg_0235.png)'
- en: Figure 2-35\. QuickSight example dashboard
  id: totrans-251
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-35\. QuickSight示例仪表板
- en: 'Among the many QuickSight data sources ([Figure 2-36](#quicksight_datasources)),
    there are two options to connect to Amazon Redshift: Redshift Auto-discovered
    and Redshift Manual connect. With the connection in place, users can start building
    reports and dashboards with a few button clicks.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多QuickSight数据源（[图 2-36](#quicksight_datasources)）中，有两种选项可连接到Amazon Redshift：Redshift自动发现和Redshift手动连接。一旦建立连接，用户可以通过几次点击开始构建报告和仪表板。
- en: '![QuickSight Data Sources](assets/ardg_0236.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![QuickSight 数据源](assets/ardg_0236.png)'
- en: Figure 2-36\. QuickSight data sources
  id: totrans-254
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-36\. QuickSight数据源
- en: When you leverage the Redshift Auto-discovered option, users select the Redshift
    Instance ID you want to connect to and enter the database, username, and password
    ([Figure 2-37](#quicksight_auto_connection)).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 当您利用Redshift自动发现选项时，用户选择要连接的Redshift实例ID，并输入数据库、用户名和密码（[图 2-37](#quicksight_auto_connection)）。
- en: '![QuickSight Redshift Auto-discovered Connection](assets/ardg_0237.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![QuickSight Redshift自动发现连接](assets/ardg_0237.png)'
- en: Figure 2-37\. QuickSight Redshift Auto-discovered connection
  id: totrans-257
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-37\. QuickSight Redshift 自动发现连接
- en: When you leverage the Redshift Manual connect option, users enter the database
    server and port in addition to the database, username, and password ([Figure 2-38](#quicksight_manual_connection)).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用 Redshift 手动连接选项时，用户除了输入数据库、用户名和密码外，还需输入数据库服务器和端口（[图 2-38](#quicksight_manual_connection)）。
- en: '![QuickSight Redshift Manual Connect](assets/ardg_0238.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![QuickSight Redshift 手动连接](assets/ardg_0238.png)'
- en: Figure 2-38\. QuickSight Redshift manual connect
  id: totrans-260
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-38\. QuickSight Redshift 手动连接
- en: Connecting to Amazon Redshift Using JDBC/ODBC
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 JDBC/ODBC 连接 Amazon Redshift
- en: Many third-party BI and ETL tools access DB platforms through the use of JDBC
    and ODBC drivers. Amazon Redshift provides open source drivers for you to download
    and may already be packaged in your third-party tools. These drivers are updated
    by AWS frequently to work with new features being released in the product. While
    Amazon Redshift is also compatible with Postgres drivers, those drivers do not
    support all the features available in the Amazon Redshift drivers, such as IAM
    authentication. To configure your Amazon Redshift driver, you can obtain the connection
    URL by navigating to the Amazon Redshift console.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 许多第三方 BI 和 ETL 工具通过 JDBC 和 ODBC 驱动访问 DB 平台。Amazon Redshift 提供开源驱动程序供您下载，并可能已经打包在您的第三方工具中。这些驱动程序由
    AWS 经常更新，以配合产品发布的新功能。虽然 Amazon Redshift 也兼容 Postgres 驱动程序，但这些驱动程序不支持 Amazon Redshift
    驱动程序中提供的所有功能，例如 IAM 认证。要配置您的 Amazon Redshift 驱动程序，您可以通过访问 Amazon Redshift 控制台获取连接
    URL。
- en: For a provisioned cluster, you can find the JDBC/ODBC URL ([Figure 2-39](#provisioned_url))
    by inspecting the Cluster summary page.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 对于预置集群，您可以通过检查集群摘要页面找到 JDBC/ODBC URL（[图 2-39](#provisioned_url)）。
- en: '![Amazon Redshift provisioned JDBC/ODBC URL](assets/ardg_0239.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift 预置 JDBC/ODBC URL](assets/ardg_0239.png)'
- en: Figure 2-39\. Amazon Redshift provisioned JDBC/ODBC URL
  id: totrans-265
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-39\. Amazon Redshift 预置 JDBC/ODBC URL
- en: For a serverless workgroup, you can find the JDBC/ODBC URL ([Figure 2-40](#serverless_url))
    by inspecting the Workgroup summary page.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 对于服务器无服务器工作组，您可以通过检查工作组摘要页面找到 JDBC/ODBC URL（[图 2-40](#serverless_url)）。
- en: '![.Amazon Redshift serverless JDBC/ODBC URL](assets/ardg_0240.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift 无服务器 JDBC/ODBC URL](assets/ardg_0240.png)'
- en: Figure 2-40\. Amazon Redshift serverless JDBC/ODBC URL
  id: totrans-268
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-40\. Amazon Redshift 无服务器 JDBC/ODBC URL
- en: In the following example, using the open source Java tool [SQL Workbench/J](https://www.sql-workbench.eu),
    we have set the client configuration ([Figure 2-41](#jdbc_client_configuration))
    using the information gathered. With this tool, you can leverage the Extended
    Properties dialog to set optional parameters required for features like SAML-based
    authentication.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，使用开源 Java 工具 [SQL Workbench/J](https://www.sql-workbench.eu)，我们已经使用收集的信息设置了客户端配置（[图 2-41](#jdbc_client_configuration)）。使用此工具，您可以利用扩展属性对话框设置用于功能（如基于
    SAML 的身份验证）所需的可选参数。
- en: '![JDBC Client](assets/ardg_0241.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![JDBC 客户端](assets/ardg_0241.png)'
- en: Figure 2-41\. JDBC client configuration
  id: totrans-271
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-41\. JDBC 客户端配置
- en: 'Also notice the checkbox for Autocommit: this is an often overlooked setting
    and should be enabled in most use cases. Because Amazon Redshift follows Atomicity
    tenant of [ACID (atomicity, consistency, isolation, durability)](https://oreil.ly/ZRTMq)
    compliance, it needs to maintain the state of the data across multiple user transactions.
    When disabled, Amazon Redshift will assume that every connection is the beginning
    of a new transaction and will not commit the transaction unless an explicit `commit`
    statement is executed. When overlooked, the system may unnecessarily use resources
    to keep track of multiple transaction states. If you find yourself in this situation,
    you can terminate idle connections using the [`PG_TERMINATE_BACKEND`](https://oreil.ly/WvQzN)
    command.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 还请注意 Autocommit 复选框：这是一个经常被忽视的设置，在大多数情况下应启用。因为 Amazon Redshift 遵循 ACID（原子性、一致性、隔离性、持久性）规范的原子性特性，需要在多个用户事务中维护数据状态。当禁用时，Amazon
    Redshift 将假定每个连接都是新事务的开始，并且除非执行显式的 `commit` 语句，否则不会提交事务。如果忽视了此设置，系统可能会不必要地使用资源来跟踪多个事务状态。如果发现自己处于这种情况，请使用
    [`PG_TERMINATE_BACKEND`](https://oreil.ly/WvQzN) 命令终止空闲连接。
- en: For more details and options when configuring your JDBC driver, review this
    [JDBC driver documentation](https://oreil.ly/C7mcs), and for more details and
    options when configuring your ODBC driver, review this [ODBC online documentation](https://oreil.ly/3Oto5).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取有关配置JDBC驱动程序的更多详细信息和选项，请查阅此[JDBC驱动程序文档](https://oreil.ly/C7mcs)，要获取有关配置ODBC驱动程序的更多详细信息和选项，请查阅此[ODBC在线文档](https://oreil.ly/3Oto5)。
- en: Summary
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we showed you how Amazon Redshift is architected and how to
    get started. We compared the serverless and provisioned deployment options, showed
    you how to quickly query sample data, and showed you the different authentication
    and connection options.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们向您展示了Amazon Redshift的架构及其入门方式。我们比较了无服务器和预配置的部署选项，展示了如何快速查询示例数据，并展示了不同的认证和连接选项。
- en: In the next chapter, we will show you how to best model and load data from your
    data lake, operational sources, and real-time streaming sources.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将向您展示如何从数据湖、操作性源和实时流数据源最佳建模和加载数据。
