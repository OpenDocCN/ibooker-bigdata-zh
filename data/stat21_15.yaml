- en: Chapter 14 The General Linear Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第14章 通用线性模型
- en: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/the-general-linear-model.html](https://statsthinking21.github.io/statsthinking21-core-site/the-general-linear-model.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/the-general-linear-model.html](https://statsthinking21.github.io/statsthinking21-core-site/the-general-linear-model.html)
- en: 'Remember that early in the book we described the basic model of statistics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在本书的早期，我们描述了统计学的基本模型：
- en: \[ data = model + error \] where our general goal is to find the model that
    minimizes the error, subject to some other constraints (such as keeping the model
    relatively simple so that we can generalize beyond our specific dataset). In this
    chapter we will focus on a particular implementation of this approach, which is
    known as the *general linear model* (or GLM). You have already seen the general
    linear model in the earlier chapter on Fitting Models to Data, where we modeled
    height in the NHANES dataset as a function of age; here we will provide a more
    general introduction to the concept of the GLM and its many uses. Nearly every
    model used in statistics can be framed in terms of the general linear model or
    an extension of it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 数据 = 模型 + 误差 \]，我们的一般目标是找到最小化误差的模型，同时满足其他一些约束（例如保持模型相对简单，以便我们可以推广到我们的特定数据集之外）。在本章中，我们将专注于这种方法的特定实现，即*通用线性模型*（或GLM）。在早期关于将模型拟合到数据的章节中，您已经看到了通用线性模型，我们对NHANES数据集中的身高建模为年龄的函数；在这里，我们将更一般地介绍GLM的概念及其许多用途。几乎统计学中使用的每个模型都可以用通用线性模型或其扩展来表述。
- en: 'Before we discuss the general linear model, let’s first define two terms that
    will be important for our discussion:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论通用线性模型之前，让我们首先定义两个对我们讨论重要的术语：
- en: '*dependent variable*: This is the outcome variable that our model aims to explain
    (usually referred to as *Y*)'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*因变量*：这是我们的模型旨在解释的结果变量（通常称为*Y*）'
- en: '*independent variable*: This is a variable that we wish to use in order to
    explain the dependent variable (usually referred to as *X*).'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自变量*：这是我们希望用来解释因变量的变量（通常称为*X*）。'
- en: There may be multiple independent variables, but for this course we will focus
    primarily on situations where there is only one dependent variable in our analysis.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会有多个自变量，但在本课程中，我们将主要关注分析中只有一个因变量的情况。
- en: A general linear model is one in which the model for the dependent variable
    is composed of a *linear combination* of independent variables that are each multiplied
    by a weight (which is often referred to as the Greek letter beta - \(\beta\)),
    which determines the relative contribution of that independent variable to the
    model prediction.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通用线性模型是一个模型，其中因变量的模型由独立变量的*线性组合*组成，每个独立变量都乘以一个权重（通常称为希腊字母beta - \(\beta\)），这决定了该独立变量对模型预测的相对贡献。
- en: '![Relation between study time and grades](../Images/0c9b614638c0e4be7c66a0f49fc8342a.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![学习时间和成绩之间的关系](../Images/0c9b614638c0e4be7c66a0f49fc8342a.png)'
- en: 'Figure 14.1: Relation between study time and grades'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1：学习时间和成绩之间的关系
- en: 'As an example, let’s generate some simulated data for the relationship between
    study time and exam grades (see Figure [14.1](the-general-linear-model.html#fig:StudytimeGrades)).
    Given these data, we might want to engage in each of the three fundamental activities
    of statistics:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，让我们生成一些模拟数据，来描述学习时间和考试成绩之间的关系（见图[14.1](the-general-linear-model.html#fig:StudytimeGrades)）。根据这些数据，我们可能想要进行统计学的三个基本活动：
- en: '*Describe*: How strong is the relationship between grade and study time?'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*描述*：成绩和学习时间之间的关系有多强？'
- en: '*Decide*: Is there a statistically significant relationship between grade and
    study time?'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*决定*：成绩和学习时间之间是否存在统计学上显著的关系？'
- en: '*Predict*: Given a particular amount of study time, what grade do we expect?'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测*：给定特定的学习时间，我们期望得到什么成绩？'
- en: 'In the previous chapter we learned how to describe the relationship between
    two variables using the correlation coefficient. Let’s use our statistical software
    to compute that relationship for these data and test whether the correlation is
    significantly different from zero:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用相关系数描述两个变量之间的关系。让我们使用统计软件来计算这些数据的相关关系，并测试相关性是否显著不同于零：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The correlation is quite high, but notice that the confidence interval around
    the estimate is very wide, spanning nearly the entire range from zero to one,
    which is due in part to the small sample size.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性非常高，但请注意，估计周围的置信区间非常宽，几乎涵盖了从零到一的整个范围，这在一定程度上是由于样本量较小造成的。
- en: 14.1 Linear regression
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.1 线性回归
- en: We can use the general linear model to describe the relation between two variables
    and to decide whether that relationship is statistically significant; in addition,
    the model allows us to predict the value of the dependent variable given some
    new value(s) of the independent variable(s). Most importantly, the general linear
    model will allow us to build models that incorporate multiple independent variables,
    whereas the correlation coefficient can only describe the relationship between
    two individual variables.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用通用线性模型来描述两个变量之间的关系，并决定该关系是否具有统计学意义；此外，该模型还允许我们根据自变量的新值来预测因变量的值。最重要的是，通用线性模型将允许我们构建包含多个自变量的模型，而相关系数只能描述两个单独变量之间的关系。
- en: The specific version of the GLM that we use for this is referred to as as *linear
    regression*. The term *regression* was coined by Francis Galton, who had noted
    that when he compared parents and their children on some feature (such as height),
    the children of extreme parents (i.e. the very tall or very short parents) generally
    fell closer to the mean than did their parents. This is an extremely important
    point that we return to below.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用于此的GLM的具体版本被称为*线性回归*。 *回归*一词是由弗朗西斯·高尔顿创造的，他注意到当他比较父母和他们的孩子在某些特征上（如身高）时，极端父母的孩子（即非常高或非常矮的父母）通常比他们的父母更接近平均值。这是一个非常重要的观点，我们将在下面回到这一点。
- en: 'The simplest version of the linear regression model (with a single independent
    variable) can be expressed as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型的最简单版本（具有单个自变量）可以表示如下：
- en: '\[ y = x * \beta_x + \beta_0 + \epsilon \] The \(\beta_x\) value tells us how
    much we would expect y to change given a one-unit change in \(x\). The intercept
    \(\beta_0\) is an overall offset, which tells us what value we would expect y
    to have when \(x=0\); you may remember from our early modeling discussion that
    this is important to model the overall magnitude of the data, even if \(x\) never
    actually attains a value of zero. The error term \(\epsilon\) refers to whatever
    is left over once the model has been fit; we often refer to these as the *residuals*
    from the model. If we want to know how to predict y (which we call \(\hat{y}\))
    after we estimate the \(\beta\) values, then we can drop the error term:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = x * \beta_x + \beta_0 + \epsilon \] \(\beta_x\)值告诉我们，我们期望y在给定x变化一个单位时会发生多大变化。截距\(\beta_0\)是一个整体偏移量，告诉我们当\(x=0\)时我们期望y有什么值；您可能还记得我们早期建模讨论中提到的，即使\(x\)从未真正达到零，这对于模拟数据的整体幅度也很重要。误差项\(\epsilon\)指的是模型拟合后剩下的东西；我们经常将这些称为模型的*残差*。如果我们想知道在估计了\(\beta\)值之后如何预测y（我们称之为\(\hat{y}\)），那么我们可以去掉误差项：
- en: \[ \hat{y} = x * \hat{\beta_x} + \hat{\beta_0} \] Note that this is simply the
    equation for a line, where \(\hat{\beta_x}\) is our estimate of the slope and
    \(\hat{\beta_0}\) is the intercept. Figure [14.2](the-general-linear-model.html#fig:LinearRegression)
    shows an example of this model applied to the study time data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = x * \hat{\beta_x} + \hat{\beta_0} \] 请注意，这只是一条线的方程，其中\(\hat{\beta_x}\)是我们对斜率的估计，\(\hat{\beta_0}\)是截距。图[14.2](the-general-linear-model.html#fig:LinearRegression)显示了将此模型应用于研究时间数据的示例。
- en: '![The linear regression solution for the study time data is shown in the solid
    line The value of the intercept is equivalent to the predicted value of the y
    variable when the x variable is equal to zero; this is shown with a dotted line.  The
    value of beta is equal to the slope of the line -- that is, how much y changes
    for a unit change in x.  This is shown schematically in the dashed lines, which
    show the degree of increase in grade for a single unit increase in study time.](../Images/be0c3609b17120dcee38fbc52a526a4b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![研究时间数据的线性回归解决方案显示在实线中，截距的值等于当x变量等于零时y变量的预测值；这用虚线表示。 beta的值等于线的斜率--也就是说，y在x变化一个单位时的变化量。这在虚线中以示意图的方式显示，显示了学习时间增加一个单位时成绩的增加程度。](../Images/be0c3609b17120dcee38fbc52a526a4b.png)'
- en: 'Figure 14.2: The linear regression solution for the study time data is shown
    in the solid line The value of the intercept is equivalent to the predicted value
    of the y variable when the x variable is equal to zero; this is shown with a dotted
    line. The value of beta is equal to the slope of the line – that is, how much
    y changes for a unit change in x. This is shown schematically in the dashed lines,
    which show the degree of increase in grade for a single unit increase in study
    time.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2：研究时间数据的线性回归解决方案显示在实线中，截距的值等于当x变量等于零时y变量的预测值；这用虚线表示。 beta的值等于线的斜率-也就是说，y在x变化一个单位时的变化量。这在虚线中以示意图的方式显示，显示了学习时间增加一个单位时成绩的增加程度。
- en: We will not go into the details of how the best fitting slope and intercept
    are actually estimated from the data; if you are interested, details are available
    in the Appendix.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细介绍如何从数据中实际估计最佳拟合斜率和截距；如果您感兴趣，可以在附录中找到详细信息。
- en: 14.1.1 Regression to the mean
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.1 回归到平均值
- en: The concept of *regression to the mean* was one of Galton’s essential contributions
    to science, and it remains a critical point to understand when we interpret the
    results of experimental data analyses. Let’s say that we want to study the effects
    of a reading intervention on the performance of poor readers. To test our hypothesis,
    we might go into a school and recruit those individuals in the bottom 25% of the
    distribution on some reading test, administer the intervention, and then examine
    their performance on the test after the intervention. Let’s say that the intervention
    actually has no effect, such that reading scores for each individual are simply
    independent samples from a normal distribution. Results from a computer simulation
    of this hypothetic experiment are presented in Table [14.1](the-general-linear-model.html#tab:readingTable).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*回归到平均值*的概念是高尔顿对科学的重要贡献之一，当我们解释实验数据分析的结果时，这仍然是一个关键点。假设我们想研究阅读干预对差阅读者表现的影响。为了测试我们的假设，我们可能会进入学校并招募那些在某项阅读测试的分布中处于最低25%的个体，进行干预，然后检查他们在干预后的测试中的表现。假设干预实际上没有效果，这样每个个体的阅读分数只是来自正态分布的独立样本。这个假设实验的计算机模拟结果在表[14.1](the-general-linear-model.html#tab:readingTable)中呈现。'
- en: 'Table 14.1: Reading scores for Test 1 (which is lower, because it was the basis
    for selecting the students) and Test 2 (which is higher because it was not related
    to Test 1).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.1：测试1的阅读分数（较低，因为它是选择学生的基础）和测试2的阅读分数（较高，因为它与测试1无关）。
- en: '|  | Score |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  | 分数 |'
- en: '| --- | --- |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Test 1 | 88 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 测试1 | 88 |'
- en: '| Test 2 | 101 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 测试2 | 101 |'
- en: If we look at the difference between the mean test performance at the first
    and second test, it appears that the intervention has helped these students substantially,
    as their scores have gone up by more than ten points on the test! However, we
    know that in fact the students didn’t improve at all, since in both cases the
    scores were simply selected from a random normal distribution. What has happened
    is that some students scored badly on the first test simply due to random chance.
    If we select just those subjects on the basis of their first test scores, they
    are guaranteed to move back towards the mean of the entire group on the second
    test, even if there is no effect of training. This is the reason that we always
    need an untreated *control group* in order to interpret any changes in performance
    due to an intervention; otherwise we are likely to be tricked by regression to
    the mean. In addition, the participants need to be randomly assigned to the control
    or treatment group, so that there won’t be any systematic differences between
    the groups (on average).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看一下第一次和第二次测试的平均测试表现之间的差异，似乎干预帮助了这些学生，因为他们的分数在测试中提高了超过十分！然而，我们知道实际上学生们并没有改善，因为在这两种情况下，分数只是从随机正态分布中随机选择的。发生的是一些学生在第一次测试中由于随机机会而表现不佳。如果我们仅基于他们的第一次测试成绩选择这些学科，他们肯定会在第二次测试中回到整个组的平均水平，即使培训没有任何效果。这就是为什么我们总是需要一个未经处理的*对照组*来解释由于干预而导致的任何性能变化；否则我们很可能会被回归到平均值所欺骗。此外，参与者需要被随机分配到对照组或治疗组，这样两组之间就不会有任何系统性差异（平均而言）。
- en: 14.1.2 The relation between correlation and regression
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.2 相关和回归之间的关系
- en: 'There is a close relationship between correlation coefficients and regression
    coefficients. Remember that Pearson’s correlation coefficient is computed as the
    ratio of the covariance and the product of the standard deviations of x and y:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 相关系数和回归系数之间有着密切的关系。记住Pearson相关系数是由x和y的协方差和标准差的乘积的比值计算得出的：
- en: '\[ \hat{r} = \frac{covariance_{xy}}{s_x * s_y} \] whereas the regression beta
    for x is computed as:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{r} = \frac{covariance_{xy}}{s_x * s_y} \] 而x的回归beta计算如下：
- en: \[ \hat{\beta_x} = \frac{covariance_{xy}}{s_x*s_x} \]
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{\beta_x} = \frac{covariance_{xy}}{s_x*s_x} \]
- en: 'Based on these two equations, we can derive the relationship between \(\hat{r}\)
    and \(\hat{beta}\):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这两个方程，我们可以推导出\(\hat{r}\)和\(\hat{beta}\)之间的关系：
- en: \[ covariance_{xy} = \hat{r} * s_x * s_y \]
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: \[ covariance_{xy} = \hat{r} * s_x * s_y \]
- en: \[ \hat{\beta_x} = \frac{\hat{r} * s_x * s_y}{s_x * s_x} = r * \frac{s_y}{s_x}
    \] That is, the regression slope is equal to the correlation value multiplied
    by the ratio of standard deviations of y and x. One thing this tells us is that
    when the standard deviations of x and y are the same (e.g. when the data have
    been converted to Z scores), then the correlation estimate is equal to the regression
    slope estimate.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{\beta_x} = \frac{\hat{r} * s_x * s_y}{s_x * s_x} = r * \frac{s_y}{s_x}
    \] 也就是说，回归斜率等于相关值乘以y和x的标准差的比值。这告诉我们的一件事是，当x和y的标准差相同时（例如当数据已转换为Z分数时），相关估计等于回归斜率估计。
- en: 14.1.3 Standard errors for regression models
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.3 回归模型的标准误差
- en: 'If we want to make inferences about the regression parameter estimates, then
    we also need an estimate of their variability. To compute this, we first need
    to compute the *residual variance* or *error variance* for the model – that is,
    how much variability in the dependent variable is not explained by the model.
    We can compute the model residuals as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想对回归参数估计进行推断，那么我们还需要估计它们的变异性。为了计算这一点，我们首先需要计算模型的*残差方差*或*误差方差*——也就是，因变量中有多少变异性不是由模型解释的。我们可以计算模型残差如下：
- en: '\[ residual = y - \hat{y} = y - (x*\hat{\beta_x} + \hat{\beta_0}) \] We then
    compute the *sum of squared errors (SSE)*:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: \[ residual = y - \hat{y} = y - (x*\hat{\beta_x} + \hat{\beta_0}) \] 然后我们计算*平方误差和（SSE）*：
- en: '\[ SS_{error} = \sum_{i=1}^n{(y_i - \hat{y_i})^2} = \sum_{i=1}^n{residuals^2}
    \] and from this we compute the *mean squared error*:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: \[ SS_{error} = \sum_{i=1}^n{(y_i - \hat{y_i})^2} = \sum_{i=1}^n{residuals^2}
    \] 然后我们计算*均方误差*：
- en: '\[ MS_{error} = \frac{SS_{error}}{df} = \frac{\sum_{i=1}^n{(y_i - \hat{y_i})^2}
    }{N - p} \] where the degrees of freedom (\(df\)) are determined by subtracting
    the number of estimated parameters (2 in this case: \(\hat{\beta_x}\) and \(\hat{\beta_0}\))
    from the number of observations (\(N\)). Once we have the mean squared error,
    we can compute the standard error for the model as:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: \[ MS_{error} = \frac{SS_{error}}{df} = \frac{\sum_{i=1}^n{(y_i - \hat{y_i})^2}
    }{N - p} \] 其中自由度（\(df\)）由观测数（\(N\)）减去估计参数数（在这种情况下为2：\(\hat{\beta_x}\)和\(\hat{\beta_0}\)）确定。一旦我们有了均方误差，我们就可以计算模型的标准误差。
- en: \[ SE_{model} = \sqrt{MS_{error}} \]
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: \[ SE_{model} = \sqrt{MS_{error}} \]
- en: 'In order to get the standard error for a specific regression parameter estimate,
    \(SE_{\beta_x}\), we need to rescale the standard error of the model by the square
    root of the sum of squares of the X variable:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得特定回归参数估计的标准误差\(SE_{\beta_x}\)，我们需要通过X变量的平方和的平方根重新调整模型的标准误差：
- en: \[ SE_{\hat{\beta}_x} = \frac{SE_{model}}{\sqrt{{\sum{(x_i - \bar{x})^2}}}}
    \]
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: \[ SE_{\hat{\beta}_x} = \frac{SE_{model}}{\sqrt{{\sum{(x_i - \bar{x})^2}}}}
    \]
- en: 14.1.4 Statistical tests for regression parameters
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.4 回归参数的统计检验
- en: 'Once we have the parameter estimates and their standard errors, we can compute
    a *t* statistic to tell us the likelihood of the observed parameter estimates
    compared to some expected value under the null hypothesis. In this case we will
    test against the null hypothesis of no effect (i.e. \(\beta=0\)):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了参数估计和它们的标准误差，我们就可以计算一个*t*统计量，告诉我们观察到的参数估计与零假设下的某个期望值相比的可能性。在这种情况下，我们将针对没有效果的零假设进行检验（即\(\beta=0\)）：
- en: \[ \begin{array}{c} t_{N - p} = \frac{\hat{\beta} - \beta_{expected}}{SE_{\hat{\beta}}}\\
    t_{N - p} = \frac{\hat{\beta} - 0}{SE_{\hat{\beta}}}\\ t_{N - p} = \frac{\hat{\beta}
    }{SE_{\hat{\beta}}} \end{array} \]
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{array}{c} t_{N - p} = \frac{\hat{\beta} - \beta_{expected}}{SE_{\hat{\beta}}}\\
    t_{N - p} = \frac{\hat{\beta} - 0}{SE_{\hat{\beta}}}\\ t_{N - p} = \frac{\hat{\beta}
    }{SE_{\hat{\beta}}} \end{array} \]
- en: 'In general we would use statistical software to compute these rather than computing
    them by hand. Here are the results from the linear model function in R:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们会使用统计软件来计算这些值，而不是手工计算。以下是R中线性模型函数的结果：
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this case we see that the intercept is significantly different from zero
    (which is not very interesting) and that the effect of studyTime on grades is
    marginally significant (p = .09) – the same p-value as the correlation test that
    we performed earlier.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们看到截距与零显著不同（这并不是很有趣），而studyTime对成绩的影响略显显著（p = .09）- 与我们之前进行的相关性检验相同的p值。
- en: 14.1.5 Quantifying goodness of fit of the model
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.5 量化模型的拟合优度
- en: 'Sometimes it’s useful to quantify how well the model fits the data overall,
    and one way to do this is to ask how much of the variability in the data is accounted
    for by the model. This is quantified using a value called \(R^2\) (also known
    as the *coefficient of determination*). If there is only one x variable, then
    this is easy to compute by simply squaring the correlation coefficient:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候量化模型整体拟合数据的好坏是很有用的，其中一种方法是询问模型能解释数据变异性的多少。这可以用一个叫做\(R^2\)的值来量化（也被称为*决定系数*）。如果只有一个x变量，那么可以通过简单地平方相关系数来计算：
- en: \[ R^2 = r^2 \] In the case of our study time example, \(R^2\) = 0.4, which
    means that we have accounted for about 40% of the variance in grades.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: \[ R^2 = r^2 \] 在我们的学习时间示例中，\(R^2\) = 0.4，这意味着我们解释了大约40%的成绩方差。
- en: 'More generally we can think of \(R^2\) as a measure of the fraction of variance
    in the data that is accounted for by the model, which can be computed by breaking
    the variance into multiple components:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地，我们可以将\(R^2\)看作是模型解释数据方差的比例，可以通过将方差分解为多个部分来计算：
- en: '**THIS IS CONFUSING, CHANGE TO RESIDUAL RATHER THAN ERROR**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这很令人困惑，改为残差而不是误差
- en: '\[ SS_{total} = SS_{model} + SS_{error} \] where \(SS_{total}\) is the variance
    of the data (\(y\)) and \(SS_{model}\) and \(SS_{error}\) are computed as shown
    earlier in this chapter. Using this, we can then compute the coefficient of determination
    as:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: \[ SS_{total} = SS_{model} + SS_{error} \] 其中\(SS_{total}\)是数据（\(y\)）的方差，\(SS_{model}\)和\(SS_{error}\)如本章前面所示计算。有了这些，我们可以计算决定系数：
- en: \[ R^2 = \frac{SS_{model}}{SS_{total}} = 1 - \frac{SS_{error}}{SS_{total}} \]
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: \[ R^2 = \frac{SS_{model}}{SS_{total}} = 1 - \frac{SS_{error}}{SS_{total}} \]
- en: A small value of \(R^2\) tells us that even if the model fit is statistically
    significant, it may only explain a small amount of information in the data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一个小的\(R^2\)值告诉我们，即使模型拟合在统计上是显著的，它可能只解释了数据中的一小部分信息。
- en: 14.2 Fitting more complex models
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.2 拟合更复杂的模型
- en: 'Often we would like to understand the effects of multiple variables on some
    particular outcome, and how they relate to one another. In the context of our
    study time example, let’s say that we discovered that some of the students had
    previously taken a course on the topic. If we plot their grades (see Figure [14.3](the-general-linear-model.html#fig:LinearRegressionByPriorClass)),
    we can see that those who had a prior course perform much better than those who
    had not, given the same amount of study time. We would like to build a statistical
    model that takes this into account, which we can do by extending the model that
    we built above:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通常我们希望了解多个变量对某个特定结果的影响，以及它们之间的关系。在我们的学习时间示例中，假设我们发现一些学生之前曾上过相关课程。如果我们绘制他们的成绩（见图[14.3](the-general-linear-model.html#fig:LinearRegressionByPriorClass)），我们可以看到那些之前上过课程的学生在相同的学习时间下表现得比那些没有上过课程的学生要好得多。我们希望建立一个统计模型来考虑这一点，我们可以通过扩展上面建立的模型来实现：
- en: \[ \hat{y} = \hat{\beta_1}*studyTime + \hat{\beta_2}*priorClass + \hat{\beta_0}
    \] To model whether each individual has had a previous class or not, we use what
    we call *dummy coding* in which we create a new variable that has a value of one
    to represent having had a class before, and zero otherwise. This means that for
    people who have had the class before, we will simply add the value of \(\hat{\beta_2}\)
    to our predicted value for them – that is, using dummy coding \(\hat{\beta_2}\)
    simply reflects the difference in means between the two groups. Our estimate of
    \(\hat{\beta_1}\) reflects the regression slope over all of the data points –
    we are assuming that regression slope is the same regardless of whether someone
    has had a class before (see Figure [14.3](the-general-linear-model.html#fig:LinearRegressionByPriorClass)).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y} = \hat{\beta_1}*studyTime + \hat{\beta_2}*priorClass + \hat{\beta_0}
    \] 为了模拟每个个体是否之前上过课程，我们使用所谓的*虚拟编码*，其中我们创建一个新变量，其值为1表示之前上过课程，否则为0。这意味着对于之前上过课程的人，我们将简单地将\(\hat{\beta_2}\)的值添加到他们的预测值中-也就是说，使用虚拟编码，\(\hat{\beta_2}\)反映了两组之间的均值差异。我们对\(\hat{\beta_1}\)的估计反映了所有数据点的回归斜率-我们假设回归斜率在某人之前是否上过课程的情况下是相同的（见图[14.3](the-general-linear-model.html#fig:LinearRegressionByPriorClass)）。
- en: '[PRE2]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![The relation between study time and grade including prior experience as an
    additional component in the model.  The solid line relates study time to grades
    for students who have not had prior experience, and the dashed line relates grades
    to study time for students with prior experience. The dotted line corresponds
    to the difference in means between the two groups.](../Images/4d7f435c27dcbedda19edbe5b11da0ef.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![包括先前经验作为模型中的额外组成部分的学习时间和成绩之间的关系。实线将学习时间与没有先前经验的学生的成绩相关联，虚线将成绩与有先前经验的学生的学习时间相关联。点线对应于两组之间的均值差异。](../Images/4d7f435c27dcbedda19edbe5b11da0ef.png)'
- en: 'Figure 14.3: The relation between study time and grade including prior experience
    as an additional component in the model. The solid line relates study time to
    grades for students who have not had prior experience, and the dashed line relates
    grades to study time for students with prior experience. The dotted line corresponds
    to the difference in means between the two groups.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3：包括先前经验作为模型中的附加组件的学习时间和成绩之间的关系。实线将学习时间与没有先前经验的学生的成绩联系起来，虚线将成绩与具有先前经验的学生的学习时间联系起来。点线对应于两组之间的平均差异。
- en: 14.3 Interactions between variables
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.3 变量之间的交互作用
- en: In the previous model, we assumed that the effect of study time on grade (i.e.,
    the regression slope) was the same for both groups. However, in some cases we
    might imagine that the effect of one variable might differ depending on the value
    of another variable, which we refer to as an *interaction* between variables.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的模型中，我们假设学习时间对成绩的影响（即回归斜率）对两组是相同的。然而，在某些情况下，我们可能会想象一个变量的影响可能会根据另一个变量的值而有所不同，我们称之为变量之间的*交互作用*。
- en: 'Let’s use a new example that asks the question: What is the effect of caffeine
    on public speaking? First let’s generate some data and plot them. Looking at panel
    A of Figure [14.4](the-general-linear-model.html#fig:CaffeineAnxietyInteraction),
    there doesn’t seem to be a relationship, and we can confirm that by performing
    linear regression on the data:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一个新的例子来提出问题：咖啡因对公开演讲有什么影响？首先让我们生成一些数据并绘制它们。从图[14.4](the-general-linear-model.html#fig:CaffeineAnxietyInteraction)的A面来看，似乎没有关系，我们可以通过对数据进行线性回归来确认这一点。
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: But now let’s say that we find research suggesting that anxious and non-anxious
    people react differently to caffeine. First let’s plot the data separately for
    anxious and non-anxious people.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在假设我们发现研究表明焦虑和非焦虑的人对咖啡因有不同的反应。首先让我们分别为焦虑和非焦虑的人绘制数据。
- en: As we see from panel B in Figure [14.4](the-general-linear-model.html#fig:CaffeineAnxietyInteraction),
    it appears that the relationship between speaking and caffeine is different for
    the two groups, with caffeine improving performance for people without anxiety
    and degrading performance for those with anxiety. We’d like to create a statistical
    model that addresses this question. First let’s see what happens if we just include
    anxiety in the model.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从图[14.4](the-general-linear-model.html#fig:CaffeineAnxietyInteraction)的B面可以看出，似乎演讲和咖啡因之间的关系对两组是不同的，咖啡因可以提高没有焦虑的人的表现，但会降低有焦虑的人的表现。我们想要创建一个可以回答这个问题的统计模型。首先让我们看看如果我们只在模型中包括焦虑会发生什么。
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here we see there are no significant effects of either caffeine or anxiety,
    which might seem a bit confusing. The problem is that this model is trying to
    use the same slope relating speaking to caffeine for both groups. If we want to
    fit them using lines with separate slopes, we need to include an *interaction*
    in the model, which is equivalent to fitting different lines for each of the two
    groups; this is often denoted by using the \(*\) symbol in the model.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们看到咖啡因和焦虑都没有显著的影响，这可能有点令人困惑。问题在于这个模型试图使用相同的斜率来关联演讲和咖啡因对两组。如果我们想要使用具有不同斜率的线来拟合它们，我们需要在模型中包括*交互作用*，这相当于为两组中的每一组拟合不同的线；这通常用在模型中使用\(*)符号来表示。
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: From these results we see that there are significant effects of both caffeine
    and anxiety (which we call *main effects*) and an interaction between caffeine
    and anxiety. Panel C in Figure [14.4](the-general-linear-model.html#fig:CaffeineAnxietyInteraction)
    shows the separate regression lines for each group.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些结果中，我们看到咖啡因和焦虑都有显著的影响（我们称之为*主效应*），以及咖啡因和焦虑之间的交互作用。图14.4的C面显示了每组的分开回归线。
- en: '![A: The relationship between caffeine and public speaking. B: The relationship
    between caffeine and public speaking, with anxiety represented by the shape of
    the data points. C: The relationship between public speaking and caffeine, including
    an interaction with anxiety.  This results in two lines that separately model
    the slope for each group (dashed for anxious, dotted for non-anxious).](../Images/32d70c3a28ffa5708397282adefb6553.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![A：咖啡因和公开演讲之间的关系。B：咖啡因和公开演讲之间的关系，焦虑由数据点的形状表示。C：公开演讲和咖啡因之间的关系，包括与焦虑的交互作用。这导致了两条分别为每组建模的线（对焦虑的虚线，对非焦虑的点线）。](../Images/32d70c3a28ffa5708397282adefb6553.png)'
- en: 'Figure 14.4: A: The relationship between caffeine and public speaking. B: The
    relationship between caffeine and public speaking, with anxiety represented by
    the shape of the data points. C: The relationship between public speaking and
    caffeine, including an interaction with anxiety. This results in two lines that
    separately model the slope for each group (dashed for anxious, dotted for non-anxious).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4：A：咖啡因和公开演讲之间的关系。B：咖啡因和公开演讲之间的关系，焦虑由数据点的形状表示。C：公开演讲和咖啡因之间的关系，包括与焦虑的交互作用。这导致了两条分别为每组建模的线（对焦虑的虚线，对非焦虑的点线）。
- en: One important point to note is that we have to be very careful about interpreting
    a significant main effect if a significant interaction is also present, since
    the interaction suggests that the main effect differs according to the values
    of another variable, and thus is not easily interpretable.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的要点是，如果存在显著的交互作用，我们必须非常小心地解释显著的主效应，因为交互作用表明主效应根据另一个变量的值而不同，因此不容易解释。
- en: 'Sometimes we want to compare the relative fit of two different models, in order
    to determine which is a better model; we refer to this as *model comparison*.
    For the models above, we can compare the goodness of fit of the model with and
    without the interaction, using what is called an *analysis of variance*:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们想要比较两个不同模型的相对拟合，以确定哪个是更好的模型；我们称之为*模型比较*。对于上面的模型，我们可以使用所谓的*方差分析*来比较具有交互作用和不具有交互作用的模型的拟合度：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This tells us that there is good evidence to prefer the model with the interaction
    over the one without an interaction. Model comparison is relatively simple in
    this case because the two models are *nested* – one of the models is a simplified
    version of the other model, such that all of the variables in the simpler model
    are contained in the more complex model. Model comparison with non-nested models
    can get much more complicated.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们有很好的证据表明，更喜欢具有交互作用的模型而不是没有交互作用的模型。在这种情况下，模型比较相对简单，因为这两个模型是*嵌套*的 - 其中一个模型是另一个模型的简化版本，简化模型中的所有变量都包含在更复杂的模型中。与非嵌套模型的模型比较可能会变得更加复杂。
- en: 14.4 Beyond linear predictors and outcomes
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.4 超越线性预测和结果
- en: It is important to note that despite the fact that it is called the general
    *linear* model, we can actually use the same machinery to model effects that don’t
    follow a straight line (such as curves). The “linear” in the general linear model
    doesn’t refer to the shape of the response, but instead refers to the fact that
    model is linear in its parameters — that is, the predictors in the model only
    get multiplied the parameters, rather than a nonlinear relationship like being
    raised to a power of the parameter. It’s also common to analyze data where the
    outcomes are binary rather than continuous, as we saw in the chapter on categorical
    outcomes. There are ways to adapt the general linear model (known as *generalized
    linear models*) that allow this kind of analysis. We will explore these models
    later in the book.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，尽管它被称为一般*线性*模型，我们实际上可以使用相同的方法来建模不遵循直线的效应（如曲线）。一般线性模型中的“线性”并不是指响应的形状，而是指模型在其参数上是线性的
    - 也就是说，模型中的预测变量只与参数相乘，而不是像被提高到参数的幂这样的非线性关系。分析的数据通常是二元的而不是连续的，正如我们在分类结果的章节中所看到的那样。有一些方法可以调整一般线性模型（称为*广义线性模型*），允许进行这种类型的分析。我们将在本书的后面探讨这些模型。
- en: 14.5 Criticizing our model and checking assumptions
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.5 批评我们的模型和检查假设
- en: The saying “garbage in, garbage out” is as true of statistics as anywhere else.
    In the case of statistical models, we have to make sure that our model is properly
    specified and that our data are appropriate for the model.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: “垃圾进，垃圾出”这句话在统计学中同样适用。在统计模型的情况下，我们必须确保我们的模型被正确指定，并且我们的数据适合模型。
- en: When we say that the model is “properly specified”, we mean that we have included
    the appropriate set of independent variables in the model. We have already seen
    examples of misspecified models, in Figure [5.3](fitting-models.html#fig:childHeightLine).
    Remember that we saw several cases where the model failed to properly account
    for the data, such as failing to include an intercept. When building a model,
    we need to ensure that it includes all of the appropriate variables.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说模型“被正确指定”时，我们的意思是我们已经在模型中包含了适当的自变量集。我们已经看到了错误指定模型的例子，在图[5.3](fitting-models.html#fig:childHeightLine)中。请记住，我们看到了几种情况，模型未能正确解释数据，比如未包括截距。在构建模型时，我们需要确保它包括所有适当的变量。
- en: We also need to worry about whether our model satisfies the assumptions of our
    statistical methods. One of the most important assumptions that we make when using
    the general linear model is that the residuals (that is, the difference between
    the model’s predictions and the actual data) are normally distributed. This can
    fail for many reasons, either because the model was not properly specified or
    because the data that we are modeling are inappropriate.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要担心我们的模型是否满足我们统计方法的假设。当使用一般线性模型时，我们做出的最重要的假设之一是残差（即模型预测与实际数据之间的差异）是正态分布的。这可能会因为模型未正确指定或者我们建模的数据不合适而失败。
- en: We can use something called a *Q-Q* (quantile-quantile) plot to see whether
    our residuals are normally distributed. You have already encountered *quantiles*
    — they are the value that cuts off a particular proportion of a cumulative distribution.
    The Q-Q plot presents the quantiles of two distributions against one another;
    in this case, we will present the quantiles of the actual data against the quantiles
    of a normal distribution fit to the same data. Figure [14.5](the-general-linear-model.html#fig:qqplots)
    shows examples of two such Q-Q plots. The left panel shows a Q-Q plot for data
    from a normal distribution, while the right panel shows a Q-Q plot from non-normal
    data. The data points in the right panel diverge substantially from the line,
    reflecting the fact that they are not normally distributed.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用称为*Q-Q*（分位数-分位数）图来查看我们的残差是否服从正态分布。您已经遇到过*分位数* - 它们是截断特定累积分布的比例值。Q-Q图将两个分布的分位数相互对比；在这种情况下，我们将实际数据的分位数与同一数据拟合的正态分布的分位数进行对比。图[14.5](the-general-linear-model.html#fig:qqplots)显示了两个这样的Q-Q图的示例。左侧面板显示了来自正态分布的数据的Q-Q图，而右侧面板显示了来自非正态数据的Q-Q图。右侧面板中的数据点与线明显偏离，反映了它们不是正态分布的事实。
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Q-Q plotsof normal (left) and non-normal (right) data.  The line shows the
    point at which the x and y axes are equal.](../Images/f485926309d72c7d88bad24916b6b5b9.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![正态（左）和非正态（右）数据的Q-Q图。线显示了x轴和y轴相等的点。](../Images/f485926309d72c7d88bad24916b6b5b9.png)'
- en: 'Figure 14.5: Q-Q plotsof normal (left) and non-normal (right) data. The line
    shows the point at which the x and y axes are equal.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.5：正态（左）和非正态（右）数据的Q-Q图。线显示了x轴和y轴相等的点。
- en: Model diagnostics will be explored in more detail in a later chapter.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 模型诊断将在后面的章节中更详细地探讨。
- en: 14.6 What does “predict” really mean?
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.6 “预测”真正意味着什么？
- en: When we talk about “prediction” in daily life, we are generally referring to
    the ability to estimate the value of some variable in advance of seeing the data.
    However, the term is often used in the context of linear regression to refer to
    the fitting of a model to the data; the estimated values (\(\hat{y}\)) are sometimes
    referred to as “predictions” and the independent variables are referred to as
    “predictors”. This has an unfortunate connotation, as it implies that our model
    should also be able to predict the values of new data points in the future. In
    reality, the fit of a model to the dataset used to obtain the parameters will
    nearly always be better than the fit of the model to a new dataset ([Copas 1983](#ref-copa:1983)).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在日常生活中谈论“预测”时，我们通常指的是在看到数据之前估计某个变量的值的能力。然而，在线性回归的背景下，这个术语通常用来指代将模型拟合到数据；估计的值（\(\hat{y}\)）有时被称为“预测”，而独立变量被称为“预测变量”。这有一个不幸的含义，因为它意味着我们的模型也应该能够预测未来新数据点的值。实际上，将模型拟合到用于获取参数的数据集的拟合几乎总是比将模型拟合到新数据集的拟合要好（[Copas
    1983](#ref-copa:1983)）。
- en: As an example, let’s take a sample of 48 children from NHANES and fit a regression
    model for weight that includes several regressors (age, height, hours spent watching
    TV and using the computer, and household income) along with their interactions.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们从NHANES中抽取48个儿童的样本，并为包括几个回归器（年龄、身高、看电视和使用电脑的小时数以及家庭收入）及其交互作用的体重拟合回归模型。
- en: 'Table 14.2: Root mean squared error for model applied to original data and
    new data, and after shuffling the order of the y variable (in essence making the
    null hypothesis true)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.2：应用于原始数据和新数据的模型的均方根误差，以及在对y变量的顺序进行洗牌后的结果（实质上使零假设成立）
- en: '| Data type | RMSE (original data) | RMSE (new data) |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 数据类型 | RMSE（原始数据） | RMSE（新数据） |'
- en: '| --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| True data | 3.0 | 25 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 真实数据 | 3.0 | 25 |'
- en: '| Shuffled data | 7.8 | 59 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 洗牌数据 | 7.8 | 59 |'
- en: Here we see that whereas the model fit on the original data showed a very good
    fit (only off by a few kg per individual), the same model does a much worse job
    of predicting the weight values for new children sampled from the same population
    (off by more than 25 kg per individual). This happens because the model that we
    specified is quite complex, since it includes not just each of the individual
    variables, but also all possible combinations of them (i.e. their *interactions*),
    resulting in a model with 32 parameters. Since this is almost as many coefficients
    as there are data points (i.e., the heights of 48 children), the model *overfits*
    the data, just like the complex polynomial curve in our initial example of overfitting
    in Section [5.4](fitting-models.html#overfitting).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到，尽管在原始数据上拟合的模型显示出非常好的拟合（每个个体只有几公斤的偏差），但对于从同一人群中抽样的新儿童的体重值，同样的模型预测效果要差得多（每个个体超过25公斤的偏差）。这是因为我们指定的模型相当复杂，因为它不仅包括每个单独的变量，还包括它们的所有可能组合（即它们的*交互作用*），导致一个具有32个参数的模型。由于这几乎与数据点（即48个儿童的身高）一样多的系数，该模型对数据*过拟合*，就像我们在[5.4](fitting-models.html#overfitting)节中过拟合的初始示例中的复杂多项式曲线一样。
- en: Another way to see the effects of overfitting is to look at what happens if
    we randomly shuffle the values of the weight variable (shown in the second row
    of the table). Randomly shuffling the value should make it impossible to predict
    weight from the other variables, because they should have no systematic relationship.
    The results in the table show that even when there is no true relationship to
    be modeled (because shuffling should have obliterated the relationship), the complex
    model still shows a very low error in its predictions on the fitted data, because
    it fits the noise in the specific dataset. However, when that model is applied
    to a new dataset, we see that the error is much larger, as it should be.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种看过拟合效果的方法是看看如果我们随机洗牌权重变量的值会发生什么（在表的第二行显示）。随机洗牌的值应该使得从其他变量预测权重变得不可能，因为它们不应该有系统关系。表中的结果表明，即使没有真正的关系要建模（因为洗牌应该已经消除了关系），复杂模型在拟合数据的预测中仍然显示出非常低的误差，因为它适应了特定数据集中的噪音。然而，当该模型应用于新数据集时，我们看到误差要大得多，正如应该的那样。
- en: 14.6.1 Cross-validation
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.6.1 交叉验证
- en: One method that has been developed to help address the problem of overfitting
    is known as *cross-validation*. This technique is commonly used within the field
    of machine learning, which is focused on building models that will generalize
    well to new data, even when we don’t have a new dataset to test the model. The
    idea behind cross-validation is that we fit our model repeatedly, each time leaving
    out a subset of the data, and then test the ability of the model to predict the
    values in each held-out subset.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决过拟合问题，已经开发出一种称为*交叉验证*的方法。这种技术通常在机器学习领域中使用，该领域专注于构建能够很好地推广到新数据的模型，即使我们没有新的数据集来测试模型。交叉验证的想法是，我们反复拟合我们的模型，每次都留出一部分数据，然后测试模型预测每个保留子集中的值的能力。
- en: '![A schematic of the  cross-validation procedure.](../Images/02ac5fd9e69889c03b0b2c0c1ef9a2d6.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![交叉验证程序的示意图。](../Images/02ac5fd9e69889c03b0b2c0c1ef9a2d6.png)'
- en: 'Figure 14.6: A schematic of the cross-validation procedure.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.6：交叉验证程序的示意图。
- en: Let’s see how that would work for our weight prediction example. In this case
    we will perform 12-fold cross-validation, which means that we will break the data
    into 12 subsets, and then fit the model 12 times, in each case leaving out one
    of the subsets and then testing the model’s ability to accurately predict the
    value of the dependent variable for those held-out data points. Most statistical
    software provides tools to apply cross-validation to one’s data. Using this function
    we can run cross-validation on 100 samples from the NHANES dataset, and compute
    the RMSE for cross-validation, along with the RMSE for the original data and a
    new dataset, as we computed above.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这对我们的体重预测例子会有什么影响。在这种情况下，我们将进行12折交叉验证，这意味着我们将数据分成12个子集，然后在每种情况下拟合模型12次，每次留出一个子集，然后测试模型对这些留出数据点的因变量值的准确预测能力。大多数统计软件都提供工具来对数据应用交叉验证。使用这个函数，我们可以在NHANES数据集的100个样本上运行交叉验证，并计算交叉验证的RMSE，以及原始数据和新数据的RMSE，就像我们上面计算的那样。
- en: 'Table 14.3: R-squared from cross-validation and new data, showing that cross-validation
    provides a reasonable estimate of the model’s performance on new data.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.3：交叉验证和新数据的R平方，显示交叉验证提供了对模型在新数据上性能的合理估计。
- en: '|  | R-squared |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  | R平方 |'
- en: '| --- | --- |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Original data | 0.95 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 原始数据 | 0.95 |'
- en: '| New data | 0.34 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 新数据 | 0.34 |'
- en: '| Cross-validation | 0.60 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 交叉验证 | 0.60 |'
- en: Here we see that cross-validation gives us an estimate of predictive accuracy
    that is much closer to what we see with a completely new dataset than it is to
    the inflated accuracy that we see with the original dataset – in fact, it’s even
    slightly more pessimistic than the average for a new dataset, probably because
    only part of the data are being used to train each of the models.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到交叉验证给出了一个对预测准确性的估计，这个估计比我们在原始数据集上看到的要接近一个全新数据集的情况，实际上，它甚至比一个新数据集的平均值稍微悲观一些，可能是因为只有部分数据被用来训练每个模型。
- en: 'Note that using cross-validation properly is tricky, and it is recommended
    that you consult with an expert before using it in practice. However, this section
    has hopefully shown you three things:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，正确使用交叉验证是棘手的，建议在实践中使用之前咨询专家。然而，本节希望向你展示了三件事：
- en: “Prediction” doesn’t always mean what you think it means
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “预测”并不总是意味着你认为的那样
- en: Complex models can overfit data very badly, such that one can observe seemingly
    good prediction even when there is no true signal to predict
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂模型可能会严重过拟合数据，以至于即使没有真正的信号来预测，也会观察到看似良好的预测
- en: You should view claims about prediction accuracy very skeptically unless they
    have been done using the appropriate methods.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除非使用了适当的方法，否则对预测准确性的声明应该持怀疑态度。
- en: 14.7 Learning objectives
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.7 学习目标
- en: 'Having read this chapter, you should be able to:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完本章后，你应该能够：
- en: Describe the concept of linear regression and apply it to a dataset
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述线性回归的概念，并将其应用于数据集
- en: Describe the concept of the general linear model and provide examples of its
    application
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述一般线性模型的概念，并提供其应用示例
- en: Describe how cross-validation can allow us to estimate the predictive performance
    of a model on new data
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述交叉验证如何允许我们估计模型在新数据上的预测性能
- en: 14.8 Suggested readings
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.8 建议阅读
- en: '[The Elements of Statistical Learning: Data Mining, Inference, and Prediction
    (2nd Edition)](https://web.stanford.edu/~hastie/Papers/ESLII.pdf) - The “bible”
    of machine learning methods, available freely online.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[统计学习的要素：数据挖掘、推断和预测（第二版）](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)
    - 机器学习方法的“圣经”，可在网上免费获取。'
- en: 14.9 Appendix
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.9 附录
- en: 14.9.1 Estimating linear regression parameters
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.9.1 估计线性回归参数
- en: We generally estimate the parameters of a linear model from data using *linear
    algebra*, which is the form of algebra that is applied to vectors and matrices.
    If you aren’t familiar with linear algebra, don’t worry – you won’t actually need
    to use it here, as R will do all the work for us. However, a brief excursion in
    linear algebra can provide some insight into how the model parameters are estimated
    in practice.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常使用*线性代数*从数据中估计线性模型的参数，线性代数是应用于向量和矩阵的代数形式。如果你不熟悉线性代数，不用担心 - 你实际上不需要在这里使用它，因为R会为我们做所有的工作。然而，简短的线性代数探讨可以提供一些关于模型参数在实践中是如何估计的见解。
- en: First, let’s introduce the idea of vectors and matrices; you’ve already encountered
    them in the context of R, but we will review them here. A matrix is a set of numbers
    that are arranged in a square or rectangle, such that there are one or more *dimensions*
    across which the matrix varies. It is customary to place different observation
    units (such as people) in the rows, and different variables in the columns. Let’s
    take our study time data from above. We could arrange these numbers in a matrix,
    which would have eight rows (one for each student) and two columns (one for study
    time, and one for grade). If you are thinking “that sounds like a data frame in
    R” you are exactly right! In fact, a data frame is a specialized version of a
    matrix, and we can convert a data frame to a matrix using the `as.matrix()` function.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们介绍向量和矩阵的概念；你已经在R的上下文中遇到过它们，但我们将在这里进行复习。矩阵是一组按照方形或矩形排列的数字，这样矩阵在一个或多个*维度*上变化。习惯上，将不同的观测单位（比如人）放在行中，将不同的变量放在列中。让我们拿上面的学习时间数据来说。我们可以将这些数字排列成一个矩阵，它将有八行（每个学生一行）和两列（一个是学习时间，一个是成绩）。如果你在想“这听起来像是R中的数据框”，那么你说对了！实际上，数据框是矩阵的一种特殊形式，我们可以使用`as.matrix()`函数将数据框转换为矩阵。
- en: '[PRE8]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can write the general linear model in linear algebra as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将一般线性模型用线性代数表示如下：
- en: \[ Y = X*\beta + E \] This looks very much like the earlier equation that we
    used, except that the letters are all capitalized, which is meant to express the
    fact that they are vectors.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Y = X*\beta + E \] 这看起来很像我们之前使用的方程，只是所有的字母都是大写的，这是为了表达它们是向量的事实。
- en: 'We know that the grade data go into the Y matrix, but what goes into the \(X\)
    matrix? Remember from our initial discussion of linear regression that we need
    to add a constant in addition to our independent variable of interest, so our
    \(X\) matrix (which we call the *design matrix*) needs to include two columns:
    one representing the study time variable, and one column with the same value for
    each individual (which we generally fill with all ones). We can view the resulting
    design matrix graphically (see Figure [14.7](the-general-linear-model.html#fig:GLMmatrix)).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道成绩数据进入Y矩阵，但\(X\)矩阵中放入了什么？请记住，从我们对线性回归的最初讨论中，我们需要在我们感兴趣的自变量之外添加一个常数，因此我们的\(X\)矩阵（我们称之为*设计矩阵*）需要包括两列：一个代表学习时间变量，另一列对于每个个体都具有相同的值（通常我们用全为1的值填充）。我们可以以图形方式查看生成的设计矩阵（参见图[14.7](the-general-linear-model.html#fig:GLMmatrix)）。
- en: '![A depiction of the linear model for the study time data in terms of matrix
    algebra.](../Images/7b286d54fddab136cbd662293ed87218.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![用矩阵代数表示学习时间数据的线性模型的描绘。](../Images/7b286d54fddab136cbd662293ed87218.png)'
- en: 'Figure 14.7: A depiction of the linear model for the study time data in terms
    of matrix algebra.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.7：用矩阵代数表示学习时间数据的线性模型的描绘。
- en: 'The rules of matrix multiplication tell us that the dimensions of the matrices
    have to match with one another; in this case, the design matrix has dimensions
    of 8 (rows) X 2 (columns) and the Y variable has dimensions of 8 X 1\. Therefore,
    the \(\beta\) matrix needs to have dimensions 2 X 1, since an 8 X 2 matrix multiplied
    by a 2 X 1 matrix results in an 8 X 1 matrix (as the matching middle dimensions
    drop out). The interpretation of the two values in the \(\beta\) matrix is that
    they are the values to be multipled by study time and 1 respectively to obtain
    the estimated grade for each individual. We can also view the linear model as
    a set of individual equations for each individual:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法规则告诉我们，矩阵的维度必须相互匹配；在这种情况下，设计矩阵的维度为8（行）X 2（列），Y变量的维度为8 X 1。因此，\(\beta\)矩阵的维度需要为2
    X 1，因为8 X 2矩阵乘以2 X 1矩阵的结果是8 X 1矩阵（因为匹配的中间维度被消除）。\(\beta\)矩阵中的两个值的解释是它们分别与学习时间和1相乘，以获得每个个体的估计成绩。我们还可以将线性模型视为每个个体的一组单独方程：
- en: \(\hat{y}_1 = studyTime_1*\beta_1 + 1*\beta_2\)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: \(\hat{y}_1 = studyTime_1*\beta_1 + 1*\beta_2\)
- en: \(\hat{y}_2 = studyTime_2*\beta_1 + 1*\beta_2\)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: \(\hat{y}_2 = studyTime_2*\beta_1 + 1*\beta_2\)
- en: …
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: \(\hat{y}_8 = studyTime_8*\beta_1 + 1*\beta_2\)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: \(\hat{y}_8 = studyTime_8*\beta_1 + 1*\beta_2\)
- en: 'Remember that our goal is to determine the best fitting values of \(\beta\)
    given the known values of \(X\) and \(Y\). A naive way to do this would be to
    solve for \(\beta\) using simple algebra – here we drop the error term \(E\) because
    it’s out of our control:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们的目标是确定给定\(X\)和\(Y\)的已知值的最佳拟合值\(\beta\)。一个天真的方法是使用简单的代数来解决\(\beta\) – 在这里我们忽略了误差项\(E\)，因为它不在我们的控制范围内：
- en: \[ \hat{\beta} = \frac{Y}{X} \]
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{\beta} = \frac{Y}{X} \]
- en: 'The challenge here is that \(X\) and \(\beta\) are now matrices, not single
    numbers – but the rules of linear algebra tell us how to divide by a matrix, which
    is the same as multiplying by the *inverse* of the matrix (referred to as \(X^{-1}\)).
    We can do this in R:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的挑战是\(X\)和\(\beta\)现在是矩阵，而不是单个数字 – 但线性代数的规则告诉我们如何除以矩阵，这与乘以矩阵的*逆*（称为\(X^{-1}\)）相同。我们可以在R中这样做：
- en: '[PRE9]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Anyone who is interested in serious use of statistical methods is highly encouraged
    to invest some time in learning linear algebra, as it provides the basis for nearly
    all of the tools that are used in standard statistics.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于对统计方法感兴趣的任何人，强烈建议投入一些时间学习线性代数，因为它为标准统计中使用的几乎所有工具提供了基础。
