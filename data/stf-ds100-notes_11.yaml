- en: 10  Introduction to Modeling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10  建模简介
- en: 原文：[https://ds100.org/course-notes/intro_to_modeling/intro_to_modeling.html](https://ds100.org/course-notes/intro_to_modeling/intro_to_modeling.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ds100.org/course-notes/intro_to_modeling/intro_to_modeling.html](https://ds100.org/course-notes/intro_to_modeling/intro_to_modeling.html)
- en: '*Learning Outcomes* ***   Understand what models are and how to carry out the
    four-step modeling process.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*学习成果* *** 了解模型是什么，以及如何进行四步建模过程。'
- en: Define the concept of loss and gain familiarity with \(L_1\) and \(L_2\) loss.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义损失概念并熟悉\(L_1\)和\(L_2\)损失。
- en: Fit the Simple Linear Regression model using minimization techniques.**  **Up
    until this point in the semester, we’ve focused on analyzing datasets. We’ve looked
    into the early stages of the data science lifecycle, focusing on the programming
    tools, visualization techniques, and data cleaning methods needed for data analysis.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最小化技术拟合简单线性回归模型。**直到本学期为止，我们一直专注于分析数据集。我们已经研究了数据科学生命周期的早期阶段，重点是用于数据分析所需的编程工具、可视化技术和数据清理方法。
- en: 'This lecture marks a shift in focus. We will move away from examining datasets
    to actually *using* our data to better understand the world. Specifically, the
    next sequence of lectures will explore predictive modeling: generating models
    to make some predictions about the world around us. In this lecture, we’ll introduce
    the conceptual framework for setting up a modeling task. In the next few lectures,
    we’ll put this framework into practice by implementing various kinds of models.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这节课标志着关注重点的转变。我们将不再只是检查数据集，而是实际*使用*我们的数据来更好地理解世界。具体来说，接下来的一系列讲座将探讨预测建模：生成模型以对我们周围的世界进行一些预测。在这节课上，我们将介绍建立建模任务的概念框架。在接下来的几节课中，我们将通过实现各种类型的模型来将这个框架付诸实践。
- en: 10.1 What is a Model?
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 什么是模型？
- en: 'A model is an **idealized representation** of a system. A system is a set of
    principles or procedures according to which something functions. We live in a
    world full of systems: the procedure of turning on a light happens according to
    a specific set of rules dictating the flow of electricity. The truth behind how
    any event occurs is usually complex, and many times the specifics are unknown.
    The workings of the world can be viewed as its own giant procedure. Models seek
    to simplify the world and distill them into workable pieces.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是对系统的**理想化表示**。系统是一组原则或程序，根据这些原则或程序，某事物的运行方式。我们生活在一个充满系统的世界：打开灯的程序是根据一套特定的规则来进行电流流动的。任何事件发生背后的真相通常是复杂的，很多时候具体情况是未知的。世界的运作可以被视为一个巨大的程序。模型试图简化世界，并将其提炼成可操作的部分。
- en: 'Example: We model the fall of an object on Earth as subject to a constant acceleration
    of \(9.81 m/s^2\) due to gravity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：我们将地球上物体的下落建模为受到重力加速度\(9.81 m/s^2\)的恒定加速度。
- en: While this describes the behavior of our system, it is merely an approximation.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然这描述了我们系统的行为，但它只是一个近似。
- en: It doesn’t account for the effects of air resistance, local variations in gravity,
    etc.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它没有考虑空气阻力、地球重力的局部变化等影响。
- en: In practice, it’s accurate enough to be useful!
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实践中，足够准确就足够有用！
- en: 10.1.1 Reasons for Building Models
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 建立模型的原因
- en: Why do we want to build models? As far as data scientists and statisticians
    are concerned, there are three reasons, and each implies a different focus on
    modeling.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们想要建立模型？就数据科学家和统计学家而言，有三个原因，每个原因都意味着对建模的不同关注点。
- en: 'To explain complex phenomena occurring in the world we live in. Examples of
    this might be:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释我们生活中发生的复杂现象。例如：
- en: How are the parents’ average height related to their children’s average height?
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 父母的平均身高与子女的平均身高有何关联？
- en: 'How does an object’s velocity and acceleration impact how far it travels? (Physics:
    \(d = d_0 + vt + \frac{1}{2}at^2\))'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物体的速度和加速度如何影响它的行程？（物理学：\(d = d_0 + vt + \frac{1}{2}at^2\)）
- en: In these cases, we care about creating models that are *simple and interpretable*,
    allowing us to understand what the relationships between our variables are.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这些情况下，我们关心创建*简单和可解释*的模型，使我们能够理解变量之间的关系。
- en: 'To make accurate predictions about unseen data. Some examples include:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对未知数据进行准确预测。一些例子包括：
- en: Can we predict if an email is spam or not?
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否预测一封电子邮件是否是垃圾邮件？
- en: Can we generate a one-sentence summary of this 10-page long article?
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否对这篇长达10页的文章生成一个一句话的摘要？
- en: When making predictions, we care more about making extremely accurate predictions,
    at the cost of having an uninterpretable model. These are sometimes called black-box
    models and are common in fields like deep learning.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在进行预测时，我们更关心做出极其准确的预测，即使以得到一个不可解释的模型为代价。这些有时被称为黑匣子模型，在深度学习等领域很常见。
- en: To measure the causal effects of one event on some other event. For example,
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 衡量一个事件对另一个事件的因果效应。例如，
- en: Does smoking *cause* lung cancer?
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吸烟是否*导致*肺癌？
- en: Does a job training program *cause* increases in employment and wages?
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 职业培训计划是否*导致*就业和工资增加？
- en: This is a much harder question because most statistical tools are designed to
    infer association, not causation. We will not focus on this task in Data 100,
    but you can take other advanced classes on causal inference (e.g., Stat 156, Data
    102) if you are intrigued!
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是一个更难的问题，因为大多数统计工具都是设计用来推断关联而不是因果关系。我们不会在Data 100中专注于这个任务，但如果你感兴趣，可以参加其他关于因果推断的高级课程（例如Stat
    156，Data 102）！
- en: Most of the time, we aim to strike a balance between building **interpretable**
    models and building **accurate models**.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，我们的目标是在建立可解释的模型和建立准确模型之间取得平衡。
- en: 10.1.2 Common Types of Models
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.2 模型的常见类型
- en: 'In general, models can be split into two categories:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，模型可以分为两类：
- en: 'Deterministic physical (mechanistic) models: Laws that govern how the world
    works.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定性物理（机械）模型：控制世界运行方式的法则。
- en: '[Kepler’s Third Law of Planetary Motion (1619)](https://en.wikipedia.org/wiki/Kepler%27s_laws_of_planetary_motion#Third_law):
    The ratio of the square of an object’s orbital period with the cube of the semi-major
    axis of its orbit is the same for all objects orbiting the same primary.'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开普勒的行星运动第三定律（1619）](https://en.wikipedia.org/wiki/Kepler%27s_laws_of_planetary_motion#Third_law)：物体轨道周期的平方与其轨道半长轴的立方的比值对于所有绕同一主体运行的物体都是相同的。'
- en: \(T^2 \propto R^3\)
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(T^2 \propto R^3\)
- en: '[Newton’s Laws: motion and gravitation (1687)](https://en.wikipedia.org/wiki/Newton%27s_laws_of_motion):
    Newton’s second law of motion models the relationship between the mass of an object
    and the force required to accelerate it.'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[牛顿的三大定律：运动和引力（1687）](https://en.wikipedia.org/wiki/Newton%27s_laws_of_motion)：牛顿的第二定律模拟了物体的质量与加速所需的力之间的关系。'
- en: \(F = ma\)
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(F = ma\)
- en: \(F_g = G \frac{m_1 m_2}{r^2}\)
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(F_g = G \frac{m_1 m_2}{r^2}\)
- en: 'Probabilistic models: Models that attempt to understand how random processes
    evolve. These are more general and can be used to describe many phenomena in the
    real world. These models commonly make simplifying assumptions about the nature
    of the world.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 概率模型：试图理解随机过程如何演变的模型。这些模型更通用，可以用来描述现实世界中的许多现象。这些模型通常对世界的性质做出简化的假设。
- en: '[Poisson Process models](https://en.wikipedia.org/wiki/Poisson_point_process):
    Used to model random events that happen with some probability at any point in
    time and are strictly increasing in count, such as the arrival of customers at
    a store.'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[泊松过程模型](https://en.wikipedia.org/wiki/Poisson_point_process)：用于模拟在任何时间点以一定概率发生的随机事件，并且在计数上严格递增，例如顾客到达商店。'
- en: 'Note: These specific models are not in the scope of Data 100 and exist to serve
    as motivation.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这些具体的模型不在Data 100的范围内，只是作为动机存在。
- en: 10.2 Simple Linear Regression
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 简单线性回归
- en: 'The **regression line** is the unique straight line that minimizes the **mean
    squared error** of estimation among all straight lines. As with any straight line,
    it can be defined by a slope and a y-intercept:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归线**是最小化所有直线估计的**均方误差**的唯一直线。与任何直线一样，它可以由斜率和y-截距定义：'
- en: \(\text{slope} = r \cdot \frac{\text{Standard Deviation of } y}{\text{Standard
    Deviation of }x}\)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\text{斜率} = r \cdot \frac{\text{y的标准差}}{\text{x的标准差}}\)
- en: \(y\text{-intercept} = \text{average of }y - \text{slope}\cdot\text{average
    of }x\)
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(y\text{-截距} = \text{平均 }y - \text{斜率}\cdot\text{平均 }x\)
- en: \(\text{regression estimate} = y\text{-intercept} + \text{slope}\cdot\text{}x\)
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\text{回归估计} = y\text{-截距} + \text{斜率}\cdot\text{}x\)
- en: \(\text{residual} =\text{observed }y - \text{regression estimate}\)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\text{残差} =\text{观察到的 }y - \text{回归估计}\)
- en: <details><summary>Code</summary>
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE0]</details>'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE0]</details>'
- en: '![](../Images/8b4c08d40c4ce8811639ecfec49094a5.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b4c08d40c4ce8811639ecfec49094a5.png)'
- en: 10.2.1 Notations and Definitions
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 符号和定义
- en: For a pair of variables \(x\) and \(y\) representing our data \(\mathcal{D}
    = \{(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\}\), we denote their means/averages
    as \(\bar x\) and \(\bar y\) and standard deviations as \(\sigma_x\) and \(\sigma_y\).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于表示我们的数据 \(\mathcal{D} = \{(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)\}\) 的一对变量
    \(x\) 和 \(y\)，我们将它们的均值/平均值表示为 \(\bar x\) 和 \(\bar y\)，标准差表示为 \(\sigma_x\) 和 \(\sigma_y\)。
- en: 10.2.1.1 Standard Units
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10.2.1.1 标准单位
- en: 'A variable is represented in standard units if the following are true:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果以下条件成立，则变量以标准单位表示：
- en: 0 in standard units is equal to the mean (\(\bar{x}\)) in the original variable’s
    units.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标准单位中的0等于原始变量单位中的均值 (\(\bar{x}\))。
- en: An increase of 1 standard unit is an increase of 1 standard deviation (\(\sigma_x\))
    in the original variable’s units.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1个标准单位的增加等于原始变量单位中的1个标准差 (\(\sigma_x\)) 的增加。
- en: To convert a variable \(x_i\) into standard units, we subtract its mean from
    it and divide it by its standard deviation. For example, \(x_i\) in standard units
    is \(\frac{x_i - \bar x}{\sigma_x}\).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要将变量 \(x_i\) 转换为标准单位，我们从其均值中减去它，并将其除以其标准差。例如，标准单位中的 \(x_i\) 是 \(\frac{x_i -
    \bar x}{\sigma_x}\)。
- en: 10.2.1.2 Correlation
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10.2.1.2 相关性
- en: The correlation (\(r\)) is the average of the product of \(x\) and \(y\), both
    measured in *standard units*.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性 (\(r\)) 是以*标准单位*测量的 \(x\) 和 \(y\) 的乘积的平均值。
- en: \[r = \frac{1}{n} \sum_{i=1}^n (\frac{x_i - \bar{x}}{\sigma_x})(\frac{y_i -
    \bar{y}}{\sigma_y})\]
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: \[r = \frac{1}{n} \sum_{i=1}^n (\frac{x_i - \bar{x}}{\sigma_x})(\frac{y_i -
    \bar{y}}{\sigma_y})\]
- en: Correlation measures the strength of a **linear association** between two variables.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相关性衡量了两个变量之间的**线性关联**的强度。
- en: 'Correlations range between -1 and 1: \(|r| \leq 1\), with \(r=1\) indicating
    perfect linear association, and \(r=-1\) indicating perfect negative association.
    The closer \(r\) is to \(0\), the weaker the linear association is.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相关性在-1和1之间变化：\(r \leq 1\), with \(r=1\) 表示完美的线性关联，\(r=-1\) 表示完美的负相关。 \(r\) 越接近于
    \(0\), 线性关联越弱。
- en: Correlation says nothing about causation and non-linear association. Correlation
    does **not** imply causation. When \(r = 0\), the two variables are uncorrelated.
    However, they could still be related through some non-linear relationship.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相关性不能说明因果关系和非线性关联。相关性**不**意味着因果关系。当 \(r = 0\) 时，两个变量是不相关的。然而，它们仍然可以通过一些非线性关系相关。
- en: <details><summary>Code</summary>
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE1]</details>'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE1]</details>'
- en: '![](../Images/9cb5b8583487c991739f5652016a16f6.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9cb5b8583487c991739f5652016a16f6.png)'
- en: 10.2.2 Alternate Form
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 替代形式
- en: When the variables \(y\) and \(x\) are measured in *standard units*, the regression
    line for predicting \(y\) based on \(x\) has slope \(r\) and passes through the
    origin.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当变量 \(y\) 和 \(x\) 以*标准单位*测量时，用于预测 \(y\) 的回归线具有斜率 \(r\) 并通过原点。
- en: \[\hat{y}_{su} = r \cdot x_{su}\]
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y}_{su} = r \cdot x_{su}\]
- en: '![](../Images/1080d62df62bf91fa1031c195173677d.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1080d62df62bf91fa1031c195173677d.png)'
- en: In the original units, this becomes
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在原始单位中，这变为
- en: \[\frac{\hat{y} - \bar{y}}{\sigma_y} = r \cdot \frac{x - \bar{x}}{\sigma_x}\]
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\hat{y} - \bar{y}}{\sigma_y} = r \cdot \frac{x - \bar{x}}{\sigma_x}\]
- en: '![](../Images/0e60bf345378c827903cb0095eba03b4.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e60bf345378c827903cb0095eba03b4.png)'
- en: 10.2.3 Derivation
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.3 推导
- en: 'Starting from the top, we have our claimed form of the regression line, and
    we want to show that it is equivalent to the optimal linear regression line: \(\hat{y}
    = \hat{a} + \hat{b}x\).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 从顶部开始，我们有我们所要求的回归线的形式，并且我们希望表明它等价于最佳线性回归线：\(\hat{y} = \hat{a} + \hat{b}x\)。
- en: 'Recall:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下：
- en: \(\hat{b} = r \cdot \frac{\text{Standard Deviation of }y}{\text{Standard Deviation
    of }x}\)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{b} = r \cdot \frac{\text{y的标准差}}{\text{x的标准差}\)
- en: \(\hat{a} = \text{average of }y - \text{slope}\cdot\text{average of }x\)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\hat{a} = y的平均值 - \text{斜率}\cdot x的平均值\)
- en: '*Proof:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*证明：'
- en: \[\frac{\hat{y} - \bar{y}}{\sigma_y} = r \cdot \frac{x - \bar{x}}{\sigma_x}\]
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\hat{y} - \bar{y}}{\sigma_y} = r \cdot \frac{x - \bar{x}}{\sigma_x}\]
- en: Multiply by \(\sigma_y\), and add \(\bar{y}\) on both sides.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 乘以\(\sigma_y\)，并在两边加上\(\bar{y}\)。
- en: \[\hat{y} = \sigma_y \cdot r \cdot \frac{x - \bar{x}}{\sigma_x} + \bar{y}\]
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y} = \sigma_y \cdot r \cdot \frac{x - \bar{x}}{\sigma_x} + \bar{y}\]
- en: Distribute coefficient \(\sigma_{y}\cdot r\) to the \(\frac{x - \bar{x}}{\sigma_x}\)
    term
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 将系数\(\sigma_{y}\cdot r\)分配给\(\frac{x - \bar{x}}{\sigma_x}\)项
- en: \[\hat{y} = (\frac{r\sigma_y}{\sigma_x} ) \cdot x + (\bar{y} - (\frac{r\sigma_y}{\sigma_x}
    ) \bar{x})\]
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y} = (\frac{r\sigma_y}{\sigma_x} ) \cdot x + (\bar{y} - (\frac{r\sigma_y}{\sigma_x}
    ) \bar{x})\]
- en: 'We now see that we have a line that matches our claim:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们看到我们有一条符合我们要求的线：
- en: 'slope: \(r\cdot\frac{\text{SD of y}}{\text{SD of x}} = r\cdot\frac{\sigma_y}{\sigma_x}\)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斜率：\(r\cdot\frac{\text{y的标准差}}{\text{x的标准差}} = r\cdot\frac{\sigma_y}{\sigma_x}\)
- en: 'intercept: \(\bar{y} - \text{slope}\cdot \bar{x}\)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 截距：\(\bar{y} - \text{斜率}\cdot \bar{x}\)
- en: 'Note that the error for the i-th datapoint is: \(e_i = y_i - \hat{y_i}\)*  *##
    10.3 The Modeling Process'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，第i个数据点的误差为：\(e_i = y_i - \hat{y_i}\)*  *## 10.3 建模过程
- en: At a high level, a model is a way of representing a system. In Data 100, we’ll
    treat a model as some mathematical rule we use to describe the relationship between
    variables.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，模型是表示系统的一种方式。在Data 100中，我们将把模型视为我们用来描述变量之间关系的一些数学规则。
- en: 'What variables are we modeling? Typically, we use a subset of the variables
    in our sample of collected data to model another variable in this data. To put
    this more formally, say we have the following dataset \(\mathcal{D}\):'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在对哪些变量进行建模？通常，我们使用我们收集到的样本数据中的变量子集来对该数据中的另一个变量进行建模。更正式地说，假设我们有以下数据集\(\mathcal{D}\)：
- en: \[\mathcal{D} = \{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\}\]
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathcal{D} = \{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\}\]
- en: Each pair of values \((x_i, y_i)\) represents a datapoint. In a modeling setting,
    we call these **observations**. \(y_i\) is the dependent variable we are trying
    to model, also called an **output** or **response**. \(x_i\) is the independent
    variable inputted into the model to make predictions, also known as a **feature**.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 每一对值\((x_i, y_i)\)代表一个数据点。在建模环境中，我们称这些为**观察**。\(y_i\)是我们试图对其进行建模的因变量，也称为**输出**或**响应**。\(x_i\)是输入到模型中进行预测的自变量，也称为**特征**。
- en: 'Our goal in modeling is to use the observed data \(\mathcal{D}\) to predict
    the output variable \(y_i\). We denote each prediction as \(\hat{y}_i\) (read:
    “y hat sub i”).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建模的目标是使用观察到的数据\(\mathcal{D}\)来预测输出变量\(y_i\)。我们将每个预测表示为\(\hat{y}_i\)（读作：“y帽下标i”）。
- en: 'How do we generate these predictions? Some examples of models we’ll encounter
    in the next few lectures are given below:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何生成这些预测？在接下来的几堂课中，我们将遇到一些模型的例子如下：
- en: \[\hat{y}_i = \theta\] \[\hat{y}_i = \theta_0 + \theta_1 x_i\]
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y}_i = \theta\] \[\hat{y}_i = \theta_0 + \theta_1 x_i\]
- en: The examples above are known as **parametric models**. They relate the collected
    data, \(x_i\), to the prediction we make, \(\hat{y}_i\). A few parameters (\(\theta\),
    \(\theta_0\), \(\theta_1\)) are used to describe the relationship between \(x_i\)
    and \(\hat{y}_i\).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的例子被称为**参数模型**。它们将收集到的数据\(x_i\)与我们做出的预测\(\hat{y}_i\)联系起来。一些参数(\(\theta\),
    \(\theta_0\), \(\theta_1\))用于描述\(x_i\)和\(\hat{y}_i\)之间的关系。
- en: 'Notice that we don’t immediately know the values of these parameters. While
    the features, \(x_i\), are taken from our observed data, we need to decide what
    values to give \(\theta\), \(\theta_0\), and \(\theta_1\) ourselves. This is the
    heart of parametric modeling: *what parameter values should we choose so our model
    makes the best possible predictions?*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们并不立即知道这些参数的值。虽然特征\(x_i\)是从我们观察到的数据中获取的，但我们需要决定给\(\theta\)、\(\theta_0\)和\(\theta_1\)什么值。这是参数建模的核心：*我们应该选择什么参数值，使我们的模型能够做出最佳的预测？*
- en: To choose our model parameters, we’ll work through the **modeling process**.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 选择我们的模型参数，我们将通过**建模过程**来进行。
- en: 'Choose a model: how should we represent the world?'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择模型：我们应该如何表示世界？
- en: 'Choose a loss function: how do we quantify prediction error?'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择损失函数：我们如何量化预测误差？
- en: 'Fit the model: how do we choose the best parameters of our model given our
    data?'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合模型：在给定数据的情况下，我们如何选择模型的最佳参数？
- en: 'Evaluate model performance: how do we evaluate whether this process gave rise
    to a good model?'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型性能：我们如何评估这个过程是否产生了一个好的模型？
- en: 10.4 Choosing a Model
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 选择模型
- en: 'Our first step is choosing a model: defining the mathematical rule that describes
    the relationship between the features, \(x_i\), and predictions \(\hat{y}_i\).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是选择一个模型：定义描述特征\(x_i\)和预测\(\hat{y}_i\)之间关系的数学规则。
- en: 'In [Data 8](https://inferentialthinking.com/chapters/15/4/Least_Squares_Regression.html),
    you learned about the **Simple Linear Regression (SLR) model**. You learned that
    the model takes the form: \[\hat{y}_i = a + bx_i\]'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Data 8](https://inferentialthinking.com/chapters/15/4/Least_Squares_Regression.html)中，您学习了**简单线性回归（SLR）模型**。您学到了该模型的形式：\[\hat{y}_i
    = a + bx_i\]
- en: 'In Data 100, we’ll use slightly different notation: we will replace \(a\) with
    \(\theta_0\) and \(b\) with \(\theta_1\). This will allow us to use the same notation
    when we explore more complex models later on in the course.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在Data 100中，我们将使用略有不同的符号：我们将用\(\theta_0\)替换\(a\)，用\(\theta_1\)替换\(b\)。这将使我们能够在课程后期探索更复杂的模型时使用相同的符号。
- en: \[\hat{y}_i = \theta_0 + \theta_1 x_i\]
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y}_i = \theta_0 + \theta_1 x_i\]
- en: 'The parameters of the SLR model are \(\theta_0\), also called the intercept
    term, and \(\theta_1\), also called the slope term. To create an effective model,
    we want to choose values for \(\theta_0\) and \(\theta_1\) that most accurately
    predict the output variable. The “best” fitting model parameters are given the
    special names: \(\hat{\theta}_0\) and \(\hat{\theta}_1\); they are the specific
    parameter values that allow our model to generate the best possible predictions.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: SLR模型的参数是 \(\theta_0\)，也称为截距项，和 \(\theta_1\)，也称为斜率项。为了创建一个有效的模型，我们希望选择 \(\theta_0\)
    和 \(\theta_1\) 的值，以最准确地预测输出变量。 “最佳”拟合模型参数被赋予特殊名称：\(\hat{\theta}_0\) 和 \(\hat{\theta}_1\)；它们是允许我们的模型生成最佳可能预测的特定参数值。
- en: 'In Data 8, you learned that the best SLR model parameters are: \[\hat{\theta}_0
    = \bar{y} - \hat{\theta}_1\bar{x} \qquad \qquad \hat{\theta}_1 = r \frac{\sigma_y}{\sigma_x}\]'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在Data 8中，您学到了最佳SLR模型参数是：\[\hat{\theta}_0 = \bar{y} - \hat{\theta}_1\bar{x} \qquad
    \qquad \hat{\theta}_1 = r \frac{\sigma_y}{\sigma_x}\]
- en: 'A quick reminder on notation:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 关于符号的快速提醒：
- en: \(\bar{y}\) and \(\bar{x}\) indicate the mean value of \(y\) and \(x\), respectively
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\bar{y}\) 和 \(\bar{x}\) 分别表示 \(y\) 和 \(x\) 的均值
- en: \(\sigma_y\) and \(\sigma_x\) indicate the standard deviations of \(y\) and
    \(x\)
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\sigma_y\) 和 \(\sigma_x\) 表示 \(y\) 和 \(x\) 的标准偏差
- en: '\(r\) is the [correlation coefficient](https://inferentialthinking.com/chapters/15/1/Correlation.html#the-correlation-coefficient),
    defined as the average of the product of \(x\) and \(y\) measured in standard
    units: \(\frac{1}{n} \sum_{i=1}^n (\frac{x_i-\bar{x}}{\sigma_x})(\frac{y_i-\bar{y}}{\sigma_y})\)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(r\) 是[相关系数](https://inferentialthinking.com/chapters/15/1/Correlation.html#the-correlation-coefficient)，定义为
    \(x\) 和 \(y\) 的乘积的平均值，以标准单位测量：\(\frac{1}{n} \sum_{i=1}^n (\frac{x_i-\bar{x}}{\sigma_x})(\frac{y_i-\bar{y}}{\sigma_y})\)
- en: In Data 100, we want to understand *how* to derive these best model coefficients.
    To do so, we’ll introduce the concept of a loss function.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在Data 100中，我们想要了解如何推导出这些最佳模型系数。为此，我们将介绍损失函数的概念。
- en: 10.5 Choosing a Loss Function
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 选择损失函数
- en: 'We’ve talked about the idea of creating the “best” possible predictions. This
    begs the question: how do we decide how “good” or “bad” our model’s predictions
    are?'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了创建“最佳”预测的想法。这引出了一个问题：我们如何决定我们模型的预测是“好”还是“坏”？
- en: A **loss function** characterizes the cost, error, or fit resulting from a particular
    choice of model or model parameters. This function, \(L(y, \hat{y})\), quantifies
    how “bad” or “far off” a single prediction by our model is from a true, observed
    value in our collected data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**损失函数** 描述了特定模型或模型参数选择所产生的成本、误差或拟合。这个函数，\(L(y, \hat{y})\)，量化了我们模型的单个预测与我们收集的数据中真实观测值之间的“坏”或“偏离”程度。'
- en: The choice of loss function for a particular model will affect the accuracy
    and computational cost of estimation, and it’ll also depend on the estimation
    task at hand. For example,
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 特定模型的损失函数的选择将影响估计的准确性和计算成本，并且还将取决于手头的估计任务。例如，
- en: Are outputs quantitative or qualitative?
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出是定量的还是定性的？
- en: Do outliers matter?
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值重要吗？
- en: Are all errors equally costly? (e.g., a false negative on a cancer test is arguably
    more dangerous than a false positive)
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有错误一样昂贵吗？（例如，癌症测试的假阴性可能比假阳性更危险）
- en: 'Regardless of the specific function used, a loss function should follow two
    basic principles:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 无论使用的具体函数是什么，损失函数应遵循两个基本原则：
- en: If the prediction \(\hat{y}_i\) is *close* to the actual value \(y_i\), loss
    should be low.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果预测 \(\hat{y}_i\) *接近* 实际值 \(y_i\)，损失应该很低。
- en: If the prediction \(\hat{y}_i\) is *far* from the actual value \(y_i\), loss
    should be high.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果预测 \(\hat{y}_i\) 与实际值 \(y_i\) *相距很远*，损失应该很高。
- en: Two common choices of loss function are squared loss and absolute loss.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数的两种常见选择是平方损失和绝对损失。
- en: '**Squared loss**, also known as **L2 loss**, computes loss as the square of
    the difference between the observed \(y_i\) and predicted \(\hat{y}_i\): \[L(y_i,
    \hat{y}_i) = (y_i - \hat{y}_i)^2\]'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**平方损失**，也称为**L2损失**，计算观测到的 \(y_i\) 和预测的 \(\hat{y}_i\) 之间的差的平方：\[L(y_i, \hat{y}_i)
    = (y_i - \hat{y}_i)^2\]'
- en: '**Absolute loss**, also known as **L1 loss**, computes loss as the absolute
    difference between the observed \(y_i\) and predicted \(\hat{y}_i\): \[L(y_i,
    \hat{y}_i) = |y_i - \hat{y}_i|\]'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**绝对损失**，也称为**L1损失**，计算观测到的 \(y_i\) 和预测的 \(\hat{y}_i\) 之间的绝对差：\[L(y_i, \hat{y}_i)
    = |y_i - \hat{y}_i|\]'
- en: 'L1 and L2 loss give us a tool for quantifying our model’s performance on a
    single data point. This is a good start, but ideally, we want to understand how
    our model performs across our *entire* dataset. A natural way to do this is to
    compute the average loss across all data points in the dataset. This is known
    as the **cost function**, \(\hat{R}(\theta)\): \[\hat{R}(\theta) = \frac{1}{n}
    \sum^n_{i=1} L(y_i, \hat{y}_i)\]'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: L1和L2损失为我们提供了一种工具，用于量化我们模型在单个数据点上的表现。这是一个很好的开始，但是理想情况下，我们希望了解我们的模型在*整个*数据集上的表现。一个自然的方法是计算数据集中所有数据点的平均损失。这被称为**成本函数**，\(\hat{R}(\theta)\)：\[\hat{R}(\theta)
    = \frac{1}{n} \sum^n_{i=1} L(y_i, \hat{y}_i)\]
- en: 'The cost function has many names in the statistics literature. You may also
    encounter the terms:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计文献中，成本函数有许多名称。您可能还会遇到以下术语：
- en: Empirical risk (this is why we give the cost function the name \(R\))
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经验风险（这就是我们给成本函数命名为 \(R\) 的原因）
- en: Error function
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误函数
- en: Average loss
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均损失
- en: 'We can substitute our L1 and L2 loss into the cost function definition. The
    **Mean Squared Error (MSE)** is the average squared loss across a dataset: \[\text{MSE}
    = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2\]'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将我们的L1和L2损失代入成本函数的定义中。**均方误差（MSE）** 是数据集中平均平方损失：\[\text{MSE} = \frac{1}{n}
    \sum_{i=1}^n (y_i - \hat{y}_i)^2\]
- en: 'The **Mean Absolute Error (MAE)** is the average absolute loss across a dataset:
    \[\text{MAE}= \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|\]'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**平均绝对误差（MAE）** 是数据集中平均绝对损失：\[\text{MAE}= \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|\]'
- en: 10.6 Fitting the Model
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.6 拟合模型
- en: Now that we’ve established the concept of a loss function, we can return to
    our original goal of choosing model parameters. Specifically, we want to choose
    the best set of model parameters that will minimize the model’s cost on our dataset.
    This process is called fitting the model.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了损失函数的概念，我们可以回到选择模型参数的原始目标。具体来说，我们希望选择最佳的模型参数集，以最小化模型在数据集上的成本。这个过程称为拟合模型。
- en: We know from calculus that a function is minimized when (1) its first derivative
    is equal to zero and (2) its second derivative is positive. We often call the
    function being minimized the **objective function** (our objective is to find
    its minimum).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道从微积分中，当一个函数的一阶导数等于零，二阶导数为正时，函数达到最小值。我们经常称被最小化的函数为**目标函数**（我们的目标是找到它的最小值）。
- en: 'To find the optimal model parameter, we:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到最佳的模型参数，我们：
- en: Take the derivative of the cost function with respect to that parameter
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对成本函数分别对该参数求导
- en: Set the derivative equal to 0
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将导数设为0
- en: Solve for the parameter
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解出参数
- en: We repeat this process for each parameter present in the model. For now, we’ll
    disregard the second derivative condition.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对模型中每个参数重复这个过程。现在，我们将忽略二阶导数条件。
- en: 'To help us make sense of this process, let’s put it into action by deriving
    the optimal model parameters for simple linear regression using the mean squared
    error as our cost function. Remember: although the notation may look tricky, all
    we are doing is following the three steps above!'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们理解这个过程，让我们通过使用均方误差作为成本函数，推导简单线性回归的最优模型参数。记住：尽管符号可能看起来复杂，但我们所做的只是按照上面的三个步骤进行操作！
- en: 'Step 1: take the derivative of the cost function with respect to each model
    parameter. We substitute the SLR model, \(\hat{y}_i = \theta_0+\theta_1 x_i\),
    into the definition of MSE above and differentiate with respect to \(\theta_0\)
    and \(\theta_1\). \[\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    = \frac{1}{n} \sum_{i=1}^{n} (y_i - \theta_0 - \theta_1 x_i)^2\]'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤1：对成本函数分别对每个模型参数求导。我们将SLR模型\(\hat{y}_i = \theta_0+\theta_1 x_i\)代入上述MSE的定义中，并对\(\theta_0\)和\(\theta_1\)进行微分。
- en: \[\frac{\partial}{\partial \theta_0} \text{MSE} = \frac{-2}{n} \sum_{i=1}^{n}
    y_i - \theta_0 - \theta_1 x_i\]
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\partial}{\partial \theta_0} \text{MSE} = \frac{-2}{n} \sum_{i=1}^{n}
    y_i - \theta_0 - \theta_1 x_i\]
- en: \[\frac{\partial}{\partial \theta_1} \text{MSE} = \frac{-2}{n} \sum_{i=1}^{n}
    (y_i - \theta_0 - \theta_1 x_i)x_i\]
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\partial}{\partial \theta_1} \text{MSE} = \frac{-2}{n} \sum_{i=1}^{n}
    (y_i - \theta_0 - \theta_1 x_i)x_i\]
- en: Let’s walk through these derivations in more depth, starting with the derivative
    of MSE with respect to \(\theta_0\).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地走一遍这些推导，从对\(\theta_0\)的MSE的导数开始。
- en: 'Given our MSE above, we know that: \[\frac{\partial}{\partial \theta_0} \text{MSE}
    = \frac{\partial}{\partial \theta_0} \frac{1}{n} \sum_{i=1}^{n} {(y_i - \theta_0
    - \theta_1 x_i)}^{2}\]'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上面的MSE，我们知道：\[\frac{\partial}{\partial \theta_0} \text{MSE} = \frac{\partial}{\partial
    \theta_0} \frac{1}{n} \sum_{i=1}^{n} {(y_i - \theta_0 - \theta_1 x_i)}^{2}\]
- en: 'Noting that the derivative of sum is equivalent to the sum of derivatives,
    this then becomes: \[ = \frac{1}{n} \sum_{i=1}^{n} \frac{\partial}{\partial \theta_0}
    {(y_i - \theta_0 - \theta_1 x_i)}^{2}\]'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，求和的导数等于导数的和，这样就变成了：\[ = \frac{1}{n} \sum_{i=1}^{n} \frac{\partial}{\partial
    \theta_0} {(y_i - \theta_0 - \theta_1 x_i)}^{2}\]
- en: We can then apply the chain rule.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以应用链式法则。
- en: \[ = \frac{1}{n} \sum_{i=1}^{n} 2 \cdot{(y_i - \theta_0 - \theta_1 x_i)}\dot(-1)\]
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: \[ = \frac{1}{n} \sum_{i=1}^{n} 2 \cdot{(y_i - \theta_0 - \theta_1 x_i)}\dot(-1)\]
- en: Finally, we can simplify the constants, leaving us with our answer.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以简化常数，得到我们的答案。
- en: \[\frac{\partial}{\partial \theta_0} \text{MSE} = \frac{-2}{n} \sum_{i=1}^{n}{(y_i
    - \theta_0 - \theta_1 x_i)}\]
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\partial}{\partial \theta_0} \text{MSE} = \frac{-2}{n} \sum_{i=1}^{n}{(y_i
    - \theta_0 - \theta_1 x_i)}\]
- en: Following the same procedure, we can take the derivative of MSE with respect
    to \(\theta_1\).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 按照同样的步骤，我们可以对\(\theta_1\)的MSE进行求导。
- en: \[\frac{\partial}{\partial \theta_1} \text{MSE} = \frac{\partial}{\partial \theta_1}
    \frac{1}{n} \sum_{i=1}^{n} {(y_i - \theta_0 - \theta_1 x_i)}^{2}\]
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: \[\frac{\partial}{\partial \theta_1} \text{MSE} = \frac{\partial}{\partial \theta_1}
    \frac{1}{n} \sum_{i=1}^{n} {(y_i - \theta_0 - \theta_1 x_i)}^{2}\]
- en: \[ = \frac{1}{n} \sum_{i=1}^{n} \frac{\partial}{\partial \theta_1} {(y_i - \theta_0
    - \theta_1 x_i)}^{2}\]
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: \[ = \frac{1}{n} \sum_{i=1}^{n} \frac{\partial}{\partial \theta_1} {(y_i - \theta_0
    - \theta_1 x_i)}^{2}\]
- en: \[ = \frac{1}{n} \sum_{i=1}^{n} 2 \dot{(y_i - \theta_0 - \theta_1 x_i)}\dot(-x_i)\]
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: \[ = \frac{1}{n} \sum_{i=1}^{n} 2 \dot{(y_i - \theta_0 - \theta_1 x_i)}\dot(-x_i)\]
- en: \[= \frac{-2}{n} \sum_{i=1}^{n} {(y_i - \theta_0 - \theta_1 x_i)}x_i\]
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: \[= \frac{-2}{n} \sum_{i=1}^{n} {(y_i - \theta_0 - \theta_1 x_i)}x_i\]
- en: 'Step 2: set the derivatives equal to 0\. After simplifying terms, this produces
    two **estimating equations**. The best set of model parameters \((\hat{\theta}_0,
    \hat{\theta}_1)\) *must* satisfy these two optimality conditions. \[0 = \frac{-2}{n}
    \sum_{i=1}^{n} y_i - \hat{\theta}_0 - \hat{\theta}_1 x_i \Longleftrightarrow \frac{1}{n}\sum_{i=1}^{n}
    y_i - \hat{y}_i = 0\] \[0 = \frac{-2}{n} \sum_{i=1}^{n} (y_i - \hat{\theta}_0
    - \hat{\theta}_1 x_i)x_i \Longleftrightarrow \frac{1}{n}\sum_{i=1}^{n} (y_i -
    \hat{y}_i)x_i = 0\]'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤2：将导数设为0。简化项后，这产生了两个**估计方程**。模型参数的最佳集合\((\hat{\theta}_0, \hat{\theta}_1)\)
    *必须*满足这两个最优性条件。\[0 = \frac{-2}{n} \sum_{i=1}^{n} y_i - \hat{\theta}_0 - \hat{\theta}_1
    x_i \Longleftrightarrow \frac{1}{n}\sum_{i=1}^{n} y_i - \hat{y}_i = 0\] \[0 =
    \frac{-2}{n} \sum_{i=1}^{n} (y_i - \hat{\theta}_0 - \hat{\theta}_1 x_i)x_i \Longleftrightarrow
    \frac{1}{n}\sum_{i=1}^{n} (y_i - \hat{y}_i)x_i = 0\]
- en: 'Step 3: solve the estimating equations to compute estimates for \(\hat{\theta}_0\)
    and \(\hat{\theta}_1\).'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤3：解估计方程以计算\(\hat{\theta}_0\)和\(\hat{\theta}_1\)的估计值。
- en: 'Taking the first equation gives the estimate of \(\hat{\theta}_0\): \[\frac{1}{n}
    \sum_{i=1}^n y_i - \hat{\theta}_0 - \hat{\theta}_1 x_i = 0 \]'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 取第一个方程式给出了\(\hat{\theta}_0\)的估计值：\[\frac{1}{n} \sum_{i=1}^n y_i - \hat{\theta}_0
    - \hat{\theta}_1 x_i = 0\]
- en: \[\left(\frac{1}{n} \sum_{i=1}^n y_i \right) - \hat{\theta}_0 - \hat{\theta}_1\left(\frac{1}{n}
    \sum_{i=1}^n x_i \right) = 0\]
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: \[\left(\frac{1}{n} \sum_{i=1}^n y_i \right) - \hat{\theta}_0 - \hat{\theta}_1\left(\frac{1}{n}
    \sum_{i=1}^n x_i \right) = 0\]
- en: \[ \hat{\theta}_0 = \bar{y} - \hat{\theta}_1 \bar{x}\]
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{\theta}_0 = \bar{y} - \hat{\theta}_1 \bar{x}\]
- en: With a bit more maneuvering, the second equation gives the estimate of \(\hat{\theta}_1\).
    Start by multiplying the first estimating equation by \(\bar{x}\), then subtracting
    the result from the second estimating equation.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 通过稍微调整，第二个方程给出了 \(\hat{\theta}_1\) 的估计值。首先将第一个估计方程乘以 \(\bar{x}\)，然后从第二个估计方程中减去结果。
- en: \[\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)x_i - \frac{1}{n} \sum_{i=1}^n (y_i
    - \hat{y}_i)\bar{x} = 0 \]
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)x_i - \frac{1}{n} \sum_{i=1}^n
    (y_i - \hat{y}_i)\bar{x} = 0 \]
- en: \[\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)(x_i - \bar{x}) = 0 \]
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)(x_i - \bar{x}) = 0 \]
- en: 'Next, plug in \(\hat{y}_i = \hat{\theta}_0 + \hat{\theta}_1 x_i = \bar{y} +
    \hat{\theta}_1(x_i - \bar{x})\):'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，代入 \(\hat{y}_i = \hat{\theta}_0 + \hat{\theta}_1 x_i = \bar{y} + \hat{\theta}_1(x_i
    - \bar{x})\)：
- en: \[\frac{1}{n} \sum_{i=1}^n (y_i - \bar{y} - \hat{\theta}_1(x - \bar{x}))(x_i
    - \bar{x}) = 0 \]
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n (y_i - \bar{y} - \hat{\theta}_1(x - \bar{x}))(x_i
    - \bar{x}) = 0 \]
- en: \[\frac{1}{n} \sum_{i=1}^n (y_i - \bar{y})(x_i - \bar{x}) = \hat{\theta}_1 \times
    \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2 \]
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \frac{1}{n} \sum_{i=1}^n (y_i - \bar{y})(x_i - \bar{x}) = \hat{\theta}_1
    \times \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2 \]
- en: 'By using the definition of correlation \(\left(r = \frac{1}{n} \sum_{i=1}^n
    (\frac{x_i-\bar{x}}{\sigma_x})(\frac{y_i-\bar{y}}{\sigma_y}) \right)\) and standard
    deviation \(\left(\sigma_x = \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2}
    \right)\), we can conclude: \[r \sigma_x \sigma_y = \hat{\theta}_1 \times \sigma_x^2\]
    \[\hat{\theta}_1 = r \frac{\sigma_y}{\sigma_x}\]'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用相关性的定义 \(\left(r = \frac{1}{n} \sum_{i=1}^n (\frac{x_i-\bar{x}}{\sigma_x})(\frac{y_i-\bar{y}}{\sigma_y})
    \right)\) 和标准差 \(\left(\sigma_x = \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2}
    \right)\)，我们可以得出结论：\[r \sigma_x \sigma_y = \hat{\theta}_1 \times \sigma_x^2\]
    \[\hat{\theta}_1 = r \frac{\sigma_y}{\sigma_x}\]
- en: Just as was given in Data 8!
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在Data 8中给出的那样！
- en: Remember, this derivation found the optimal model parameters for SLR when using
    the MSE cost function. If we had used a different model or different loss function,
    we likely would have found different values for the best model parameters. However,
    regardless of the model and loss used, we can *always* follow these three steps
    to fit the model.***
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，这个推导是在使用MSE成本函数时找到了SLR的最佳模型参数。如果我们使用了不同的模型或不同的损失函数，我们很可能会找到最佳模型参数的不同值。然而，无论使用什么模型和损失，我们总是可以遵循这三个步骤来拟合模型。
