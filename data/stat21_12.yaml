- en: Chapter 11 Bayesian statistics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章 贝叶斯统计
- en: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/bayesian-statistics.html](https://statsthinking21.github.io/statsthinking21-core-site/bayesian-statistics.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'Translated from: [https://statsthinking21.github.io/statsthinking21-core-site/bayesian-statistics.html](https://statsthinking21.github.io/statsthinking21-core-site/bayesian-statistics.html)'
- en: In this chapter we will take up the approach to statistical modeling and inference
    that stands in contrast to the null hypothesis testing framework that you encountered
    in Chapter [9](hypothesis-testing.html#hypothesis-testing). This is known as “Bayesian
    statistics” after the Reverend Thomas Bayes, whose theorem you have already encountered
    in Chapter [6](probability.html#probability). In this chapter you will learn how
    Bayes’ theorem provides a way of understanding data that solves many of the conceptual
    problems that we discussed regarding null hypothesis testing, while also introducing
    some new challenges.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将采用与你在第[9](hypothesis-testing.html#hypothesis-testing)章中遇到的零假设检验框架相对立的统计建模和推断方法。这被称为“贝叶斯统计”，以纪念托马斯·贝叶斯牧师，你在第[6](probability.html#probability)章已经遇到过他的定理。在本章中，你将学习贝叶斯定理如何提供了一种理解数据的方式，解决了我们讨论的关于零假设检验的许多概念问题，同时也引入了一些新的挑战。
- en: 11.1 Generative models
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 生成模型
- en: Say you are walking down the street and a friend of yours walks right by but
    doesn’t say hello. You would probably try to decide why this happened – Did they
    not see you? Are they mad at you? Are you suddenly cloaked in a magic invisibility
    shield? One of the basic ideas behind Bayesian statistics is that we want to infer
    the details of how the data are being generated, based on the data themselves.
    In this case, you want to use the data (i.e. the fact that your friend did not
    say hello) to infer the process that generated the data (e.g. whether or not they
    actually saw you, how they feel about you, etc).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在走在街上，你的一个朋友就在你身边走过，但没有打招呼。你可能会试图弄清楚为什么会发生这种情况 - 他们没有看到你吗？他们生你的气了吗？你突然被一个魔法隐形盾牌包裹了吗？贝叶斯统计背后的一个基本思想是，我们想根据数据本身推断数据是如何生成的细节。在这种情况下，你想要使用数据（即你的朋友没有打招呼的事实）来推断生成数据的过程（例如他们是否真的看到了你，他们对你的感觉如何等）。
- en: The idea behind a generative model is that a *latent* (unseen) process generates
    the data we observe, usually with some amount of randomness in the process. When
    we take a sample of data from a population and estimate a parameter from the sample,
    what we are doing in essence is trying to learn the value of a latent variable
    (the population mean) that gives rise through sampling to the observed data (the
    sample mean). Figure [11.1](bayesian-statistics.html#fig:GenerativeModel) shows
    a schematic of this idea.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型背后的思想是一个*潜在*（未见）过程生成我们观察到的数据，通常在过程中有一定的随机性。当我们从一个群体中取样数据并从样本中估计参数时，我们实质上是在试图学习一个潜在变量（群体均值），通过取样产生观察到的数据（样本均值）。图[11.1](bayesian-statistics.html#fig:GenerativeModel)显示了这个想法的示意图。
- en: '![A schematic of the idea of a generative model.](../Images/d6d64e8689e3e5bc6a74dc379429c0b1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![生成模型的想法的示意图。](../Images/d6d64e8689e3e5bc6a74dc379429c0b1.png)'
- en: 'Figure 11.1: A schematic of the idea of a generative model.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1：生成模型的想法的示意图。
- en: 'If we know the value of the latent variable, then it’s easy to reconstruct
    what the observed data should look like. For example, let’s say that we are flipping
    a coin that we know to be fair, such that we would expect it to land on heads
    50% of the time. We can describe the coin by a binomial distribution with a value
    of \(P_{heads}=0.5\), and then we could generate random samples from such a distribution
    in order to see what the observed data should look like. However, in general we
    are in the opposite situation: We don’t know the value of the latent variable
    of interest, but we have some data that we would like to use to estimate it.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们知道潜在变量的值，那么重建观察到的数据应该是很容易的。例如，假设我们抛一枚我们知道是公平的硬币，我们期望它50%的时间会正面朝上。我们可以用二项分布描述硬币，其值为\(P_{heads}=0.5\)，然后我们可以从这样的分布中生成随机样本，以便看到观察到的数据应该是什么样子。然而，一般情况下我们处于相反的情况：我们不知道感兴趣的潜在变量的值，但我们有一些数据，我们希望用它来估计它。
- en: 11.2 Bayes’ theorem and inverse inference
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 贝叶斯定理和逆推推断
- en: The reason that Bayesian statistics has its name is because it takes advantage
    of Bayes’ theorem to make inferences from data about the underlying process that
    generated the data. Let’s say that we want to know whether a coin is fair. To
    test this, we flip the coin 10 times and come up with 7 heads. Before this test
    we were pretty sure that the \(P_{heads}=0.5\), but finding 7 heads out of 10
    flips would certainly give us pause if we believed that \(P_{heads}=0.5\). We
    already know how to compute the conditional probability that we would flip 7 or
    more heads out of 10 if the coin is really fair (\(P(n\ge7|p_{heads}=0.5)\)),
    using the binomial distribution.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯统计之所以得名，是因为它利用贝叶斯定理从数据中推断生成数据的潜在过程。假设我们想知道一枚硬币是否公平。为了测试这一点，我们抛了10次硬币，得到了7次正面。在这个测试之前，我们相当确定\(P_{heads}=0.5\)，但如果我们相信\(P_{heads}=0.5\)，那么在10次抛硬币中得到7次或更多次正面的条件概率（\(P(n\ge7|p_{heads}=0.5)\)）会让我们感到犹豫不决。我们已经知道如何使用二项分布计算这个条件概率。
- en: The resulting probability is 0.055\. That is a fairly small number, but this
    number doesn’t really answer the question that we are asking – it is telling us
    about the likelihood of 7 or more heads given some particular probability of heads,
    whereas what we really want to know is the true probability of heads for this
    particular coin. This should sound familiar, as it’s exactly the situation that
    we were in with null hypothesis testing, which told us about the likelihood of
    data rather than the likelihood of hypotheses.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的概率是0.055。这是一个相当小的数字，但这个数字并没有真正回答我们所问的问题 —— 它告诉我们在给定某个特定的正面概率的情况下，出现7次或更多正面的可能性，而我们真正想知道的是这枚硬币的真实正面概率。这应该听起来很熟悉，因为这正是我们在零假设检验中遇到的情况，它告诉我们的是数据的可能性而不是假设的可能性。
- en: 'Remember that Bayes’ theorem provides us with the tool that we need to invert
    a conditional probability:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，贝叶斯定理为我们提供了反转条件概率的工具：
- en: \[ P(H|D) = \frac{P(D|H)*P(H)}{P(D)} \]
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(H|D) = \frac{P(D|H)*P(H)}{P(D)} \]
- en: 'We can think of this theorem as having four parts:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个定理看作有四个部分：
- en: '*prior* (\(P(Hypothesis)\)): Our degree of belief about hypothesis H before
    seeing the data D'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*先验*（\(P(假设)\)）：在观察到数据D之前我们对假设H的信念程度'
- en: '*likelihood* (\(P(Data|Hypothesis)\)): How likely are the observed data D under
    hypothesis H?'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*似然*（\(P(数据|假设)\)）：在假设H下观察到的数据D有多大可能性？'
- en: '*marginal likelihood* (\(P(Data)\)): How likely are the observed data, combining
    over all possible hypotheses?'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*边际似然*（\(P(Data)\)）：观察到的数据有多大可能性，结合所有可能的假设？'
- en: '*posterior* (\(P(Hypothesis|Data)\)): Our updated belief about hypothesis H,
    given the data D'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*后验*（\(P(假设|数据)\)）：在观察到数据D后我们对假设H的更新信念'
- en: 'In the case of our coin-flipping example:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们抛硬币的例子中：
- en: '*prior* (\(P_{heads}\)): Our degree of belief about the likelhood of flipping
    heads, which was \(P_{heads}=0.5\)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*先验*（\(P_{heads}\)）：我们对抛硬币出现正面的可能性的信念程度，即\(P_{heads}=0.5\)'
- en: '*likelihood* (\(P(\text{7 or more heads out of 10 flips}|P_{heads}=0.5)\)):
    How likely are 7 or more heads out of 10 flips if \(P_{heads}=0.5)\)?'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*似然*（\(P(\text{10次抛硬币中出现7次或更多正面}|P_{heads}=0.5)\)）：如果\(P_{heads}=0.5\)，10次抛硬币中出现7次或更多正面的可能性有多大？'
- en: '*marginal likelihood* (\(P(\text{7 or more heads out of 10 flips})\)): How
    likely are we to observe 7 heads out of 10 coin flips, in general?'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*边际似然*（\(P(\text{10次抛硬币中出现7次或更多正面}\)）：一般情况下，我们观察到10次抛硬币中出现7次正面的可能性有多大？'
- en: '*posterior* (\(P_{heads}|\text{7 or more heads out of 10 coin flips})\)): Our
    updated belief about \(P_{heads}\) given the observed coin flips'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*后验*（\(P_{heads}|\text{10次抛硬币中出现7次或更多正面}\)）：观察到的抛硬币结果后我们对\(P_{heads}\)的更新信念'
- en: Here we see one of the primary differences between frequentist and Bayesian
    statistics. Frequentists do not believe in the idea of a probability of a hypothesis
    (i.e. our degree of belief about a hypothesis) – for them, a hypothesis is either
    true or it isn’t. Another way to say this is that for the frequentist, the hypothesis
    is fixed and the data are random, which is why frequentist inference focuses on
    describing the probability of data given a hypothesis (i.e. the p-value). Bayesians,
    on the other hand, are comfortable making probability statements about both data
    and hypotheses.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到频率派和贝叶斯统计之间的主要区别之一。频率派不相信有关假设概率的概念（即我们对假设的信念程度） —— 对他们来说，一个假设要么成立要么不成立。另一种说法是，对于频率派来说，假设是固定的，数据是随机的，这就是为什么频率派推断侧重于描述在假设下数据的概率（即p值）。另一方面，贝叶斯派则可以舒适地对数据和假设做出概率陈述。
- en: 11.3 Doing Bayesian estimation
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 进行贝叶斯估计
- en: 'We ultimately want to use Bayesian statistics to make decisions about hypotheses,
    but before we do that we need to estimate the parameters that are necessary to
    make the decision. Here we will walk through the process of Bayesian estimation.
    Let’s use another screening example: Airport security screening. If you fly a
    lot, it’s just a matter of time until one of the random explosive screenings comes
    back positive; I had the particularly unfortunate experience of this happening
    soon after September 11, 2001, when airport security staff were especially on
    edge.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终希望使用贝叶斯统计来对假设做出决策，但在这之前我们需要估计做出决策所需的参数。在这里，我们将介绍贝叶斯估计的过程。让我们再举一个筛查的例子：机场安检。如果你经常飞行，随机的爆炸物筛查结果呈阳性只是时间问题；我在2001年9月11日后不久就经历了这样的不幸经历，当时机场安检人员特别紧张。
- en: What the security staff want to know is what is the likelihood that a person
    is carrying an explosive, given that the machine has given a positive test. Let’s
    walk through how to calculate this value using Bayesian analysis.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 安检人员想要知道的是一个人携带爆炸物的可能性，假设机器给出了阳性测试。让我们通过贝叶斯分析来计算这个值。
- en: 11.3.1 Specifying the prior
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.1 指定先验
- en: To use Bayes’ theorem, we first need to specify the prior probability for the
    hypothesis. In this case, we don’t know the real number but we can assume that
    it’s quite small. According to the [FAA](https://www.faa.gov/air_traffic/by_the_numbers/media/Air_Traffic_by_the_Numbers_2018.pdf),
    there were 971,595,898 air passengers in the U.S. in 2017\. Let’s say that one
    of those travelers was carrying an explosive in their bag — that would give a
    prior probability of 1 out of 971 million, which is very small! The security personnel
    may have reasonably held a stronger prior in the months after the 9/11 attack,
    so let’s say that their subjective belief was that one out of every million flyers
    was carrying an explosive.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用贝叶斯定理，我们首先需要指定假设的先验概率。在这种情况下，我们不知道真实数字，但我们可以假设它相当小。根据[FAA](https://www.faa.gov/air_traffic/by_the_numbers/media/Air_Traffic_by_the_Numbers_2018.pdf)的数据，2017年美国有971,595,898名航空乘客。假设其中一名旅客携带了爆炸物
    —— 这将给出一个先验概率为971百万分之一，非常小！安检人员在9/11袭击后的几个月内可能会有更强烈的先验概率，所以我们假设他们的主观信念是每百万名飞行者中有一人携带爆炸物。
- en: 11.3.2 Collect some data
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.2 收集一些数据
- en: The data are composed of the results of the explosive screening test. Let’s
    say that the security staff runs the bag through their testing apparatus 3 times,
    and it gives a positive reading on 3 of the 3 tests.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 数据由爆炸物筛查测试的结果组成。假设安全人员将袋子通过他们的测试设备进行3次测试，并且在3次测试中有3次阳性读数。
- en: 11.3.3 Computing the likelihood
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.3 计算可能性
- en: We want to compute the likelihood of the data under the hypothesis that there
    is an explosive in the bag. Let’s say that we know (from the machine’s manufacturer)
    that the sensitivity of the test is 0.99 – that is, when a device is present,
    it will detect it 99% of the time. To determine the likelihood of our data under
    the hypothesis that a device is present, we can treat each test as a Bernoulli
    trial (that is, a trial with an outcome of true or false) with a probability of
    success of 0.99, which we can model using a binomial distribution.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想计算在有爆炸物存在的假设下数据的可能性。假设我们知道（来自机器制造商）测试的灵敏度为0.99 - 也就是说，当设备存在时，它会在99%的时间内检测到它。为了确定在有设备存在的假设下我们的数据的可能性，我们可以将每个测试视为伯努利试验（即具有真或假结果的试验），成功的概率为0.99，我们可以使用二项分布来建模。
- en: 11.3.4 Computing the marginal likelihood
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.4 计算边际可能性
- en: 'We also need to know the overall likelihood of the data – that is, finding
    3 positives out of 3 tests. Computing the marginal likelihood is often one of
    the most difficult aspects of Bayesian analysis, but for our example it’s simple
    because we can take advantage of the specific form of Bayes’ theorem for a binary
    outcome that we introduced in Section [6.7](probability.html#bayestheorem):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要知道数据的整体可能性 - 也就是说，在3次测试中找到3个阳性。计算边际可能性通常是贝叶斯分析中最困难的部分之一，但对于我们的例子来说很简单，因为我们可以利用我们在第[6.7]节中介绍的二元结果的贝叶斯定理的特定形式：
- en: \[ P(E|T) = \frac{P(T|E)*P(E)}{P(T|E)*P(E) + P(T|\neg E)*P(\neg E)} \]
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(E|T) = \frac{P(T|E)*P(E)}{P(T|E)*P(E) + P(T|\neg E)*P(\neg E)} \]
- en: where \(E\) refers to the presence of explosives, and \(T\) refers to a postive
    test result.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(E\)指的是爆炸物的存在，\(T\)指的是阳性测试结果。
- en: The marginal likelihood in this case is a weighted average of the likelihood
    of the data under either presence or absence of the explosive, multiplied by the
    probability of the explosive being present (i.e. the prior). In this case, let’s
    say that we know (from the manufacturer) that the specificity of the test is 0.99,
    such that the likelihood of a positive result when there is no explosive (\(P(T|\neg
    E)\)) is 0.01.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，边际可能性是数据在爆炸物存在或不存在的情况下的可能性的加权平均值，乘以爆炸物存在的概率（即先验）。在这种情况下，假设我们知道（来自制造商）测试的特异性为0.99，因此当没有爆炸物时的阳性结果的可能性（\(P(T|\neg
    E)\)）为0.01。
- en: 11.3.5 Computing the posterior
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.5 计算后验
- en: We now have all of the parts that we need to compute the posterior probability
    of an explosive being present, given the observed 3 positive outcomes out of 3
    tests.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了计算爆炸物存在的后验概率所需的所有部分，这是在观察到3次测试中的3次阳性结果后。
- en: This result shows us that the posterior probability of an explosive in the bag
    given these positive tests (0.492) is just under 50%, again highlighting the fact
    that testing for rare events is almost always liable to produce high numbers of
    false positives, even when the specificity and sensitivity are very high.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果告诉我们，在这些阳性测试中，爆炸物在袋子里的后验概率（0.492）略低于50%，再次突出了测试罕见事件几乎总是容易产生大量假阳性的事实，即使特异性和灵敏度非常高。
- en: An important aspect of Bayesian analysis is that it can be sequential. Once
    we have the posterior from one analysis, it can become the prior for the next
    analysis!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯分析的一个重要方面是它可以是顺序的。一旦我们有了一个分析的后验，它可以成为下一个分析的先验！
- en: 11.4 Estimating posterior distributions
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.4 估计后验分布
- en: In the previous example there were only two possible outcomes – the explosive
    is either there or it’s not – and we wanted to know which outcome was most likely
    given the data. However, in other cases we want to use Bayesian estimation to
    estimate the numeric value of a parameter. Let’s say that we want to know about
    the effectiveness of a new drug for pain; to test this, we can administer the
    drug to a group of patients and then ask them whether their pain was improved
    or not after taking the drug. We can use Bayesian analysis to estimate the proportion
    of people for whom the drug will be effective using these data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的例子中，只有两种可能的结果 - 爆炸物要么存在，要么不存在 - 我们想知道在给定数据的情况下哪种结果最有可能。然而，在其他情况下，我们想使用贝叶斯估计来估计参数的数值。假设我们想了解一种新药物对疼痛的有效性；为了测试这一点，我们可以向一组患者施用药物，然后询问他们在服药后疼痛是否有所改善。我们可以使用贝叶斯分析来估计使用这些数据药物对患者有效的比例。
- en: 11.4.1 Specifying the prior
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.1 指定先验
- en: In this case, we don’t have any prior information about the effectiveness of
    the drug, so we will use a *uniform distribution* as our prior, since all values
    are equally likely under a uniform distribution. In order to simplify the example,
    we will only look at a subset of 99 possible values of effectiveness (from .01
    to .99, in steps of .01). Therefore, each possible value has a prior probability
    of 1/99.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们没有关于药物有效性的先验信息，因此我们将使用*均匀分布*作为我们的先验，因为在均匀分布下所有值都是同等可能的。为了简化例子，我们只会查看99个可能有效性值的子集（从.01到.99，步长为.01）。因此，每个可能的值都有1/99的先验概率。
- en: 11.4.2 Collect some data
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.2 收集一些数据
- en: We need some data in order to estimate the effect of the drug. Let’s say that
    we administer the drug to 100 individuals, we find that 64 respond positively
    to the drug.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一些数据来估计药物的效果。假设我们向100个人施用药物，我们发现64人对药物有积极反应。
- en: 11.4.3 Computing the likelihood
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.3 计算可能性
- en: We can compute the likelihood of the observed data under any particular value
    of the effectiveness parameter using the binomial density function. In Figure
    [11.2](bayesian-statistics.html#fig:like2) you can see the likelihood curves over
    numbers of responders for several different values of \(P_{respond}\). Looking
    at this, it seems that our observed data are relatively more likely under the
    hypothesis of \(P_{respond}=0.7\), somewhat less likely under the hypothesis of
    \(P_{respond}=0.5\), and quite unlikely under the hypothesis of \(P_{respond}=0.3\).
    One of the fundamental ideas of Bayesian inference is that we should upweight
    our belief in values of our parameter of interest in proportion to how likely
    the data are under those values, balanced against what we believed about the parameter
    values before having seen the data (our prior knowledge).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用二项密度函数计算在任何特定效果参数值下的观察数据的似然性。在图[11.2](bayesian-statistics.html#fig:like2)中，您可以看到在几种不同\(P_{respond}\)值下对响应者数量的似然曲线。从这个图中可以看出，我们的观察数据在\(P_{respond}=0.7\)的假设下相对更可能，在\(P_{respond}=0.5\)的假设下略不太可能，在\(P_{respond}=0.3\)的假设下相当不可能。贝叶斯推断的一个基本思想是，我们应该根据数据在这些值下的可能性来加强我们对感兴趣参数值的信念，同时平衡我们在看到数据之前对参数值的信念（我们的先验知识）。
- en: '![Likelihood of each possible number of responders under several different
    hypotheses (p(respond)=0.5 (solid), 0.7 (dotted), 0.3 (dashed).  Observed value
    shown in the vertical line](../Images/869a6b74505cf24d7eb32be2d1e48608.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![在几种不同假设下每个可能的响应者数量的似然性（p(respond)=0.5（实线），0.7（虚线），0.3（虚线）。观察值显示在垂直线上](../Images/869a6b74505cf24d7eb32be2d1e48608.png)'
- en: 'Figure 11.2: Likelihood of each possible number of responders under several
    different hypotheses (p(respond)=0.5 (solid), 0.7 (dotted), 0.3 (dashed). Observed
    value shown in the vertical line'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2：在几种不同假设下每个可能的响应者数量的似然性（p(respond)=0.5（实线），0.7（虚线），0.3（虚线）。观察值显示在垂直线上
- en: 11.4.4 Computing the marginal likelihood
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.4 计算边际似然
- en: In addition to the likelihood of the data under different hypotheses, we need
    to know the overall likelihood of the data, combining across all hypotheses (i.e.,
    the marginal likelihood). This marginal likelihood is primarily important because
    it helps to ensure that the posterior values are true probabilities. In this case,
    our use of a set of discrete possible parameter values makes it easy to compute
    the marginal likelihood, because we can just compute the likelihood of each parameter
    value under each hypothesis and add them up.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在不同假设下数据的似然性，我们还需要知道数据的整体似然性，结合所有假设（即边际似然）。这种边际似然主要重要是因为它有助于确保后验值是真实概率。在这种情况下，我们使用一组离散可能的参数值使得计算边际似然变得容易，因为我们可以计算每个假设下每个参数值的似然性并将它们相加。
- en: 11.4.5 Computing the posterior
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.5 计算后验
- en: We now have all of the parts that we need to compute the posterior probability
    distribution across all possible values of \(p_{respond}\), as shown in Figure
    [11.3](bayesian-statistics.html#fig:posteriorDist).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在拥有计算后验概率分布的所有部分所需的部分，这些部分涵盖了所有可能的\(p_{respond}\)值，如图[11.3](bayesian-statistics.html#fig:posteriorDist)所示。
- en: '![Posterior probability distribution for the observed data plotted in solid
    line against uniform prior distribution (dotted line). The maximum a posteriori
    (MAP) value is signified by the diamond symbol.](../Images/076cabac9ac6dc00217399841125525f.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![观察数据的后验概率分布以实线绘制，与均匀先验分布（虚线）相对。最大后验概率（MAP）值由菱形符号表示。](../Images/076cabac9ac6dc00217399841125525f.png)'
- en: 'Figure 11.3: Posterior probability distribution for the observed data plotted
    in solid line against uniform prior distribution (dotted line). The maximum a
    posteriori (MAP) value is signified by the diamond symbol.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3：观察数据的后验概率分布以实线绘制，与均匀先验分布（虚线）相对。最大后验概率（MAP）值由菱形符号表示。
- en: 11.4.6 Maximum a posteriori (MAP) estimation
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.6 最大后验概率（MAP）估计
- en: Given our data we would like to obtain an estimate of \(p_{respond}\) for our
    sample. One way to do this is to find the value of \(p_{respond}\) for which the
    posterior probability is the highest, which we refer to as the *maximum a posteriori*
    (MAP) estimate. We can find this from the data in [11.3](bayesian-statistics.html#fig:posteriorDist)
    — it’s the value shown with a marker at the top of the distribution. Note that
    the result (0.64) is simply the proportion of responders from our sample – this
    occurs because the prior was uniform and thus didn’t influence our estimate.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的数据，我们想要获得样本的\(p_{respond}\)估计值。一种方法是找到后验概率最高的\(p_{respond}\)值，我们称之为*最大后验概率*（MAP）估计。我们可以从[11.3](bayesian-statistics.html#fig:posteriorDist)的数据中找到这个值——它是在分布顶部标记的值。请注意，结果（0.64）只是我们样本中响应者的比例——这是因为先验是均匀的，因此并没有影响我们的估计。
- en: 11.4.7 Credible intervals
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.7 可信区间
- en: 'Often we would like to know not just a single estimate for the posterior, but
    an interval in which we are confident that the posterior falls. We previously
    discussed the concept of confidence intervals in the context of frequentist inference,
    and you may remember that the interpretation of confidence intervals was particularly
    convoluted: It was an interval that will contain the the value of the parameter
    95% of the time. What we really want is an interval in which we are confident
    that the true parameter falls, and Bayesian statistics can give us such an interval,
    which we call a *credible interval*.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们不仅想知道后验的单个估计值，还想知道一个区间，我们对后验落在其中有信心。我们之前在频率派推断的背景下讨论了置信区间的概念，您可能还记得置信区间的解释特别复杂：它是一个将包含参数值95%的时间的区间。我们真正想要的是一个我们对真实参数落在其中有信心的区间，而贝叶斯统计可以给我们这样的区间，我们称之为*可信区间*。
- en: 'The interpretation of this credible interval is much closer to what we had
    hoped we could get from a confidence interval (but could not): It tells us that
    there is a 95% probability that the value of \(p_{respond}\) falls between these
    two values. Importantly, in this case it shows that we have high confidence that
    \(p_{respond} > 0.0\), meaning that the drug seems to have a positive effect.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这个可信区间的解释更接近我们希望从置信区间中得到的（但没有得到）：它告诉我们，有95%的概率\(p_{respond}\)的值在这两个数值之间。重要的是，在这种情况下，它表明我们非常有信心\(p_{respond}
    > 0.0\)，这意味着药物似乎有积极的效果。
- en: In some cases the credible interval can be computed *numerically* based on a
    known distribution, but it’s more common to generate a credible interval by sampling
    from the posterior distribution and then to compute quantiles of the samples.
    This is particularly useful when we don’t have an easy way to express the posterior
    distribution numerically, which is often the case in real Bayesian data analysis.
    One such method (rejection sampling) is explained in more detail in the Appendix
    at the end of this chapter.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，可信区间可以根据已知分布*数值*计算，但更常见的是通过从后验分布中抽样来生成可信区间，然后计算样本的分位数。当我们没有简单的方法来数值表达后验分布时，这种方法特别有用，而在真实的贝叶斯数据分析中通常是这种情况。这样的一种方法（拒绝抽样）在本章末尾的附录中有更详细的解释。
- en: 11.4.8 Effects of different priors
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.8 不同先验的影响
- en: 'In the previous example we used a *flat prior*, meaning that we didn’t have
    any reason to believe that any particular value of \(p_{respond}\) was more or
    less likely. However, let’s say that we had instead started with some previous
    data: In a previous study, researchers had tested 20 people and found that 10
    of them had responded positively. This would have lead us to start with a prior
    belief that the treatment has an effect in 50% of people. We can do the same computation
    as above, but using the information from our previous study to inform our prior
    (see panel A in Figure [11.4](bayesian-statistics.html#fig:posteriorDistPrior)).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们使用了*平坦先验*，这意味着我们没有理由相信\(p_{respond}\)的任何特定值更可能或更不可能。然而，假设我们之前有一些先前的数据：在一项先前的研究中，研究人员测试了20人，发现其中有10人对治疗作出了积极反应。这将导致我们开始具有先验信念，即治疗对50%的人有效。我们可以做与上面相同的计算，但使用我们先前研究的信息来指导我们的先验（参见图[11.4](bayesian-statistics.html#fig:posteriorDistPrior)的A面板）。
- en: Note that the likelihood and marginal likelihood did not change - only the prior
    changed. The effect of the change in prior to was to pull the posterior closer
    to the mass of the new prior, which is centered at 0.5.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，似然和边际似然没有改变 - 只有先验改变了。先验变化的效果是将后验拉近到新先验的集中点，即0.5。
- en: 'Now let’s see what happens if we come to the analysis with an even stronger
    prior belief. Let’s say that instead of having previously observed 10 responders
    out of 20 people, the prior study had instead tested 500 people and found 250
    responders. This should in principle give us a much stronger prior, and as we
    see in panel B of Figure [11.4](bayesian-statistics.html#fig:posteriorDistPrior)
    , that’s what happens: The prior is much more concentrated around 0.5, and the
    posterior is also much closer to the prior. The general idea is that Bayesian
    inference combines the information from the prior and the likelihood, weighting
    the relative strength of each.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如果我们带着更强烈的先验信念进行分析会发生什么。假设我们之前观察到20个人中有10个反应者，而先前的研究测试了500人，发现250个反应者。这原则上应该给我们一个更强的先验，正如我们在图[11.4](bayesian-statistics.html#fig:posteriorDistPrior)的B面板中看到的那样：先验更加集中在0.5附近，后验也更接近先验。总的想法是，贝叶斯推断结合了先验和似然的信息，权衡了每个的相对强度。
- en: This example also highlights the sequential nature of Bayesian analysis – the
    posterior from one analysis can become the prior for the next analysis.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子也突出了贝叶斯分析的顺序性质 - 一个分析的后验可以成为下一个分析的先验。
- en: Finally, it is important to realize that if the priors are strong enough, they
    can completely overwhelm the data. Let’s say that you have an absolute prior that
    \(p_{respond}\) is 0.8 or greater, such that you set the prior likelihood of all
    other values to zero. What happens if we then compute the posterior?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，重要的是要意识到，如果先验足够强大，它们可以完全压倒数据。假设你有一个绝对先验，即\(p_{respond}\)大于等于0.8，这样你就将所有其他值的先验概率设为零。如果我们计算后验会发生什么呢？
- en: '![A: Effects of priors on the posterior distribution.  The original posterior
    distribution based on a flat prior is plotted in blue. The prior based on the
    observation of 10 responders out of 20 people is plotted in the dotted black line,
    and the posterior using this prior is plotted in red.  B: Effects of the strength
    of the prior on the posterior distribution. The blue line shows the posterior
    obtained using the prior based on 50 heads out of 100 people.  The dotted black
    line shows the prior based on 250 heads out of 500 flips, and the red line shows
    the posterior based on that prior. C: Effects of the strength of the prior on
    the posterior distribution. The blue line shows the posterior obtained using an
    absolute prior which states that p(respond) is 0.8 or greater.  The prior is shown
    in the dotted black line.](../Images/eed354f40056b218959302c62da23e9f.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![A: 先验对后验分布的影响。基于平坦先验的原始后验分布以蓝色绘制。基于观察到20人中有10个反应者的先验以虚线黑色线绘制，使用此先验的后验以红色绘制。B:
    先验强度对后验分布的影响。蓝线显示使用基于100人中50个反应者的先验获得的后验。虚线黑线显示基于500次抛硬币中250次正面的先验，红线显示基于该先验的后验。C:
    先验强度对后验分布的影响。蓝线显示使用绝对先验获得的后验，该先验指出p(respond)大于等于0.8。先验以虚线黑线显示。](../Images/eed354f40056b218959302c62da23e9f.png)'
- en: 'Figure 11.4: A: Effects of priors on the posterior distribution. The original
    posterior distribution based on a flat prior is plotted in blue. The prior based
    on the observation of 10 responders out of 20 people is plotted in the dotted
    black line, and the posterior using this prior is plotted in red. B: Effects of
    the strength of the prior on the posterior distribution. The blue line shows the
    posterior obtained using the prior based on 50 heads out of 100 people. The dotted
    black line shows the prior based on 250 heads out of 500 flips, and the red line
    shows the posterior based on that prior. C: Effects of the strength of the prior
    on the posterior distribution. The blue line shows the posterior obtained using
    an absolute prior which states that p(respond) is 0.8 or greater. The prior is
    shown in the dotted black line.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4：A：先验对后验分布的影响。基于平坦先验的原始后验分布以蓝色绘制。基于20人中10名回答者的观察的先验以虚线黑色线绘制，使用此先验的后验以红色绘制。B：先验强度对后验分布的影响。蓝线显示使用基于100人中50个头的先验获得的后验。虚线黑线显示基于500次抛硬币中250个头的先验，红线显示基于该先验的后验。C：先验强度对后验分布的影响。蓝线显示使用绝对先验获得的后验，该先验表明p（回答）为0.8或更高。先验以虚线黑线显示。
- en: In panel C of Figure [11.4](bayesian-statistics.html#fig:posteriorDistPrior)
    we see that there is zero density in the posterior for any of the values where
    the prior was set to zero - the data are overwhelmed by the absolute prior.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在图[11.4](bayesian-statistics.html#fig:posteriorDistPrior)的C面板中，我们看到后验中没有任何值的密度，其中先验被设为零
    - 数据被绝对先验所压倒。
- en: 11.5 Choosing a prior
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.5 选择先验
- en: The impact of priors on the resulting inferences are the most controversial
    aspect of Bayesian statistics. What is the right prior to use? If the choice of
    prior determines the results (i.e., the posterior), how can you be sure you results
    are trustworthy? These are difficult questions, but we should not back away just
    because we are faced with hard questions. As we discussed previously, Bayesian
    analyses give us interpretable results (credible intervals, etc.). This alone
    should inspire us to think hard about these questions so that we can arrive with
    results that are reasonable and interpretable.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯统计中最具争议的方面是先验对推断结果的影响。什么是正确的先验？如果先验的选择决定了结果（即后验），你如何确信你的结果是可信的？这些是困难的问题，但我们不应该因为面对困难问题而退缩。正如我们之前讨论过的，贝叶斯分析给我们提供了可解释的结果（可信区间等）。这本身就应该激励我们认真思考这些问题，以便得出合理和可解释的结果。
- en: There are various ways to choose one’s priors, which (as we saw above) can impact
    the resulting inferences. Sometimes we have a very specific prior, as in the case
    where we expected our coin to lands heads 50% of the time, but in many cases we
    don’t have such strong a starting point. *Uninformative priors* attempt to influence
    the resulting posterior as little as possible, as we saw in the example of the
    uniform prior above. It’s also common to use *weakly informative priors* (or *default
    priors*), which influence the result only very slightly. For example, if we had
    used a binomial distribution based on one heads out of two coin flips, the prior
    would have been centered around 0.5 but fairly flat, influencing the posterior
    only slightly. It is also possible to use priors based on the scientific literature
    or pre-existing data, which we would call *empirical priors*. In general, however,
    we will stick to the use of uninformative/weakly informative priors, since they
    raise the least concern about influencing our results.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种方法可以选择先验，这些方法（如上所述）可能会影响结果的推断。有时我们有一个非常具体的先验，就像我们预期硬币掷出正面的概率为50%一样，但在许多情况下，我们没有这样强烈的起点。*无信息先验*试图尽可能少地影响结果的后验，就像我们在上面的均匀先验的例子中看到的那样。使用*弱信息先验*（或*默认先验*）也很常见，它们只会轻微地影响结果。例如，如果我们使用基于两次抛硬币中的一次正面的二项分布，先验将以0.5为中心，但相当平坦，只会轻微地影响后验。还可以使用基于科学文献或现有数据的先验，我们称之为*经验先验*。然而，总的来说，我们将坚持使用无信息/弱信息先验，因为它们最少地引起我们对结果的担忧。
- en: 11.6 Bayesian hypothesis testing
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.6 贝叶斯假设检验
- en: 'Having learned how to perform Bayesian estimation, we now turn to the use of
    Bayesian methods for hypothesis testing. Let’s say that there are two politicians
    who differ in their beliefs about whether the public is in favor an extra tax
    to support the national parks. Senator Smith thinks that only 40% of people are
    in favor of the tax, whereas Senator Jones thinks that 60% of people are in favor.
    They arrange to have a poll done to test this, which asks 1000 randomly selected
    people whether they support such a tax. The results are that 490 of the people
    in the polled sample were in favor of the tax. Based on these data, we would like
    to know: Do the data support the claims of one senator over the other,and by how
    much? We can test this using a concept known as the [Bayes factor](https://bayesfactor.blogspot.com/2014/02/the-bayesfactor-package-this-blog-is.html),
    which quantifies which hypothesis is better by comparing how well each predicts
    the observed data.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 学会了如何进行贝叶斯估计后，我们现在转向使用贝叶斯方法进行假设检验。假设有两位政治家在他们对公众是否支持额外税收以支持国家公园的信念上存在差异。史密斯参议员认为只有40%的人支持这项税收，而琼斯参议员认为有60%的人支持。他们安排进行一项民意调查来测试这一点，询问了1000名随机选取的人是否支持这样的税收。结果是，在接受调查的样本中，有490人支持这项税收。基于这些数据，我们想知道：数据是否支持一位参议员的主张胜过另一位，以及胜过多少？我们可以使用一个称为[贝叶斯因子](https://bayesfactor.blogspot.com/2014/02/the-bayesfactor-package-this-blog-is.html)的概念来测试这一点，它通过比较每个假设对观察到的数据的预测能力来量化哪个假设更好。
- en: 11.6.1 Bayes factors
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.6.1 贝叶斯因子
- en: 'The Bayes factor characterizes the relative likelihood of the data under two
    different hypotheses. It is defined as:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯因子表征了数据在两种不同假设下的相对可能性。它的定义如下：
- en: \[ BF = \frac{p(data|H_1)}{p(data|H_2)} \]
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: \[ BF = \frac{p(data|H_1)}{p(data|H_2)} \]
- en: for two hypotheses \(H_1\) and \(H_2\). In the case of our two senators, we
    know how to compute the likelihood of the data under each hypothesis using the
    binomial distribution; let’s assume for the moment that our prior probability
    for each senator being correct is the same (\(P_{H_1} = P_{H_2} = 0.5\)). We will
    put Senator Smith in the numerator and Senator Jones in the denominator, so that
    a value greater than one will reflect greater evidence for Senator Smith, and
    a value less than one will reflect greater evidence for Senator Jones. The resulting
    Bayes Factor (3325.26) provides a measure of the evidence that the data provides
    regarding the two hypotheses - in this case, it tells us the data support Senator
    Smith more than 3000 times more strongly than they support Senator Jones.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对于两个假设\(H_1\)和\(H_2\)。在我们的两位参议员的情况下，我们知道如何使用二项分布计算每个假设下数据的可能性；暂时假设每位参议员的先验概率相同（\(P_{H_1}
    = P_{H_2} = 0.5\)）。我们将参议员史密斯放在分子中，参议员琼斯放在分母中，这样大于一的值将反映对参议员史密斯更大的证据，小于一的值将反映对参议员琼斯更大的证据。得到的贝叶斯因子（3325.26）提供了关于数据支持两个假设的证据的度量
    - 在这种情况下，它告诉我们数据支持参议员史密斯比支持参议员琼斯强大3000多倍。
- en: 11.6.2 Bayes factors for statistical hypotheses
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.6.2 统计假设的贝叶斯因子
- en: In the previous example we had specific predictions from each senator, whose
    likelihood we could quantify using the binomial distribution. In addition, our
    prior probability for the two hypotheses was equal. However, in real data analysis
    we generally must deal with uncertainty about our parameters, which complicates
    the Bayes factor, because we need to compute the marginal likelihood (that is,
    an integrated average of the likelihoods over all possible model parameters, weighted
    by their prior probabilities). However, in exchange we gain the ability to quantify
    the relative amount of evidence in favor of the null versus alternative hypotheses.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们对每位参议员都有具体的预测，我们可以使用二项分布来量化它们的可能性。此外，我们对两个假设的先验概率是相等的。然而，在实际数据分析中，我们通常必须处理关于参数的不确定性，这使得贝叶斯因子变得复杂，因为我们需要计算边际似然（即在所有可能的模型参数上的似然的综合平均，按其先验概率加权）。然而，作为交换，我们获得了量化支持零假设与备择假设相对证据量的能力。
- en: 'Let’s say that we are a medical researcher performing a clinical trial for
    the treatment of diabetes, and we wish to know whether a particular drug reduces
    blood glucose compared to placebo. We recruit a set of volunteers and randomly
    assign them to either drug or placebo group, and we measure the change in hemoglobin
    A1C (a marker for blood glucose levels) in each group over the period in which
    the drug or placebo was administered. What we want to know is: Is there a difference
    between the drug and placebo?'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们是一名进行糖尿病治疗临床试验的医学研究人员，我们希望知道一种特定药物是否与安慰剂相比能够降低血糖。我们招募了一组志愿者，并将他们随机分配到药物组或安慰剂组，然后我们测量在药物或安慰剂使用期间每组的血红蛋白A1C（血糖水平的标志）的变化。我们想知道的是：药物和安慰剂之间是否有差异？
- en: 'First, let’s generate some data and analyze them using null hypothesis testing
    (see Figure [11.5](bayesian-statistics.html#fig:bayesTesting)). Then let’s perform
    an independent-samples t-test, which shows that there is a significant difference
    between the groups:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们生成一些数据并使用零假设检验进行分析（参见图[11.5](bayesian-statistics.html#fig:bayesTesting)）。然后让我们进行独立样本t检验，结果显示组之间存在显著差异：
- en: '![Box plots showing data for drug and placebo groups.](../Images/d19b8bd81b514b0c4c5c79953be26919.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![显示药物组和安慰剂组的箱线图。](../Images/d19b8bd81b514b0c4c5c79953be26919.png)'
- en: 'Figure 11.5: Box plots showing data for drug and placebo groups.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5：箱线图显示药物组和安慰剂组的数据。
- en: '[PRE0]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This test tells us that there is a significant difference between the groups,
    but it doesn’t quantify how strongly the evidence supports the null versus alternative
    hypotheses. To measure that, we can compute a Bayes factor using `ttestBF` function
    from the BayesFactor package in R:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这个检验告诉我们组之间存在显著差异，但它并没有量化证据支持零假设与备择假设的强度。为了衡量这一点，我们可以使用R中BayesFactor包的`ttestBF`函数计算贝叶斯因子：
- en: '[PRE1]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We are particularly interested in the Bayes Factor for an effect greater than
    zero, which is listed in the line marked “[1]” in the report. The Bayes factor
    here tells us that the alternative hypothesis (i.e. that the difference is greater
    than zero) is about 3 times more likely than the point null hypothesis (i.e. a
    mean difference of exactly zero) given the data. Thus, while the effect is significant,
    the amount of evidence it provides us in favor of the alternative hypothesis is
    rather weak.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们特别关注大于零效应的贝叶斯因子，在报告中标有“[1]”的行中列出。这里的贝叶斯因子告诉我们，备择假设（即差异大于零）相对于点零假设（即均值差异恰好为零）在数据给定的情况下大约有3倍的可能性。因此，虽然效应是显著的，但它提供给我们支持备择假设的证据量相当弱。
- en: 11.6.2.1 One-sided tests
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.6.2.1 单侧检验
- en: 'We generally are less interested in testing against the null hypothesis of
    a specific point value (e.g. mean difference = 0) than we are in testing against
    a directional null hypothesis (e.g. that the difference is less than or equal
    to zero). We can also perform a directional (or *one-sided*) test using the results
    from `ttestBF` analysis, since it provides two Bayes factors: one for the alternative
    hypothesis that the mean difference is greater than zero, and one for the alternative
    hypothesis that the mean difference is less than zero. If we want to assess the
    relative evidence for a positive effect, we can compute a Bayes factor comparing
    the relative evidence for a positive versus a negative effect by simply dividing
    the two Bayes factors returned by the function:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常对特定点值的零假设（例如，平均差异= 0）进行测试的兴趣不如对方向性零假设（例如，差异小于或等于零）进行测试。我们还可以使用`ttestBF`分析的结果执行方向（或*单侧*）检验，因为它提供两个贝叶斯因子：一个是备择假设，即平均差异大于零，另一个是备择假设，即平均差异小于零。如果我们想评估正效应的相对证据，我们可以通过简单地将函数返回的两个贝叶斯因子相除来计算比较正效应与负效应的相对证据：
- en: '[PRE2]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we see that the Bayes factor for a positive effect versus a negative effect
    is substantially larger (almost 30).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们看到，正效应与负效应的贝叶斯因子大得多（几乎30）。
- en: 11.6.2.2 Interpreting Bayes Factors
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.6.2.2 解释贝叶斯因子
- en: 'How do we know whether a Bayes factor of 2 or 20 is good or bad? There is a
    general guideline for interpretation of Bayes factors suggested by [Kass & Rafferty
    (1995)](https://www.andrew.cmu.edu/user/kk3n/simplicity/KassRaftery1995.pdf):'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何知道贝叶斯因子为2或20是好还是坏？[Kass & Rafferty (1995)](https://www.andrew.cmu.edu/user/kk3n/simplicity/KassRaftery1995.pdf)提出了贝叶斯因子解释的一般指导方针：
- en: '| BF | Strength of evidence |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| BF | 证据的强度 |'
- en: '| --- | --- |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 to 3 | not worth more than a bare mention |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 1到3 | 不值一提 |'
- en: '| 3 to 20 | positive |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 3到20 | 正效应 |'
- en: '| 20 to 150 | strong |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 20到150 | 强 |'
- en: '| >150 | very strong |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| >150 | 非常强 |'
- en: Based on this, even though the statisical result is significant, the amount
    of evidence in favor of the alternative vs. the point null hypothesis is weak
    enough that it’s hardly worth even mentioning, whereas the evidence for the directional
    hypothesis is relatively strong.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，即使统计结果显着，支持备择假设与点零假设相比的证据量也很弱，几乎不值一提，而对于方向性假设的证据相对较强。
- en: 11.6.3 Assessing evidence for the null hypothesis
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.6.3 评估零假设的证据
- en: Because the Bayes factor is comparing evidence for two hypotheses, it also allows
    us to assess whether there is evidence in favor of the null hypothesis, which
    we couldn’t do with standard null hypothesis testing (because it starts with the
    assumption that the null is true). This can be very useful for determining whether
    a non-significant result really provides strong evidence that there is no effect,
    or instead just reflects weak evidence overall.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 因为贝叶斯因子比较了两个假设的证据，所以它还允许我们评估是否有证据支持零假设，这是标准零假设检验无法做到的（因为它假设零假设为真）。这对于确定非显著结果是否真的提供了无效果的强有力证据，或者只是总体证据较弱非常有用。
- en: 11.7 Learning objectives
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.7 学习目标
- en: 'After reading this chapter, should be able to:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完本章后，应该能够：
- en: Describe the main differences between Bayesian analysis and null hypothesis
    testing
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述贝叶斯分析和零假设检验之间的主要区别
- en: Describe and perform the steps in a Bayesian analysis
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述并执行贝叶斯分析的步骤
- en: Describe the effects of different priors, and the considerations that go into
    choosing a prior
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述不同先验的影响以及选择先验的考虑因素
- en: Describe the difference in interpretation between a confidence interval and
    a Bayesian credible interval
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述置信区间和贝叶斯可信区间之间的解释差异
- en: 11.8 Suggested readings
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.8 建议阅读
- en: '*The Theory That Would Not Die: How Bayes’ Rule Cracked the Enigma Code, Hunted
    Down Russian Submarines, and Emerged Triumphant from Two Centuries of Controversy*,
    by Sharon Bertsch McGrayne'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《不会消失的理论：贝叶斯定理如何破译了密码，追踪俄罗斯潜艇，并在两个世纪的争议中胜出》，作者：沙龙·伯奇·麦格雷恩
- en: '*Doing Bayesian Data Analysis: A Tutorial Introduction with R*, by John K.
    Kruschke'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《贝叶斯数据分析：R的教程介绍》，作者：约翰·K·克鲁斯克
- en: '11.9 Appendix:'
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.9 附录：
- en: 11.9.1 Rejection sampling
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.9.1 拒绝抽样
- en: We will generate samples from our posterior distribution using a simple algorithm
    known as [*rejection sampling*](https://am207.github.io/2017/wiki/rejectionsampling.html).
    The idea is that we choose a random value of x (in this case \(p_{respond}\))
    and a random value of y (in this case, the posterior probability of \(p_{respond}\))
    each from a uniform distribution. We then only accept the sample if \(y < f(x)\)
    - in this case, if the randomly selected value of y is less than the actual posterior
    probability of y. Figure [11.6](bayesian-statistics.html#fig:rejectionSampling)
    shows an example of a histogram of samples using rejection sampling, along with
    the 95% credible intervals obtained using this method (with the values presented
    in Table [**??**](#tab:credInt)).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一种称为[*拒绝抽样*](https://am207.github.io/2017/wiki/rejectionsampling.html)的简单算法从后验分布中生成样本。其思想是我们从均匀分布中选择x（在本例中为\(p_{respond}\)）和y（在本例中为\(p_{respond}\)的后验概率）的随机值。然后，我们只接受样本，如果\(y
    < f(x)\) - 在本例中，如果随机选择的y值小于y的实际后验概率。图[11.6](bayesian-statistics.html#fig:rejectionSampling)显示了使用拒绝抽样的样本直方图示例，以及使用该方法获得的95％可信区间（表[**??**](#tab:credInt)中的值）。
- en: '|  | x |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  | x |'
- en: '| :-- | --: |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| :-- | --: |'
- en: '| 2.5% | 0.54 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 2.5% | 0.54 |'
- en: '| 97.5% | 0.73 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 97.5% | 0.73 |'
- en: '![Rejection sampling example.The black line shows the density of all possible
    values of p(respond); the blue lines show the 2.5th and 97.5th percentiles of
    the distribution, which represent the 95 percent credible interval for the estimate
    of p(respond).](../Images/3d7a2b1b97f896465eaddeee9ac7f642.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![拒绝抽样示例。黑线显示所有可能的p（respond）值的密度；蓝线显示分布的2.5和97.5百分位数，代表p（respond）估计的95％可信区间。](../Images/3d7a2b1b97f896465eaddeee9ac7f642.png)'
- en: 'Figure 11.6: Rejection sampling example.The black line shows the density of
    all possible values of p(respond); the blue lines show the 2.5th and 97.5th percentiles
    of the distribution, which represent the 95 percent credible interval for the
    estimate of p(respond).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6：拒绝抽样示例。黑线显示了p(回答)所有可能值的密度；蓝线显示了分布的2.5和97.5百分位数，代表了对p(回答)估计的95%可信区间。
