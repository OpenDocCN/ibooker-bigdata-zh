- en: Chapter 1\. Streaming 101
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。流处理101
- en: 'Streaming data processing is a big deal in big data these days, and for good
    reasons; among them are the following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 流数据处理在大数据领域是一件大事，而且有很多好的原因；其中包括以下几点：
- en: Businesses crave ever-more timely insights into their data, and switching to
    streaming is a good way to achieve lower latency
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 企业渴望对其数据获得更及时的洞察，转向流处理是实现更低延迟的好方法。
- en: The massive, unbounded datasets that are increasingly common in modern business
    are more easily tamed using a system designed for such never-ending volumes of
    data.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在现代商业中越来越普遍的大规模、无限的数据集，更容易通过设计用于这种不断增长的数据量的系统来驯服。
- en: Processing data as they arrive spreads workloads out more evenly over time,
    yielding more consistent and predictable consumption of resources.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着数据到达时进行处理，可以更均匀地分配工作负载，从而产生更一致和可预测的资源消耗。
- en: Despite this business-driven surge of interest in streaming, streaming systems
    long remained relatively immature compared to their batch brethren. It’s only
    recently that the tide has swung conclusively in the other direction. In my more
    bumptious moments, I hope that might be in small part due to the solid dose of
    goading I originally served up in my [“Streaming 101”](http://oreil.ly/1p1AKux)
    and [“Streaming 102”](http://oreil.ly/1TV7YGU) blog posts (on which the first
    few chapters of this book are rather obviously based). But in reality, there’s
    also just a lot of industry interest in seeing streaming systems mature and a
    lot of smart and active folks out there who enjoy building them.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管业务驱动的对流处理的兴趣激增，但与批处理系统相比，流处理系统长期以来仍然相对不够成熟。直到最近，潮水才明确地向另一个方向转变。在我更为自负的时刻，我希望这在某种程度上是由于我最初在我的[“流处理101”](http://oreil.ly/1p1AKux)和[“流处理102”](http://oreil.ly/1TV7YGU)博客文章中提出的坚定的激励（这本书的前几章显然是基于这些文章）。但实际上，行业对流处理系统成熟的兴趣很大，有很多聪明而积极的人喜欢构建这些系统。
- en: Even though the battle for general streaming advocacy has been, in my opinion,
    effectively won, I’m still going to present my original arguments from “Streaming
    101” more or less unaltered. For one, they’re still very applicable today, even
    if much of industry has begun to heed the battle cry. And for two, there are a
    lot of folks out there who still haven’t gotten the memo; this book is an extended
    attempt at getting these points across.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我认为一般流处理的倡导战已经取得了有效的胜利，但我仍然会基本上原封不动地提出我在“流处理101”中的原始论点。首先，即使行业的大部分已经开始听从这个呼声，这些论点今天仍然非常适用。其次，还有很多人还没有得到这个消息；这本书是我努力传达这些观点的延续尝试。
- en: 'To begin, I cover some important background information that will help frame
    the rest of the topics I want to discuss. I do this in three specific sections:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我介绍一些重要的背景信息，这将有助于构建我想讨论的其他主题。我在三个具体的部分中做了这件事：
- en: Terminology
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 术语
- en: To talk precisely about complex topics requires precise definitions of terms.
    For some terms that have overloaded interpretations in current use, I’ll try to
    nail down exactly what I mean when I say them.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要准确地讨论复杂的主题，需要对术语进行准确的定义。对于一些当前使用中具有多重解释的术语，我将尽量明确我使用它们时的确切含义。
- en: Capabilities
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 能力
- en: I remark on the oft-perceived shortcomings of streaming systems. I also propose
    the frame of mind that I believe data processing system builders need to adopt
    in order to address the needs of modern data consumers going forward.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我谈到了人们对流处理系统常常认为存在的缺点。我还提出了我认为数据处理系统构建者需要采取的心态，以满足现代数据消费者的需求。
- en: Time domains
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 时间领域
- en: I introduce the two primary domains of time that are relevant in data processing,
    show how they relate, and point out some of the difficulties these two domains
    impose.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我介绍了数据处理中相关的两个主要时间领域，展示它们的关系，并指出这两个领域所带来的一些困难。
- en: 'Terminology: What Is Streaming?'
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语：什么是流处理？
- en: 'Before going any further, I’d like to get one thing out of the way: what is
    streaming? The term streaming is used today to mean a variety of different things
    (and for simplicity I’ve been using it somewhat loosely up until now), which can
    lead to misunderstandings about what streaming really is or what streaming systems
    are actually capable of. As a result, I would prefer to define the term somewhat
    precisely.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我想先搞清楚一件事：什么是流处理？今天，流处理这个术语被用来表示各种不同的东西（为了简单起见，我到目前为止一直在使用它有些宽泛），这可能会导致对流处理的真正含义或流处理系统实际能够做什么产生误解。因此，我更愿意对这个术语进行比较精确的定义。
- en: The crux of the problem is that many things that ought to be described by *what*
    they are (unbounded data processing, approximate results, etc.), have come to
    be described colloquially by *how* they historically have been accomplished (i.e.,
    via streaming execution engines). This lack of precision in terminology clouds
    what streaming really means, and in some cases it burdens streaming systems themselves
    with the implication that their capabilities are limited to characteristics historically
    described as “streaming,” such as approximate or speculative results.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 问题的关键在于，许多本应该被描述为“它们是什么”（无限数据处理、近似结果等）的事物，却已经在口头上被描述为它们历史上是如何完成的（即通过流处理执行引擎）。术语的不精确使得流处理的真正含义变得模糊，并且在某些情况下，给流处理系统本身带来了这样的暗示，即它们的能力仅限于历史上被描述为“流处理”的特征，比如近似或推测性结果。
- en: 'Given that well-designed streaming systems are just as capable (technically
    more so) of producing correct, consistent, repeatable results as any existing
    batch engine, I prefer to isolate the term “streaming” to a very specific meaning:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于设计良好的流处理系统在技术上与任何现有的批处理引擎一样能够产生正确、一致、可重复的结果，我更倾向于将术语“流处理”限定为非常具体的含义：
- en: Streaming system
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理系统
- en: A type of data processing engine that is designed with infinite datasets in
    mind.¹
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一种设计时考虑到无限数据集的数据处理引擎。¹
- en: If I want to talk about low-latency, approximate, or speculative results, I
    use those specific words rather than imprecisely calling them “streaming.”
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我想谈论低延迟、近似或推测性结果，我会使用这些具体的词，而不是不准确地称它们为“流处理”。
- en: 'Precise terms are also useful when discussing the different types of data one
    might encounter. From my perspective, there are two important (and orthogonal)
    dimensions that define the shape of a given dataset: *cardinality* and *constitution*.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论可能遇到的不同类型的数据时，精确的术语也是有用的。在我看来，有两个重要（且正交的）维度来定义给定数据集的形状：*基数*和*构成*。
- en: 'The cardinality of a dataset dictates its size, with the most salient aspect
    of cardinality being whether a given dataset is finite or infinite. Here are the
    two terms I prefer to use for describing the coarse cardinality in a dataset:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的基数决定了其大小，基数最显著的方面是给定数据集是有限的还是无限的。以下是我喜欢用来描述数据集中粗略基数的两个术语：
- en: Bounded data
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有界数据
- en: A type of dataset that is finite in size.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 有限大小的数据集类型。
- en: Unbounded data
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 无界数据
- en: A type of dataset that is infinite in size (at least theoretically).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 无限大小的数据集类型（至少在理论上是这样）。
- en: Cardinality is important because the unbounded nature of infinite datasets imposes
    additional burdens on data processing frameworks that consume them. More on this
    in the next section.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 基数很重要，因为无限数据集的无界性对消耗它们的数据处理框架施加了额外的负担。在下一节中会详细介绍这一点。
- en: 'The constitution of a dataset, on the other hand, dictates its physical manifestation.
    As a result, the constitution defines the ways one can interact with the data
    in question. We won’t get around to deeply examining constitutions until Chapter 6,
    but to give you a brief sense of things, there are two primary constitutions of
    importance:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，数据集的构成决定了其物理表现形式。因此，构成定义了人们可以与所讨论的数据进行交互的方式。我们直到第6章才会深入研究构成，但为了让你对事情有一个简要的了解，有两种主要的构成很重要：
- en: Table
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 表
- en: A holistic view of a dataset at a specific point in time. SQL systems have traditionally
    dealt in tables.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在特定时间点上对数据集的整体视图。SQL系统传统上处理表。
- en: Stream²
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 流²
- en: An element-by-element view of the evolution of a dataset over time. The MapReduce
    lineage of data processing systems have traditionally dealt in streams.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 逐个元素地查看数据集随时间的演变。MapReduce数据处理系统传统上处理流。
- en: We look quite deeply at the relationship between streams and tables in Chapters
    6, 8, and 9, and in Chapter 8 we also learn about the unifying underlying concept
    of *time-varying relations* that ties them together. But until then, we deal primarily
    in streams because that’s the constitution pipeline developers directly interact
    with in most data processing systems today (both batch and streaming). It’s also
    the constitution that most naturally embodies the challenges that are unique to
    stream processing.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第6、8和9章深入探讨了流和表之间的关系，在第8章中，我们还了解了将它们联系在一起的统一基本概念*时变关系*。但在那之前，我们主要处理流，因为这是大多数数据处理系统（批处理和流处理）中开发人员直接交互的内容。它也是最自然地体现了流处理所特有的挑战的内容。
- en: On the Greatly Exaggerated Limitations of Streaming
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对流处理的夸大限制
- en: On that note, let’s next talk a bit about what streaming systems can and can’t
    do, with an emphasis on can. One of the biggest things I want to get across in
    this chapter is just how capable a well-designed streaming system can be. Streaming
    systems have historically been relegated to a somewhat niche market of providing
    low-latency, inaccurate, or speculative results, often in conjunction with a more
    capable batch system to provide eventually correct results; in other words, the
    [Lambda Architecture](http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，让我们接下来谈一谈流处理系统能做什么和不能做什么，重点是能做什么。我在本章最想传达的一件重要的事情是，一个设计良好的流处理系统有多么强大。流处理系统历来被局限在为提供低延迟、不准确或推测性结果的一些小众市场上，通常与更有能力的批处理系统一起提供最终正确的结果；换句话说，[Lambda架构](http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html)。
- en: 'For those of you not already familiar with the Lambda Architecture, the basic
    idea is that you run a streaming system alongside a batch system, both performing
    essentially the same calculation. The streaming system gives you low-latency,
    inaccurate results (either because of the use of an approximation algorithm, or
    because the streaming system itself does not provide correctness), and some time
    later a batch system rolls along and provides you with correct output. Originally
    proposed by Twitter’s Nathan Marz (creator of [Storm](http://storm.apache.org)),
    it ended up being quite successful because it was, in fact, a fantastic idea for
    the time; streaming engines were a bit of a letdown in the correctness department,
    and batch engines were as inherently unwieldy as you’d expect, so Lambda gave
    you a way to have your proverbial cake and eat it too. Unfortunately, maintaining
    a Lambda system is a hassle: you need to build, provision, and maintain two independent
    versions of your pipeline and then also somehow merge the results from the two
    pipelines at the end.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些对Lambda架构不太熟悉的人，基本思想是你同时运行一个流处理系统和一个批处理系统，两者基本上执行相同的计算。流处理系统提供低延迟、不准确的结果（要么是因为使用了近似算法，要么是因为流处理系统本身没有提供正确性），然后一段时间后，批处理系统提供正确的输出。最初由Twitter的Nathan
    Marz（[Storm](http://storm.apache.org)的创建者）提出，它最终非常成功，因为事实上这是一个很棒的想法；流处理引擎在正确性方面有点令人失望，而批处理引擎像你期望的那样本质上难以处理，所以Lambda让你可以同时拥有你的谚语蛋糕并吃掉它。不幸的是，维护Lambda系统很麻烦：你需要构建、提供和维护两个独立版本的管道，然后还要以某种方式合并两个管道的结果。
- en: As someone who spent years working on a strongly consistent streaming engine,
    I also found the entire principle of the Lambda Architecture a bit unsavory. Unsurprisingly,
    I was a huge fan of Jay Kreps’ [“Questioning the Lambda Architecture”](https://oreil.ly/2LSEdqz)
    post when it came out. Here was one of the first highly visible statements against
    the necessity of dual-mode execution. Delightful. Kreps addressed the issue of
    repeatability in the context of using a replayable system like Kafka as the streaming
    interconnect, and went so far as to propose the Kappa Architecture, which basically
    means running a single pipeline using a well-designed system that’s appropriately
    built for the job at hand. I’m not convinced that notion requires its own Greek
    letter name, but I fully support the idea in principle.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个花了多年时间在一个强一致性的流式引擎上工作的人，我也觉得Lambda架构的整个原则有点不可取。毫不奇怪，当Jay Kreps的“质疑Lambda架构”一文出来时，我是一个巨大的粉丝。这是对双模式执行的必要性的一个最早的高度可见的声明。令人愉快。Kreps在使用可重放系统（如Kafka）作为流式互连的情况下，解决了可重复性的问题，并且甚至提出了Kappa架构，基本上意味着使用一个为手头的工作量量身定制的系统来运行一个单一的流水线。我并不确定这个概念需要自己的希腊字母名称，但我完全支持这个原则。
- en: Quite honestly, I’d take things a step further. I would argue that well-designed
    streaming systems actually provide a strict superset of batch functionality. Modulo
    perhaps an efficiency delta, there should be no need for batch systems as they
    exist today. And kudos to the [Apache Flink](http://flink.apache.org) folks for
    taking this idea to heart and building a system that’s all-streaming-all-the-time
    under the covers, even in “batch” mode; I love it.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 坦率地说，我会更进一步。我会认为，设计良好的流式系统实际上提供了批处理功能的严格超集。除了效率差异之外，今天的批处理系统应该没有存在的必要。对于[Apache
    Flink](http://flink.apache.org)的人来说，他们将这个想法内化并构建了一个在底层始终是全流式的系统，即使在“批处理”模式下也是如此；我喜欢这一点。
- en: 'The corollary of all this is that broad maturation of streaming systems combined
    with robust frameworks for unbounded data processing will in time allow for the
    relegation of the Lambda Architecture to the antiquity of big data history where
    it belongs. I believe the time has come to make this a reality. Because to do
    so—that is, to beat batch at its own game—you really only need two things:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这一切的推论是，流式系统的广泛成熟，加上对无界数据处理的健壮框架，最终将允许Lambda架构被归类到大数据历史的古董中。我相信现在是时候让这成为现实了。因为要做到这一点，也就是说，要在批处理的游戏中击败批处理，你真的只需要两件事：
- en: Correctness
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正确性
- en: This gets you parity with batch. At the core, correctness boils down to consistent
    storage. Streaming systems need a method for checkpointing persistent state over
    time (something Kreps has talked about in his [“Why local state is a fundamental
    primitive in stream processing”](https://oreil.ly/2l8asqf) post), and it must
    be well designed enough to remain consistent in light of machine failures. When
    Spark Streaming first appeared in the public big data scene a few years ago, it
    was a beacon of consistency in an otherwise dark streaming world. Thankfully,
    things have improved substantially since then, but it is remarkable how many streaming
    systems still try to get by without strong consistency.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这让你与批处理保持一致。在核心上，正确性归结为一致的存储。流式系统需要一种方法来随着时间对持久状态进行检查点（Kreps在他的“为什么本地状态是流处理中的基本原语”一文中谈到了这一点），并且必须设计得足够好，以便在机器故障的情况下保持一致。几年前，当Spark
    Streaming首次出现在公共大数据领域时，它是一个一致性的信标，而其他流式系统则是黑暗的。幸运的是，事情自那时以来已经有了显著改善，但令人惊讶的是，仍然有很多流式系统试图在没有强一致性的情况下运行。
- en: 'To reiterate—because this point is important: strong consistency is required
    for exactly-once processing,³ which is required for correctness, which is a requirement
    for any system that’s going to have a chance at meeting or exceeding the capabilities
    of batch systems.  Unless you just truly don’t care about your results, I implore
    you to shun any streaming system that doesn’t provide strongly consistent state.
    Batch systems don’t require you to verify ahead of time if they are capable of
    producing correct answers; don’t waste your time on streaming systems that can’t
    meet that same bar.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 再重申一遍——因为这一点很重要：强一致性对于精确一次处理是必需的，这对于正确性是必需的，而这又是任何系统的要求，这个系统要有机会满足或超过批处理系统的能力。除非你真的不在乎你的结果，我恳求你抵制任何不提供强一致状态的流式系统。批处理系统不要求你提前验证它们是否能够产生正确的答案；不要浪费时间在那些无法达到同样标准的流式系统上。
- en: If you’re curious to learn more about what it takes to get strong consistency
    in a streaming system, I recommend you check out the [MillWheel](http://bit.ly/2Muob70),
    [Spark Streaming](http://bit.ly/2Mrq8Be), and [Flink snapshotting](http://bit.ly/2t4DGK0)
    papers. All three spend a significant amount of time discussing consistency. Reuven
    will dive into consistency guarantees in Chapter 5, and if you still find yourself
    craving more, there’s a large amount of quality information on this topic in the
    literature and elsewhere.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解如何在流式系统中获得强一致性，我建议你查看[MillWheel](http://bit.ly/2Muob70)、[Spark Streaming](http://bit.ly/2Mrq8Be)和[Flink
    snapshotting](http://bit.ly/2t4DGK0)的论文。这三篇论文都花了大量时间讨论一致性。Reuven将在第5章深入探讨一致性保证，如果你仍然渴望更多，文献和其他地方都有大量关于这个主题的高质量信息。
- en: Tools for reasoning about time
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 关于时间推理的工具
- en: This gets you beyond batch. Good tools for reasoning about time are essential
    for dealing with unbounded, unordered data of varying event-time skew. An increasing
    number of modern datasets exhibit these characteristics, and existing batch systems
    (as well as many streaming systems) lack the necessary tools to cope with the
    difficulties they impose (though this is now rapidly changing, even as I write
    this). We will spend the bulk of this book explaining and focusing on various
    facets of this point.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这使您超越了批处理。对于处理无界、无序数据的良好工具对于处理具有不同事件时间偏差的现代数据集至关重要。越来越多的现代数据集表现出这些特征，现有的批处理系统（以及许多流处理系统）缺乏应对它们带来的困难的必要工具（尽管我写这篇文章时情况正在迅速改变）。我们将在本书的大部分内容中解释和关注这一点的各个方面。
- en: To begin with, we get a basic understanding of the important concept of time
    domains, after which we take a deeper look at what I mean by unbounded, unordered
    data of varying event-time skew. We then spend the rest of this chapter looking
    at common approaches to bounded and unbounded data processing, using both batch
    and streaming systems.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们要对时间域的重要概念有基本的理解，然后深入研究我所说的无界、无序数据的不同事件时间偏差。然后，我们将在本章的其余部分中，使用批处理和流处理系统，看一下有界和无界数据处理的常见方法。
- en: Event Time Versus Processing Time
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件时间与处理时间
- en: 'To speak cogently about unbounded data processing requires a clear understanding
    of the domains of time involved. Within any data processing system, there are
    typically two domains of time that we care about:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要明晰地讨论无界数据处理，需要对涉及的时间域有清晰的理解。在任何数据处理系统中，通常有两个我们关心的时间域：
- en: Event time
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 事件时间
- en: This is the time at which events actually occurred.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这是事件实际发生的时间。
- en: Processing time
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 处理时间
- en: This is the time at which events are observed in the system.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在系统中观察事件的时间。
- en: Not all use cases care about event times (and if yours doesn’t, hooray! your
    life is easier), but many do. Examples include characterizing user behavior over
    time, most billing applications, and many types of anomaly detection, to name
    a few.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有的用例都关心事件时间（如果你的用例不关心，太好了！你的生活会更轻松），但许多用例确实关心。例如，对用户行为进行时间特征化、大多数计费应用程序以及许多类型的异常检测等。
- en: 'In an ideal world, event time and processing time would always be equal, with
    events being processed immediately as they occur. Reality is not so kind, however,
    and the skew between event time and processing time is not only nonzero, but often
    a highly variable function of the characteristics of the underlying input sources,
    execution engine, and hardware. Things that can affect the level of skew include
    the following:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想的世界中，事件时间和处理时间总是相等的，事件发生时立即进行处理。然而，现实并不那么友好，事件时间和处理时间之间的偏差不仅不为零，而且通常是底层输入源、执行引擎和硬件特征的高度可变函数。影响偏差水平的因素包括以下内容：
- en: Shared resource limitations, like network congestion, network partitions, or
    shared CPU in a nondedicated environment
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享资源限制，如网络拥塞、网络分区或非专用环境中的共享CPU
- en: Software causes such as distributed system logic, contention, and so on
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件原因，如分布式系统逻辑、争用等
- en: Features of the data themselves, like key distribution, variance in throughput,
    or variance in disorder (i.e., a plane full of people taking their phones out
    of airplane mode after having used them offline for the entire flight)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据本身的特征，如键分布、吞吐量的方差或无序性的方差（即，整个飞机上的人们在整个飞行中离线使用手机后将其从飞行模式中取出）
- en: As a result, if you plot the progress of event time and processing time in any
    real-world system, you typically end up with something that looks a bit like the
    red line in Figure 1-1.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果在任何现实世界的系统中绘制事件时间和处理时间的进展，通常会得到类似图1-1中红线的结果。
- en: '![](img/stsy_0101.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0101.png)'
- en: Figure 1-1\. Time-domain mapping. The x-axis represents event-time completeness
    in the system; that is, the time X in event time up to which all data with event
    times less than X have been observed. The y-axis⁴ represents the progress of processing
    time; that is, normal clock time as observed by the data processing system as
    it executes.
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1. 时间域映射。x轴表示系统中事件时间的完整性；即，事件时间X之前的所有数据已被观察到。y轴⁴表示处理时间的进展；即，数据处理系统执行时所观察到的正常时钟时间。
- en: 'In Figure 1-1, the black dashed line with slope of 1 represents the ideal,
    where processing time and event time are exactly equal; the red line represents
    reality. In this example, the system lags a bit at the beginning of processing
    time, veers closer toward the ideal in the middle, and then lags again a bit toward
    the end. At first glance, there are two types of skew visible in this diagram,
    each in different time domains:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在图1-1中，具有斜率为1的黑色虚线代表理想状态，其中处理时间和事件时间完全相等；红线代表现实情况。在这个例子中，系统在处理时间开始时稍微滞后，向理想状态靠近，然后在结束时再次稍微滞后。乍一看，这个图表中有两种不同时间域中的偏差：
- en: Processing time
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 处理时间
- en: The vertical distance between the ideal and the red line is the lag in the processing-time
    domain. That distance tells you how much delay is observed (in processing time)
    between when the events for a given time occurred and when they were processed.
    This is the perhaps the more natural and intuitive of the two skews.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 理想状态和红线之间的垂直距离是处理时间域中的滞后。这个距离告诉您在事件发生时和它们被处理时之间观察到的延迟（在处理时间上）。这可能是两种偏差中更自然和直观的一种。
- en: Event time
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 事件时间
- en: The horizontal distance between the ideal and the red line is the amount of
    event-time skew in the pipeline at that moment. It tells you how far behind the
    ideal (in event time) the pipeline is currently.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 理想状态和红线之间的水平距离是管道中事件时间偏差的量。它告诉您管道当前在事件时间上距离理想状态有多远。
- en: 'In reality, processing-time lag and event-time skew at any given point in time
    are identical; they’re just two ways of looking at the same thing.⁵ The important
    takeaway regarding lag/skew is this: Because the overall mapping between event
    time and processing time is not static (i.e., the lag/skew can vary arbitrarily
    over time), this means that you cannot analyze your data solely within the context
    of when they are observed by your pipeline if you care about their event times
    (i.e., when the events actually occurred). Unfortunately, this is the way many
    systems designed for unbounded data have historically operated. To cope with the
    infinite nature of unbounded datasets, these systems typically provide some notion
    of windowing the incoming data. We discuss windowing in great depth a bit later,
    but it essentially means chopping up a dataset into finite pieces along temporal
    boundaries. If you care about correctness and are interested in analyzing your
    data in the context of their event times, you cannot define those temporal boundaries
    using processing time (i.e., processing-time windowing), as many systems do; with
    no consistent correlation between processing time and event time, some of your
    event-time data are going to end up in the wrong processing-time windows (due
    to the inherent lag in distributed systems, the online/offline nature of many
    types of input sources, etc.), throwing correctness out the window, as it were.
    We look at this problem in more detail in a number of examples in the sections
    that follow, as well as the remainder of the book.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在任何给定时间点上，处理时间滞后和事件时间偏差是相同的；它们只是观察同一事物的两种方式。关于滞后/偏差的重要要点是：因为事件时间和处理时间之间的整体映射不是静态的（即，滞后/偏差可以随时间任意变化），这意味着如果你关心它们的事件时间（即事件实际发生的时间），你不能仅仅在管道观察它们时分析你的数据。不幸的是，这是历史上许多为无限数据设计的系统的运行方式。为了应对无限数据集的特性，这些系统通常提供了一些关于窗口化传入数据的概念。我们稍后会深入讨论窗口化，但它基本上意味着沿着时间边界将数据集切分成有限的部分。如果你关心正确性并且有兴趣在它们的事件时间上分析你的数据，你不能使用处理时间来定义这些时间边界（即处理时间窗口化），因为许多系统这样做；由于处理时间和事件时间之间没有一致的关联，你的一些事件时间数据将会出现在错误的处理时间窗口中（由于分布式系统的固有滞后，许多类型的输入源的在线/离线性质等），这将使正确性不复存在。我们将在接下来的几个部分以及本书的其余部分中更详细地讨论这个问题。
- en: 'Unfortunately, the picture isn’t exactly rosy when windowing by event time,
    either. In the context of unbounded data, disorder and variable skew induce a
    completeness problem for event-time windows: lacking a predictable mapping between
    processing time and event time, how can you determine when you’ve observed all
    of the data for a given event time *X*? For many real-world data sources, you
    simply can’t. But the vast majority of data processing systems in use today rely
    on some notion of completeness, which puts them at a severe disadvantage when
    applied to unbounded datasets.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，按事件时间进行窗口化也并非一帆风顺。在无界数据的情况下，混乱和可变的偏差为事件时间窗口带来了完整性问题：缺乏处理时间和事件时间之间的可预测映射，你如何确定你何时观察到了给定事件时间*X*的所有数据？对于许多真实世界的数据源来说，你根本无法确定。但是今天大多数使用的数据处理系统都依赖于某种完整性的概念，这使它们在应用于无界数据集时处于严重劣势。
- en: I propose that instead of attempting to groom unbounded data into finite batches
    of information that eventually become complete, we should be designing tools that
    allow us to live in the world of uncertainty imposed by these complex datasets.
    New data will arrive, old data might be retracted or updated, and any system we
    build should be able to cope with these facts on its own, with notions of completeness
    being a convenient optimization for specific and appropriate use cases rather
    than a semantic necessity across all of them.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议，我们不应该试图将无限的数据整理成最终变得完整的有限批次的信息，而是应该设计一些工具，让我们能够生活在这些复杂数据集所施加的不确定性世界中。新数据会到达，旧数据可能会被撤回或更新，我们构建的任何系统都应该能够自行应对这些事实，完整性的概念应该是特定和适当用例的便利优化，而不是所有用例的语义必要性。
- en: 'Before getting into specifics about what such an approach might look like,
    let’s finish up one more useful piece of background: common data processing patterns.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入讨论这种方法可能是什么样子之前，让我们先完成一个有用的背景知识：常见的数据处理模式。
- en: Data Processing Patterns
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理模式
- en: At this point, we have enough background established that we can begin looking
    at the core types of usage patterns common across bounded and unbounded data processing
    today. We look at both types of processing and, where relevant, within the context
    of the two main types of engines we care about (batch and streaming, where in
    this context, I’m essentially lumping microbatch in with streaming because the
    differences between the two aren’t terribly important at this level).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们已经建立了足够的背景知识，可以开始看一下今天有界和无界数据处理中常见的核心使用模式。我们将在两种处理类型和相关的情况下看一下我们关心的两种主要引擎（批处理和流处理，在这个上下文中，我基本上将微批处理与流处理归为一类，因为在这个层面上两者之间的差异并不是非常重要）。
- en: Bounded Data
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有界数据
- en: Processing bounded data is conceptually quite straightforward, and likely familiar
    to everyone. In Figure 1-2, we start out on the left with a dataset full of entropy.
    We run it through some data processing engine (typically batch, though a well-designed
    streaming engine would work just as well), such as [MapReduce](http://bit.ly/2sZNfuA),
    and on the right side end up with a new structured dataset with greater inherent
    value.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 处理有界数据在概念上非常简单，可能对每个人都很熟悉。在图1-2中，我们从左侧开始，有一个充满熵的数据集。我们将其通过一些数据处理引擎（通常是批处理，尽管一个设计良好的流处理引擎也可以很好地工作），比如[MapReduce](http://bit.ly/2sZNfuA)，最终在右侧得到一个具有更大内在价值的新结构化数据集。
- en: '![](img/stsy_0102.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0102.png)'
- en: Figure 1-2\. Bounded data processing with a classic batch engine. A finite pool
    of unstructured data on the left is run through a data processing engine, resulting
    in corresponding structured data on the right.
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2。使用经典批处理引擎处理有界数据。左侧的有限的非结构化数据通过数据处理引擎，生成右侧对应的结构化数据。
- en: Though there are of course infinite variations on what you can actually calculate
    as part of this scheme, the overall model is quite simple. Much more interesting
    is the task of processing an unbounded dataset. Let’s now look at the various
    ways unbounded data are typically processed, beginning with the approaches used
    with traditional batch engines and then ending up with the approaches you can
    take with a system designed for unbounded data, such as most streaming or microbatch
    engines.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在这种方案中实际上可以计算出无限多种变化，但总体模型非常简单。更有趣的是处理无界数据集的任务。现在让我们来看看通常处理无界数据的各种方式，从传统批处理引擎使用的方法开始，然后再看看您可以使用设计用于无界数据的系统（如大多数流式或微批处理引擎）采取的方法。
- en: 'Unbounded Data: Batch'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无界数据：批处理
- en: Batch engines, though not explicitly designed with unbounded data in mind, have
    nevertheless been used to process unbounded datasets since batch systems were
    first conceived. As you might expect, such approaches revolve around slicing up
    the unbounded data into a collection of bounded datasets appropriate for batch
    processing.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管批处理引擎并非专门为无界数据设计，但自批处理系统首次构思以来，就一直被用于处理无界数据集。正如您所期望的那样，这些方法围绕将无界数据切分为适合批处理的有界数据集的集合。
- en: Fixed windows
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 固定窗口
- en: The most common way to process an unbounded dataset using repeated runs of a
    batch engine is by windowing the input data into fixed-size windows and then processing
    each of those windows as a separate, bounded data source (sometimes also called
    *tumbling windows*), as in Figure 1-3. Particularly for input sources like logs,
    for which events can be written into directory and file hierarchies whose names
    encode the window they correspond to, this sort of thing appears quite straightforward
    at first blush because you’ve essentially performed the time-based shuffle to
    get data into the appropriate event-time windows ahead of time.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用批处理引擎的重复运行来处理无界数据集的最常见方式是将输入数据分割成固定大小的窗口，然后将每个窗口作为单独的有界数据源进行处理（有时也称为*滚动窗口*），如图1-3所示。特别是对于像日志这样的输入源，事件可以被写入目录和文件层次结构，其名称编码了它们对应的窗口，这种方法乍看起来似乎非常简单，因为您已经在适当的事件时间窗口中进行了基于时间的洗牌以提前获取数据。
- en: In reality, however, most systems still have a completeness problem to deal
    with (What if some of your events are delayed en route to the logs due to a network
    partition? What if your events are collected globally and must be transferred
    to a common location before processing? What if your events come from mobile devices?),
    which means some sort of mitigation might be necessary (e.g., delaying processing
    until you’re sure all events have been collected or reprocessing the entire batch
    for a given window whenever data arrive late).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，实际上，大多数系统仍然存在完整性问题需要解决（如果您的一些事件由于网络分区而延迟到达日志，该怎么办？如果您的事件是全球收集的，并且必须在处理之前转移到一个共同的位置，该怎么办？如果您的事件来自移动设备？），这意味着可能需要某种形式的缓解（例如，延迟处理直到确保所有事件都已收集，或者在数据迟到时重新处理给定窗口的整个批次）。
- en: '![](img/stsy_0103.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0103.png)'
- en: Figure 1-3\. Unbounded data processing via ad hoc fixed windows with a classic
    batch engine. An unbounded dataset is collected up front into finite, fixed-size
    windows of bounded data that are then processed via successive runs a of classic
    batch engine.
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3。通过经典批处理引擎将无界数据处理成临时固定窗口。无界数据集首先被收集到有限的、固定大小的有界数据窗口中，然后通过经典批处理引擎的连续运行进行处理。
- en: Sessions
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 会话
- en: This approach breaks down even more when you try to use a batch engine to process
    unbounded data into more sophisticated windowing strategies, like sessions. Sessions
    are typically defined as periods of activity (e.g., for a specific user) terminated
    by a gap of inactivity. When calculating sessions using a typical batch engine,
    you often end up with sessions that are split across batches, as indicated by
    the red marks in Figure 1-4. We can reduce the number of splits by increasing
    batch sizes, but at the cost of increased latency. Another option is to add additional
    logic to stitch up sessions from previous runs, but at the cost of further complexity.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当尝试使用批处理引擎处理无界数据以实现更复杂的窗口策略（如会话）时，这种方法会变得更加复杂。会话通常被定义为活动期间（例如特定用户的活动）之后的不活动间隔。当使用典型的批处理引擎计算会话时，通常会出现会话跨批次分割的情况，如图1-4中的红色标记所示。我们可以通过增加批处理大小来减少分割的次数，但这会增加延迟。另一种选择是添加额外的逻辑来从之前的运行中拼接会话，但这会增加复杂性。
- en: '![](img/stsy_0104.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0104.png)'
- en: Figure 1-4\. Unbounded data processing into sessions via ad hoc fixed windows
    with a classic batch engine. An unbounded dataset is collected up front into finite,
    fixed-size windows of bounded data that are then subdivided into dynamic session
    windows via successive runs a of classic batch engine.
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4。通过经典批处理引擎将无界数据处理成会话，使用临时固定窗口。无界数据集首先被收集到有限的、固定大小的有界数据窗口中，然后通过经典批处理引擎的连续运行将其细分为动态会话窗口。
- en: Either way, using a classic batch engine to calculate sessions is less than
    ideal. A nicer way would be to build up sessions in a streaming manner, which
    we look at later on.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，使用经典批处理引擎计算会话都不是理想的方式。更好的方式是以流式方式构建会话，我们稍后会详细介绍。
- en: 'Unbounded Data: Streaming'
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无界数据：流式
- en: 'Contrary to the ad hoc nature of most batch-based unbounded data processing
    approaches, streaming systems are built for unbounded data. As we talked about
    earlier, for many real-world, distributed input sources, you not only find yourself
    dealing with unbounded data, but also data such as the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数基于批处理的无界数据处理方法的临时性相反，流处理系统是为无界数据而构建的。正如我们之前讨论的，对于许多真实世界的分布式输入源，你不仅需要处理无界数据，还需要处理以下类型的数据：
- en: Highly unordered with respect to event times, meaning that you need some sort
    of time-based shuffle in your pipeline if you want to analyze the data in the
    context in which they occurred.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与事件时间相关的无序性很高，这意味着如果你想在发生事件的上下文中分析数据，你的管道中需要一些基于时间的洗牌。
- en: Of varying event-time skew, meaning that you can’t just assume you’ll always
    see most of the data for a given event time *X* within some constant epsilon of
    time *Y*.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件时间偏移不同，这意味着你不能假设你总是会在某个常数时间*Y*内看到给定事件时间*X*的大部分数据。
- en: 'There are a handful of approaches that you can take when dealing with data
    that have these characteristics. I generally categorize these approaches into
    four groups: time-agnostic, approximation, windowing by processing time, and windowing
    by event time.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 处理具有这些特征的数据时，你可以采取几种方法。我通常将这些方法归为四类：时间不敏感、近似、按处理时间窗口分组、按事件时间窗口分组。
- en: Let’s now spend a little bit of time looking at each of these approaches.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们花一点时间来看看这些方法。
- en: Time-agnostic
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 时间不敏感
- en: Time-agnostic processing is used for cases in which time is essentially irrelevant;
    that is, all relevant logic is data driven. Because everything about such use
    cases is dictated by the arrival of more data, there’s really nothing special
    a streaming engine has to support other than basic data delivery. As a result,
    essentially all streaming systems in existence support time-agnostic use cases
    out of the box (modulo system-to-system variances in consistency guarantees, of
    course, if you care about correctness). Batch systems are also well suited for
    time-agnostic processing of unbounded data sources by simply chopping the unbounded
    source into an arbitrary sequence of bounded datasets and processing those datasets
    independently. We look at a couple of concrete examples in this section, but given
    the straightforwardness of handling time-agnostic processing (from a temporal
    perspective at least), we won’t spend much more time on it beyond that.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 时间不敏感的处理用于时间基本无关的情况；也就是说，所有相关逻辑都是数据驱动的。因为这类用例的一切都由更多数据的到达来决定，所以流处理引擎实际上没有什么特别之处需要支持，除了基本的数据传递。因此，实际上所有现有的流处理系统都可以直接支持时间不敏感的用例（当然，如果你关心正确性，系统之间的一致性保证可能会有所不同）。批处理系统也非常适合对无界数据源进行时间不敏感的处理，只需将无界数据源切割成一系列有界数据集并独立处理这些数据集。本节中我们将看一些具体的例子，但考虑到处理时间不敏感的简单性（至少从时间的角度来看），我们不会在此之外花费太多时间。
- en: Filtering
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 过滤
- en: A very basic form of time-agnostic processing is filtering, an example of which
    is rendered in Figure 1-5. Imagine that you’re processing web traffic logs and
    you want to filter out all traffic that didn’t originate from a specific domain.
    You would look at each record as it arrived, see if it belonged to the domain
    of interest, and drop it if not. Because this sort of thing depends only on a
    single element at any time, the fact that the data source is unbounded, unordered,
    and of varying event-time skew is irrelevant.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 时间不敏感处理的一个非常基本的形式是过滤，一个例子如图1-5所示。想象一下，你正在处理网站流量日志，并且想要过滤掉所有不是来自特定域的流量。当每条记录到达时，你会查看它是否属于感兴趣的域，并丢弃不属于的记录。因为这种处理方式只依赖于任何时间的单个元素，数据源是无界的、无序的，并且事件时间偏移不同是无关紧要的。
- en: '![](img/stsy_0105.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0105.png)'
- en: Figure 1-5\. Filtering unbounded data. A collection of data (flowing left to
    right) of varying types is filtered into a homogeneous collection containing a
    single type.
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5。过滤无界数据。各种类型的数据（从左到右流动）被过滤成包含单一类型的同质集合。
- en: Inner joins
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 内连接
- en: Another time-agnostic example is an inner join, diagrammed in Figure 1-6. When
    joining two unbounded data sources, if you care only about the results of a join
    when an element from both sources arrive, there’s no temporal element to the logic.
    Upon seeing a value from one source, you can simply buffer it up in persistent
    state; only after the second value from the other source arrives do you need to
    emit the joined record. (In truth, you’d likely want some sort of garbage collection
    policy for unemitted partial joins, which would likely be time based. But for
    a use case with little or no uncompleted joins, such a thing might not be an issue.)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个时间不敏感的例子是内连接，如图1-6所示。当连接两个无界数据源时，如果你只关心当来自两个源的元素到达时连接的结果，那么逻辑上就没有时间元素。在看到一个源的值后，你可以简单地将其缓存到持久状态中；只有在另一个源的第二个值到达后，你才需要发出连接的记录。（事实上，你可能希望对未发出的部分连接进行某种垃圾回收策略，这可能是基于时间的。但对于几乎没有未完成连接的用例来说，这可能不是一个问题。）
- en: '![](img/stsy_0106.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0106.png)'
- en: Figure 1-6\. Performing an inner join on unbounded data. Joins are produced
    when matching elements from both sources are observed.
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6。在无界数据上执行内连接。当观察到来自两个源的匹配元素时，连接就会产生。
- en: 'Switching semantics to some sort of outer join introduces the data completeness
    problem we’ve talked about: after you’ve seen one side of the join, how do you
    know whether the other side is ever going to arrive or not? Truth be told, you
    don’t, so you need to introduce some notion of a timeout, which introduces an
    element of time. That element of time is essentially a form of windowing, which
    we’ll look at more closely in a moment.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 将语义切换到某种外连接会引入我们之前讨论过的数据完整性问题：在看到连接的一侧之后，你怎么知道另一侧是否会到达或不会到达？说实话，你不知道，所以你需要引入某种超时的概念，这就引入了时间的元素。这个时间元素本质上是一种窗口，我们稍后会更仔细地看一下。
- en: Approximation algorithms
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 近似算法
- en: The second major category of approaches is approximation algorithms, such as
    [approximate Top-N](http://bit.ly/2JLcOG9), [streaming k-means](http://bit.ly/2JLQE6O),
    and so on. They take an unbounded source of input and provide output data that,
    if you squint at them, look more or less like what you were hoping to get, as
    in Figure 1-7. The upside of approximation algorithms is that, by design, they
    are low overhead and designed for unbounded data. The downsides are that a limited
    set of them exist, the algorithms themselves are often complicated (which makes
    it difficult to conjure up new ones), and their approximate nature limits their
    utility.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 第二大类方法是近似算法，比如[近似Top-N](http://bit.ly/2JLcOG9)，[流式k均值](http://bit.ly/2JLQE6O)等。它们接受无限的输入源，并提供输出数据，如果你仔细看，它们看起来或多或少像你希望得到的结果，如图1-7所示。近似算法的优势在于，它们设计上开销低，适用于无限数据。缺点是它们的种类有限，算法本身通常很复杂（这使得很难想出新的算法），而且它们的近似性质限制了它们的实用性。
- en: '![](img/stsy_0107.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0107.png)'
- en: Figure 1-7\. Computing approximations on unbounded data. Data are run through
    a complex algorithm, yielding output data that look more or less like the desired
    result on the other side.
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-7。在无限数据上计算近似值。数据经过复杂算法处理，产生的输出数据看起来或多或少像另一侧期望的结果。
- en: It’s worth noting that these algorithms typically do have some element of time
    in their design (e.g., some sort of built-in decay). And because they process
    elements as they arrive, that time element is usually processing-time based. This
    is particularly important for algorithms that provide some sort of provable error
    bounds on their approximations. If those error bounds are predicated on data arriving
    in order, they mean essentially nothing when you feed the algorithm unordered
    data with varying event-time skew. Something to keep in mind.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，这些算法通常在设计上都有一定的时间元素（例如，一些内置的衰减）。由于它们处理元素的方式是按照到达的顺序进行的，所以时间元素通常是基于处理时间的。这对于那些在近似中提供一定的可证明误差界限的算法尤为重要。如果这些误差界限是基于数据按顺序到达的，那么当你向算法提供无序数据和不同的事件时间偏移时，它们基本上就毫无意义了。这是需要记住的一点。
- en: Approximation algorithms themselves are a fascinating subject, but as they are
    essentially another example of time-agnostic processing (modulo the temporal features
    of the algorithms themselves), they’re quite straightforward to use and thus not
    worth further attention, given our current focus.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 近似算法本身是一个迷人的课题，但由于它们本质上是时间不可知的处理的另一个例子（除了算法本身的时间特征），它们非常容易使用，因此在我们目前的重点下，不值得进一步关注。
- en: Windowing
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 窗口
- en: The remaining two approaches for unbounded data processing are both variations
    of windowing. Before diving into the differences between them, I should make it
    clear exactly what I mean by windowing, insomuch as we touched on it only briefly
    in the previous section. Windowing is simply the notion of taking a data source
    (either unbounded or bounded), and chopping it up along temporal boundaries into
    finite chunks for processing. Figure 1-8 shows three different windowing patterns.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 处理无限数据的剩下两种方法都是窗口的变体。在深入讨论它们之间的区别之前，我应该明确窗口的确切含义，因为我们在上一节中只是简单提到了它。窗口简单地意味着将数据源（无论是无限的还是有限的）沿着时间边界切割成有限的块进行处理。图1-8显示了三种不同的窗口模式。
- en: '![](img/stsy_0108.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0108.png)'
- en: Figure 1-8\. Windowing strategies. Each example is shown for three different
    keys, highlighting the difference between aligned windows (which apply across
    all the data) and unaligned windows (which apply across a subset of the data).
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8。窗口策略。每个示例都显示了三个不同的键，突出了对齐窗口（适用于所有数据）和不对齐窗口（适用于数据子集）之间的差异。
- en: 'Let’s take a closer look at each strategy:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看每种策略：
- en: Fixed windows (aka tumbling windows)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 固定窗口（又称滚动窗口）
- en: We discussed fixed windows earlier. Fixed windows slice time into segments with
    a fixed-size temporal length. Typically (as shown in Figure 1-9), the segments
    for fixed windows are applied uniformly across the entire dataset, which is an
    example of *aligned* windows. In some cases, it’s desirable to phase-shift the
    windows for different subsets of the data (e.g., per key) to spread window completion
    load more evenly over time, which instead is an example of *unaligned* windows
    because they vary across the data.⁶
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论过固定窗口。固定窗口将时间划分为具有固定时间长度的段。通常（如图1-9所示），固定窗口的段均匀应用于整个数据集，这是*对齐*窗口的一个例子。在某些情况下，希望为数据的不同子集（例如，按键）相位移窗口，以更均匀地分散窗口完成负载，这反而是*不对齐*窗口的一个例子，因为它们在数据上变化。⁶
- en: Sliding windows (aka hopping windows)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 滑动窗口（又称跳跃窗口）
- en: A generalization of fixed windows, sliding windows are defined by a fixed length
    and a fixed period. If the period is less than the length, the windows overlap.
    If the period equals the length, you have fixed windows. And if the period is
    greater than the length, you have a weird sort of sampling window that looks only
    at subsets of the data over time. As with fixed windows, sliding windows are typically
    aligned, though they can be unaligned as a performance optimization in certain
    use cases. Note that the sliding windows in Figure 1-8 are drawn as they are to
    give a sense of sliding motion; in reality, all five windows would apply across
    the entire dataset.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 滑动窗口是固定长度和固定周期定义的。如果周期小于长度，窗口会重叠。如果周期等于长度，你就有了固定窗口。如果周期大于长度，你就有了一种奇怪的采样窗口，它只在时间上查看数据的子集。与固定窗口一样，滑动窗口通常是对齐的，尽管在某些用例中，它们可以是不对齐的性能优化。请注意，图1-8中的滑动窗口是按照它们的方式绘制的，以给出滑动运动的感觉；实际上，所有五个窗口都会应用于整个数据集。
- en: Sessions
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 会话
- en: An example of dynamic windows, sessions are composed of sequences of events
    terminated by a gap of inactivity greater than some timeout. Sessions are commonly
    used for analyzing user behavior over time, by grouping together a series of temporally
    related events (e.g., a sequence of videos viewed in one sitting). Sessions are
    interesting because their lengths cannot be defined a priori; they are dependent
    upon the actual data involved. They’re also the canonical example of unaligned
    windows because sessions are practically never identical across different subsets
    of data (e.g., different users).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 动态窗口的一个例子，会话由一系列事件组成，这些事件以大于某个超时的不活动间隙结束。会话通常用于分析用户随时间的行为，通过将一系列时间相关的事件（例如，一系列视频在一次观看中观看）分组在一起。会话很有趣，因为它们的长度不能事先定义；它们取决于实际涉及的数据。它们也是不对齐窗口的典型例子，因为会话在不同数据子集中几乎从不相同（例如，不同用户）。
- en: The two domains of time we discussed earlier (processing time and event time)
    are essentially the two we care about.⁷ Windowing makes sense in both domains,
    so let’s look at each in detail and see how they differ. Because processing-time
    windowing has historically been more common, we’ll start there.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论过的两个时间领域（处理时间和事件时间）基本上是我们关心的两个领域。分窗在这两个领域都是有意义的，所以让我们详细看看每个领域，并看看它们有何不同。因为按处理时间分窗在历史上更常见，我们将从那里开始。
- en: Windowing by processing time
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 按处理时间分窗
- en: When windowing by processing time, the system essentially buffers up incoming
    data into windows until some amount of processing time has passed. For example,
    in the case of five-minute fixed windows, the system would buffer data for five
    minutes of processing time, after which it would treat all of the data it had
    observed in those five minutes as a window and send them downstream for processing.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 按处理时间分窗时，系统基本上会将传入的数据缓冲到窗口中，直到经过一定的处理时间。例如，在五分钟的固定窗口的情况下，系统会缓冲五分钟的处理时间的数据，之后将把在这五分钟内观察到的所有数据视为一个窗口，并将它们发送到下游进行处理。
- en: '![](img/stsy_0109.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0109.png)'
- en: Figure 1-9\. Windowing into fixed windows by processing time. Data are collected
    into windows based on the order they arrive in the pipeline.
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-9。按处理时间分窗到固定窗口。数据根据它们在管道中到达的顺序被收集到窗口中。
- en: 'There are a few nice properties of processing-time windowing:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 按处理时间分窗有一些不错的特性：
- en: It’s simple. The implementation is extremely straightforward because you never
    worry about shuffling data within time. You just buffer things as they arrive
    and send them downstream when the window closes.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这很简单。实现非常简单，因为你永远不用担心在时间内对数据进行洗牌。当窗口关闭时，你只需按照它们到达的顺序缓冲数据并将它们发送到下游。
- en: Judging window completeness is straightforward. Because the system has perfect
    knowledge of whether all inputs for a window have been seen, it can make perfect
    decisions about whether a given window is complete. This means there is no need
    to be able to deal with “late” data in any way when windowing by processing time.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判断窗口的完整性是直截了当的。因为系统完全知道窗口的所有输入是否都已被看到，它可以对是否给定窗口完整做出完美的决定。这意味着在按处理时间分窗时，无需以任何方式处理“延迟”数据。
- en: If you’re wanting to infer information about the source *as it is observed*,
    processing-time windowing is exactly what you want. Many monitoring scenarios
    fall into this category. Imagine tracking the number of requests per second sent
    to a global-scale web service. Calculating a rate of these requests for the purpose
    of detecting outages is a perfect use of processing-time windowing.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您想推断关于源*在观察到的*时刻的信息，按处理时间分窗正是您想要的。许多监控场景属于这一类。想象一下跟踪发送到全球规模网络服务的每秒请求的数量。计算这些请求的速率以便检测故障是按处理时间分窗的完美用途。
- en: 'Good points aside, there is one very big downside to processing-time windowing:
    *if the data in question have event times associated with them, those data must
    arrive in event-time order if the processing-time windows are to reflect the reality
    of when those events actually happened.* Unfortunately, event-time ordered data
    are uncommon in many real-world, distributed input sources.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 好处是一回事，但按处理时间分窗有一个非常大的缺点：*如果所讨论的数据与事件时间相关联，那么如果处理时间窗口要反映这些事件实际发生的时间，这些数据必须按事件时间顺序到达。*不幸的是，在许多真实世界的分布式输入源中，按事件时间排序的数据并不常见。
- en: As a simple example, imagine any mobile app that gathers usage statistics for
    later processing. For cases in which a given mobile device goes offline for any
    amount of time (brief loss of connectivity, airplane mode while flying across
    the country, etc.), the data recorded during that period won’t be uploaded until
    the device comes online again. This means that data might arrive with an event-time
    skew of minutes, hours, days, weeks, or more. It’s essentially impossible to draw
    any sort of useful inferences from such a dataset when windowed by processing
    time.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 举个简单的例子，想象一下任何收集使用统计信息以供以后处理的移动应用程序。对于给定移动设备在任何时间段内离线的情况（短暂的连接丢失，飞越国家时的飞行模式等），在该期间记录的数据直到设备再次联机才会上传。这意味着数据可能会出现几分钟、几小时、几天、几周甚至更长的事件时间偏移。当按处理时间分窗时，基本上不可能从这样的数据集中得出任何有用的推断。
- en: As another example, many distributed input sources might *seem* to provide event-time
    ordered (or very nearly so) data when the overall system is healthy. Unfortunately,
    the fact that event-time skew is low for the input source when healthy does not
    mean it will always stay that way. Consider a global service that processes data
    collected on multiple continents. If network issues across a bandwidth-constrained
    transcontinental line (which, sadly, are surprisingly common) further decrease
    bandwidth and/or increase latency, suddenly a portion of your input data might
    begin arriving with much greater skew than before. If you are windowing those
    data by processing time, your windows are no longer representative of the data
    that actually occurred within them; instead, they represent the windows of time
    as the events arrived at the processing pipeline, which is some arbitrary mix
    of old and current data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，许多分布式输入源在整个系统健康时可能*看起来*提供了按事件时间排序（或非常接近）的数据。不幸的是，当输入源在健康状态下事件时间偏移较低时，并不意味着它会一直保持在这种状态。考虑一个全球服务，处理在多个大陆上收集的数据。如果跨大陆线路上的网络问题（可悲的是，这种情况出奇地常见）进一步降低带宽和/或增加延迟，突然之间，部分输入数据的偏移可能比以前大得多。如果您按处理时间对这些数据进行窗口处理，那么您的窗口将不再代表实际发生在其中的数据；相反，它们代表事件到达处理管道时的时间窗口，这是一些旧数据和当前数据的任意混合。
- en: What we really want in both of those cases is to window data by their event
    times in a way that is robust to the order of arrival of events. What we really
    want is event-time windowing.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们真正想要的是根据事件时间对数据进行窗口处理，以便能够抵御事件到达顺序的影响。我们真正想要的是事件时间窗口。
- en: Windowing by event time
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 按事件时间窗口化
- en: Event-time windowing is what you use when you need to observe a data source
    in finite chunks that reflect the times at which those events actually happened.
    It’s the gold standard of windowing. Prior to 2016, most data processing systems
    in use lacked native support for it (though any system with a decent consistency
    model, like Hadoop or Spark Streaming 1.x, could act as a reasonable substrate
    for building such a windowing system). I’m happy to say that the world of today
    looks very different, with multiple systems, from Flink to Spark to Storm to Apex,
    natively supporting event-time windowing of some sort.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 当您需要以反映事件实际发生时间的有限块观察数据源时，事件时间窗口是您使用的窗口处理方式。这是窗口处理的黄金标准。在2016年之前，大多数使用的数据处理系统都缺乏对其的本地支持（尽管具有良好一致性模型的任何系统，如Hadoop或Spark
    Streaming 1.x，都可以作为构建此类窗口处理系统的合理基础）。我很高兴地说，今天的世界看起来非常不同，从Flink到Spark再到Storm和Apex，多个系统都原生支持某种形式的事件时间窗口处理。
- en: Figure 1-10 shows an example of windowing an unbounded source into one-hour
    fixed windows.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图1-10显示了将无界数据源窗口化为一小时固定窗口的示例。
- en: '![](img/stsy_0110.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0110.png)'
- en: Figure 1-10\. Windowing into fixed windows by event time. Data are collected
    into windows based on the times at which they occurred. The black arrows call
    out example data that arrived in processing-time windows that differed from the
    event-time windows to which they belonged.
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10。按事件时间窗口化为固定窗口。数据根据发生时间被收集到窗口中。黑色箭头指出了到达处理时间窗口的示例数据，这些数据与它们所属的事件时间窗口不同。
- en: The black arrows in Figure 1-10 call out two particularly interesting pieces
    of data. Each arrived in processing-time windows that did not match the event-time
    windows to which each bit of data belonged. As such, if these data had been windowed
    into processing-time windows for a use case that cared about event times, the
    calculated results would have been incorrect. As you would expect, event-time
    correctness is one nice thing about using event-time windows.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图1-10中的黑色箭头指出了两个特别有趣的数据片段。每个片段都到达了与其所属的事件时间窗口不匹配的处理时间窗口。因此，如果这些数据被按处理时间窗口化，用于关注事件时间的用例的计算结果将是不正确的。正如您所期望的那样，事件时间的正确性是使用事件时间窗口的一个好处。
- en: 'Another nice thing about event-time windowing over an unbounded data source
    is that you can create dynamically sized windows, such as sessions, without the
    arbitrary splits observed when generating sessions over fixed windows (as we saw
    previously in the sessions example from “Unbounded Data: Streaming”), as demonstrated
    in Figure 1-11.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 事件时间窗口在无界数据源上的另一个好处是，您可以创建动态大小的窗口，例如会话，而无需在固定窗口上生成会话时观察到的任意拆分（如我们在“无界数据：流式处理”中看到的会话示例中所示），如图1-11所示。
- en: '![](img/stsy_0111.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0111.png)'
- en: Figure 1-11\. Windowing into session windows by event time. Data are collected
    into session windows capturing bursts of activity based on the times that the
    corresponding events occurred. The black arrows again call out the temporal shuffle
    necessary to put the data into their correct event-time locations.
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-11。按事件时间窗口化为会话窗口。数据被收集到会话窗口中，根据相应事件发生的时间捕获活动突发。黑色箭头再次指出了必要的时间重排，以将数据放置在它们正确的事件时间位置。
- en: 'Of course, powerful semantics rarely come for free, and event-time windows
    are no exception. Event-time windows have two notable drawbacks due to the fact
    that windows must often live longer (in processing time) than the actual length
    of the window itself:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，强大的语义很少是免费的，事件时间窗口也不例外。事件时间窗口由于窗口通常必须比窗口本身的实际长度（在处理时间上）存在更长的时间，因此具有两个显着的缺点：
- en: Buffering
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲
- en: Due to extended window lifetimes, more buffering of data is required. Thankfully,
    persistent storage is generally the cheapest of the resource types most data processing
    systems depend on (the others being primarily CPU, network bandwidth, and RAM).
    As such, this problem is typically much less of a concern than you might think
    when using any well-designed data processing system with strongly consistent persistent
    state and a decent in-memory caching layer. Also, many useful aggregations do
    not require the entire input set to be buffered (e.g., sum or average), but instead
    can be performed incrementally, with a much smaller, intermediate aggregate stored
    in persistent state.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 由于延长的窗口生命周期，需要更多的数据缓冲。幸运的是，持久存储通常是大多数数据处理系统所依赖的资源类型中最便宜的（其他资源主要是 CPU、网络带宽和 RAM）。因此，这个问题通常比你想象的要少得多，当使用任何设计良好的数据处理系统与强一致的持久状态和一个良好的内存缓存层时。此外，许多有用的聚合不需要整个输入集被缓冲（例如，求和或平均值），而是可以以增量方式执行，将一个更小的中间聚合存储在持久状态中。
- en: Completeness
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 完整性
- en: Given that we often have no good way of knowing when we’ve seen all of the data
    for a given window, how do we know when the results for the window are ready to
    materialize? In truth, we simply don’t. For many types of inputs, the system can
    give a reasonably accurate heuristic estimate of window completion via something
    like the watermarks found in MillWheel, Cloud Dataflow, and Flink (which we talk
    about more in Chapters 3 and 4). But for cases in which absolute correctness is
    paramount (again, think billing), the only real option is to provide a way for
    the pipeline builder to express when they want results for windows to be materialized
    and how those results should be refined over time. Dealing with window completeness
    (or lack thereof) is a fascinating topic but one perhaps best explored in the
    context of concrete examples, which we look at next.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们经常没有好的方法来知道我们是否已经看到了给定窗口的所有数据，那么我们如何知道窗口的结果何时准备好实现？事实上，我们根本不知道。对于许多类型的输入，系统可以通过类似于
    MillWheel、Cloud Dataflow 和 Flink 中的水印这样的东西给出一个相当准确的启发式估计窗口完成的时间（我们将在第三章和第四章中更多地讨论）。但对于绝对正确性至关重要的情况（再次思考计费），唯一的选择是为流水线构建者提供一种表达他们希望何时实现窗口结果以及如何随时间改进这些结果的方式。处理窗口的完整性（或缺乏完整性）是一个迷人的话题，但也许最好在具体例子的背景下进行探讨，这是我们接下来要看的内容。
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'Whew! That was a lot of information. If you’ve made it this far, you are to
    be commended! But we are only just getting started. Before forging ahead to looking
    in detail at the Beam Model approach, let’s briefly step back and recap what we’ve
    learned so far. In this chapter, we’ve done the following:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！这是大量的信息。如果你已经走到这一步，你应该受到表扬！但我们只是刚刚开始。在继续深入研究 Beam 模型方法之前，让我们简要地回顾一下我们到目前为止学到的东西。在本章中，我们已经做了以下工作：
- en: 'Clarified terminology, focusing the definition of “streaming” to refer to systems
    built with unbounded data in mind, while using more descriptive terms like approximate/speculative
    results for distinct concepts often categorized under the “streaming” umbrella.
    Additionally, we highlighted two important dimensions of large-scale datasets:
    cardinality (i.e., bounded versus unbounded) and encoding (i.e., table versus
    stream), the latter of which will consume much of the second half of the book.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 澄清了术语，将“流处理”的定义重点放在了指建立在无界数据基础上的系统上，同时使用更具描述性的术语来区分通常被归类为“流处理”的不同概念，例如近似/推测性结果。此外，我们还强调了大规模数据集的两个重要维度：基数（有界与无界）和编码（表与流），后者将占据本书下半部分的大部分内容。
- en: Assessed the relative capabilities of well-designed batch and streaming systems,
    positing streaming is in fact a strict superset of batch, and that notions like
    the Lambda Architecture, which are predicated on streaming being inferior to batch,
    are destined for retirement as streaming systems mature.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估了设计良好的批处理和流处理系统的相对能力，假设流处理实际上是批处理的严格超集，并且像 Lambda 架构这样的概念，这些概念是基于流处理比批处理差的，注定会在流处理系统成熟时被淘汰。
- en: Proposed two high-level concepts necessary for streaming systems to both catch
    up to and ultimately surpass batch, those being correctness and tools for reasoning
    about time, respectively.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提出了流式系统赶上并最终超越批处理所需的两个高级概念，分别是正确性和关于时间推理的工具。
- en: Established the important differences between event time and processing time,
    characterized the difficulties those differences impose when analyzing data in
    the context of when they occurred, and proposed a shift in approach away from
    notions of completeness and toward simply adapting to changes in data over time.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定了事件时间和处理时间之间的重要差异，描述了这些差异在分析数据时所带来的困难，并提出了一种从完整性概念转向简单地适应数据随时间变化的方法。
- en: 'Looked at the major data processing approaches in common use today for bounded
    and unbounded data, via both batch and streaming engines, roughly categorizing
    the unbounded approaches into: time-agnostic, approximation, windowing by processing
    time, and windowing by event time.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审视了今天常见的有界和无界数据的主要数据处理方法，通过批处理和流处理引擎，粗略地将无界方法分类为：时间不可知、近似、按处理时间分窗和按事件时间分窗。
- en: 'Next up, we dive into the details of the Beam Model, taking a conceptual look
    at how we’ve broken up the notion of data processing across four related axes:
    what, where, when, and how. We also take a detailed look at processing a simple,
    concrete example dataset across multiple scenarios, highlighting the plurality
    of use cases enabled by the Beam Model, with some concrete APIs to ground us in
    reality. These examples will help drive home the notions of event time and processing
    time introduced in this chapter while additionally exploring new concepts such
    as watermarks.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入了解Beam模型的细节，概念上看看我们如何在四个相关的轴上分解了数据处理的概念：什么、在哪里、何时和如何。我们还将详细研究在多种场景下处理一个简单的具体示例数据集，突出了Beam模型所支持的多种用例，同时提供一些具体的API来使我们更接地气。这些示例将有助于加深本章介绍的事件时间和处理时间的概念，同时还将探索水印等新概念。
- en: ¹ For completeness, it’s perhaps worth calling out that this definition includes
    both true streaming as well as microbatch implementations. For those of you who
    aren’t familiar with microbatch systems, they are streaming systems that use repeated
    executions of a batch processing engine to process unbounded data. Spark Streaming
    is the canonical example in the industry.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 为了完整起见，也许值得指出，这个定义包括真正的流式处理以及微批量实现。对于那些不熟悉微批量系统的人来说，它们是使用重复执行批处理引擎来处理无界数据的流式系统。Spark
    Streaming是行业中的典型例子。
- en: '² Readers familiar with my original [“Streaming 101”](https://oreil.ly/2JBfN7X)
    article might recall that I rather emphatically encouraged the abandonment of
    the term “stream” when referring to datasets. That never caught on, which I initially
    thought was due to its catchiness and pervasive existing usage. In retrospect,
    however, I think I was simply wrong. There actually is great value in distinguishing
    between the two different types of dataset constitutions: tables and streams.
    Indeed, most of the second half of this book is dedicated to understanding the
    relationship between those two.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ² 熟悉我原始文章的读者可能会记得，我曾强烈鼓励放弃在引用数据集时使用术语“流”。这从未流行起来，我最初认为是因为它的朗朗上口和广泛的使用。然而，回想起来，我认为我错了。实际上，在区分两种不同类型的数据集构成：表和流方面有很大的价值。事实上，本书的大部分后半部分都致力于理解这两者之间的关系。
- en: '³ If you’re unfamiliar with what I mean when I say *exactly-once*, it’s referring
    to a specific type of consistency guarantee that certain data processing frameworks
    provide. Consistency guarantees are typically bucketed into three main classes:
    at-most-once processing, at-least-once processing, and exactly-once processing.
    Note that the names in use here refer to the effective semantics as observed within
    the outputs generated by the pipeline, not the actual number of times a pipeline
    might process (or attempt to process) any given record. For this reason, the term
    *effectively-once* is sometimes used instead of exactly-once, since it’s more
    representative of the underlying nature of things. Reuven covers these concepts
    in much more detail in Chapter 5.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ³ 如果你不熟悉我所说的“仅一次”，它指的是某些数据处理框架提供的特定类型的一致性保证。一致性保证通常分为三个主要类别：最多一次处理、至少一次处理和仅一次处理。请注意，这里使用的名称是指在管道生成的输出中观察到的有效语义，而不是管道可能处理（或尝试处理）任何给定记录的实际次数。因此，有时会使用“有效一次”这个术语来代替“仅一次”，因为它更能代表事物的基本性质。Reuven在第5章中更详细地介绍了这些概念。
- en: ⁴ Since the original publication of “Streaming 101,” numerous individuals have
    pointed out to me that it would have been more intuitive to place processing time
    on the x-axis and event time on the y-axis. I do agree that swapping the two axes
    would initially feel more natural, as event time seems like the dependent variable
    to processing time’s independent variable. However, because both variables are
    monotonic and intimately related, they’re effectively interdependent variables.
    So I think from a technical perspective you just have to pick an axis and stick
    with it. Math is confusing (especially outside of North America, where it suddenly
    becomes plural and gangs up on you).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴ 自从《流式处理101》最初出版以来，许多人指出对我来说，在x轴上放置处理时间，y轴上放置事件时间可能更直观。我同意，交换这两个轴最初会感觉更自然，因为事件时间似乎是处理时间的因变量。然而，由于这两个变量都是单调的并且密切相关，它们实际上是相互依存的变量。所以我认为从技术角度来看，你只需要选择一个轴并坚持下去。数学很令人困惑（特别是在北美以外的地方，它突然变成复数并且对你进行围攻）。
- en: ⁵ This result really shouldn’t be surprising (but was for me, hence why I’m
    pointing it out), because we’re effectively creating a right triangle with the
    ideal line when measuring the two types of skew/lag. Maths are cool.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵ 这个结果实际上不应该令人惊讶（但对我来说是），因为我们实际上是在测量两种偏差/滞后时创建了一个直角三角形。数学很酷。
- en: ⁶ We look at aligned fixed windows in detail in Chapter 2, and unaligned fixed
    windows in Chapter 4.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ⁶ 我们将在第2章详细讨论对齐的固定窗口，以及在第4章讨论未对齐的固定窗口。
- en: '⁷ If you poke around enough in the academic literature or SQL-based streaming
    systems, you’ll also come across a third windowing time domain: *tuple-based windowing*
    (i.e., windows whose sizes are counted in numbers of elements). However, tuple-based
    windowing is essentially a form of processing-time windowing in which elements
    are assigned monotonically increasing timestamps as they arrive at the system.
    As such, we won’t discuss tuple-based windowing in detail any further.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ⁷ 如果你在学术文献或基于SQL的流处理系统中仔细研究，你还会遇到第三种窗口时间域：基于元组的窗口（即，其大小以元素数量计算的窗口）。然而，基于元组的窗口实质上是一种处理时间窗口，其中元素在到达系统时被分配单调递增的时间戳。因此，我们不会进一步详细讨论基于元组的窗口。
