- en: Chapter 6 Probability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 概率
- en: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/probability.html](https://statsthinking21.github.io/statsthinking21-core-site/probability.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://statsthinking21.github.io/statsthinking21-core-site/probability.html](https://statsthinking21.github.io/statsthinking21-core-site/probability.html)'
- en: Probability theory is the branch of mathematics that deals with chance and uncertainty.
    It forms an important part of the foundation for statistics, because it provides
    us with the mathematical tools to describe uncertain events. The study of probability
    arose in part due to interest in understanding games of chance, like cards or
    dice. These games provide useful examples of many statistical concepts, because
    when we repeat these games the likelihood of different outcomes remains (mostly)
    the same. However, there are deep questions about the meaning of probability that
    we will not address here; see Suggested Readings at the end if you are interested
    in learning more about this fascinating topic and its history.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 概率论是处理机会和不确定性的数学分支。它构成了统计学基础的重要部分，因为它为我们提供了描述不确定事件的数学工具。概率的研究部分是由于对理解卡牌或骰子等游戏的兴趣。这些游戏提供了许多统计概念的有用例子，因为当我们重复这些游戏时，不同结果发生的可能性保持（大部分）不变。然而，关于概率含义的深刻问题我们在这里不会讨论；如果您对了解更多有关这个迷人主题及其历史感兴趣，请参阅结尾的建议阅读。
- en: 6.1 What is probability?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 什么是概率？
- en: Informally, we usually think of probability as a number that describes the likelihood
    of some event occurring, which ranges from zero (impossibility) to one (certainty).
    Sometimes probabilities will instead be expressed in percentages, which range
    from zero to one hundred, as when the weather forecast predicts a twenty percent
    chance of rain today. In each case, these numbers are expressing how likely that
    particular event is, ranging from absolutely impossible to absolutely certain.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 非正式地，我们通常将概率视为描述某个事件发生可能性的数字，范围从零（不可能）到一（确定）。有时概率将以百分比的形式表示，范围从零到一百，就像天气预报预测今天下雨的概率为百分之二十一样。在每种情况下，这些数字都表达了该特定事件有多大可能发生，从绝对不可能到绝对确定。
- en: 'To formalize probability theory, we first need to define a few terms:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了形式化概率论，我们首先需要定义一些术语：
- en: An **experiment** is any activity that produces or observes an outcome. Examples
    are flipping a coin, rolling a 6-sided die, or trying a new route to work to see
    if it’s faster than the old route.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验**是产生或观察结果的任何活动。例如，抛硬币、掷一个六面骰子，或者尝试一条新的上班路线看看它是否比旧路线更快。'
- en: 'The **sample space** is the set of possible outcomes for an experiment. We
    represent these by listing them within a set of squiggly brackets. For a coin
    flip, the sample space is {heads, tails}. For a six-sided die, the sample space
    is each of the possible numbers that can appear: {1,2,3,4,5,6}. For the amount
    of time it takes to get to work, the sample space is all possible real numbers
    greater than zero (since it can’t take a negative amount of time to get somewhere,
    at least not yet). We won’t bother trying to write out all of those numbers within
    the brackets.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样本空间**是实验的可能结果的集合。我们通过在一组花括号中列出它们来表示这些结果。对于抛硬币，样本空间是{正面，反面}。对于一个六面骰子，样本空间是可能出现的每个数字：{1,2,3,4,5,6}。对于到达工作地点所需的时间，样本空间是所有可能的实数大于零（因为到达某个地方不可能花费负数的时间，至少目前还不可能）。我们不会尝试在括号内写出所有这些数字。'
- en: An **event** is a subset of the sample space. In principle it could be one or
    more of possible outcomes in the sample space, but here we will focus primarily
    on *elementary events* which consist of exactly one possible outcome. For example,
    this could be obtaining heads in a single coin flip, rolling a 4 on a throw of
    the die, or taking 21 minutes to get home by the new route.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件**是样本空间的子集。原则上，它可以是样本空间中可能结果的一个或多个，但在这里，我们将主要关注*基本事件*，它们由恰好一个可能结果组成。例如，这可能是在一次抛硬币中获得正面，掷骰子时掷出4，或者通过新路线回家花费21分钟。'
- en: 'Now that we have those definitions, we can outline the formal features of a
    probability, which were first defined by the Russian mathematician Andrei Kolmogorov.
    These are the features that a value *has* to have if it is going to be a probability.
    Let’s say that we have a sample space defined by N independent events, \({E_1,
    E_2, ... , E_N}\), and \(X\) is a random variable denoting which of the events
    has occurred. \(P(X=E_i)\) is the probability of event \(i\):'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了这些定义，我们可以概述概率的正式特征，这些特征是由俄罗斯数学家安德烈·科尔莫戈洛夫首次定义的。这些是值必须具备的特征，如果它要成为概率的话。假设我们有一个由N个独立事件\({E_1,
    E_2, ... , E_N}\)定义的样本空间，\(X\)是一个随机变量，表示发生了哪个事件。\(P(X=E_i)\)是事件\(i\)的概率：
- en: 'Probability cannot be negative: \(P(X=E_i) \ge 0\)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率不能为负数：\(P(X=E_i) \ge 0\)
- en: 'The total probability of all outcomes in the sample space is 1; that is, if
    the , if we take the probability of each Ei and add them up, they must sum to
    1\. We can express this using the summation symbol \(\sum\): \[ \sum_{i=1}^N{P(X=E_i)}
    = P(X=E_1) + P(X=E_2) + ... + P(X=E_N) = 1 \] This is interpreted as saying “Take
    all of the N elementary events, which we have labeled from 1 to N, and add up
    their probabilities. These must sum to one.”'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本空间中所有结果的总概率为1；也就是说，如果我们取每个Ei的概率并将它们相加，它们必须加起来等于1。我们可以使用求和符号\(\sum\)来表示这一点：\[
    \sum_{i=1}^N{P(X=E_i)} = P(X=E_1) + P(X=E_2) + ... + P(X=E_N) = 1 \] 这被解释为“取所有N个基本事件，我们已经从1到N进行了标记，并将它们的概率相加。它们必须加起来等于一。”
- en: 'The probability of any individual event cannot be greater than one: \(P(X=E_i)\le
    1\). This is implied by the previous point; since they must sum to one, and they
    can’t be negative, then any particular probability cannot exceed one.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何单个事件的概率都不能大于一：\(P(X=E_i)\le 1\)。这是由前面的观点所暗示的；因为它们必须加起来等于一，而且它们不能是负数，所以任何特定的概率都不能超过一。
- en: 6.2 How do we determine probabilities?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 我们如何确定概率？
- en: Now that we know what a probability is, how do we actually figure out what the
    probability is for any particular event?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们知道了概率是什么，我们如何实际确定任何特定事件的概率呢？
- en: 6.2.1 Personal belief
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 个人信念
- en: Let’s say that I asked you what the probability was that Bernie Sanders would
    have won the 2016 presidential election if he had been the democratic nominee
    instead of Hilary Clinton? We can’t actually do the experiment to find the outcome.
    However, most people with knowledge of American politics would be willing to at
    least offer a guess at the probability of this event. In many cases personal knowledge
    and/or opinion is the only guide we have determining the probability of an event,
    but this is not very scientifically satisfying.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我问你如果伯尼·桑德斯在2016年总统选举中成为民主党提名人而不是希拉里·克林顿，他会赢得选举的概率是多少？我们实际上无法进行实验来找到结果。然而，大多数了解美国政治的人都愿意至少猜测这一事件的概率。在许多情况下，个人知识和/或意见是我们确定事件概率的唯一指南，但这并不是非常科学上令人满意的。
- en: 6.2.2 Empirical frequency
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 经验频率
- en: Another way to determine the probability of an event is to do the experiment
    many times and count how often each event happens. From the relative frequency
    of the different outcomes, we can compute the probability of each outcome. For
    example, let’s say that we are interested in knowing the probability of rain in
    San Francisco. We first have to define the experiment — let’s say that we will
    look at the National Weather Service data for each day in 2017 and determine whether
    there was any rain at the downtown San Francisco weather station. According to
    these data, in 2017 there were 73 rainy days. To compute the probability of rain
    in San Francisco, we simply divide the number of rainy days by the number of days
    counted (365), giving P(rain in SF in 2017) = 0.2.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 确定事件概率的另一种方法是多次进行实验，并计算每个事件发生的频率。从不同结果的相对频率，我们可以计算出每个结果的概率。例如，假设我们想知道旧金山下雨的概率。我们首先必须定义实验
    - 假设我们将查看2017年每一天的国家气象局数据，并确定在旧金山市中心气象站是否有下雨。根据这些数据，2017年有73天下雨。为了计算旧金山下雨的概率，我们只需将下雨的天数除以计数的天数（365），得出P（2017年旧金山下雨）=
    0.2。
- en: How do we know that empirical probability gives us the right number? The answer
    to this question comes from the *law of large numbers*, which shows that the empirical
    probability will approach the true probability as the sample size increases. We
    can see this by simulating a large number of coin flips, and looking at our estimate
    of the probability of heads after each flip. We will spend more time discussing
    simulation in a later chapter; for now, just assume that we have a computational
    way to generate a random outcome for each coin flip.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何知道经验概率给出了正确的数字？这个问题的答案来自于*大数定律*，它表明随着样本量的增加，经验概率将接近真实概率。我们可以通过模拟大量的硬币抛掷来看到这一点，并在每次抛掷后查看我们对正面概率的估计。我们将在后面的章节中更多地讨论模拟；现在，只需假设我们有一种计算方法来生成每次硬币抛掷的随机结果。
- en: The left panel of Figure [6.1](probability.html#fig:ElectionResults) shows that
    as the number of samples (i.e., coin flip trials) increases, the estimated probability
    of heads converges onto the true value of 0.5\. However, note that the estimates
    can be very far off from the true value when the sample sizes are small. A real-world
    example of this was seen in the 2017 special election for the US Senate in Alabama,
    which pitted the Republican Roy Moore against Democrat Doug Jones. The right panel
    of Figure [6.1](probability.html#fig:ElectionResults) shows the relative amount
    of the vote reported for each of the candidates over the course of the evening,
    as an increasing number of ballots were counted. Early in the evening the vote
    counts were especially volatile, swinging from a large initial lead for Jones
    to a long period where Moore had the lead, until finally Jones took the lead to
    win the race.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图[6.1](probability.html#fig:ElectionResults)的左侧面板显示，随着样本数量（即，硬币抛掷试验）的增加，正面的估计概率会收敛到0.5的真实值。然而，请注意，当样本量较小时，估计值可能与真实值相差甚远。这在2017年阿拉巴马州美国参议院特别选举中得到了真实世界的例证，该选举将共和党人罗伊·摩尔对阵民主党人道格·琼斯。图[6.1](probability.html#fig:ElectionResults)的右侧面板显示了在晚上的过程中每个候选人报告的相对选票数量，随着越来越多的选票被计算出来。晚上早些时候，选票数量特别不稳定，从琼斯的大幅领先到摩尔长时间领先，最终琼斯取得领先并赢得了比赛。
- en: '![Left: A demonstration of the law of large numbers.  A coin was flipped 30,000
    times, and after each flip the probability of heads was computed based on the
    number of heads and tail collected up to that point.  It takes about 15,000 flips
    for the probability to settle at the true probability of 0.5\. Right: Relative
    proportion of the vote in the Dec 12, 2017 special election for the US Senate
    seat in Alabama, as a function of the percentage of precincts reporting. These
    data were transcribed from https://www.ajc.com/news/national/alabama-senate-race-live-updates-roy-moore-doug-jones/KPRfkdaweoiXICW3FHjXqI/](../Images/d75fea6f2a2ca31ec20151baceeb1f2c.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: 左侧：大数定律的演示。硬币被抛掷了30,000次，每次抛掷后，根据迄今为止收集到的正反面数量计算出正面的概率。大约需要15,000次抛掷，概率才会稳定在真实概率0.5。右侧：2017年12月12日阿拉巴马州参议院特别选举中的选票相对比例，作为报告选区百分比的函数。这些数据是从https://www.ajc.com/news/national/alabama-senate-race-live-updates-roy-moore-doug-jones/KPRfkdaweoiXICW3FHjXqI/转录的。
- en: 'Figure 6.1: Left: A demonstration of the law of large numbers. A coin was flipped
    30,000 times, and after each flip the probability of heads was computed based
    on the number of heads and tail collected up to that point. It takes about 15,000
    flips for the probability to settle at the true probability of 0.5\. Right: Relative
    proportion of the vote in the Dec 12, 2017 special election for the US Senate
    seat in Alabama, as a function of the percentage of precincts reporting. These
    data were transcribed from [https://www.ajc.com/news/national/alabama-senate-race-live-updates-roy-moore-doug-jones/KPRfkdaweoiXICW3FHjXqI/](https://www.ajc.com/news/national/alabama-senate-race-live-updates-roy-moore-doug-jones/KPRfkdaweoiXICW3FHjXqI/)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1：左侧：大数定律的演示。硬币被抛掷了30,000次，每次抛掷后根据迄今为止收集到的正反面数量计算出正面的概率。大约需要15,000次抛掷才能使概率稳定在真实概率0.5。右侧：2017年12月12日阿拉巴马州参议院特别选举中的选票相对比例，作为报告选区百分比的函数。这些数据是从[https://www.ajc.com/news/national/alabama-senate-race-live-updates-roy-moore-doug-jones/KPRfkdaweoiXICW3FHjXqI/](https://www.ajc.com/news/national/alabama-senate-race-live-updates-roy-moore-doug-jones/KPRfkdaweoiXICW3FHjXqI/)转录的。
- en: These two examples show that while large samples will ultimately converge on
    the true probability, the results with small samples can be far off. Unfortunately,
    many people forget this and overinterpret results from small samples. This was
    referred to as the *law of small numbers* by the psychologists Danny Kahneman
    and Amos Tversky, who showed that people (even trained researchers) often behave
    as if the law of large numbers applies even to small samples, giving too much
    credence to results based on small datasets. We will see examples throughout the
    course of just how unstable statistical results can be when they are generated
    on the basis of small samples.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个例子表明，虽然大样本最终会收敛于真实概率，但小样本的结果可能相差甚远。不幸的是，许多人忘记了这一点，并过分解释了小样本的结果。这被心理学家丹尼·卡尼曼和阿莫斯·特沃斯基称为“小数定律”，他们表明人们（甚至是受过训练的研究人员）经常表现得好像大数定律甚至适用于小样本，对基于小数据集的结果给予了过多的信任。在课程中，我们将看到许多例子，说明当统计结果是基于小样本生成时，它们是多么不稳定。
- en: 6.2.3 Classical probability
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.3 古典概率
- en: It’s unlikely that any of us has ever flipped a coin tens of thousands of times,
    but we are nonetheless willing to believe that the probability of flipping heads
    is 0.5\. This reflects the use of yet another approach to computing probabilities,
    which we refer to as *classical probability*. In this approach, we compute the
    probability directly based on our knowledge of the situation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很少有人会抛掷硬币数万次，但我们仍然愿意相信抛掷正面的概率是0.5。这反映了我们使用另一种计算概率的方法，我们称之为“古典概率”。在这种方法中，我们根据对情况的了解直接计算概率。
- en: 'Classical probability arose from the study of games of chance such as dice
    and cards. A famous example arose from a problem encountered by a French gambler
    who went by the name of Chevalier de Méré. de Méré played two different dice games:
    In the first he bet on the chance of at least one six on four rolls of a six-sided
    die, while in the second he bet on the chance of at least one double-six on 24
    rolls of two dice. He expected to win money on both of these gambles, but he found
    that while on average he won money on the first gamble, he actually lost money
    on average when he played the second gamble many times. To understand this he
    turned to his friend, the mathematician Blaise Pascal, who is now recognized as
    one of the founders of probability theory.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 古典概率起源于对骰子和纸牌等游戏的研究。一个著名的例子来自于法国赌徒谢瓦利埃·德梅雷遇到的问题。德梅雷玩了两种不同的骰子游戏：在第一种游戏中，他押注至少有一个六在投掷六面骰子的四次中出现的机会，而在第二种游戏中，他押注至少有一个双六在投掷两个骰子的24次中出现的机会。他期望在这两个赌博中赚钱，但他发现，虽然平均上他在第一个赌博中赚了钱，但当他多次玩第二个赌博时，他实际上平均上是赔钱的。为了理解这一点，他求助于他的朋友、数学家布莱兹·帕斯卡，现在他被认为是概率论的创始人之一。
- en: 'How can we understand this question using probability theory? In classical
    probability, we start with the assumption that all of the elementary events in
    the sample space are equally likely; that is, when you roll a die, each of the
    possible outcomes ({1,2,3,4,5,6}) is equally likely to occur. (No loaded dice
    allowed!) Given this, we can compute the probability of any individual outcome
    as one divided by the number of possible outcomes:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何使用概率论来理解这个问题呢？在古典概率中，我们假设样本空间中的所有基本事件是等可能发生的；也就是说，当你掷骰子时，每种可能的结果（{1,2,3,4,5,6}）都是等可能发生的。（不允许使用偏骰子！）在这种情况下，我们可以计算任何单个结果的概率为1除以可能结果的数量：
- en: \[ P(outcome_i) = \frac{1}{\text{number of possible outcomes}} \]
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(outcome_i) = \frac{1}{\text{number of possible outcomes}} \]
- en: For the six-sided die, the probability of each individual outcome is 1/6.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于六面骰子，每个单个结果的概率是1/6。
- en: 'This is nice, but de Méré was interested in more complex events, like what
    happens on multiple dice throws. How do we compute the probability of a complex
    event (which is a *union* of single events), like rolling a six on the first *or*
    the second throw? We represent the union of events mathematically using the \(\cup\)
    symbol: for example, if the probability of rolling a six on the first throw is
    referred to as \(P(Roll6_{throw1})\) and the probability of rolling a six on the
    second throw is \(P(Roll6_{throw2})\), then the union is referred to as \(P(Roll6_{throw1}
    \cup Roll6_{throw2})\).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但德梅雷对更复杂的事件感兴趣，比如多次掷骰子会发生什么。我们如何计算复杂事件的概率（这是单个事件的“并集”），比如在第一次或第二次掷骰子时掷出一个六？我们用\(\cup\)符号在数学上表示事件的并集：例如，如果第一次掷骰子掷出六的概率被称为\(P(Roll6_{throw1})\)，第二次掷骰子掷出六的概率被称为\(P(Roll6_{throw2})\)，那么并集被称为\(P(Roll6_{throw1}
    \cup Roll6_{throw2})\)。
- en: 'de Méré thought (incorrectly, as we will see below) that he could simply add
    together the probabilities of the individual events to compute the probability
    of the combined event, meaning that the probability of rolling a six on the first
    or second roll would be computed as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: de Méré认为（我们将在下面看到是错误的），他可以简单地将两个事件的概率相加来计算组合事件的概率，这意味着首次或第二次掷出六的概率将如下计算：
- en: \[ P(Roll6_{throw1}) = 1/6 \] \[ P(Roll6_{throw2}) = 1/6 \]
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(Roll6_{throw1}) = 1/6 \] \[ P(Roll6_{throw2}) = 1/6 \]
- en: '\[ de Méré''s \ error: \] \[ P(Roll6_{throw1} \cup Roll6_{throw2}) = P(Roll6_{throw1})
    + P(Roll6_{throw2}) = 1/6 + 1/6 = 1/3 \]'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '\[ de Méré的错误: \] \[ P(Roll6_{throw1} \cup Roll6_{throw2}) = P(Roll6_{throw1})
    + P(Roll6_{throw2}) = 1/6 + 1/6 = 1/3 \]'
- en: 'de Méré reasoned based on this incorrect assumption that the probability of
    at least one six in four rolls was the sum of the probabilities on each of the
    individual throws: \(4*\frac{1}{6}=\frac{2}{3}\). Similarly, he reasoned that
    since the probability of a double-six when throwing two dice is 1/36, then the
    probability of at least one double-six on 24 rolls of two dice would be \(24*\frac{1}{36}=\frac{2}{3}\).
    Yet, while he consistently won money on the first bet, he lost money on the second
    bet. What gives?'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: de Méré基于这个错误的假设推理，即四次掷骰子至少有一个六的概率是每次单独掷骰子的概率之和：\(4*\frac{1}{6}=\frac{2}{3}\)。同样，他推断出，由于掷两个骰子时出现双六的概率是1/36，那么掷两个骰子24次至少出现一次双六的概率将是\(24*\frac{1}{36}=\frac{2}{3}\)。然而，尽管他在第一次赌注上一直赢钱，但在第二次赌注上却输钱了。是什么原因呢？
- en: 'To understand de Méré’s error, we need to introduce some of the rules of probability
    theory. The first is the *rule of subtraction*, which says that the probability
    of some event A *not* happening is one minus the probability of the event happening:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解de Méré的错误，我们需要介绍一些概率论的规则。第一个是*减法规则*，它说事件A *不*发生的概率是1减去事件发生的概率：
- en: \[ P(\neg A) = 1 - P(A) \]
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\neg A) = 1 - P(A) \]
- en: where \(\neg A\) means “not A”. This rule derives directly from the axioms that
    we discussed above; because A and \(\neg A\) are the only possible outcomes, then
    their total probability must sum to 1\. For example, if the probability of rolling
    a one in a single throw is \(\frac{1}{6}\), then the probability of rolling anything
    other than a one is \(\frac{5}{6}\).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(\neg A\)表示“非A”。这个规则直接源自我们上面讨论的公理；因为A和\(\neg A\)是唯一可能的结果，所以它们的总概率必须加起来为1。例如，如果单次掷骰子掷出1的概率是\(\frac{1}{6}\)，那么掷出非1的概率就是\(\frac{5}{6}\)。
- en: 'A second rule tells us how to compute the probability of a conjoint event –
    that is, the probability that both of two events will occur. We refer to this
    as an *intersection*, which is signified by the \(\cap\) symbol; thus, \(P(A \cap
    B)\) means the probability that both A and B will occur. We will focus on a version
    of the rule that tells us how to compute this quantity in the special case when
    the two events are independent from one another; we will learn later exactly what
    the concept of *independence* means, but for now we can just take it for granted
    that the two die throws are independent events. We compute the probability of
    the intersection of two independent events by simply multiplying the probabilities
    of the individual events:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 第二条规则告诉我们如何计算联合事件的概率 - 也就是两个事件都发生的概率。我们称之为*交集*，用\(\cap\)符号表示；因此，\(P(A \cap B)\)表示A和B都发生的概率。我们将专注于一种规则的版本，该规则告诉我们如何在两个事件彼此独立的特殊情况下计算这个数量；我们稍后将学习*独立性*概念的确切含义，但现在我们可以认为两次掷骰子是独立事件。我们通过简单地将两个事件的概率相乘来计算两个独立事件的交集的概率：
- en: \[ P(A \cap B) = P(A) * P(B)\ \text{if and only if A and B are independent}
    \] Thus, the probability of throwing a six on both of two rolls is \(\frac{1}{6}*\frac{1}{6}=\frac{1}{36}\).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A) * P(B)\ \text{当且仅当A和B是独立的时候} \] 因此，两次掷出六的概率是\(\frac{1}{6}*\frac{1}{6}=\frac{1}{36}\)。
- en: 'The third rule tells us how to add together probabilities - and it is here
    that we see the source of de Méré’s error. The addition rule tells us that to
    obtain the probability of either of two events occurring, we add together the
    individual probabilities, but then subtract the likelihood of both occurring together:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 第三条规则告诉我们如何将概率相加 - 就是在这里我们看到了de Méré的错误来源。加法规则告诉我们，要获得两个事件中任一事件发生的概率，我们将单独的概率相加，然后减去两者同时发生的可能性：
- en: '\[ P(A \cup B) = P(A) + P(B) - P(A \cap B) \] In a sense, this prevents us
    from counting those instances twice, and that’s what distinguishes the rule from
    de Méré’s incorrect computation. Let’s say that we want to find the probability
    of rolling 6 on either of two throws. According to our rules:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cup B) = P(A) + P(B) - P(A \cap B) \] 从某种意义上说，这阻止我们将这些实例计算两次，这就是这条规则与de
    Méré的错误计算有何不同。假设我们想要找到两次掷骰子中至少掷出6的概率。根据我们的规则：
- en: \[ P(Roll6_{throw1} \cup Roll6_{throw2}) = P(Roll6_{throw1}) + P(Roll6_{throw2})
    - P(Roll6_{throw1} \cap Roll6_{throw2}) \] \[ = \frac{1}{6} + \frac{1}{6} - \frac{1}{36}
    = \frac{11}{36} \]
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(Roll6_{throw1} \cup Roll6_{throw2}) = P(Roll6_{throw1}) + P(Roll6_{throw2})
    - P(Roll6_{throw1} \cap Roll6_{throw2}) \] \[ = \frac{1}{6} + \frac{1}{6} - \frac{1}{36}
    = \frac{11}{36} \]
- en: '![Each cell in this matrix represents one outcome of two throws of a die, with
    the columns representing the first throw and the rows representing the second
    throw. Cells shown in red represent the cells with a six in either the first or
    second throw; the rest are shown in blue.](../Images/3aa77af46b830e860f6ae210873a2317.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![此矩阵中的每个单元格代表掷骰子两次的一个结果，列代表第一次掷骰子，行代表第二次掷骰子。红色表示第一次或第二次掷出六的单元格；其余显示为蓝色。](../Images/3aa77af46b830e860f6ae210873a2317.png)'
- en: 'Figure 6.2: Each cell in this matrix represents one outcome of two throws of
    a die, with the columns representing the first throw and the rows representing
    the second throw. Cells shown in red represent the cells with a six in either
    the first or second throw; the rest are shown in blue.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2：此矩阵中的每个单元格代表掷骰子两次的一个结果，列代表第一次掷骰子，行代表第二次掷骰子。红色表示第一次或第二次掷出六的单元格；其余显示为蓝色。
- en: Let’s use a graphical depiction to get a different view of this rule. Figure
    [6.2](probability.html#fig:ThrowMatrix) shows a matrix representing all possible
    combinations of results across two throws, and highlights the cells that involve
    a six on either the first or second throw. If you count up the cells in red you
    will see that there are 11 such cells. This shows why the addition rule gives
    a different answer from de Méré’s; if we were to simply add together the probabilities
    for the two throws as he did, then we would count (6,6) towards both, when it
    should really only be counted once.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用图形描述来对这个规则有一个不同的视角。图[6.2](probability.html#fig:ThrowMatrix)显示了表示两次投掷中所有可能结果组合的矩阵，并突出显示了涉及第一次或第二次投掷中的六的单元格。如果你数一数红色的单元格，你会发现有11个这样的单元格。这说明了为什么加法规则给出了与de
    Méré不同的答案；如果我们像他一样简单地将两次投掷的概率相加，那么我们会将(6,6)计算两次，而实际上它只应该计算一次。
- en: 6.2.4 Solving de Méré’s problem
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.4 解决de Méré的问题
- en: 'Blaise Pascal used the rules of probability to come up with a solution to de
    Méré’s problem. First, he realized that computing the probability of at least
    one event out of a combination was tricky, whereas computing the probability that
    something does not occur across several events is relatively easy – it’s just
    the product of the probabilities of the individual events. Thus, rather than computing
    the probability of at least one six in four rolls, he instead computed the probability
    of no sixes across all rolls:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Blaise Pascal利用概率规则解决了de Méré的问题。首先，他意识到计算至少一个事件的概率组合是棘手的，而计算某事在多个事件中不发生的概率相对容易——它只是各个事件概率的乘积。因此，他不是计算四次投掷中至少出现一个六的概率，而是计算所有投掷中没有六的概率：
- en: \[ P(\text{no sixes in four rolls}) = \frac{5}{6}*\frac{5}{6}*\frac{5}{6}*\frac{5}{6}=\bigg(\frac{5}{6}\bigg)^4=0.482
    \]
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\text{四次投掷中没有六}) = \frac{5}{6}*\frac{5}{6}*\frac{5}{6}*\frac{5}{6}=\bigg(\frac{5}{6}\bigg)^4=0.482
    \]
- en: 'He then used the fact that the probability of no sixes in four rolls is the
    complement of at least one six in four rolls (thus they must sum to one), and
    used the rule of subtraction to compute the probability of interest:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后他利用四次投掷中没有六的概率是至少有一个六的概率的补集（因此它们必须相加为一），并使用减法规则计算感兴趣的概率：
- en: \[ P(\text{at least one six in four rolls}) = 1 - \bigg(\frac{5}{6}\bigg)^4=0.517
    \]
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\text{四次投掷中至少有一个六}) = 1 - \bigg(\frac{5}{6}\bigg)^4=0.517 \]
- en: de Méré’s gamble that he would throw at least one six in four rolls has a probability
    of greater than 0.5, explaning why de Méré made money on this bet on average.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: de Méré打赌他在四次投掷中至少会掷出一个六的概率大于0.5，这解释了为什么de Méré平均赚钱。
- en: 'But what about de Méré’s second bet? Pascal used the same trick:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 但是de Méré的第二次赌注呢？Pascal使用了同样的技巧：
- en: \[ P(\text{no double six in 24 rolls}) = \bigg(\frac{35}{36}\bigg)^{24}=0.509
    \] \[ P(\text{at least one double six in 24 rolls}) = 1 - \bigg(\frac{35}{36}\bigg)^{24}=0.491
    \]
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\text{24次投掷中没有双六}) = \bigg(\frac{35}{36}\bigg)^{24}=0.509 \] \[ P(\text{24次投掷中至少有一个双六})
    = 1 - \bigg(\frac{35}{36}\bigg)^{24}=0.491 \]
- en: The probability of this outcome was slightly below 0.5, showing why de Méré
    lost money on average on this bet.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这种结果的概率略低于0.5，说明了为什么de Méré在这个赌注上平均亏钱。
- en: 6.3 Probability distributions
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 概率分布
- en: 'A *probability distribution* describes the probability of all of the possible
    outcomes in an experiment. For example, on Jan 20 2018, the basketball player
    Steph Curry hit only 2 out of 4 free throws in a game against the Houston Rockets.
    We know that Curry’s overall probability of hitting free throws across the entire
    season was 0.91, so it seems pretty unlikely that he would hit only 50% of his
    free throws in a game, but exactly how unlikely is it? We can determine this using
    a theoretical probability distribution; throughout this book we will encounter
    a number of these probability distributions, each of which is appropriate to describe
    different types of data. In this case, we use the *binomial* distribution, which
    provides a way to compute the probability of some number of successes out of a
    number of trials on which there is either success or failure and nothing in between
    (known as “Bernoulli trials”), given some known probability of success on each
    trial. This distribution is defined as:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*概率分布*描述了实验中所有可能结果的概率。例如，2018年1月20日，篮球运动员斯蒂芬·库里在对休斯顿火箭队的比赛中只投中了4次罚球中的2次。我们知道库里整个赛季罚球的概率是0.91，所以他在一场比赛中只投中50%的罚球似乎是不太可能的，但确切有多少可能性呢？我们可以使用理论概率分布来确定这一点；在本书中，我们将遇到许多这些概率分布，每个都适合描述不同类型的数据。在这种情况下，我们使用*二项式*分布，它提供了一种计算在每次试验中成功或失败的情况下，某些成功次数的概率的方法，给定每次试验上的已知成功概率（称为“伯努利试验”）。这个分布被定义为：'
- en: \[ P(k; n,p) = P(X=k) = \binom{n}{k} p^k(1-p)^{n-k} \]
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(k; n,p) = P(X=k) = \binom{n}{k} p^k(1-p)^{n-k} \]
- en: 'This refers to the probability of k successes on n trials when the probability
    of success is p. You may not be familiar with \(\binom{n}{k}\), which is referred
    to as the *binomial coefficient*. The binomial coefficient is also referred to
    as “n-choose-k” because it describes the number of different ways that one can
    choose k items out of n total items. The binomial coefficient is computed as:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这指的是在概率为p的情况下，在n次试验中出现k次成功的概率。你可能不熟悉\(\binom{n}{k}\)，它被称为*二项式系数*。二项式系数也被称为“n选k”，因为它描述了从n个总项中选择k个项的不同方式的数量。二项式系数计算如下：
- en: '\[ \binom{n}{k} = \frac{n!}{k!(n-k)!} \] where the exclamation point (!) refers
    to the *factorial* of the number:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \binom{n}{k} = \frac{n!}{k!(n-k)!} \] 其中感叹号（!）表示数字的*阶乘*：
- en: \[ n! = \prod_{i=1}^n i = n*(n-1)*...*2*1 \]
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: \[ n! = \prod_{i=1}^n i = n*(n-1)*...*2*1 \]
- en: The product operator \(\prod\) is similar to the summation operator \(\sum\),
    except that it multiplies instead of adds. In this case, it is multiplying together
    all numbers from one to \(n\).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 乘积运算符\(\prod\)类似于求和运算符\(\sum\)，只是它是相乘而不是相加。在这种情况下，它将从一到\(n\)的所有数字相乘在一起。
- en: 'In the example of Steph Curry’s free throws:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在斯蒂芬·库里罚球的例子中：
- en: \[ P(2;4,0.91) = \binom{4}{2} 0.91^2(1-0.91)^{4-2} = 0.040 \]
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(2;4,0.91) = \binom{4}{2} 0.91^2(1-0.91)^{4-2} = 0.040 \]
- en: This shows that given Curry’s overall free throw percentage, it is very unlikely
    that he would hit only 2 out of 4 free throws. Which just goes to show that unlikely
    things do actually happen in the real world.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，鉴于库里的整体罚球命中率，他在4次罚球中只命中2次的概率是非常低的。这只是表明在现实世界中不太可能的事情实际上确实会发生。
- en: 6.3.1 Cumulative probability distributions
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.1 累积概率分布
- en: Often we want to know not just how likely a specific value is, but how likely
    it is to find a value that is as extreme or more than a particular value; this
    will become very important when we discuss hypothesis testing in Chapter 9\. To
    answer this question, we can use a *cumulative* probability distribution; whereas
    a standard probability distribution tells us the probability of some specific
    value, the cumulative distribution tells us the probability of a value as large
    or larger (or as small or smaller) than some specific value.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通常我们不仅想知道特定值有多大可能性，还想知道找到一个与特定值一样极端或更极端的值有多大可能性；当我们在第9章讨论假设检验时，这将变得非常重要。为了回答这个问题，我们可以使用*累积*概率分布；标准概率分布告诉我们某个特定值的概率，而累积分布告诉我们一个与某个特定值一样大或更大（或者一样小或更小）的值的概率。
- en: 'In the free throw example, we might want to know: What is the probability that
    Steph Curry hits 2 *or fewer* free throws out of four, given his overall free
    throw probability of 0.91\. To determine this, we could simply use the the binomial
    probability equation and plug in all of the possible values of k and add them
    together:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在罚球的例子中，我们可能想知道：鉴于库里的整体罚球概率为0.91，斯蒂芬·库里在四次尝试中命中2次或更少罚球的概率是多少。为了确定这一点，我们可以简单地使用二项概率方程，并将所有可能的k值代入并相加。
- en: \[ P(k\le2)= P(k=2) + P(k=1) + P(k=0) = 6e^{-5} + .002 + .040 = .043 \]
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(k\le2)= P(k=2) + P(k=1) + P(k=0) = 6e^{-5} + .002 + .040 = .043 \]
- en: In many cases the number of possible outcomes would be too large for us to compute
    the cumulative probability by enumerating all possible values; fortunately, it
    can be computed directly for any theoretical probability distribution. Table [6.1](probability.html#tab:freethrow)
    shows the cumulative probability of each possible number of successful free throws
    in the example from above, from which we can see that the probability of Curry
    landing 2 or fewer free throws out of 4 attempts is 0.043.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，可能结果的数量对我们来说太大，无法通过枚举所有可能的值来计算累积概率；幸运的是，它可以直接计算任何理论概率分布。表[6.1](probability.html#tab:freethrow)显示了上面示例中每个成功罚球次数的累积概率，从中我们可以看到库里在4次尝试中命中2次或更少罚球的概率为0.043。
- en: 'Table 6.1: Simple and cumulative probability distributions for number of successful
    free throws by Steph Curry in 4 attempts.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.1：斯蒂芬·库里在4次尝试中成功罚球次数的简单和累积概率分布。
- en: '| numSuccesses | Probability | CumulativeProbability |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| numSuccesses | Probability | CumulativeProbability |'
- en: '| --: | --: | --: |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| --: | --: | --: |'
- en: '| 0 | 0.000 | 0.000 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.000 | 0.000 |'
- en: '| 1 | 0.003 | 0.003 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.003 | 0.003 |'
- en: '| 2 | 0.040 | 0.043 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.040 | 0.043 |'
- en: '| 3 | 0.271 | 0.314 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.271 | 0.314 |'
- en: '| 4 | 0.686 | 1.000 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.686 | 1.000 |'
- en: 6.4 Conditional probability
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 条件概率
- en: So far we have limited ourselves to simple probabilities - that is, the probability
    of a single event or combination of events. However, we often wish to determine
    the probability of some event given that some other event has occurred, which
    are known as *conditional probabilities*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只限制在简单概率上 - 也就是单个事件或事件组合的概率。然而，我们经常希望确定某个事件发生的概率，假设发生了另一个事件，这被称为*条件概率*。
- en: 'Let’s take the 2016 US Presidential election as an example. There are two simple
    probabilities that we could use to describe the electorate. First, we know the
    probability that a voter in the US is affiliated with the Republican party: \(p(Republican)
    = 0.44\). We also know the probability that a voter cast their vote in favor of
    Donald Trump: \(p(Trump voter)=0.46\). However, let’s say that we want to know
    the following: What is the probability that a person cast their vote for Donald
    Trump, *given that they are a Republican*?'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以2016年美国总统选举为例。有两个简单的概率可以用来描述选民。首先，我们知道美国选民与共和党有关的概率：\(p(共和党) = 0.44\)。我们还知道投票支持唐纳德·特朗普的选民的概率：\(p(特朗普选民)=0.46\)。然而，假设我们想知道以下内容：一个人投票支持唐纳德·特朗普的概率是多少，*假设他们是共和党人*？
- en: 'To compute the conditional probability of A given B (which we write as \(P(A|B)\),
    “probability of A, given B”), we need to know the *joint probability* (that is,
    the probability of both A and B occurring) as well as the overall probability
    of B:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算给定B的条件概率A（我们将其写为\(P(A|B)\)，“给定B的A的概率”），我们需要知道*联合概率*（即A和B同时发生的概率）以及B的整体概率：
- en: \[ P(A|B) = \frac{P(A \cap B)}{P(B)} \]
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) = \frac{P(A \cap B)}{P(B)} \]
- en: That is, we want to know the probability that both things are true, given that
    the one being conditioned upon is true.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，我们想知道在被条件限制的情况下，两件事情都是真的概率。
- en: '![A graphical depiction of conditional probability, showing how the conditional
    probability limits our analysis to a subset of the data.](../Images/7fce2c336897afcc2cc2bcdd1bf8583b.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![条件概率的图形描述，显示了条件概率如何将我们的分析限制在数据的子集中。](../Images/7fce2c336897afcc2cc2bcdd1bf8583b.png)'
- en: 'Figure 6.3: A graphical depiction of conditional probability, showing how the
    conditional probability limits our analysis to a subset of the data.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3：条件概率的图形描述，显示了条件概率如何将我们的分析限制在数据的子集中。
- en: It can be useful to think of this graphically. Figure [6.3](probability.html#fig:conditionalProbability)
    shows a flow chart depicting how the full population of voters breaks down into
    Republicans and Democrats, and how the conditional probability (conditioning on
    party) further breaks down the members of each party according to their vote.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以图形方式思考这点可能会有所帮助。图[6.3](probability.html#fig:conditionalProbability)显示了一个流程图，描述了选民的整体人口是如何分为共和党人和民主党人的，并且条件概率（以政党为条件）如何进一步根据他们的投票将每个政党的成员细分。
- en: 6.5 Computing conditional probabilities from data
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 从数据计算条件概率
- en: 'We can also compute conditional probabilities directly from data. Let’s say
    that we are interested in the following question: What is the probability that
    someone has diabetes, given that they are not physically active? – that is, \(P(diabetes|inactive)\).
    The NHANES dataset includes two variables that address the two parts of this question.
    The first (`Diabetes`) asks whether the person has ever been told that they have
    diabetes, and the second (`PhysActive`) records whether the person engages in
    sports, fitness, or recreational activities that are at least of moderate intensity.
    Let’s first compute the simple probabilities, which are shown in Table [6.2](probability.html#tab:simpleProb).
    The table shows that the probability that someone in the NHANES dataset has diabetes
    is .1, and the probability that someone is inactive is .45.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以直接从数据中计算条件概率。假设我们对以下问题感兴趣：一个人患有糖尿病的概率是多少，假设他们不活跃？即，\(P(糖尿病|不活跃)\)。NHANES数据集包括两个变量，涉及这个问题的两个部分。第一个（`糖尿病`）询问这个人是否被告知他们患有糖尿病，第二个（`身体活动`）记录这个人是否参加至少中等强度的体育、健身或娱乐活动。让我们首先计算简单概率，如表[6.2](probability.html#tab:simpleProb)所示。表格显示NHANES数据集中有糖尿病的人的概率为0.1，不活跃的人的概率为0.45。
- en: 'Table 6.2: Summary data for diabetes and physical activity'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.2：糖尿病和体力活动的摘要数据
- en: '| Answer | N_diabetes | P_diabetes | N_PhysActive | P_PhysActive |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 答案 | 无糖尿病 | 糖尿病概率 | 无身体活动 | 身体活动概率 |'
- en: '| :-- | --: | --: | --: | --: |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| :-- | --: | --: | --: | --: |'
- en: '| No | 4893 | 0.9 | 2472 | 0.45 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 否 | 4893 | 0.9 | 2472 | 0.45 |'
- en: '| Yes | 550 | 0.1 | 2971 | 0.55 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 是 | 550 | 0.1 | 2971 | 0.55 |'
- en: 'Table 6.3: Joint probabilities for Diabetes and PhysActive variables.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.3：糖尿病和身体活动变量的联合概率。
- en: '| Diabetes | PhysActive | n | prob |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 糖尿病 | 身体活动 | n | 概率 |'
- en: '| :-- | :-- | --: | --: |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- | --: | --: |'
- en: '| No | No | 2123 | 0.39 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 否 | 否 | 2123 | 0.39 |'
- en: '| No | Yes | 2770 | 0.51 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 否 | 是 | 2770 | 0.51 |'
- en: '| Yes | No | 349 | 0.06 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 是 | 否 | 349 | 0.06 |'
- en: '| Yes | Yes | 201 | 0.04 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 是 | 是 | 201 | 0.04 |'
- en: To compute \(P(diabetes|inactive)\) we would also need to know the joint probability
    of being diabetic *and* inactive, in addition to the simple probabilities of each.
    These are shown in Table [6.3](probability.html#tab:jointProb). Based on these
    joint probabilities, we can compute \(P(diabetes|inactive)\). One way to do this
    in a computer program is to first determine the whether the PhysActive variable
    was equal to “No” for each indivdual, and then take the mean of those truth values.
    Since TRUE/FALSE values are treated as 1/0 respectively by most programming languages
    (including R and Python), this allows us to easily identify the probability of
    a simple event by simply taking the mean of a logical variable representing its
    truth value. We then use that value to compute the conditional probability, where
    we find that the probability of someone having diabetes given that they are physically
    inactive is 0.141.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算 \(P(糖尿病|不活跃)\) ，我们还需要知道患糖尿病和不活跃的联合概率，除了每个简单概率。这些显示在表[6.3](probability.html#tab:jointProb)中。根据这些联合概率，我们可以计算
    \(P(糖尿病|不活跃)\)。在计算机程序中，一种方法是首先确定每个个体的 PhysActive 变量是否等于“否”，然后取这些真值的平均值。由于大多数编程语言（包括R和Python）将TRUE/FALSE值分别视为1/0，这使我们可以通过简单地取表示其真值的逻辑变量的平均值来轻松识别简单事件的概率。然后我们使用该值来计算条件概率，从中我们发现，患糖尿病的人在身体不活跃的情况下的概率为0.141。
- en: 6.6 Independence
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.6 独立性
- en: 'The term “independent” has a very specific meaning in statistics, which is
    somewhat different from the common usage of the term. Statistical independence
    between two variables means that knowing the value of one variable doesn’t tell
    us anything about the value of the other. This can be expressed as:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: “独立”这个术语在统计学中有一个非常具体的含义，与常规用法略有不同。两个变量之间的统计独立意味着知道一个变量的值不会告诉我们关于另一个变量的值的任何信息。这可以表示为：
- en: \[ P(A|B) = P(A) \]
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) = P(A) \]
- en: That is, the probability of A given some value of B is just the same as the
    overall probability of A. Looking at it this way, we see that many cases of what
    we would call “independence” in the real world are not actually statistically
    independent. For example, there is currently a move by a small group of California
    citizens to declare a new independent state called Jefferson, which would comprise
    a number of counties in northern California and Oregon. If this were to happen,
    then the probability that a current California resident would now live in the
    state of Jefferson would be \(P(\text{Jeffersonian})=0.014\), whereas the probability
    that they would remain a California resident would be \(P(\text{Californian})=0.986\).
    The new states might be politically independent, but they would *not* be statistically
    independent, because if we know that a person is Jeffersonian, then we can be
    sure that they are *not* Californian! That is, while independence in common language
    often refers to sets that are exclusive, statistical independence refers to the
    case where one cannot predict anything about one variable from the value of another
    variable. For example, knowing a person’s hair color is unlikely to tell you whether
    they prefer chocolate or strawberry ice cream.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，给定B的某个值时A的概率与A的整体概率是一样的。从这个角度来看，我们发现在现实世界中许多我们称之为“独立”的情况实际上并不是统计上独立的。例如，加利福尼亚州的一小部分公民目前正在推动宣布一个名为杰斐逊的新独立州，该州将包括加利福尼亚州北部和俄勒冈州的一些县。如果这种情况发生，那么当前加利福尼亚居民现在居住在杰斐逊州的概率将是
    \(P(\text{杰斐逊人})=0.014\)，而他们仍然是加利福尼亚居民的概率将是 \(P(\text{加利福尼亚人})=0.986\)。新的州可能在政治上是独立的，但它们*不*在统计上是独立的，因为如果我们知道一个人是杰斐逊人，那么我们可以肯定他们*不*是加利福尼亚人！也就是说，尽管在日常语言中，“独立”通常指的是互斥的集合，但统计独立是指一个变量的值无法从另一个变量的值预测出来的情况。例如，知道一个人的头发颜色不太可能告诉你他们更喜欢巧克力还是草莓冰淇淋。
- en: 'Let’s look at another example, using the NHANES data: Are physical health and
    mental health independent of one another? NHANES includes two relevant questions:
    *PhysActive*, which asks whether the individual is physically active, and *DaysMentHlthBad*,
    which asks how many days out of the last 30 that the individual experienced bad
    mental health. Let’s consider anyone who had more than 7 days of bad mental health
    in the last month to be in bad mental health. Based on this, we can define a new
    variable called *badMentalHealth* as a logical variable telling whether each person
    had more than 7 days of bad mental health or not. We can first summarize the data
    to show how many individuals fall into each combination of the two variables (shown
    in Table [6.4](probability.html#tab:mhCounts)), and then divide by the total number
    of observations to create a table of proportions (shown in Table [6.5](probability.html#tab:mhProps)):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看另一个例子，使用NHANES数据：身体健康和心理健康是否彼此独立？NHANES包括两个相关问题：*PhysActive*，询问个体是否进行身体活动，以及*DaysMentHlthBad*，询问个体在过去30天中有多少天经历了糟糕的心理健康。让我们考虑在过去一个月中有超过7天糟糕心理健康的人。基于此，我们可以定义一个名为*badMentalHealth*的新变量，作为一个逻辑变量，告诉每个人是否有超过7天的糟糕心理健康。我们可以首先总结数据，显示有多少个体落入两个变量的每种组合（在表[6.4](probability.html#tab:mhCounts)中显示），然后除以总观察数，创建一个比例表（在表[6.5](probability.html#tab:mhProps)中显示）：
- en: 'Table 6.4: Summary of absolute frequency data for mental health and physical
    activity.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.4：心理健康和身体活动的绝对频率数据总结。
- en: '| PhysActive | Bad Mental Health | Good Mental Health | Total |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| PhysActive | Bad Mental Health | Good Mental Health | Total |'
- en: '| :-- | --: | --: | --: |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| :-- | --: | --: | --: |'
- en: '| No | 414 | 1664 | 2078 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| No | 414 | 1664 | 2078 |'
- en: '| Yes | 292 | 1926 | 2218 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| Yes | 292 | 1926 | 2218 |'
- en: '| Total | 706 | 3590 | 4296 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| Total | 706 | 3590 | 4296 |'
- en: 'Table 6.5: Summary of relative frequency data for mental health and physical
    activity.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.5：心理健康和身体活动的相对频率数据总结。
- en: '| PhysActive | Bad Mental Health | Good Mental Health | Total |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| PhysActive | Bad Mental Health | Good Mental Health | Total |'
- en: '| :-- | --: | --: | --: |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| :-- | --: | --: | --: |'
- en: '| No | 0.10 | 0.39 | 0.48 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| No | 0.10 | 0.39 | 0.48 |'
- en: '| Yes | 0.07 | 0.45 | 0.52 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| Yes | 0.07 | 0.45 | 0.52 |'
- en: '| Total | 0.16 | 0.84 | 1.00 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| Total | 0.16 | 0.84 | 1.00 |'
- en: This shows us the proportion of all observations that fall into each cell. However,
    what we want to know here is the conditional probability of bad mental health,
    depending on whether one is physically active or not. To compute this, we divide
    each physical activity group by its total number of observations, so that each
    row now sums to one (shown in Table [6.6](probability.html#tab:condProb)). Here
    we see the conditional probabilities of bad or good mental health for each physical
    activity group (in the top two rows) along with the overall probability of good
    or bad mental health in the third row. To determine whether mental health and
    physical activity are independent, we would compare the simple probability of
    bad mental health (in the third row) to the conditional probability of bad mental
    health given that one is physically active (in the second row).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有观察结果中落入每个单元格的比例。然而，我们想要知道的是这里的条件概率，即取决于是否进行身体活动的糟糕心理健康的条件概率。为了计算这个，我们将每个身体活动组除以其总观察数，使得每行现在总和为1（在表[6.6](probability.html#tab:condProb)中显示）。在这里，我们看到了每个身体活动组的糟糕或良好心理健康的条件概率（在前两行中），以及第三行中的总体糟糕或良好心理健康的概率。要确定心理健康和身体活动是否独立，我们将比较糟糕心理健康的简单概率（第三行）与在进行身体活动的情况下糟糕心理健康的条件概率（第二行）。
- en: 'Table 6.6: Summary of conditional probabilities for mental health given physical
    activity.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '表6.6：给定身体活动的条件概率总结。 '
- en: '| PhysActive | Bad Mental Health | Good Mental Health | Total |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| PhysActive | Bad Mental Health | Good Mental Health | Total |'
- en: '| :-- | --: | --: | --: |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| :-- | --: | --: | --: |'
- en: '| No | 0.20 | 0.80 | 1 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| No | 0.20 | 0.80 | 1 |'
- en: '| Yes | 0.13 | 0.87 | 1 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| Yes | 0.13 | 0.87 | 1 |'
- en: '| Total | 0.16 | 0.84 | 1 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| Total | 0.16 | 0.84 | 1 |'
- en: The overall probability of bad mental health \(P(\text{bad mental health})\)
    is 0.16 while the conditional probability \(P(\text{bad mental health|physically
    active})\) is 0.13\. Thus, it seems that the conditional probability is somewhat
    smaller than the overall probability, suggesting that they are not independent,
    though we can’t know for sure just by looking at the numbers, since these numbers
    might be different due to random variability in our sample. Later in the book
    we will discuss statistical tools that will let us directly test whether two variables
    are independent.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 糟糕心理健康的总体概率\(P(\text{bad mental health})\)为0.16，而条件概率\(P(\text{bad mental health|physically
    active})\)为0.13。因此，似乎条件概率略小于总体概率，这表明它们不是独立的，尽管我们不能仅凭数字就确定，因为这些数字可能由于样本中的随机变异而不同。本书后面我们将讨论统计工具，让我们直接测试两个变量是否独立。
- en: '6.7 Reversing a conditional probability: Bayes’ rule'
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.7 反转条件概率：贝叶斯定理
- en: 'In many cases, we know \(P(A|B)\) but we really want to know \(P(B|A)\). This
    commonly occurs in medical screening, where we know \(P(\text{positive test result|
    disease})\) but what we want to know is \(P(\text{disease|positive test result})\).
    For example, some doctors recommend that men over the age of 50 undergo screening
    using a test called prostate specific antigen (PSA) to screen for possible prostate
    cancer. Before a test is approved for use in medical practice, the manufacturer
    needs to test two aspects of the test’s performance. First, they need to show
    how *sensitive* it is – that is, how likely is it to find the disease when it
    is present: \(\text{sensitivity} = P(\text{positive test| disease})\). They also
    need to show how *specific* it is: that is, how likely is it to give a negative
    result when there is no disease present: \(\text{specificity} = P(\text{negative
    test|no disease})\). For the PSA test, we know that sensitivity is about 80% and
    specificity is about 70%. However, these don’t answer the question that the physician
    wants to answer for any particular patient: what is the likelihood that they actually
    have cancer, given that the test comes back positive? This requires that we reverse
    the conditional probability that defines sensitivity: instead of \(P(positive\
    test| disease)\) we want to know \(P(disease|positive\ test)\).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我们知道\(P(A|B)\)，但我们真正想知道的是\(P(B|A)\)。这在医学筛查中经常发生，我们知道\(P(\text{疾病|阳性检测结果})\)，但我们想知道的是\(P(\text{阳性检测结果|疾病})\)。例如，一些医生建议50岁以上的男性接受一种名为前列腺特异抗原（PSA）的检测，以筛查可能的前列腺癌。在一项测试被批准用于医学实践之前，制造商需要测试测试性能的两个方面。首先，他们需要展示它的*敏感性*
    - 也就是说，当疾病存在时发现疾病的可能性有多大：\(\text{敏感性} = P(\text{疾病|阳性检测})\)。他们还需要展示它的*特异性*：也就是说，在没有疾病的情况下给出阴性结果的可能性有多大：\(\text{特异性}
    = P(\text{无疾病|阴性检测})\)。对于PSA测试，我们知道敏感性约为80%，特异性约为70%。然而，这些并不能回答医生想要为任何特定患者回答的问题：在检测结果呈阳性的情况下，他们实际上患癌症的可能性有多大？这要求我们反转定义敏感性的条件概率：我们想知道的不是\(P(阳性\
    检测| 疾病)\)，而是\(P(疾病| 阳性\ 检测)\)。
- en: 'In order to reverse a conditional probability, we can use *Bayes’ rule*:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为了反转条件概率，我们可以使用*贝叶斯定理*：
- en: \[ P(B|A) = \frac{P(A|B)*P(B)}{P(A)} \]
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(B|A) = \frac{P(A|B)*P(B)}{P(A)} \]
- en: Bayes’ rule is fairly easy to derive, based on the rules of probability that
    we learned earlier in the chapter (see the Appendix for this derivation).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理相当容易推导出来，基于我们在本章早些时候学到的概率规则（有关此推导，请参阅附录）。
- en: 'If we have only two outcomes, we can express Bayes’ rule in a somewhat clearer
    way, using the sum rule to redefine \(P(A)\):'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只有两个结果，我们可以使用总和规则重新定义\(P(A)\)来更清晰地表达贝叶斯定理：
- en: \[ P(A) = P(A|B)*P(B) + P(A|\neg B)*P(\neg B) \]
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A) = P(A|B)*P(B) + P(A|\neg B)*P(\neg B) \]
- en: 'Using this, we can redefine Bayes’s rule:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这一点，我们可以重新定义贝叶斯定理：
- en: \[ P(B|A) = \frac{P(A|B)*P(B)}{P(A|B)*P(B) + P(A|\neg B)*P(\neg B)} \]
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(B|A) = \frac{P(A|B)*P(B)}{P(A|B)*P(B) + P(A|\neg B)*P(\neg B)} \]
- en: 'We can plug the relevant numbers into this equation to determine the likelihood
    that an individual with a positive PSA result actually has cancer – but note that
    in order to do this, we also need to know the overall probability of cancer for
    that person, which we often refer to as the *base rate*. Let’s take a 60 year
    old man, for whom the probability of prostate cancer in the next 10 years is \(P(cancer)=0.058\).
    Using the sensitivity and specificity values that we outlined above, we can compute
    the individual’s likelihood of having cancer given a positive test:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将相关数字代入这个方程中，以确定一个PSA检测结果呈阳性的个体实际上患癌症的可能性 - 但请注意，为了做到这一点，我们还需要知道该人群患癌症的总体概率，我们通常称之为*基础率*。让我们以一个60岁的男性为例，他在接下来的10年内患前列腺癌的概率为\(P(癌症)=0.058\)。使用我们上面概述的敏感性和特异性值，我们可以计算个体在检测结果呈阳性的情况下患癌症的可能性：
- en: \[ P(\text{cancer|test}) = \frac{P(\text{test|cancer})*P(\text{cancer})}{P(\text{test|cancer})*P(\text{cancer})
    + P(\text{test|}\neg\text{cancer})*P(\neg\text{cancer})} \] \[ = \frac{0.8*0.058}{0.8*0.058
    +0.3*0.942 } = 0.14 \] That’s pretty small – do you find that surprising? Many
    people do, and in fact there is a substantial psychological literature showing
    that people systematically neglect *base rates* (i.e. overall prevalence) in their
    judgments.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(\text{癌症|检测}) = \frac{P(\text{检测|癌症})*P(\text{癌症})}{P(\text{检测|癌症})*P(\text{癌症})
    + P(\text{检测|}\neg\text{癌症})*P(\neg\text{癌症})} \] \[ = \frac{0.8*0.058}{0.8*0.058
    +0.3*0.942 } = 0.14 \] 这相当小 - 你觉得这让人惊讶吗？许多人确实如此，事实上有大量的心理学文献表明人们在判断中系统地忽视*基础率*（即总体患病率）。
- en: 6.8 Learning from data
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.8 从数据中学习
- en: 'Another way to think of Bayes’ rule is as a way to update our beliefs on the
    basis of data – that is, learning about the world using data. Let’s look at Bayes’
    rule again:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种思考贝叶斯定理的方式是作为一种根据数据更新我们对世界的信念的方式 - 也就是说，利用数据来了解世界。让我们再次看看贝叶斯定理：
- en: \[ P(B|A) = \frac{P(A|B)*P(B)}{P(A)} \]
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(B|A) = \frac{P(A|B)*P(B)}{P(A)} \]
- en: The different parts of Bayes’ rule have specific names, that relate to their
    role in using Bayes’ rule to update our beliefs. We start out with an initial
    guess about the probability of B (\(P(B)\)), which we refer to as the *prior*
    probability. In the PSA example we used the base rate as our prior, since it was
    our best guess as to the individual’s chance of cancer before we knew the test
    result. We then collect some data, which in our example was the test result. The
    degree to which the data A are consistent with outcome B is given by \(P(A|B)\),
    which we refer to as the *likelihood*. You can think of this as how likely the
    data are, given that the particular hypothesis being tested is true. In our example,
    the hypothesis being tested was whether the individual had cancer, and the likelihood
    was based on our knowledge about the sensitivity of the test (that is, the probability
    of a positive test outcome given cancer is present). The denominator (\(P(A)\))
    is referred to as the *marginal likelihood*, because it expresses the overall
    likelihood of the data, averaged across all of the possible values of B (which
    in our example were disease present and disease absent). The outcome to the left
    (\(P(B|A)\)) is referred to as the *posterior* - because it’s what comes out the
    back end of the computation.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理的不同部分有特定的名称，与它们在使用贝叶斯定理更新我们的信念中的作用有关。我们首先对B的概率有一个初始猜测（\(P(B)\)），我们称之为*先验*概率。在PSA示例中，我们使用基础率作为先验，因为这是我们在知道测试结果之前对个体患癌症机会的最佳猜测。然后我们收集一些数据，在我们的例子中是测试结果。数据A与结果B一致的程度由\(P(A|B)\)给出，我们称之为*似然性*。你可以把它看作是在特定假设为真的情况下，数据有多大可能性。在我们的例子中，被测试的假设是个体是否患有癌症，似然性是基于我们对测试敏感性的了解（即，给定癌症存在的情况下测试呈阳性的概率）。分母（\(P(A)\)）被称为*边际似然性*，因为它表达了数据的整体可能性，平均分布在B的所有可能值上（在我们的例子中是疾病存在和疾病不存在）。左边的结果（\(P(B|A)\)）被称为*后验*
    - 因为它是计算的最终结果。
- en: 'There is another way of writing Bayes rule that makes this a bit clearer:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一种写贝叶斯定理的方式，使得这一点更加清晰：
- en: \[ P(B|A) = \frac{P(A|B)}{P(A)}*P(B) \]
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(B|A) = \frac{P(A|B)}{P(A)}*P(B) \]
- en: The part on the left (\(\frac{P(A|B)}{P(A)}\)) tells us how much more or less
    likely the data A are given B, relative to the overall (marginal) likelihood of
    the data, while the part on the right side (\(P(B)\)) tells us how likely we thought
    B was before we knew anything about the data. This makes it clearer that the role
    of Bayes theorem is to update our prior knowledge based on the degree to which
    the data are more likely given B than they would be overall. If the hypothesis
    is more likely given the data than it would be in general, then we increase our
    belief in the hypothesis; if it’s less likely given the data, then we decrease
    our belief.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 左边的部分（\(\frac{P(A|B)}{P(A)}\)）告诉我们，相对于数据的整体（边际）概率，数据A在给定B的情况下更可能或更不可能发生，而右边的部分（\(P(B)\)）告诉我们，在我们对数据一无所知之前，我们认为B有多大可能性。这使得更清楚，贝叶斯定理的作用是根据数据在给定B的情况下比整体更可能发生的程度来更新我们的先验知识。如果假设在给定数据的情况下更可能发生，那么我们会增加对假设的信念；如果在给定数据的情况下更不可能发生，那么我们会减少对假设的信念。
- en: 6.9 Odds and odds ratios
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.9 赔率和赔率比
- en: 'The result in the last section showed that the likelihood that the individual
    has cancer based on a positive PSA test result is still fairly low, even though
    it’s more than twice as big as it was before we knew the test result. We would
    often like to quantify the relation between probabilities more directly, which
    we can do by converting them into *odds* which express the relative likelihood
    of something happening or not:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节的结果显示，基于阳性PSA测试结果，个体患癌症的可能性仍然相当低，尽管比我们知道测试结果之前大两倍。我们经常希望更直接地量化概率之间的关系，这可以通过将它们转换为*赔率*来实现，赔率表达了某件事发生或不发生的相对可能性：
- en: \[ \text{odds of A} = \frac{P(A)}{P(\neg A)} \]
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{A的赔率} = \frac{P(A)}{P(\neg A)} \]
- en: 'In our PSA example, the odds of having cancer (given the positive test) are:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的PSA示例中，患癌症的赔率（给定阳性测试）为：
- en: \[ \text{odds of cancer} = \frac{P(\text{cancer})}{P(\neg \text{cancer})} =\frac{0.14}{1
    - 0.14} = 0.16 \]
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{癌症的赔率} = \frac{P(\text{癌症})}{P(\neg \text{癌症})} =\frac{0.14}{1 - 0.14}
    = 0.16 \]
- en: 'This tells us that the that the odds are fairly low of having cancer, even
    though the test was positive. For comparison, the odds of rolling a 6 in a single
    dice throw are:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，即使测试呈阳性，患癌症的赔率也相当低。作为对比，单次掷骰子出现6的赔率为：
- en: \[ \text{odds of 6} = \frac{1}{5} = 0.2 \]
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{赔率为6} = \frac{1}{5} = 0.2 \]
- en: As an aside, this is a reason why many medical researchers have become increasingly
    wary of the use of widespread screening tests for relatively uncommon conditions;
    most positive results will turn out to be false positives, resulting in unneccessary
    followup tests with possible complications, not to mention added stress for the
    patient.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，这就是为什么许多医学研究人员越来越谨慎地使用广泛的筛查测试来检测相对不常见的疾病的原因；大多数阳性结果最终都会被证明是假阳性，导致不必要的后续测试可能会出现并发症，更不用说给患者增加的压力了。
- en: 'We can also use odds to compare different probabilities, by computing what
    is called an *odds ratio* - which is exactly what it sounds like. For example,
    let’s say that we want to know how much the positive test increases the individual’s
    odds of having cancer. We can first compute the *prior odds* – that is, the odds
    before we knew that the person had tested positively. These are computed using
    the base rate:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用赔率来比较不同的概率，通过计算所谓的*赔率比* - 这正是它的名字。例如，假设我们想知道阳性测试如何增加个体患癌症的赔率。我们可以首先计算*先验赔率*
    - 也就是，在我们知道这个人测试呈阳性之前的赔率。这些是使用基础率计算的：
- en: \[ \text{prior odds} = \frac{P(\text{cancer})}{P(\neg \text{cancer})} =\frac{0.058}{1
    - 0.058} = 0.061 \]
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{先验赔率} = \frac{P(\text{癌症})}{P(\neg \text{癌症})} =\frac{0.058}{1 - 0.058}
    = 0.061 \]
- en: 'We can then compare these with the posterior odds, which are computed using
    the posterior probability:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以将这些与后验赔率进行比较，后验赔率是使用后验概率计算的：
- en: \[ \text{odds ratio} = \frac{\text{posterior odds}}{\text{prior odds}} = \frac{0.16}{0.061}
    = 2.62 \]
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{赔率比} = \frac{\text{后验赔率}}{\text{先验赔率}} = \frac{0.16}{0.061} = 2.62
    \]
- en: This tells us that the odds of having cancer are increased by 2.62 times given
    the positive test result. An odds ratio is an example of what we will later call
    an *effect size*, which is a way of quantifying how relatively large any particular
    statistical effect is.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，给出阳性检测结果，患癌症的几率增加了2.62倍。赔率比是我们后来将称之为*效应大小*的一个例子，它是量化任何特定统计效应相对大小的一种方式。
- en: 6.10 What do probabilities mean?
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.10 概率是什么意思？
- en: It might strike you that it is a bit odd to talk about the probability of a
    person having cancer depending on a test result; after all, the person either
    has cancer or they don’t. Historically, there have been two different ways that
    probabilities have been interpreted. The first (known as the *frequentist* interpretation)
    interprets probabilities in terms of long-run frequencies. For example, in the
    case of a coin flip, it would reflect the relative frequencies of heads in the
    long run after a large number of flips. While this interpretation might make sense
    for events that can be repeated many times like a coin flip, it makes less sense
    for events that will only happen once, like an individual person’s life or a particular
    presidential election; and as the economist John Maynard Keynes famously said,
    “In the long run, we are all dead.”
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会觉得谈论一个人患癌症的概率取决于检测结果有点奇怪；毕竟，一个人要么患癌症，要么不患。在历史上，概率有两种不同的解释方式。第一种（称为*频率*解释）是根据长期频率解释概率。例如，在抛硬币的情况下，它将反映在大量抛掷后长期内正面的相对频率。虽然这种解释对于可以重复多次的事件（如抛硬币）可能是有意义的，但对于只会发生一次的事件（如个人的生活或特定的总统选举）就不那么合理了；正如经济学家约翰·梅纳德·凯恩斯所说，“从长远来看，我们都会死去。”
- en: The other interpretation of probablities (known as the *Bayesian* interpretation)
    is as a degree of belief in a particular proposition. If I were to ask you “How
    likely is it that the US will return to the moon by 2040”, you can provide an
    answer to this question based on your knowledge and beliefs, even though there
    are no relevant frequencies to compute a frequentist probability. One way that
    we often frame subjective probabilities is in terms of one’s willingness to accept
    a particular gamble. For example, if you think that the probability of the US
    landing on the moon by 2040 is 0.1 (i.e. odds of 9 to 1), then that means that
    you should be willing to accept a gamble that would pay off with anything more
    than 9 to 1 odds if the event occurs.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 概率的另一种解释（称为*贝叶斯*解释）是对特定命题的信念程度。如果我问你“美国在2040年前返回月球的可能性有多大”，你可以根据你的知识和信念回答这个问题，即使没有相关频率来计算频率概率。我们经常表达主观概率的一种方式是根据一个人愿意接受特定赌注的程度。例如，如果你认为美国在2040年前登月的概率是0.1（即9比1的赔率），那意味着如果事件发生，你应该愿意接受任何超过9比1赔率的赌注。
- en: As we will see, these two different definitions of probability are very relevant
    to the two different ways that statisticians think about testing statistical hypotheses,
    which we will encounter in later chapters.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将看到的，概率的这两种不同定义与统计学家在测试统计假设时所考虑的两种不同方式非常相关，我们将在后面的章节中遇到。
- en: 6.11 Learning objectives
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.11 学习目标
- en: 'Having read this chapter, you should be able to:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完本章后，你应该能够：
- en: Describe the sample space for a selected random experiment.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述所选随机实验的样本空间。
- en: Compute relative frequency and empirical probability for a given set of events
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算给定事件集的相对频率和经验概率
- en: Compute probabilities of single events, complementary events, and the unions
    and intersections of collections of events.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算单个事件、互补事件以及事件集合的并集和交集的概率。
- en: Describe the law of large numbers.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述大数定律。
- en: Describe the difference between a probability and a conditional probability
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述概率和条件概率之间的差异
- en: Describe the concept of statistical independence
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述统计独立的概念
- en: Use Bayes’ theorem to compute the inverse conditional probability.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用贝叶斯定理计算逆条件概率。
- en: 6.12 Suggested readings
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.12 建议阅读
- en: '*The Drunkard’s Walk: How Randomness Rules Our Lives*, by Leonard Mlodinow'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《醉汉的漫步：随机性如何统治我们的生活》*，作者Leonard Mlodinow'
- en: '*Ten Great Ideas about Chance*, by Persi Diaconis and Brian Skyrms'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《关于机会的十大伟大思想》*，作者Persi Diaconis和Brian Skyrms'
- en: 6.13 Appendix
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.13 附录
- en: 6.13.1 Derivation of Bayes’ rule
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.13.1 贝叶斯规则的推导
- en: 'First, remember the rule for computing a conditional probability:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，记住计算条件概率的规则：
- en: \[ P(A|B) = \frac{P(A \cap B)}{P(B)} \]
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A|B) = \frac{P(A \cap B)}{P(B)} \]
- en: 'We can rearrange this to get the formula to compute the joint probability using
    the conditional:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重新排列这个公式，得到使用条件概率计算联合概率的公式：
- en: \[ P(A \cap B) = P(A|B) * P(B) \]
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(A \cap B) = P(A|B) * P(B) \]
- en: 'Using this we can compute the inverse probability:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这个公式，我们可以计算逆概率：
- en: \[ P(B|A) = \frac{P(A \cap B)}{P(A)} = \frac{P(A|B)*P(B)}{P(A)} \]
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(B|A) = \frac{P(A \cap B)}{P(A)} = \frac{P(A|B)*P(B)}{P(A)} \]
