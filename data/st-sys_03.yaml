- en: Chapter 2\. The *What*, *Where*, *When*, and *How* of Data Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章。数据处理的*什么*、*哪里*、*何时*和*如何*
- en: Okay party people, it’s time to get concrete!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，派对的人们，是时候变得具体了！
- en: 'Chapter 1 focused on three main areas: *terminology*, defining precisely what
    I mean when I use overloaded terms like “streaming”; *batch versus streaming*,
    comparing the theoretical capabilities of the two types of systems, and postulating
    that only two things are necessary to take streaming systems beyond their batch
    counterparts: correctness and tools for reasoning about time; and *data processing
    patterns*, looking at the conceptual approaches taken with both batch and streaming
    systems when processing bounded and unbounded data.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章主要关注三个主要领域：*术语*，准确定义我在使用“流式处理”等术语时的含义；*批处理与流处理*，比较两种类型系统的理论能力，并假设将流处理系统提升到与批处理系统相同水平只需要两样东西：正确性和关于时间推理的工具；以及*数据处理模式*，研究在处理有界和无界数据时批处理和流处理系统采取的概念方法。
- en: In this chapter, we’re now going to focus further on the data processing patterns
    from Chapter 1, but in more detail, and within the context of concrete examples.
    By the time we’re finished, we’ll have covered what I consider to be the core
    set of principles and concepts required for robust out-of-order data processing;
    these are the tools for reasoning about time that truly get you beyond classic
    batch processing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们现在将进一步关注第一章中的数据处理模式，但会更详细地结合具体示例进行讨论。到最后，我们将涵盖我认为是鲁棒的乱序数据处理所需的核心原则和概念；这些是真正让你超越经典批处理的关于时间推理的工具。
- en: To give you a sense of what things look like in action, I use snippets of [Apache
    Beam](https://beam.apache.org/) code, coupled with time-lapse diagrams¹ to provide
    a visual representation of the concepts. Apache Beam is a unified programming
    model and portability layer for batch and stream processing, with a set of concrete
    SDKs in various languages (e.g., Java and Python). Pipelines written with Apache
    Beam can then be portably run on any of the supported execution engines (Apache
    Apex, Apache Flink, Apache Spark, Cloud Dataflow, etc.).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你对实际情况有所了解，我使用了[Apache Beam](https://beam.apache.org/)代码片段，结合时间流逝图表¹，以提供概念的可视化表示。Apache
    Beam是用于批处理和流处理的统一编程模型和可移植性层，具有各种语言的具体SDK（例如Java和Python）。使用Apache Beam编写的管道可以在任何受支持的执行引擎上进行可移植运行（例如Apache
    Apex，Apache Flink，Apache Spark，Cloud Dataflow等）。
- en: I use Apache Beam here for examples not because this is a Beam book (it’s not),
    but because it most completely embodies the concepts described in this book. Back
    when [“Streaming 102”](http://oreil.ly/1TV7YGU) was originally written (back when
    it was still the Dataflow Model from Google Cloud Dataflow and not the Beam Model
    from Apache Beam), it was literally the only system in existence that provided
    the amount of expressiveness necessary for all the examples we’ll cover here.
    A year and a half later, I’m happy to say much has changed, and most of the major
    systems out there have moved or are moving toward supporting a model that looks
    a lot like the one described in this book. So rest assured that the concepts we
    cover here, though informed through the Beam lens, as it were, will apply equally
    across most other systems you’ll come across.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里使用Apache Beam作为示例，不是因为这是一本Beam的书（不是），而是因为它最完全地体现了本书中描述的概念。回顾[“流式处理102”](http://oreil.ly/1TV7YGU)最初写作时（当时它仍然是来自Google
    Cloud Dataflow的Dataflow模型，而不是来自Apache Beam的Beam模型），它实际上是唯一存在的系统，提供了所有我们将在这里涵盖的示例所需的表达能力。一年半后，我很高兴地说，很多事情已经改变，大多数主要系统都已经或正在朝着支持与本书描述的模型非常相似的模型迈进。因此，请放心，我们在这里涵盖的概念，虽然是通过Beam的视角得出的，但同样适用于你将遇到的大多数其他系统。
- en: Roadmap
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路线图
- en: To help set the stage for this chapter, I want to lay out the five main concepts
    that will underpin all of the discussions therein, and really, for most of the
    rest of Part I. We’ve already covered two of them.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助铺设本章的基础，我想先阐明将支撑其中所有讨论的五个主要概念，而且，对于第一部分的大部分内容来说，这些概念也是至关重要的。我们已经涵盖了其中的两个。
- en: 'In Chapter 1, I first established the critical distinction between event time
    (the time that events happen) and processing time (the time they are observed
    during processing). This provides the foundation for one of the main theses put
    forth in this book: if you care about both correctness and the context within
    which events actually occurred, you must analyze data relative to their inherent
    event times, not the processing time at which they are encountered during the
    analysis itself.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，我首先建立了事件时间（事件发生的时间）和处理时间（在处理过程中观察到的时间）之间的关键区别。这为本书提出的一个主要论点奠定了基础：如果你关心正确性和事件实际发生的上下文，你必须分析数据相对于它们固有的事件时间，而不是它们在分析过程中遇到的处理时间。
- en: I then introduced the concept of *windowing* (i.e., partitioning a dataset along
    temporal boundaries), which is a common approach used to cope with the fact that
    unbounded data sources technically might never end. Some simpler examples of windowing
    strategies are *fixed* and *sliding* windows, but more sophisticated types of
    windowing, such as *sessions* (in which the windows are defined by features of
    the data themselves; for example, capturing a session of activity per user followed
    by a gap of inactivity) also see broad usage.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我介绍了*窗口化*的概念（即，沿着时间边界对数据集进行分区），这是一种常用的方法，用来应对无界数据源在技术上可能永远不会结束的事实。一些更简单的窗口化策略示例是*固定*和*滑动*窗口，但更复杂的窗口化类型，比如*会话*（其中窗口由数据本身的特征定义；例如，捕获用户活动的会话，然后是一段不活动的间隙）也被广泛使用。
- en: 'In addition to these two concepts, we’re now going to look closely at three
    more:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这两个概念之外，我们现在要仔细研究另外三个：
- en: Triggers
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器
- en: A trigger is a mechanism for declaring when the output for a window should be
    materialized relative to some external signal. Triggers provide flexibility in
    choosing when outputs should be emitted. In some sense, you can think of them
    as a flow control mechanism for dictating when results should be materialized.
    Another way of looking at it is that triggers are like the shutter-release on
    a camera, allowing you to declare when to take a snapshots in time of the results
    being computed.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器是一种声明窗口输出何时相对于某些外部信号实现的机制。触发器在选择何时发出输出方面提供了灵活性。在某种意义上，你可以将它们看作是用于指示何时实现结果的流控制机制。另一种看法是，触发器就像相机的快门释放，允许你声明何时在计算的结果中拍摄时间快照。
- en: Triggers also make it possible to observe the output for a window multiple times
    as it evolves. This in turn opens up the door to refining results over time, which
    allows for providing speculative results as data arrive, as well as dealing with
    changes in upstream data (revisions) over time or data that arrive late (e.g.,
    mobile scenarios, in which someone’s phone records various actions and their event
    times while the person is offline and then proceeds to upload those events for
    processing upon regaining connectivity).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器还使得可以观察窗口输出随着时间的演变而多次发生。这反过来打开了随着时间推移改进结果的大门，这允许在数据到达时提供推测结果，以及处理上游数据（修订）随时间变化或者延迟到达的数据（例如，移动场景，其中某人的手机在离线时记录各种操作和事件时间，然后在恢复连接后上传这些事件进行处理）。
- en: Watermarks
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 水印
- en: 'A watermark is a notion of input completeness with respect to event times.
    A watermark with value of time *X* makes the statement: “all input data with event
    times less than *X* have been observed.” As such, watermarks act as a metric of
    progress when observing an unbounded data source with no known end. We touch upon
    the basics of watermarks in this chapter, and then Slava goes super deep on the
    subject in Chapter 3.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 水印是相对于事件时间的输入完整性概念。具有时间*X*值的水印表示：“所有事件时间小于*X*的输入数据都已被观察到。”因此，当观察没有已知结束的无界数据源时，水印充当进度的度量。我们在本章中简要介绍了水印的基础知识，然后Slava在第三章中深入探讨了这个主题。
- en: Accumulation
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 累积
- en: An accumulation mode specifies the relationship between multiple results that
    are observed for the same window. Those results might be completely disjointed;
    that is, representing independent deltas over time, or there might be overlap
    between them. Different accumulation modes have different semantics and costs
    associated with them and thus find applicability across a variety of use cases.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 累积模式指定了对于同一窗口观察到的多个结果之间的关系。这些结果可能是完全不相交的；即，代表随时间独立的增量，或者它们之间可能存在重叠。不同的累积模式具有不同的语义和相关成本，因此在各种用例中找到适用性。
- en: 'Also, because I think it makes it easier to understand the relationships between
    all of these concepts, we revisit the old and explore the new within the structure
    of answering four questions, all of which I propose are critical to every unbounded
    data processing problem:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，因为我认为这样做可以更容易地理解所有这些概念之间的关系，我们重新审视了旧的并在回答四个问题的结构中探索了新的，我提出这四个问题对于每个无界数据处理问题都至关重要：
- en: '*What* results are calculated? This question is answered by the types of transformations
    within the pipeline. This includes things like computing sums, building histograms,
    training machine learning models, and so on. It’s also essentially the question
    answered by classic batch processing'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算什么结果？这个问题的答案取决于管道中的转换类型。这包括计算总和、构建直方图、训练机器学习模型等。这本质上也是经典批处理所回答的问题
- en: '*Where* in event time are results calculated? This question is answered by
    the use of event-time windowing within the pipeline. This includes the common
    examples of windowing from Chapter 1 (fixed, sliding, and sessions); use cases
    that seem to have no notion of windowing (e.g., time-agnostic processing; classic
    batch processing also generally falls into this category); and other, more complex
    types of windowing, such as time-limited auctions. Also note that it can include
    processing-time windowing, as well, if you assign ingress times as event times
    for records as they arrive at the system.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在事件时间中，结果在何处计算？这个问题的答案取决于管道中的事件时间窗口化。这包括第1章中的常见示例（固定、滑动和会话）；似乎没有窗口化概念的用例（例如，无时间概念的处理；经典的批处理通常也属于这一类）；以及其他更复杂的窗口化类型，例如有时间限制的拍卖。还要注意，如果你将记录的进入时间分配为系统到达时的事件时间，它也可以包括处理时间窗口化。
- en: '*When* in processing time are results materialized? This question is answered
    by the use of triggers and (optionally) watermarks. There are infinite variations
    on this theme, but the most common patterns are those involving repeated updates
    (i.e., materialized view semantics), those that utilize a watermark to provide
    a single output per window only after the corresponding input is believed to be
    complete (i.e., classic batch processing semantics applied on a per-window basis),
    or some combination of the two.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理时间中，结果何时实现？这个问题的答案取决于触发器和（可选）水印的使用。在这个主题上有无限的变化，但最常见的模式是涉及重复更新（即，实现视图语义）、利用水印在相应输入被认为是完整后为每个窗口提供单一输出（即，经典的批处理语义应用于每个窗口），或者两者的某种组合。
- en: '*How* do refinements of results relate? This question is answered by the type
    of accumulation used: discarding (in which results are all independent and distinct),
    accumulating (in which later results build upon prior ones), or accumulating and
    retracting (in which both the accumulating value plus a retraction for the previously
    triggered value(s) are emitted).'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果的改进如何相关？这个问题的答案取决于所使用的累积类型：丢弃（其中结果都是独立和不同的）、累积（其中后续结果建立在先前结果的基础上）、或者累积和撤销（其中发出累积值以及先前触发的值的撤销）。
- en: We look at each of these questions in much more detail throughout the rest of
    the book. And, yes, I’m going to run this color scheme thing into the ground in
    an attempt to make it abundantly clear which concepts relate to which question
    in the *What*/*Where*/*When*/*How* idiom. You’re welcome <winky-smiley/>.²
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的其余部分更详细地讨论这些问题。是的，我将尽量清楚地表明*什么*/*在哪里*/*何时*/*如何*这种习语中的哪些概念与哪些问题相关，以此来运用这种颜色方案。不客气
    <winky-smiley/>。²
- en: 'Batch Foundations: *What* and *Where*'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批处理基础：*什么*和*在哪里*
- en: 'Okay, let’s get this party started. First stop: batch processing.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们开始吧。首先停下来：批处理。
- en: '*What*: Transformations'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*什么*：转换'
- en: 'The transformations applied in classic batch processing answer the question:
    “*What* results are calculated?” Even though you are likely already familiar with
    classic batch processing, we’re going to start there anyway because it’s the foundation
    on top of which we add all of the other concepts.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在经典批处理中应用的转换回答了问题：“*计算*出了什么结果？”即使您可能已经熟悉经典批处理，我们仍然要从那里开始，因为它是我们添加所有其他概念的基础。
- en: 'In the rest of this chapter (and indeed, through much of the book), we look
    at a single example: computing keyed integer sums over a simple dataset consisting
    of nine values. Let’s imagine that we’ve written a team-based mobile game and
    we want to build a pipeline that calculates team scores by summing up the individual
    scores reported by users’ phones. If we were to capture our nine example scores
    in a SQL table named “UserScores,” it might look something like this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分（实际上，在本书的大部分内容中），我们将看一个单一的示例：计算一个简单数据集上的键控整数求和，该数据集由九个值组成。假设我们编写了一个基于团队的手机游戏，并且我们想要构建一个管道，通过对用户手机报告的个人得分进行求和来计算团队得分。如果我们将我们的九个示例得分捕获在名为“UserScores”的SQL表中，它可能看起来像这样：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Note that all the scores in this example are from users on the same team; this
    is to keep the example simple, given that we have a limited number of dimensions
    in our diagrams that follow. And because we’re grouping by team, we really just
    care about the last three columns:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此示例中的所有得分都来自同一团队的用户；这是为了保持示例简单，因为我们的后续图表中的维度数量有限。而且因为我们是按团队分组，所以我们实际上只关心最后三列：
- en: '`Score`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`得分`'
- en: The individual user score associated with this event
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 与此事件相关联的个人用户得分
- en: '`EventTime`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`事件时间`'
- en: The event time for the score; that is, the time at which the score occurred
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 得分的事件时间；即，得分发生的时间
- en: '`ProcTime`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`处理时间`'
- en: The processing for the score; that is, the time at which the score was observed
    by the pipeline
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 得分的处理时间；即，管道观察到得分的时间
- en: 'For each example pipeline, we’ll look at a time-lapse diagram that highlights
    how the data evolves over time. Those diagrams plot our nine scores in the two
    dimensions of time we care about: event time in the x-axis, and processing time
    in the y-axis. Figure 2-1 illustrates what a static plot of the input data looks
    like.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个示例管道，我们将查看一个时间跨度图，突出显示数据随时间如何演变。这些图表以我们关心的两个时间维度绘制了我们的九个得分：事件时间在x轴上，处理时间在y轴上。图2-1说明了输入数据的静态图的样子。
- en: '![](img/stsy_0201.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0201.png)'
- en: Figure 2-1\. Nine input records, plotted in both event time and processing time
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1。九个输入记录，分别以事件时间和处理时间绘制
- en: Subsequent time-lapse diagrams are either animations (Safari) or a sequence
    of frames (print and all other digital formats), allowing you to see how the data
    are processed over time (more on this shortly after we get to the first time-lapse
    diagram).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 随后的时间跨度图要么是动画（Safari），要么是一系列帧（打印和所有其他数字格式），让您可以看到数据随时间如何处理（在我们到达第一个时间跨度图之后不久，我们将更详细地讨论这一点）。
- en: Preceding each example is a short snippet of Apache Beam Java SDK pseudocode
    to make the definition of the pipeline more concrete. It is pseudocode in the
    sense that I sometime bend the rules to make the examples clearer, elide details
    (like the use of concrete I/O sources), or simplify names (the trigger names in
    Beam Java 2.x and earlier are painfully verbose; I use simpler names for clarity).
    Beyond minor things like those, it’s otherwise real-world Beam code (and real
    code is available on [GitHub](http://bit.ly/2KMsDwR) for all examples in this
    chapter).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个示例之前，都有一小段Apache Beam Java SDK伪代码，以使管道的定义更加具体。这是伪代码，因为我有时会弯曲规则，以使示例更清晰，省略细节（比如具体I/O源的使用），或简化名称（Beam
    Java 2.x和之前的触发器名称非常冗长；我使用更简单的名称以增加清晰度）。除了这些小事情之外，它是真实世界的Beam代码（本章中的所有示例的真实代码都可以在[GitHub](http://bit.ly/2KMsDwR)上找到）。
- en: 'If you’re already familiar with something like Spark or Flink, you should have
    a relatively easy time understanding what the Beam code is doing. But to give
    you a crash course in things, there are two basic primitives in Beam:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经熟悉类似Spark或Flink的东西，您应该相对容易理解Beam代码在做什么。但是，为了给您一个快速入门，Beam中有两个基本原语：
- en: '`PCollections`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`PCollections`'
- en: These represent datasets (possibly massive ones) across which parallel transformations
    can be performed (hence the “P” at the beginning of the name).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些代表数据集（可能是庞大的数据集），可以在其上执行并行转换（因此名称开头的“P”）。
- en: '`PTransforms`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`PTransforms`'
- en: These are applied to `PCollections` to create new `PCollections`. `PTransforms`
    may perform element-wise transformations, they may group/aggregate multiple elements
    together, or they may be a composite combination of other `PTransforms`, as depicted
    in Figure 2-2.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些应用于`PCollections`以创建新的`PCollections`。`PTransforms`可以执行逐元素转换，它们可以将多个元素分组/聚合在一起，或者它们可以是其他`PTransforms`的复合组合，如图2-2所示。
- en: '![](img/stsy_0202.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0202.png)'
- en: Figure 2-2\. Types of transformations
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-2。转换的类型
- en: For the purposes of our examples, we typically assume that we start out with
    a pre-loaded `PCollection<KV<Team, Integer>>` named “input” (that is, a `PCollection`
    composed of key/value pairs of `Teams` and `Integers`, where the `Teams` are just
    something like `Strings` representing team names, and the `Integers` are scores
    from any individual on the corresponding team). In a real-world pipeline, we would’ve
    acquired input by reading in a `PCollection<String>` of raw data (e.g., log records)
    from an I/O source and then transforming it into a `PCollection<KV<Team, Integer>>`
    by parsing the log records into appropriate key/value pairs. For the sake of clarity
    in this first example, I include pseudocode for all of those steps, but in subsequent
    examples, I elide the I/O and parsing.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例，我们通常假设我们从预加载的`PCollection<KV<Team, Integer>>`（即由`Teams`和`Integers`组成的`PCollection`，其中`Teams`只是表示团队名称的`Strings`，而`Integers`是相应团队中任何个人的得分）开始（例如，从I/O源读取原始数据（例如，日志记录）并将其转换为`PCollection<KV<Team,
    Integer>>`）。为了在第一个示例中更清晰，我包含了所有这些步骤的伪代码，但在后续示例中，我省略了I/O和解析。
- en: Thus, for a pipeline that simply reads in data from an I/O source, parses team/score
    pairs, and calculates per-team sums of scores, we’d have something like that shown
    in Example 2-1.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于一个简单地从I/O源读取数据，解析团队/得分对，并计算得分的每个团队的管道，我们将会得到类似于示例2-1中所示的内容。
- en: Example 2-1\. Summation pipeline
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-1. 求和管道
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Key/value data are read from an I/O source, with a `Team` (e.g., `String` of
    the team name) as the key and an `Integer` (e.g., individual team member scores)
    as the value. The values for each key are then summed together to generate per-key
    sums (e.g., total team score) in the output collection.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 键/值数据从I/O源读取，其中`Team`（例如，球队名称的`String`）作为键，`Integer`（例如，个人团队成员得分）作为值。然后对每个键的值进行求和，以生成输出集合中的每个键的总和（例如，团队总得分）。
- en: For all the examples to come, after seeing a code snippet describing the pipeline
    that we’re analyzing, we’ll then look at a time-lapse diagram showing the execution
    of that pipeline over our concrete dataset for a single key. In a real pipeline,
    you can imagine that similar operations would be happening in parallel across
    multiple machines, but for the sake of our examples, it will be clearer to keep
    things simple.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的所有示例中，在看到描述我们正在分析的管道的代码片段之后，我们将看一下一个时间跨度图，显示该管道在我们的具体数据集上针对单个键的执行情况。在真实的管道中，你可以想象类似的操作会在多台机器上并行进行，但为了我们的示例，保持简单会更清晰。
- en: As noted previously, Safari editions present the complete execution as an animated
    movie, whereas print and all other digital formats use a static sequence of key
    frames that provide a sense of how the pipeline progresses over time. In both
    cases, we also provide a URL to a fully animated version on [*www.streamingbook.net*](http://www.streamingbook.net).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前提到的，Safari版本呈现完整的执行过程，就像一部动画电影，而打印和所有其他数字格式则使用一系列静态关键帧，以提供管道随时间的进展的感觉。在这两种情况下，我们还提供一个完全动画版本的网址[*www.streamingbook.net*](http://www.streamingbook.net)。
- en: 'Each diagram plots the inputs and outputs across two dimensions: event time
    (on the x-axis) and processing time (on the y-axis). Thus, real time as observed
    by the pipeline progresses from bottom to top, as indicated by the thick horizontal
    black line that ascends in the processing-time axis as time progresses. Inputs
    are circles, with the number inside the circle representing the value of that
    specific record. They start out light gray, and darken as the pipeline observes
    them.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 每个图表都在两个维度上绘制输入和输出：事件时间（x轴）和处理时间（y轴）。因此，由管道观察到的实时时间从底部到顶部逐渐推移，如在处理时间轴上上升的粗黑水平线所示。输入为圆圈，圆圈内的数字表示该特定记录的值。它们开始为浅灰色，并在管道观察到它们时变暗。
- en: As the pipeline observes values, it accumulates them in its intermediate state
    and eventually materializes the aggregate results as output. State and output
    are represented by rectangles (gray for state, blue for output), with the aggregate
    value near the top, and with the area covered by the rectangle representing the
    portions of event time and processing time accumulated into the result. For the
    pipeline in Example 2-1, it would look something like that shown in Figure 2-3
    when executed on a classic batch engine.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当管道观察值时，它会将这些值累积到其中间状态中，并最终将聚合结果实现为输出。状态和输出由矩形表示（状态为灰色，输出为蓝色），聚合值靠近顶部，矩形覆盖的区域表示事件时间和处理时间累积到结果中的部分。对于示例2-1中的管道，在经典的批处理引擎上执行时，它看起来会像图2-3中所示的样子。
- en: <assets/stsy_0203.mp4>
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/stsy_0203.mp4>
- en: '![Classic batch processing](img/stsy_0203.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![经典批处理](img/stsy_0203.png)'
- en: Figure 2-3\. Classic batch processing
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-3. 经典批处理
- en: Because this is a batch pipeline, it accumulates state until it’s seen all of
    the inputs (represented by the dashed green line at the top), at which point it
    produces its single output of 48\. In this example, we’re calculating a sum over
    all of event time because we haven’t applied any specific windowing transformations;
    hence the rectangles for state and output cover the entirety of the x-axis. If
    we want to process an unbounded data source, however, classic batch processing
    won’t be sufficient; we can’t wait for the input to end, because it effectively
    never will. One of the concepts we want is windowing, which we introduced in Chapter 1.
    Thus, within the context of our second question—“*Where* in event time are results
    calculated?”—we’ll now briefly revisit windowing.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这是一个批处理管道，它会累积状态，直到看到所有的输入（由顶部的虚线绿线表示），然后产生48的单个输出。在这个示例中，我们计算了所有事件时间的总和，因为我们还没有应用任何特定的窗口处理转换；因此，状态和输出的矩形覆盖了整个x轴。然而，如果我们想要处理无界数据源，经典的批处理就不够了；我们不能等待输入结束，因为它实际上永远不会结束。我们想要的概念之一是窗口处理，我们在第1章中介绍过。因此，在我们的第二个问题的背景下——“*在事件时间中*结果是在哪里计算的？”——我们现在将简要回顾一下窗口处理。
- en: '*Where*: Windowing'
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*Where*: 窗口处理'
- en: As discussed in Chapter 1, windowing is the process of slicing up a data source
    along temporal boundaries. Common windowing strategies include fixed windows,
    sliding windows, and sessions windows, as demonstrated in Figure 2-4.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如第1章所讨论的，窗口化是沿着时间边界切分数据源的过程。常见的窗口化策略包括固定窗口、滑动窗口和会话窗口，如图2-4所示。
- en: '![](img/stsy_0204.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0204.png)'
- en: Figure 2-4\. Example windowing strategies. Each example is shown for three different
    keys, highlighting the difference between aligned windows (which apply across
    all the data) and unaligned windows (which apply across a subset of the data).
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-4。示例窗口策略。每个示例都显示了三个不同的键，突出了对齐窗口（适用于所有数据）和不对齐窗口（适用于数据子集）之间的差异。
- en: To get a better sense of what windowing looks like in practice, let’s take our
    integer summation pipeline and window it into fixed, two-minute windows. With
    Beam, the change is a simple addition of a `Window.into` transform, which you
    can see highlighted in Example 2-2.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解窗口化在实践中的样子，让我们将整数求和管道窗口化为固定的两分钟窗口。使用Beam，只需简单地添加一个`Window.into`转换，如示例2-2中所示。
- en: Example 2-2\. Windowed summation code
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-2。窗口化求和代码
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Recall that Beam provides a unified model that works in both batch and streaming
    because semantically batch is really just a subset of streaming. As such, let’s
    first execute this pipeline on a batch engine; the mechanics are more straightforward,
    and it will give us something to directly compare against when we switch to a
    streaming engine. Figure 2-5 presents the result.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，Beam提供了一个统一的模型，可以在批处理和流处理中同时工作，因为语义上批处理实际上只是流处理的一个子集。因此，让我们首先在批处理引擎上执行此管道；机制更加直接，而且在切换到流处理引擎时，可以直接进行对比。图2-5呈现了结果。
- en: <assets/stsy_0205.mp4>
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/stsy_0205.mp4>
- en: '![Windowed summation on a batch engine](img/stsy_0205.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![批处理引擎上的窗口化求和](img/stsy_0205.png)'
- en: Figure 2-5\. Windowed summation on a batch engine
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-5。批处理引擎上的窗口化求和
- en: 'As before, inputs are accumulated in state until they are entirely consumed,
    after which output is produced. In this case, however, instead of one output,
    we get four: a single output, for each of the four relevant two-minute event-time
    windows.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前一样，输入在状态中累积，直到完全消耗，然后产生输出。但是，在这种情况下，我们不是得到一个输出，而是得到四个输出：一个输出，分别对应四个相关的两分钟事件时间窗口。
- en: 'At this point we’ve revisited the two main concepts that I introduced in Chapter 1:
    the relationship between the event-time and processing-time domains, and windowing.
    If we want to go any further, we’ll need to start adding the new concepts mentioned
    at the beginning of this section: triggers, watermarks, and accumulation.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经重新讨论了我在第1章介绍的两个主要概念：事件时间和处理时间域之间的关系，以及窗口化。如果我们想进一步，我们需要开始添加本节开头提到的新概念：触发器、水印和累积。
- en: 'Going Streaming: *When* and *How*'
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转向流处理：*When*和*How*
- en: We just observed the execution of a windowed pipeline on a batch engine. But,
    ideally, we’d like to have lower latency for our results, and we’d also like to
    natively handle unbounded data sources. Switching to a streaming engine is a step
    in the right direction, but our previous strategy of waiting until our input has
    been consumed in its entirety to generate output is no longer feasible. Enter
    triggers and watermarks.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚观察了批处理引擎上的窗口化管道的执行。但是，理想情况下，我们希望结果的延迟更低，并且我们还希望原生地处理无界数据源。切换到流处理引擎是朝着正确方向迈出的一步，但是我们以前的策略等待输入完全被消耗才生成输出的做法不再可行。这时就需要触发器和水印。
- en: '*When*: The Wonderful Thing About Triggers Is Triggers Are Wonderful Things!'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*When*：触发器的奇妙之处在于触发器是奇妙的东西！'
- en: 'Triggers provide the answer to the question: “*When* in processing time are
    results materialized?” Triggers declare when output for a window should happen
    in processing time (though the triggers themselves might make those decisions
    based on things that happen in other time domains, such as watermarks progressing
    in the event-time domain, as we’ll see in a few moments). Each specific output
    for a window is referred to as a *pane* of the window.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器提供了对问题的答案：“*When*在处理时间中何时生成结果？”触发器声明在处理时间中窗口的输出应该发生的时间（尽管触发器本身可能基于在其他时间域中发生的事情做出这些决定，比如随着事件时间域中的水印进展，我们马上就会看到）。窗口的每个具体输出被称为窗口的*窗格*。
- en: 'Though it’s possible to imagine quite a breadth of possible triggering semantics,³
    conceptually there are only two generally useful types of triggers, and practical
    applications almost always boil down using either one or a combination of both:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以想象出各种可能的触发语义，³但在概念上，通常只有两种通用的有用触发类型，实际应用几乎总是使用其中一种或两种的组合：
- en: Repeated update triggers
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 重复更新触发器
- en: These periodically generate updated panes for a window as its contents evolve.
    These updates can be materialized with every new record, or they can happen after
    some processing-time delay, such as once a minute. The choice of period for a
    repeated update trigger is primarily an exercise in balancing latency and cost.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这些会定期为窗口生成更新的窗格，随着其内容的演变。这些更新可以随着每个新记录的到来而实现，也可以在一定的处理时间延迟后发生，比如每分钟一次。重复更新触发器的周期选择主要是在平衡延迟和成本方面的考量。
- en: Completeness triggers
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 完整性触发器
- en: 'These materialize a pane for a window only after the input for that window
    is believed to be complete to some threshold. This type of trigger is most analogous
    to what we’re familiar with in batch processing: only after the input is complete
    do we provide a result. The difference in the trigger-based approach is that the
    notion of completeness is scoped to the context of a single window, rather than
    always being bound to the completeness of the entire input.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这些在认为窗口的输入完全到达某个阈值后才为窗口生成一个窗格。这种类型的触发器最类似于我们在批处理中熟悉的：只有在输入完成后才提供结果。触发器方法的不同之处在于完整性的概念仅限于单个窗口的上下文范围，而不总是与整个输入的完整性绑定。
- en: 'Repeated update triggers are the most common type of trigger encountered in
    streaming systems. They are simple to implement and simple to understand, and
    they provide useful semantics for a specific type of use case: repeated (and eventually
    consistent) updates to a materialized dataset, analogous to the semantics you
    get with materialized views in the database world.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 重复更新触发器是流式系统中最常见的触发器类型。它们易于实现和理解，并为特定类型的用例提供有用的语义：对材料化数据集的重复（并最终一致）更新，类似于数据库世界中材料化视图的语义。
- en: 'Completeness triggers are less frequently encountered, but provide streaming
    semantics that more closely align with those from the classic batch processing
    world. They also provide tools for reasoning about things like missing data and
    late data, both of which we discuss shortly (and in the next chapter) as we explore
    the underlying primitive that drives completeness triggers: watermarks.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 完整性触发器并不经常遇到，但提供了更接近经典批处理世界的流语义。它们还提供了用于推理诸如缺失数据和延迟数据之类的工具，我们很快会讨论（并在下一章中）当我们探索驱动完整性触发器的基础原语：水印。
- en: 'But first, let’s start simple and look at some basic repeated update triggers
    in action. To make the notion of triggers a bit more concrete, let’s go ahead
    and add the most straightforward type of trigger to our example pipeline: a trigger
    that fires with every new record, as shown in Example 2-3.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，让我们从简单的开始，看看一些基本的重复更新触发器的实际操作。为了使触发器的概念更加具体，让我们继续向我们的示例管道添加最简单类型的触发器：随着每条新记录的触发，如例2-3所示。
- en: Example 2-3\. Triggering repeatedly with every record
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例2-3。重复触发每条记录
- en: '[PRE3]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If we were to run this new pipeline on a streaming engine, the results would
    look something like that shown in Figure 2-6.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在流式引擎上运行这个新的管道，结果会看起来像图2-6所示。
- en: <assets/stsy_0206.mp4>
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/stsy_0206.mp4>
- en: '![Per-record triggering on a streaming engine](img/stsy_0206.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![在流式引擎上按记录触发](img/stsy_0206.png)'
- en: Figure 2-6\. Per-record triggering on a streaming engine
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-6。在流式引擎上按记录触发
- en: 'You can see how we now get multiple outputs (panes) for each window: once per
    corresponding input. This sort of triggering pattern works well when the output
    stream is being written to some sort of table that you can simply poll for results.
    Any time you look in the table, you’ll see the most up-to-date value for a given
    window, and those values will converge toward correctness over time.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到我们现在为每个窗口获得多个输出（窗格）：每个输入对应一次。当输出流被写入某种表格时，这种触发模式效果很好，您可以简单地轮询结果。无论何时查看表格，您都会看到给定窗口的最新值，并且这些值随着时间的推移会趋向于正确。
- en: 'One downside of per-record triggering is that it’s quite chatty. When processing
    large-scale data, aggregations like summation provide a nice opportunity to reduce
    the cardinality of the stream without losing information. This is particularly
    noticeable for cases in which you have high-volume keys; for our example, massive
    teams with lots of active players. Imagine a massively multiplayer game in which
    players are split into one of two factions, and you want to tally stats on a per-faction
    basis. It’s probably unnecessary to update your tallies with every new input record
    for every player in a given faction. Instead, you might be happy updating them
    after some processing-time delay, say every second, or every minute. The nice
    side effect of using processing-time delays is that it has an equalizing effect
    across high-volume keys or windows: the resulting stream ends up being more uniform
    cardinality-wise.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 按记录触发的一个缺点是它非常啰嗦。在处理大规模数据时，像求和这样的聚合提供了一个很好的机会，可以减少流的基数而不丢失信息。这在您有高容量键的情况下尤为明显；例如，我们的例子中有很多活跃玩家的大型团队。想象一下一个大型多人游戏，玩家被分成两个派别，您想要按派别统计数据。可能不需要在给定派别的每个玩家的每条新输入记录后更新您的统计数据。相反，您可能会在一定的处理时间延迟后，比如每秒或每分钟，更新它们。使用处理时间延迟的一个好处是它对高容量键或窗口具有均衡效果：结果流最终会在基数方面更加均匀。
- en: 'There are two different approaches to processing-time delays in triggers: *aligned
    delays* (where the delay slices up processing time into fixed regions that align
    across keys and windows) and *unaligned delays* (where the delay is relative to
    the data observed within a given window). A pipeline with unaligned delays might
    look like Example 2-4, the results of which are shown in Figure 2-7.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器中有两种不同的处理时间延迟方法：*对齐延迟*（其中延迟将处理时间划分为与键和窗口对齐的固定区域）和*未对齐延迟*（其中延迟相对于给定窗口内观察到的数据）。具有未对齐延迟的管道可能看起来像例2-4，其结果如图2-7所示。
- en: Example 2-4\. Triggering on aligned two-minute processing-time boundaries
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例2-4。在对齐的两分钟处理时间边界上触发
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: <assets/stsy_0207.mp4>
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/stsy_0207.mp4>
- en: '![Two-minute aligned delay triggers (i.e., microbatching)](img/stsy_0207.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![两分钟对齐延迟触发器（即，微批处理）](img/stsy_0207.png)'
- en: Figure 2-7\. Two-minute aligned delay triggers (i.e., microbatching)
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-7。两分钟对齐延迟触发器（即，微批处理）
- en: 'This sort of aligned delay trigger is effectively what you get from a microbatch
    streaming system like Spark Streaming. The nice thing about it is predictability;
    you get regular updates across all modified windows at the same time. That’s also
    the downside: all updates happen at once, which results in bursty workloads that
    often require greater peak provisioning to properly handle the load. The alternative
    is to use an unaligned delay. That would look something Example 2-5 in Beam. Figure 2-8
    presents the results.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对齐延迟触发实际上就是您从像Spark Streaming这样的微批处理流系统中获得的。它的好处在于可预测性；您可以同时获得所有修改窗口的定期更新。这也是它的缺点：所有更新同时发生，这导致了经常需要更大的峰值预配来正确处理负载的工作负载。另一种选择是使用未对齐延迟。这在Beam中可能看起来像例2-5。图2-8呈现了结果。
- en: Example 2-5\. Triggering on unaligned two-minute processing-time boundaries
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例2-5。在未对齐的两分钟处理时间边界上触发
- en: '[PRE5]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: <assets/stsy_0208.mp4>
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/stsy_0208.mp4>
- en: '![Two-minute unaligned delay triggers](img/stsy_0208.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![两分钟不对齐延迟触发器](img/stsy_0208.png)'
- en: Figure 2-8\. Two-minute unaligned delay triggers
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-8. 两分钟不对齐延迟触发器
- en: Contrasting the unaligned delays in Figure 2-8 to the aligned delays in Figure 2-6,
    it’s easy to see how the unaligned delays spread the load out more evenly across
    time. The actual latencies involved for any given window differ between the two,
    sometimes more and sometimes less, but in the end the average latency will remain
    essentially the same. From that perspective, unaligned delays are typically the
    better choice for large-scale processing because they result in a more even load
    distribution over time.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 将图2-8中的不对齐延迟与图2-6中的对齐延迟进行对比，很容易看出不对齐延迟如何在时间上更均匀地分布负载。对于任何给定窗口涉及的实际延迟在这两种情况下有所不同，有时更多，有时更少，但最终平均延迟基本上保持不变。从这个角度来看，不对齐延迟通常是大规模处理的更好选择，因为它会导致负载在时间上更均匀地分布。
- en: Repeated update triggers are great for use cases in which we simply want periodic
    updates to our results over time and are fine with those updates converging toward
    correctness with no clear indication of when correctness is achieved. However,
    as we discussed in Chapter 1, the vagaries of distributed systems often lead to
    a varying level of skew between the time an event happens and the time it’s actually
    observed by your pipeline, which means it can be difficult to reason about when
    your output presents an accurate and complete view of your input data. For cases
    in which input completeness matters, it’s important to have some way of reasoning
    about completeness rather than blindly trusting the results calculated by whichever
    subset of data happen to have found their way to your pipeline. Enter watermarks.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 重复更新触发器非常适用于我们只是希望定期更新结果并且可以接受这些更新朝着正确性收敛而没有明确指示何时达到正确性的用例。然而，正如我们在第1章中讨论的那样，分布式系统的种种变数经常导致事件发生的时间和管道实际观察到事件的时间之间存在不同程度的偏差，这意味着很难推断输出何时呈现出准确和完整的输入数据视图。对于输入完整性很重要的情况，有一种推理完整性的方式是很重要的，而不是盲目地相信计算结果，无论哪个数据子集恰好已经传递到管道中。这就是水印的作用。
- en: '*When*: Watermarks'
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*何时*：水印'
- en: 'Watermarks are a supporting aspect of the answer to the question: “*When* in
    processing time are results materialized?” Watermarks are temporal notions of
    input completeness in the event-time domain. Worded differently, they are the
    way the system measures progress and completeness relative to the event times
    of the records being processed in a stream of events (either bounded or unbounded,
    though their usefulness is more apparent in the unbounded case).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 水印是对问题“*何时*在处理时间中结果实现？”的支持方面。水印是事件时间域中输入完整性的时间概念。换句话说，它们是系统相对于正在处理的事件流中记录的事件时间的进度和完整性的方式（有界或无界的情况下它们的用处更加明显）。
- en: Recall this diagram from Chapter 1, slightly modified in Figure 2-9, in which
    I described the skew between event time and processing time as an ever-changing
    function of time for most real-world distributed data processing systems.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下第1章中的这个图表，在图2-9中稍作修改，我描述了事件时间和处理时间之间的偏差，对于大多数实际的分布式数据处理系统来说，这是一个随时间不断变化的函数。
- en: '![](img/stsy_0209.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0209.png)'
- en: Figure 2-9\. Event-time progress, skew, and watermarks
  id: totrans-113
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-9. 事件时间进度、偏差和水印
- en: 'That meandering red line that I claimed represented reality is essentially
    the watermark; it captures the progress of event-time completeness as processing
    time progresses. Conceptually, you can think of the watermark as a function, *F*(*P*)
    → *E*, which takes a point in processing time and returns a point in event time.⁴
    That point in event time, *E*, is the point up to which the system believes all
    inputs with event times less than *E* have been observed. In other words, it’s
    an assertion that no more data with event times less than *E* will ever be seen
    again. Depending upon the type of watermark, perfect or heuristic, that assertion
    can be a strict guarantee or an educated guess, respectively:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我声称代表现实的那条蜿蜒的红线本质上就是水印；它捕捉了事件时间完整性随着处理时间的进展而变化。在概念上，您可以将水印视为一个函数，*F*(*P*) →
    *E*，它接受一个处理时间点并返回一个事件时间点。⁴ 事件时间点*E*是系统认为所有事件时间小于*E*的输入都已被观察到的点。换句话说，这是一个断言，即再也不会看到事件时间小于*E*的数据。根据水印的类型，完美或启发式，这个断言可以是严格的保证或是一个有根据的猜测。
- en: Perfect watermarks
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 完美水印
- en: For the case in which we have perfect knowledge of all of the input data, it’s
    possible to construct a perfect watermark. In such a case, there is no such thing
    as late data; all data are early or on time.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们完全了解所有输入数据的情况，可以构建完美水印。在这种情况下，不存在延迟数据；所有数据都是提前或准时的。
- en: Heuristic watermarks
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 启发式水印
- en: For many distributed input sources, perfect knowledge of the input data is impractical,
    in which case the next best option is to provide a heuristic watermark. Heuristic
    watermarks use whatever information is available about the inputs (partitions,
    ordering within partitions if any, growth rates of files, etc.) to provide an
    estimate of progress that is as accurate as possible. In many cases, such watermarks
    can be remarkably accurate in their predictions. Even so, the use of a heuristic
    watermark means that it might sometimes be wrong, which will lead to late data.
    We show you about ways to deal with late data soon.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多分布式输入源，完全了解输入数据是不切实际的，因此提供启发式水印是下一个最佳选择。启发式水印使用有关输入的任何可用信息（分区、分区内的排序（如果有）、文件的增长率等）来提供尽可能准确的进度估计。在许多情况下，这些水印的预测可以非常准确。即便如此，使用启发式水印意味着它有时可能是错误的，这将导致延迟数据。我们很快会向您展示处理延迟数据的方法。
- en: 'Because they provide a notion of completeness relative to our inputs, watermarks
    form the foundation for the second type of trigger mentioned previously: *completeness
    triggers*. Watermarks themselves are a fascinating and complex topic, as you’ll
    see when you get to Slava’s watermarks deep dive in Chapter 3. But for now, let’s
    look at them in action by updating our example pipeline to utilize a completeness
    trigger built upon watermarks, as demonstrated in Example 2-6.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它们提供了相对于我们的输入的完整性概念，水印构成了先前提到的第二种触发器的基础：*完整性触发器*。水印本身是一个迷人而复杂的话题，当你看到Slava在第3章中深入研究水印时，你会发现这一点。但现在，让我们通过更新我们的示例管道来利用建立在水印之上的完整性触发器来看看它们的作用，就像在示例2-6中演示的那样。
- en: Example 2-6\. Watermark completeness trigger
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-6。水印完整性触发器
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, an interesting quality of watermarks is that they are a class of functions,
    meaning there are multiple different functions *F*(*P*) → *E* that satisfy the
    properties of a watermark, to varying degrees of success. As I noted earlier,
    for situations in which you have perfect knowledge of your input data, it might
    be possible to build a perfect watermark, which is the ideal situation. But for
    cases in which you lack perfect knowledge of the inputs or for which it’s simply
    too computationally expensive to calculate the perfect watermark, you might instead
    choose to utilize a heuristic for defining your watermark. The point I want to
    make here is that the given watermark algorithm in use is independent from the
    pipeline itself. We’re not going to discuss in detail what it means to implement
    a watermark here (Slava does that in Chapter 3). For now, to help drive home this
    idea that a given input set can have different watermarks applied to it, let’s
    take a look at our pipeline in Example 2-6 when executed on the same dataset but
    using two distinct watermark implementations (Figure 2-10): on the left, a perfect
    watermark; on the right, a heuristic watermark.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，水印的一个有趣的特性是它们是一类函数，这意味着有多个不同的函数*F*(*P*) → *E*满足水印的属性，成功程度各不相同。正如我之前所指出的，对于你对输入数据有完美的了解的情况，可能可以构建一个完美的水印，这是理想的情况。但对于你缺乏对输入的完美了解的情况，或者计算完美水印太昂贵的情况，你可能会选择使用启发式来定义你的水印。我想要在这里强调的是，所使用的水印算法与管道本身是独立的。我们不打算在这里详细讨论实现水印意味着什么（Slava在第3章中会讲到）。现在，为了帮助强调这个观点，即给定的输入集可以应用不同的水印，让我们看一下我们在示例2-6中的管道在相同数据集上执行时使用两种不同的水印实现（图2-10）：左侧是完美水印；右侧是启发式水印。
- en: In both cases, windows are materialized as the watermark passes the end of the
    window. The perfect watermark, as you might expect, perfectly captures the event-time
    completeness of the pipeline as time progresses. In contrast, the specific algorithm
    used for the heuristic watermark on the right fails to take the value of 9 into
    account,⁵ which drastically changes the shape of the materialized outputs, both
    in terms of output latency and correctness (as seen by the incorrect answer of
    5 that’s provided for the 12:00, 12:02) window).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，当水印通过窗口的末端时，窗口会被实体化。正如你所期望的那样，完美的水印完美地捕捉了管道随着时间的推移而发生的事件完整性。相比之下，右侧启发式水印的具体算法未考虑值为9，⁵这极大地改变了实体化输出的形状，无论是在输出延迟还是正确性方面（如12:00、12:02提供的错误答案为5）。
- en: The big difference between the watermark triggers from Figure 2-9 and the repeated
    update triggers we saw in Figures 2-5 through 2-7 is that the *watermarks give
    us a way to reason about the completeness of our input*. Until the system materializes
    an output for a given window, we know that the system does not yet believe the
    inputs to be complete. This is especially important for use cases in which you
    want to reason about a *lack of data* in the input, or *missing data*.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 水印触发器与我们在图2-5到2-7中看到的重复更新触发器的一个重大区别是*水印给了我们一种推理输入完整性的方式*。直到系统为给定的窗口实体化输出，我们知道系统还不相信输入是完整的。这对于那些想要推理输入中的*数据缺失*或*缺失数据*的用例尤为重要。
- en: <assets/stsy_0210.mp4>
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: <资产/ stsy_0210.mp4>
- en: '![Windowed summation on a streaming engine with perfect (left) and heuristic
    (right) watermarks'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![在具有完美（左）和启发式（右）水印的流处理引擎上的窗口求和'
- en: Figure 2-10\. Windowed summation on a streaming engine with perfect (left) and
    heuristic (right) watermarks
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-10。在具有完美（左）和启发式（右）水印的流处理引擎上的窗口求和
- en: 'A great example of a missing-data use case is outer joins. Without a notion
    of completeness like watermarks, how do you know when to give up and emit a partial
    join rather than continue to wait for that join to complete? You don’t. And basing
    that decision on a processing-time delay, which is the common approach in streaming
    systems that lack true watermark support, is not a safe way to go, because of
    the variable nature of event-time skew we spoke about in Chapter 1: as long as
    skew remains smaller than the chosen processing-time delay, your missing-data
    results will be correct, but any time skew grows beyond that delay, they will
    suddenly become *in*correct. From this perspective, event-time watermarks are
    a critical piece of the puzzle for many real-world streaming use cases which must
    reason about a lack of data in the input, such as outer joins, anomaly detection,
    and so on.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据用例的一个很好的例子是外连接。如果没有像水印这样的完整性概念，你怎么知道何时放弃并发出部分连接，而不是继续等待该连接完成？你不知道。基于处理时间延迟做出决定的方式，这是缺乏真正水印支持的流处理系统的常见方法，这不是一个安全的方式，因为我们在第1章中讨论过的事件时间偏移的可变性：只要偏移保持小于所选的处理时间延迟，你的缺失数据结果将是正确的，但是一旦偏移超过了该延迟，它们将突然变得*不*正确。从这个角度来看，事件时间水印对于许多必须推理输入数据缺失的真实世界流处理用例（如外连接、异常检测等）是一个关键的拼图。
- en: 'Now, with that said, these watermark examples also highlight two *shortcomings*
    of watermarks (and any other notion of completeness), specifically that they can
    be one of the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，话虽如此，这些水印示例也突显了水印（以及任何其他完整性概念）的两个*缺点*，具体来说，它们可能是以下两种情况之一：
- en: Too slow
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 太慢
- en: When a watermark of any type is correctly delayed due to known unprocessed data
    (e.g., slowly growing input logs due to network bandwidth constraints), that translates
    directly into delays in output if advancement of the watermark is the only thing
    you depend on for stimulating results.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当任何类型的水印由于已知未处理的数据（例如，由于网络带宽限制而缓慢增长的输入日志）而被正确延迟时，如果水印的推进是你唯一依赖于刺激结果的因素，那么这直接转化为输出的延迟。
- en: This is most obvious in the left diagram of Figure 2-10, for which the late
    arriving 9 holds back the watermark for all the subsequent windows, even though
    the input data for those windows become complete earlier. This is particularly
    apparent for the second window, 12:02, 12:04), for which it takes nearly seven
    minutes from the time the first value in the window occurs until we see any results
    for the window whatsoever. The heuristic watermark in this example doesn’t suffer
    the same issue quite so badly (five minutes until output), but don’t take that
    to mean heuristic watermarks never suffer from watermark lag; that’s really just
    a consequence of the record I chose to omit from the heuristic watermark in this
    specific example.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这在图2-10的左侧图中最为明显，晚到的9会阻碍所有后续窗口的水印，即使这些窗口的输入数据较早就变得完整。对于第二个窗口，12:02, 12:04），从窗口中的第一个值出现到我们看到窗口的任何结果几乎需要七分钟。在这个示例中，启发式水印并没有遭受同样严重的问题（五分钟直到输出），但不要认为启发式水印永远不会遭受水印滞后的问题；这实际上只是我选择在这个特定示例中省略的记录的结果。
- en: 'The important point here is the following: Although watermarks provide a very
    useful notion of completeness, depending upon completeness for producing output
    is often not ideal from a latency perspective. Imagine a dashboard that contains
    valuable metrics, windowed by hour or day. It’s unlikely you’d want to wait a
    full hour or day to begin seeing results for the current window; that’s one of
    the pain points of using classic batch systems to power such systems. Instead,
    it would be much nicer to see the results for those windows refine over time as
    the inputs evolve and eventually become complete.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的重要一点是：尽管水印提供了一个非常有用的完整性概念，但依赖完整性来产生输出通常从延迟的角度来看并不理想。想象一下一个包含有价值的指标的仪表板，按小时或天进行窗口化。你不太可能希望等到整整一个小时或一天才开始看到当前窗口的结果；这是使用经典批处理系统来支持这样的系统的痛点之一。相反，随着输入的演变和最终变得完整，看到这些窗口的结果随着时间的推移而不断完善会更好。
- en: Too fast
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 太快
- en: 'When a heuristic watermark is incorrectly advanced earlier than it should be,
    it’s possible for data with event times before the watermark to arrive some time
    later, creating late data. This is what happened in the example on the right:
    the watermark advanced past the end of the first window before all the input data
    for that window had been observed, resulting in an incorrect output value of 5
    instead of 14\. This shortcoming is strictly a problem with heuristic watermarks;
    their heuristic nature implies they will sometimes be wrong. As a result, relying
    on them alone for determining when to materialize output is insufficient if you
    care about correctness.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 当启发式水印比它应该提前推进时，事件时间早于水印的数据可能会在之后的某个时间到达，从而产生延迟数据。这就是右侧示例中发生的情况：水印在第一个窗口结束之前推进，而该窗口的所有输入数据尚未被观察到，导致输出值不正确，而不是14。这个缺点严格来说是启发式水印的问题；它们的启发式本质意味着它们有时会出错。因此，如果你关心正确性，仅仅依赖它们来确定何时产生输出是不够的。
- en: In [Chapter 1, I made some rather emphatic statements about notions of completeness
    being insufficient for most use cases requiring robust out-of-order processing
    of unbounded data streams. These two shortcomings—watermarks being too slow or
    too fast—are the foundations for those arguments. You simply cannot get both low
    latency and correctness out of a system that relies solely on notions of completeness.⁶
    So, for cases for which you do want the best of both worlds, what’s a person to
    do? Well, if repeated update triggers provide low-latency updates but no way to
    reason about completeness, and watermarks provide a notion of completeness but
    variable and possible high latency, why not combine their powers together?
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章中，我对完整性概念不足以满足大多数需要对无界数据流进行强大的乱序处理的用例做出了一些非常强调的陈述。这两个缺点——水印太慢或太快——是这些论点的基础。你简单地无法从完整性概念的系统中同时获得低延迟和正确性。因此，对于那些希望兼顾两全的情况，一个人该怎么办呢？如果重复更新触发器提供了低延迟更新但无法推理完整性，水印提供了完整性概念但变化和可能的高延迟，为什么不将它们的力量结合起来呢？
- en: '*When*: Early/On-Time/Late Triggers FTW!'
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*何时*：早期/准时/延迟触发器胜利！'
- en: 'We’ve now looked at the two main types of triggers: repeated update triggers
    and completeness/watermark triggers. In many case, neither of them alone is sufficient,
    but the combination of them together is. Beam recognizes this fact by providing
    an extension of the standard watermark trigger that also supports repeated update
    triggering on either side of the watermark. This is known as the early/on-time/late
    trigger because it partitions the panes that are materialized by the compound
    trigger into three categories:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经看过了两种主要类型的触发器：重复更新触发器和完整性/水印触发器。在许多情况下，它们单独都不足够，但它们的组合是。Beam通过提供标准水印触发器的扩展来认识到这一事实，该扩展还支持水印两侧的重复更新触发。这被称为早期/准时/延迟触发器，因为它将由复合触发器实现的窗格分为三类：
- en: Zero or more *early panes*, which are the result of a repeated update trigger
    that periodically fires up until the watermark passes the end of the window. The
    panes generated by these firings contain speculative results, but allow us to
    observe the evolution of the window over time as new input data arrive. This compensates
    for the shortcoming of watermarks sometimes being *too slow*.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零个或多个*早期窗格*，这是重复更新触发器的结果，它会定期触发，直到水印通过窗口的末尾。这些触发产生的窗格包含推测结果，但允许我们观察随着新的输入数据到达，窗口随时间的演变。这弥补了水印有时会*太慢*的缺点。
- en: A single *on-time pane*, which is the result of the completeness/watermark trigger
    firing after the watermark passes the end of the window. This firing is special
    because it provides an assertion that the system now believes the input for this
    window to be complete.⁷ This means that it is now safe to reason about *missing
    data*; for example, to emit a partial join when performing an outer join.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*准时窗格*，这是完整性/水印触发器在水印通过窗口的末尾后触发的结果。这种触发是特殊的，因为它提供了一个断言，即系统现在认为这个窗口的输入是完整的。这意味着现在可以推断*缺失数据*；例如，在执行外连接时发出部分连接。
- en: Zero or more *late panes*, which are the result of another (possibly different)
    repeated update trigger that periodically fires any time late data arrive after
    the watermark has passed the end of the window. In the case of a perfect watermark,
    there will always be zero late panes. But in the case of a heuristic watermark,
    any data the watermark failed to properly account for will result in a late firing.
    This compensates for the shortcoming of watermarks being *too fast*.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零个或多个*迟到窗格*，这是另一个（可能不同的）重复更新触发器的结果，它会定期触发，任何迟到数据到达后，水印已经通过窗口的末尾。在完美的水印情况下，将始终没有迟到窗格。但在启发式水印的情况下，水印未能正确计算的任何数据都将导致迟到触发。这弥补了水印*太快*的缺点。
- en: Let’s see how this looks in action. We’ll update our pipeline to use a periodic
    processing-time trigger with an aligned delay of one minute for the early firings,
    and a per-record trigger for the late firings. That way, the early firings will
    give us some amount of batching for high-volume windows (thanks to the fact that
    the trigger will fire only once per minute, regardless of the throughput into
    the window), but we won’t introduce unnecessary latency for the late firings,
    which are hopefully somewhat rare if we’re using a reasonably accurate heuristic
    watermark. In Beam, that looks Example 2-7 (Figure 2-11 shows the results).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这在实际中是什么样子。我们将更新我们的管道，使用周期性的处理时间触发器，早期触发的对齐延迟为一分钟，迟到触发的每条记录触发。这样，早期触发将为我们的高吞吐量窗口提供一定量的批处理（由于触发器每分钟只触发一次，不管窗口中的吞吐量如何），但我们不会为迟到触发引入不必要的延迟，如果我们使用一个相当准确的启发式水印，迟到触发应该是相当罕见的。在Beam中，这看起来像例2-7（图2-11显示了结果）。
- en: Example 2-7\. Early, on-time, and late firings via the early/on-time/late API
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 例2-7。通过早期/准时/迟到API进行早期、准时和迟到触发
- en: '[PRE7]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: <assets/stsy_0211.mp4>
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/stsy_0211.mp4>
- en: '![Windowed summation on a streaming engine with early, on-time, and late firings](img/stsy_0211.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![在具有早期、准时和迟到触发的流引擎上的窗口求和](img/stsy_0211.png)'
- en: Figure 2-11\. Windowed summation on a streaming engine with early, on-time,
    and late firings
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-11。在具有早期、准时和迟到触发的流引擎上的窗口求和
- en: 'This version has two clear improvements over Figure 2-9:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这个版本比图2-9有两个明显的改进：
- en: 'For the “watermarks too slow” case in the second window, 12:02, 12:04): we
    now provide periodic early updates once per minute. The difference is most stark
    in the perfect watermark case, for which time-to-first-output is reduced from
    almost seven minutes down to three and a half; but it’s also clearly improved
    in the heuristic case, as well. Both versions now provide steady refinements over
    time (panes with values 7, 10, then 18), with relatively minimal latency between
    the input becoming complete and materialization of the final output pane for the
    window.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于第二个窗口（12:02, 12:04）中的“水印太慢”的情况：我们现在每分钟提供定期的早期更新。最大的差异在于完美的水印情况，首次输出时间从将近七分钟减少到三分半；但在启发式情况下，也明显改善了。现在两个版本都随时间稳定改进（窗格的值为7、10，然后是18），在输入变得完整和窗口的最终输出窗格实现之间的延迟相对较小。
- en: 'For the “heuristic watermarks too fast” case in the first window, [12:00, 12:02):
    when the value of 9 shows up late, we immediately incorporate it into a new, corrected
    pane with value of 14.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于第一个窗口（12:00, 12:02）中的“启发式水印太快”的情况：当值为9的数据迟到时，我们立即将其合并到一个新的、更正的窗格中，值为14。
- en: 'One interesting side effect of these new triggers is that they effectively
    normalize the output pattern between the perfect and heuristic watermark versions.
    Whereas the two versions in [Figure 2-10 were starkly different, the two versions
    here look quite similar. They also look much more similar to the various repeated
    update version from Figures 2-6 through 2-8, with one important difference: thanks
    to the use of the watermark trigger, we can also reason about input completeness
    in the results we generate with the early/on-time/late trigger. This allows us
    to better handle use cases that care about *missing data*, like outer joins, anomaly
    detection, and so on.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这些新触发器的一个有趣的副作用是，它们有效地使完美和启发式水印版本之间的输出模式得到了规范化。在图2-10中，两个版本截然不同，而在这里的两个版本看起来非常相似。它们看起来也更类似于图2-6到2-8中的各种重复更新版本，但有一个重要的区别：由于使用了水印触发器，我们还可以推断我们使用早期/准时/迟到触发器生成的结果的输入完整性。这使我们能够更好地处理关心*缺失数据*的用例，比如外连接，异常检测等。
- en: The biggest remaining difference between the perfect and heuristic early/on-time/late
    versions at this point is window lifetime bounds. In the perfect watermark case,
    we know we’ll never see any more data for a window after the watermark has passed
    the end of it, hence we can drop all of our state for the window at that time.
    In the heuristic watermark case, we still need to hold on to the state for a window
    for some amount of time to account for late data. But as of yet, our system doesn’t
    have any good way of knowing just how long state needs to be kept around for each
    window. That’s where *allowed lateness* comes in.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，完美和启发式的早期/准时/延迟版本之间最大的区别是窗口生命周期的限制。在完美的水印情况下，我们知道在水印通过窗口结束之后我们不会再看到任何窗口的数据，因此我们可以在那时丢弃窗口的所有状态。在启发式水印情况下，我们仍然需要保留窗口的状态一段时间来处理延迟数据。但是到目前为止，我们的系统还没有一个好的方法来知道每个窗口需要保留状态的时间。这就是*允许延迟*的作用。
- en: '*When*: Allowed Lateness (i.e., Garbage Collection)'
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*何时*：允许延迟（即，垃圾回收）'
- en: 'Before moving on to our last question (“*How* do refinements of results relate?”),
    I’d like to touch on a practical necessity within long-lived, out-of-order stream
    processing systems: garbage collection. In the heuristic watermarks example in
    Figure 2-11, the persistent state for each window lingers around for the entire
    lifetime of the example; this is necessary to allow us to appropriately deal with
    late data when/if they arrive. But while it would be great to be able to keep
    around all of our persistent state until the end of time, in reality, when dealing
    with an unbounded data source, it’s often not practical to keep state (including
    metadata) for a given window indefinitely; we’ll eventually run out of disk space
    (or at the very least tire of paying for it, as the value for older data diminishes
    over time).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续我们的最后一个问题（“*结果的改进*如何相关？”）之前，我想谈谈长期、乱序的流处理系统中的一个实际必要性：垃圾回收。在图2-11中的启发式水印示例中，每个窗口的持久状态在整个示例的生命周期内都会持续存在；这是必要的，以便我们在需要时能够适当地处理延迟数据。但是，虽然能够一直保留我们的持久状态直到永远是很好的，但实际上，在处理无界数据源时，通常不太可能无限期地保留给定窗口的状态（包括元数据）；我们最终会耗尽磁盘空间（或者至少厌倦为其付费，因为随着时间的推移，旧数据的价值会降低）。
- en: 'As a result, any real-world out-of-order processing system needs to provide
    some way to bound the lifetimes of the windows it’s processing. A clean and concise
    way of doing this is by defining a horizon on the allowed lateness within the
    system; that is, placing a bound on how late any given *record* may be (relative
    to the watermark) for the system to bother processing it; any data that arrives
    after this horizon are simply dropped. After you’ve bounded how late individual
    data may be, you’ve also established precisely how long the state for windows
    must be kept around: until the watermark exceeds the lateness horizon for the
    end of the window. But in addition, you’ve also given the system the liberty to
    immediately drop any data later than the horizon as soon as they’re observed,
    which means the system doesn’t waste resources processing data that no one cares
    about.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，任何现实世界中的乱序处理系统都需要提供一种方式来限制它正在处理的窗口的生命周期。一个清晰而简洁的方法是在系统内定义允许延迟的地平线；也就是说，对于系统来说，设定任何给定*记录*相对于水印可以有多晚（相对于水印）才值得处理；超过这个地平线的任何数据都会被简单地丢弃。在你设定了个别数据可以有多晚之后，你也确立了窗口状态必须保留多久的时间：直到水印超过窗口结束时的延迟地平线。但另外，你也给了系统自由，让它在观察到后面的数据时立即丢弃超过地平线的任何数据，这意味着系统不会浪费资源处理没有人关心的数据。
- en: 'Because the interaction between allowed lateness and the watermark is a little
    subtle, it’s worth looking at an example. Let’s take the heuristic watermark pipeline
    from Example 2-7/Figure 2-11 and add in Example 2-8 a lateness horizon of one
    minute (note that this particular horizon has been chosen strictly because it
    fits nicely into the diagram; for real-world use cases, a larger horizon would
    likely be much more practical):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于允许延迟和水印之间的相互作用有点微妙，值得看一个例子。让我们看一下示例2-7/图2-11中的启发式水印流水线，并在示例2-8中添加一个一分钟的延迟地平线（请注意，这个特定的地平线之所以被选择，纯粹是因为它在图中很好地适应；对于实际用例，一个更大的地平线可能会更实用）：
- en: Example 2-8\. Early/on-time/late firings with allowed lateness
  id: totrans-157
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-8。允许延迟的早期/准时/延迟触发
- en: '[PRE8]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The execution of this pipeline would look something like Figure 2-12, in which
    I’ve added the following features to highlight the effects of allowed lateness:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此流水线的过程看起来有点像图2-12，我在其中添加了以下功能以突出允许延迟的影响：
- en: The thick black line denoting the current position in processing time is now
    annotated with ticks indicating the lateness horizon (in event time) for all active
    windows.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表示处理时间中当前位置的粗黑线现在带有刻度，用于指示所有活动窗口的延迟地平线（以事件时间为单位）。
- en: When the watermark passes the lateness horizon for a window, that window is
    closed, which means that all state for the window is discarded. I leave around
    a dotted rectangle showing the extent of time (in both domains) that the window
    covered when it was closed, with a little tail extending to the right to denote
    the lateness horizon for the window (for contrasting against the watermark).
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当水印通过窗口的延迟地平线时，该窗口关闭，这意味着窗口的所有状态都被丢弃。我留下一个虚线矩形，显示窗口关闭时它覆盖的时间范围（在两个域中），并在右侧延伸一小段以表示窗口的延迟地平线（与水印进行对比）。
- en: For this diagram only, I’ve added an additional late datum for the first window
    with value 6\. The 6 is late, but still within the allowed lateness horizon and
    thus is incorporated into an updated result with value 11\. The 9, however, arrives
    beyond the lateness horizon, so it is simply dropped.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅对于此图，我为第一个值为6的窗口添加了一个额外的延迟数据。6是延迟的，但仍在允许的延迟地平线内，因此被合并到值为11的更新结果中。然而，9到达的时间超过了延迟地平线，因此被简单地丢弃。
- en: <assets/stsy_0212.mp4>
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/stsy_0212.mp4>
- en: '![Windowed summation on a streaming engine with early, on-time, and late firings](img/stsy_0212.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![在具有早期、准时和延迟触发的流引擎上的窗口求和](img/stsy_0212.png)'
- en: Figure 2-12\. Allowed lateness with early/on-time/late firings
  id: totrans-165
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-12。具有早期/准时/延迟触发的允许延迟
- en: 'Two final side notes about lateness horizons:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 关于延迟时间范围的两个最终注意事项：
- en: To be absolutely clear, if you happen to be consuming data from sources for
    which perfect watermarks are available, there’s no need to deal with late data,
    and an allowed lateness horizon of zero seconds will be optimal. This is what
    we saw in the perfect watermark portion of Figure 2-10.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要非常清楚，如果你恰好从具有完美水印的数据源中获取数据，就不需要处理延迟数据，允许的延迟时间为零秒将是最佳的。这就是我们在图2-10的完美水印部分看到的情况。
- en: One noteworthy exception to the rule of needing to specify lateness horizons,
    even when heuristic watermarks are in use, would be something like computing global
    aggregates over all time for a tractably finite number of keys (e.g., computing
    the total number of visits to your site over all time, grouped by web browser
    family). In this case, the number of active windows in the system is bounded by
    the limited keyspace in use. As long as the number of keys remains manageably
    low, there’s no need to worry about limiting the lifetime of windows via allowed
    lateness.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使在使用启发式水印时，需要指定延迟时间范围的规则有一个值得注意的例外，那就是对于可管理的有限数量的键（例如，按网页浏览器系列对所有时间的全局聚合进行计算，例如，按网页浏览器系列对所有时间的总访问次数进行计算）。在这种情况下，系统中活动窗口的数量受到使用的有限键空间的限制。只要键的数量保持在可以管理的范围内，就不需要担心通过允许的延迟时间来限制窗口的生命周期。
- en: Practicality sated, let’s move on to our fourth and final question.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 实用性满足后，让我们继续我们的第四个和最后一个问题。
- en: '*How*: Accumulation'
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*如何*：累积'
- en: 'When triggers are used to produce multiple panes for a single window over time,
    we find ourselves confronted with the last question: “*How* do refinements of
    results relate?” In the examples we’ve seen so far, each successive pane is built
    upon the one immediately preceding it. However, there are actually three⁸ different
    modes of accumulation:⁹'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当触发器用于在一段时间内为单个窗口生成多个窗格时，我们发现自己面临最后一个问题：“*结果的修正*如何相关？”在我们迄今为止看到的例子中，每个连续的窗格都是建立在紧随其后的窗格之上的。然而，实际上有三种不同的累积模式：⁹
- en: Discarding
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃
- en: Every time a pane is materialized, any stored state is discarded. This means
    that each successive pane is independent from any that came before. Discarding
    mode is useful when the downstream consumer is performing some sort of accumulation
    itself; for example, when sending integers into a system that expects to receive
    deltas that it will sum together to produce a final count.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 每次窗格被实现，任何存储的状态都会被丢弃。这意味着每个连续的窗格都与之前的窗格无关。当下游消费者执行某种累积时，丢弃模式是有用的；例如，当将整数发送到一个期望接收将它们相加以产生最终计数的增量的系统时。
- en: Accumulating
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 累积
- en: As in Figures 2-6 through 2-11, every time a pane is materialized, any stored
    state is retained, and future inputs are accumulated into the existing state.
    This means that each successive pane builds upon the previous panes. Accumulating
    mode is useful when later results can simply overwrite previous results, such
    as when storing output in a key/value store like HBase or Bigtable.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 与图2-6到2-11一样，每次窗格被实现，任何存储的状态都会被保留，并且未来的输入会累积到现有的状态中。这意味着每个连续的窗格都建立在以前的窗格之上。当后续结果可以简单地覆盖先前的结果时，累积模式是有用的，例如在将输出存储在HBase或Bigtable等键/值存储中时。
- en: Accumulating and retracting
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 累积和撤消
- en: 'This is like accumulating mode, but when producing a new pane, it also produces
    independent retractions for the previous pane(s). Retractions (combined with the
    new accumulated result) are essentially an explicit way of saying “I previously
    told you the result was *X*, but I was wrong. Get rid of the *X* I told you last
    time, and replace it with *Y*.” There are two cases for which retractions are
    particularly helpful:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这就像是累积模式，但是在生成新的窗格时，它还会为以前的窗格产生独立的撤消。撤消（与新的累积结果结合）本质上是一种明确地说“我之前告诉过你结果是*X*，但我错了。去掉我上次告诉你的*X*，用*Y*替换它。”的方式。撤消有两种情况特别有帮助：
- en: When consumers downstream are *regrouping data by a different dimension*, it’s
    entirely possible the new value may end up keyed differently from the previous
    value and thus end up in a different group. In that case, the new value can’t
    just overwrite the old value; you instead need the retraction to remove the old
    value
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当下游消费者*通过不同的维度重新分组数据*时，新值很可能会以与以前的值不同的键方式进行分组，因此最终会进入不同的组。在这种情况下，新值不能简单地覆盖旧值；相反，您需要撤消以删除旧值
- en: When *dynamic windows* (e.g., sessions, which we look at more closely in a few
    moments) are in use, the new value might be replacing more than one previous window,
    due to window merging. In this case, it can be difficult to determine from the
    new window alone which old windows are being replaced. Having explicit retractions
    for the old windows makes the task straightforward. We see an example of this
    in detail in Chapter 8.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用*动态窗口*（例如，我们稍后将更仔细地研究的会话）时，新值可能会替换多个以前的窗口，因为窗口合并。在这种情况下，仅从新窗口中确定替换了哪些旧窗口可能会很困难。为旧窗口提供明确的撤消使得这个任务变得简单。我们在第8章中详细看到了一个例子。
- en: The different semantics for each group are somewhat clearer when seen side-by-side.
    Consider the two panes for the second window (the one with event-time range 12:06,
    12:08)) in [Figure 2-11 (the one with early/on-time/late triggers). Table 2-1
    shows what the values for each pane would look like across the three accumulation
    modes (with *accumulating* mode being the specific mode used in Figure 2-11 itself).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组的不同语义在并排看时会更清晰一些。考虑图2-11中第二个窗口（事件时间范围为12:06, 12:08）的两个窗格。表2-1显示了在三种累积模式下（*累积*模式是图2-11本身使用的特定模式）每个窗格的值会是什么样子。
- en: Table 2-1\. Comparing accumulation modes using the second window from Figure 2-11
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 表2-1。使用图2-11的第二个窗口比较累积模式
- en: '|   | **Discarding** | **Accumulating** | **Accumulating & Retracting** |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|   | **丢弃** | **累积** | **累积和撤回** |'
- en: '| **Pane 1: inputs=[3]** | 3 | 3 | 3 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| **窗格1：输入=[3]** | 3 | 3 | 3 |'
- en: '| **Pane 2: inputs=[8, 1]** | 9 | 12 | 12, –3 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| **窗格2：输入=[8, 1]** | 9 | 12 | 12, –3 |'
- en: '| **Value of final normal pane** | 9 | 12 | 12 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| **最终正常窗格的值** | 9 | 12 | 12 |'
- en: '| **Sum of all panes** | 12 | 15 | 12 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| **所有窗格的总和** | 12 | 15 | 12 |'
- en: 'Let’s take a closer look at what’s happening:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看发生了什么：
- en: Discarding
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃
- en: Each pane incorporates only the values that arrived during that specific pane.
    As such, the final value observed does not fully capture the total sum. However,
    if you were to sum all of the independent panes themselves, you would arrive at
    a correct answer of 12\. This is why discarding mode is useful when the downstream
    consumer itself is performing some sort of aggregation on the materialized panes.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 每个窗格只包含在该特定窗格期间到达的值。因此，观察到的最终值并不能完全捕捉到总和。然而，如果你将所有独立窗格的值相加，你会得到一个正确的答案12。这就是为什么在下游消费者本身对实体窗格执行某种聚合时，丢弃模式是有用的。
- en: Accumulating
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 累积
- en: 'As in Figure 2-11, each pane incorporates the values that arrived during that
    specific pane, plus all of the values from previous panes. As such, the final
    value observed correctly captures the total sum of 12\. If you were to sum up
    the individual panes themselves, however, you’d effectively be double-counting
    the inputs from pane 1, giving you an incorrect total sum of 15\. This is why
    accumulating mode is most useful when you can simply overwrite previous values
    with new values: the new value already incorporates all of the data seen thus
    far.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 就像图2-11一样，每个窗格都包含在该特定窗格期间到达的值，以及之前窗格的所有值。因此，观察到的最终值正确地捕捉到了总和12。然而，如果你将各个窗格本身相加，你实际上会重复计算窗格1的输入，得到一个不正确的总和15。这就是为什么当你可以简单地用新值覆盖先前的值时，累积模式是最有用的：新值已经包含了迄今为止看到的所有数据。
- en: Accumulating and retracting
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 累积和撤回
- en: Each pane includes both a new accumulating mode value as well as a retraction
    of the previous pane’s value. As such, both the last value observed (excluding
    retractions) as well as the total sum of all materialized panes (including retractions)
    provide you with the correct answer of 12\. This is why retractions are so powerful.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 每个窗格都包括一个新的累积模式值以及前一个窗格值的撤回。因此，最后观察到的值（不包括撤回）以及所有实体窗格的总和（包括撤回）都会给出正确答案12。这就是为什么撤回是如此强大。
- en: 'Example 2-9 demonstrates discarding mode in action, illustrating the changes
    we would make to Example 2-7:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 示例2-9演示了丢弃模式的运行，说明了我们将对示例2-7进行的更改：
- en: Example 2-9\. Discarding mode version of early/on-time/late firings
  id: totrans-195
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-9。流引擎上早期/及时/延迟触发的丢弃模式版本
- en: '[PRE9]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Running again on a streaming engine with a heuristic watermark would produce
    output like that shown in Figure 2-13.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有启发式水印的流引擎上再次运行会产生类似于图2-13所示的输出。
- en: <assets/stsy_0213.mp4>
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/stsy_0213.mp4>
- en: '![Discarding mode version of early/on-time/late firings on a streaming engine](img/stsy_0213.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![流引擎上早期/及时/延迟触发的丢弃模式版本](img/stsy_0213.png)'
- en: Figure 2-13\. Discarding mode version of early/on-time/late firings on a streaming
    engine
  id: totrans-200
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-13。流引擎上早期/及时/延迟触发的丢弃模式版本
- en: Even though the overall shape of the output is similar to the accumulating mode
    version from Figure 2-11, note how none of the panes in this discarding version
    overlap. As a result, each output is independent from the others.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管输出的整体形状与图2-11中的累积模式版本相似，但请注意，这个丢弃版本中没有任何窗格重叠。因此，每个输出都是独立的。
- en: If we want to look at retractions in action, the change would be similar, as
    shown in Example 2-10. ??? depicts the results.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想看撤回的运行情况，更改将是类似的，如示例2-10所示。???描述了结果。
- en: Example 2-10\. Accumulating and retracting mode version of early/on-time/late
    firings
  id: totrans-203
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例2-10。流引擎上早期/及时/延迟触发的累积和撤回模式版本
- en: '[PRE10]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: <assets/stsy_0214.mp4>
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: <assets/stsy_0214.mp4>
- en: '![Accumulating and retracting mode version of early/late firings on a streaming
    engine](img/stsy_0214.png) Accumulating and retracting mode version of early/late
    firings on a streaming engine'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '![流引擎上早期/及时/延迟触发的累积和撤回模式版本](img/stsy_0214.png) 流引擎上早期/及时/延迟触发的累积和撤回模式版本'
- en: Because the panes for each window all overlap, it’s a little tricky to see the
    retractions clearly. The retractions are indicated in red, which combines with
    the overlapping blue panes to yield a slightly purplish color. I’ve also horizontally
    shifted the values of the two outputs within a given pane slightly (and separated
    them with a comma) to make them easier to differentiate.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 因为每个窗口的窗格都重叠，清楚地看到撤回有点棘手。撤回用红色表示，与重叠的蓝色窗格结合在一起，产生了略带紫色的颜色。我还稍微水平移动了给定窗格内的两个输出的值（并用逗号分隔），以便更容易区分它们。
- en: Figure 2-14 combines the final frames of Figures 2-9, 2-11 (heuristic only),
    and side-by-side, providing a nice visual contrast of the three modes.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图2-14结合了图2-9、2-11（仅启发式）和并排的最终帧，提供了三种模式的良好视觉对比。
- en: '![](img/stsy_0215.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/stsy_0215.png)'
- en: Figure 2-14\. Side-by-side comparison of accumulation modes
  id: totrans-210
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-14。累积模式的并排比较
- en: As you can imagine, the modes in the order presented (discarding, accumulating,
    accumulating and retracting) are each successively more expensive in terms of
    storage and computation costs. To that end, choice of accumulation mode provides
    yet another dimension for making trade-offs along the axes of correctness, latency,
    and cost.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所想象的，按照呈现的顺序（丢弃、累积、累积和撤回）的模式在存储和计算成本方面是逐渐增加的。因此，累积模式的选择为在正确性、延迟和成本的轴上进行权衡提供了另一个维度。
- en: Summary
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'With this chapter complete, you now understand the basics of robust stream
    processing and are ready to go forth into the world and do amazing things. Of
    course, there are eight more chapters anxiously waiting for your attention, so
    hopefully you won’t go forth like right now, this very minute. But regardless,
    let’s recap what we’ve just covered, lest you forget any of it in your haste to
    amble forward. First, the major concepts we touched upon:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章的学习，您现在了解了强大的流处理的基础知识，并准备好进入世界，做出惊人的成就。当然，还有八章等着您去关注，所以希望您不要马上就出发，就在这一刻。但无论如何，让我们回顾一下我们刚刚涉及的主要概念：
- en: Event time versus processing time
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 事件时间与处理时间
- en: The all-important distinction between when events occurred and when they are
    observed by your data processing system.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 事件发生的时间和数据处理系统观察到它们的时间之间的重要区别。
- en: Windowing
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口
- en: The commonly utilized approach to managing unbounded data by slicing it along
    temporal boundaries (in either processing time or event time, though we narrow
    the definition of windowing in the Beam Model to mean only within event time).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 通过沿着时间边界（无论是处理时间还是事件时间，尽管在Beam模型中我们将窗口的定义缩小为仅在事件时间内）切分无界数据的常用方法。
- en: Triggers
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器
- en: The declarative mechanism for specifying precisely when materialization of output
    makes sense for your particular use case.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 用于准确指定何时对于特定用例来说输出的实现是有意义的声明性机制。
- en: Watermarks
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 水印
- en: The powerful notion of progress in event time that provides a means of reasoning
    about completeness (and thus missing data) in an out-of-order processing system
    operating on unbounded data.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 事件时间中进展的强大概念，提供了一种推理完整性（因此缺失数据）的方式，用于处理无界数据的无序处理系统。
- en: Accumulation
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 累积
- en: The relationship between refinements of results for a single window for cases
    in which it’s materialized multiple times as it evolves.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单个窗口结果的改进与其多次实现时的情况之间的关系。
- en: 'Second, the four questions we used to frame our exploration:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们用来构建我们探索的四个问题：
- en: '*What* results are calculated? = transformations.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么*结果被计算？=转换。'
- en: '*Where* in event time are results calculated? = windowing.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在*事件时间中计算结果的位置？=窗口。'
- en: '*When* in processing time are results materialized? = triggers plus watermarks.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在*处理时间中结果何时实现？=触发器加水印。'
- en: '*How* do refinements of results relate? = accumulation.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如何*结果的改进相关？=累积。'
- en: 'Third, to drive home the flexibility afforded by this model of stream processing
    (because in the end, that’s really what this is all about: balancing competing
    tensions like correctness, latency, and cost), a recap of the major variations
    in output we were able to achieve over the same dataset with only a minimal amount
    of code change:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，为了强调这种流处理模型所提供的灵活性（因为归根结底，这才是关键：平衡正确性、延迟和成本等竞争张力），我们能够通过最少量的代码更改在相同数据集上实现的输出的主要变化的回顾：
- en: '|   | ![](img/stsy_02in01.png)Integer summation Example 2-1 / Figure 2-3 |
    ![](img/stsy_02in02.png)Integer summation Fixed windows batch'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '|   | ![](img/stsy_02in01.png)整数求和 例2-1 / 图2-3 | ![](img/stsy_02in02.png)整数求和
    固定窗口批处理'
- en: Example 2-2 / Figure 2-5 | ![](img/stsy_02in03.png)Integer summation Fixed windows
    streaming
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 例2-2 / 图2-5 | ![](img/stsy_02in03.png)整数求和 固定窗口流
- en: Repeated per-record trigger
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 每条记录重复触发
- en: Example 2-3 / Figure 2-6 |
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 例2-3 / 图2-6 |
- en: '|   | ![](img/stsy_02in04.png)Integer summation Fixed windows streaming'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '|   | ![](img/stsy_02in04.png)整数求和 固定窗口流'
- en: Repeated aligned-delay trigger
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 重复对齐延迟触发
- en: Example 2-4 / Figure 2-7 | ![](img/stsy_02in05.png)Integer summation Fixed windows
    streaming
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 例2-4 / 图2-7 | ![](img/stsy_02in05.png)整数求和 固定窗口流
- en: Repeated unaligned-delay trigger
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 重复不对齐延迟触发
- en: Example 2-5 / Figure 2-8 | ![](img/stsy_02in06.png)Integer summation Fixed windows
    streaming
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 例2-5 / 图2-8 | ![](img/stsy_02in06.png)整数求和 固定窗口流
- en: Heuristic watermark trigger
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 启发式水印触发
- en: Example 2-6 / Figure 2-10 |
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 例2-6 / 图2-10 |
- en: '|   | ![](img/stsy_02in07.png)Integer summation Fixed windows streaming'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '|   | ![](img/stsy_02in07.png)整数求和 固定窗口流'
- en: Early/on-time/late trigger
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 早期/准时/延迟触发
- en: Discarding
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃
- en: Example 2-9 / Figure 2-13 | ![](img/stsy_02in08.png)Integer summation Fixed
    windows streaming
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 例2-9 / 图2-13 | ![](img/stsy_02in08.png)整数求和 固定窗口流
- en: Early/on-time/late trigger
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 早期/准时/延迟触发
- en: Accumulating
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 累积
- en: Example 2-7 / Figure 2-11 | ![](img/stsy_02in09.png)Integer summation Fixed
    windows streaming
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 例2-7 / 图2-11 | ![](img/stsy_02in09.png)整数求和 固定窗口流
- en: Early/on-time/late trigger
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 早期/准时/延迟触发
- en: Accumulating and Retracting
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 累积和撤销
- en: Example 2-10 / ??? |
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 例2-10 / ??? |
- en: 'All that said, at this point, we’ve really looked at only one type of windowing:
    fixed windowing in event time. As we know, there are a number of dimensions to
    windowing, and I’d like to touch upon at least two more of those before we call
    it day with the Beam Model. First, however, we’re going to take a slight detour
    to dive deeper into the world of watermarks, as this knowledge will help frame
    future discussions (and be fascinating in and of itself). Enter Slava, stage right...'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，到目前为止，我们只看了一种窗口方式：事件时间中的固定窗口。正如我们所知，窗口有许多维度，我想至少在我们结束Beam模型之前再触及另外两个维度。然而，首先，我们将稍微偏离一下，深入探讨水印的世界，因为这些知识将有助于构建未来的讨论（并且本身也很有趣）。斯拉瓦，右边的舞台进入...
- en: ¹ If you’re fortunate enough to be reading the Safari version of the book, you
    have full-blown time-lapse animations just like in [“Streaming 102”](http://oreil.ly/1TV7YGU).
    For print, Kindle, and other ebook versions, there are static images with a link
    to animated versions on the web.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 如果您有幸阅读Safari版本的书，您将拥有完整的延时动画，就像[“流处理102”](http://oreil.ly/1TV7YGU)中一样。对于印刷版、Kindle和其他电子书版本，有静态图像并附有指向网络上动画版本的链接。
- en: ² Bear with me here. Fine-grained emotional expressions via composite punctuation
    (i.e., emoticons) are strictly forbidden in O’Reilly publications <​winky-smiley/>.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ² 请耐心等待。在O'Reilly出版物中，严禁使用复合标点（即表情符号）进行细粒度的情感表达<​winky-smiley/>。
- en: ³ And indeed, we did just that with the original triggers feature in Beam. In
    retrospect, we went a bit overboard. Future iterations will be simpler and easier
    to use, and in this book I focus only on the pieces that are likely to remain
    in some form or another.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们在 Beam 中的原始触发器功能中就是这样做的。回顾起来，我们有点过头了。未来的迭代将更简单、更易于使用，在本书中，我只关注那些可能以某种形式保留的部分。
- en: '⁴ More accurately, the input to the function is really the state at time *P*
    of everything upstream of the point in the pipeline where the watermark is being
    observed: the input source, buffered data, data actively being processed, and
    so on; but conceptually it’s simpler to think of it as a mapping from processing
    time to event time.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 更准确地说，函数的输入实际上是在观察到水印的管道中的那一点上游的一切的时间 *P* 的状态：输入源、缓冲数据、正在处理的数据等等；但在概念上，将其简单地视为从处理时间到事件时间的映射会更简单。
- en: ⁵ Note that I specifically chose to omit the value of 9 from the heuristic watermark
    because it will help me to make some important points about late data and watermark
    lag. In reality, a heuristic watermark might be just as likely to omit some other
    value(s) instead, which in turn could have significantly less drastic effect on
    the watermark. If winnowing late-arriving data from the watermark is your goal
    (which is very valid in some cases, such as abuse detection, for which you just
    want to see a significant majority of the data as quickly as possible), you don’t
    necessarily want a heuristic watermark rather than a perfect watermark. What you
    really want is a percentile watermark, which explicitly drops some percentile
    of late-arriving data from its calculations. See Chapter 3.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我特意选择省略启发式水印中值为 9 的价值，因为这将帮助我就延迟数据和水印滞后做出一些重要观点。实际上，启发式水印可能会选择省略其他一些值，这反过来可能会对水印产生显著较小的影响。如果筛选迟到的数据是你的目标（在某些情况下非常有效，比如滥用检测，你只想尽快看到大部分数据），你不一定想要启发式水印而不是完美水印。你真正想要的是百分位水印，它明确地从计算中删除一些百分位的迟到数据。参见第
    3 章。
- en: ⁶ Which isn’t to say there aren’t use cases that care primarily about correctness
    and not so much about latency; in those cases, using an accurate watermark​ as
    the sole driver of output from a pipeline is a reasonable approach.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是说没有主要关心正确性而不太关心延迟的用例；在这些情况下，使用准确的水印作为管道输出的唯一驱动是一个合理的方法。
- en: ⁷ And, as we know from before, this assertion is either guaranteed, in the case
    of a perfect watermark being used, or an educated guess, in the case of a heuristic
    watermark.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所知，这种断言要么是有保证的，如果使用完美的水印，要么是一个有根据的猜测，如果使用启发式水印。
- en: '⁸ You might note that there should logically be a fourth mode: discarding and
    retracting. That mode isn’t terribly useful in most cases, so I don’t discuss
    it further here.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，逻辑上应该有第四种模式：丢弃和撤销。在大多数情况下，这种模式并不是非常有用，所以我在这里不再讨论它。
- en: '⁹ In retrospect, it probably would have been clearer to choose a different
    set of names that are more oriented toward the observed nature of data in the
    materialized stream (e.g., “output modes”) rather than names describing the state
    management semantics that yield those data. Perhaps: discarding mode → delta mode,
    accumulating mode → value mode, accumulating and retracting mode → value and retraction
    mode? However, the discarding/accumulating/accumulating and retracting names are
    enshrined in the 1.x and 2.x lineages of the Beam Model, so I don’t want to introduce
    potential confusion in the book by deviating. Also, it’s very likely accumulating
    modes will blend into the background more with Beam 3.0 and the introduction of
    [sink triggers](https://s.apache.org/beam-sink-triggers); more on this when we
    discuss SQL in Chapter 8.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾起来，也许选择一组更加面向物化流中数据观察性质的名称会更清晰一些（例如，“输出模式”），而不是描述产生这些数据的状态管理语义的名称。也许：丢弃模式
    → 增量模式，累积模式 → 值模式，累积和撤销模式 → 值和撤销模式？然而，丢弃/累积/累积和撤销的名称已经成为 Beam 模型的 1.x 和 2.x 系列的一部分，所以我不想在书中引入潜在的混淆。此外，随着
    Beam 3.0 和 [sink triggers](https://s.apache.org/beam-sink-triggers) 的引入，累积模式很可能会更加淡化；关于这一点，我们将在第
    8 章讨论 SQL 时详细介绍。
