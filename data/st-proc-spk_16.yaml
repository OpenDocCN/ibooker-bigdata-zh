- en: Chapter 12\. Event Time–Based Stream Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章\. 基于事件时间的流处理
- en: In [“The Effect of Time”](ch02.xhtml#event-time-intro), we discussed the effect
    of time in stream processing from a general perspective.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [“时间的影响”](ch02.xhtml#event-time-intro) 中，我们从一般角度讨论了流处理中时间的影响。
- en: As we recall, *event-time processing* refers to looking at the stream of events
    from the timeline at which they were produced and applying the processing logic
    from that perspective. When we are interested in analyzing the patterns of the
    event data over time, it is necessary to process the events as if we were observing
    them at the time they were produced. To do this, we require the device or system
    that produces the event to “stamp” the events with the time of creation. Hence,
    the usual name “timestamp” to refer to a specific event-bound time. We use that
    time as our frame of reference for how time evolves.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们回忆的那样，*事件时间处理* 指的是从产生时的时间轴观察事件流，并从这个视角应用处理逻辑。当我们有兴趣分析事件数据随时间变化的模式时，有必要像在事件产生时观察它们一样处理事件。为此，我们需要设备或系统在事件产生时为其“盖上时间戳”。因此，特定事件绑定时间通常称为“时间戳”。我们使用这个时间作为我们的时间演变参考框架。
- en: To illustrate this concept, let’s explore a familiar example. Consider a network
    of weather stations used to monitor local weather conditions. Some remote stations
    are connected through the mobile network, whereas others, hosted at volunteering
    homes, have access to internet connections of varying quality. The weather monitoring
    system cannot rely on the arrival order of the events because that order is mostly
    dependent on the speed and reliability of the network they are connected to. Instead,
    the weather application relies on each weather station to timestamp the events
    delivered. Our stream processing then uses these timestamps to compute the time-based
    aggregations that feed the weather forecasting system.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个概念，让我们探讨一个熟悉的例子。考虑一个用于监控本地天气状况的天气站网络。一些远程站点通过移动网络连接，而其他一些站点则托管在志愿者家中，其可访问的互联网连接质量不同。天气监测系统不能依赖事件的到达顺序，因为这种顺序主要依赖于它们连接到的网络的速度和可靠性。相反，天气应用依赖于每个天气站为传递的事件标记时间戳。我们的流处理然后使用这些时间戳来计算基于时间的聚合，供天气预报系统使用。
- en: The capability of a stream-processing engine to use event time is important
    because we are usually interested in the relative order in which events were produced,
    not the sequence in which the events are processed. In this chapter, we learn
    how Structured Streaming provides seamless support for event-time processing.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理引擎使用事件时间的能力很重要，因为我们通常关注事件产生的相对顺序，而不是事件处理的顺序。在本章中，我们将了解结构化流处理如何无缝支持事件时间处理。
- en: Understanding Event Time in Structured Streaming
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解结构化流处理中的事件时间
- en: At the server side, the notion of time is ruled by the internal clock of the
    computers running any given application. In the case of distributed applications
    running on a cluster of machines, it is a mandatory practice to use a clock synchronization
    technique and protocol such as *Network Time Protocol* (NTP) to align all clocks
    to the same time. The purpose is that the different parts of a distributed application
    running on a cluster of computers can make consistent decisions about the timeline
    and relative ordering of events.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务器端，时间的概念由运行任何给定应用程序的计算机的内部时钟控制。对于在机群上运行的分布式应用程序，使用诸如*网络时间协议*（NTP）等时钟同步技术和协议是强制性的做法，以将所有时钟调整到同一时间。其目的是，运行在一群计算机集群上的分布式应用程序的不同部分可以对事件的时间轴和相对顺序做出一致的决策。
- en: However, when data is coming from external devices, such as sensor networks,
    other datacenters, mobile phones, or connected cars, to name few examples, we
    have no guarantees that their clocks are aligned with our cluster of machines.
    We need to interpret the timeline of the incoming events from the perspective
    of the producing system and not in reference to the internal clock of the processing
    system. [Figure 12-1](#internal-event-timeline) depicts this scenario.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当数据来自外部设备，例如传感器网络、其他数据中心、手机或连接的汽车等，我们无法保证它们的时钟与我们集群中的机器对齐。我们需要从产生系统的角度解释传入事件的时间轴，而不是参考处理系统的内部时钟。[图 12-1](#internal-event-timeline)
    描绘了这种场景。
- en: '![spas 1201](Images/spas_1201.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![spas 1201](Images/spas_1201.png)'
- en: Figure 12-1\. Internal event timeline
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-1\. 内部事件时间线
- en: 'In [Figure 12-1](#internal-event-timeline), we visualize how the time is handled
    in Structured Streaming:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 12-1](#internal-event-timeline)中，我们展示了结构化流处理中时间处理的方式：
- en: In the x-axis, we have the processing time, the clock time of the processing
    system.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在x轴上，我们有处理时间，即处理系统的时钟时间。
- en: The y-axis represents the internal representation of the event time timeline.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: y轴表示事件时间轴的内部表示。
- en: Events are represented with a circle with their corresponding event time label
    next to them.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件以圆圈表示，并且其对应的事件时间标签显示在旁边。
- en: The event arrival time corresponds to the time on the x-axis.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件到达时间对应于x轴上的时间。
- en: 'As events arrive in the system, our internal notion of time progresses:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着事件进入系统，我们内部的时间概念也在不断前进：
- en: The first event, `00:08`, arrives into the system at `00:07`, “early” from the
    point of view of the machine clock. We can appreciate that the internal clock
    time does not affect our perception of the event timeline.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个事件`00:08`在`00:07`进入系统，“早”于机器时钟的视角。我们可以理解，内部时钟时间不影响我们对事件时间轴的感知。
- en: The event timeline advances to `00:08`.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 事件时间轴前进到`00:08`。
- en: The next batch of events, `00:10`, `00:12`, `00:18` arrive for processing. The
    event timeline moves up to `00:18` because it’s the maximum observed time so far.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一批事件，`00:10`、`00:12`、`00:18`到达进行处理。事件时间轴提升到`00:18`，因为这是到目前为止观察到的最大时间。
- en: '`00:15` enters the system. The event timeline remains in its current value
    of `00:18` as `00:15` is earlier than the current internal time.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`00:15`进入系统。由于`00:15`早于当前内部时间的`00:18`，事件时间轴保持其当前值。'
- en: Likewise, `00:11` and `00:09` are received. Should we process these events or
    are they too late?
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，接收到了`00:11`和`00:09`。我们应该处理这些事件吗，还是已经太晚了？
- en: When the next set of events are processed, `00:14`, `00:25`, `00:28`, the streaming
    clock increases up to their maximum of `00:28`.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理下一组事件时，`00:14`、`00:25`、`00:28`，流式处理时钟增加到它们的最大值`00:28`。
- en: In general, Structured Streaming infers the timeline of the events processed
    with event time by keeping a monotonically increasing upper bound of the field
    declared as timestamp in the events. This nonlinear timeline is the ruling clock
    used for the time-based processing features in this chapter. The ability of Structured
    Streaming to understand the time flow of the event source decouples the event
    generation from the event processing time. In particular, we can replay a sequence
    of past events and have Structured Streaming produce the correct results for all
    event-time aggregations. We could, for example, replay a week’s worth of events
    in a few minutes and have our system produce results consistent with a week period.
    This would be impossible if time were governed by the computer clock.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，结构化流处理通过保持在事件中声明为时间戳字段的单调递增上界来推断事件处理的时间轴。这个非线性时间轴是本章时间处理特性中使用的主要时钟。结构化流处理理解事件源时间流动的能力将事件生成与事件处理时间分离开来。例如，我们可以回放一周内的事件序列，并且结构化流处理能够为所有事件时间聚合产生正确的结果。如果时间由计算机时钟控制，这是不可能的。
- en: Using Event Time
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用事件时间
- en: 'In Structured Streaming, we can take advantage of the built-in support for
    event time in two areas: time-based aggregation and state management.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在结构化流处理中，我们可以利用内置的事件时间支持来进行两个方面的优化：基于时间的聚合和状态管理。
- en: In both cases, the first step is to have a field in our data in the right format
    for Structured Streaming to understand it as a timestamp.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，第一步都是确保我们的数据中有一个以正确格式存在的字段，以便结构化流处理能够将其理解为时间戳。
- en: Spark SQL supports `java.sql.Timestamp` as a `Timestamp` type. For other base
    types, we need to first convert the value to a `Timestamp` before we can use it
    for event-time processing. In [Table 12-1](#obtaining_timestamp_field), the initial
    `ts` field contains the timestamp of a given type, and we summarize how to obtain
    the corresponding `Timestamp` type.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Spark SQL支持`java.sql.Timestamp`作为`Timestamp`类型。对于其他基本类型，我们需要先将值转换为`Timestamp`，然后才能用于事件时间处理。在[表 12-1](#obtaining_timestamp_field)中，初始的`ts`字段包含给定类型的时间戳，并总结了如何获取相应的`Timestamp`类型。
- en: Table 12-1\. Obtaining a Timestamp field
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12-1\. 获取时间戳字段
- en: '| `ts` base type | SQL function |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| `ts`基本类型 | SQL函数 |'
- en: '| --- | --- |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `Long` | `$"ts".cast(TimestampType))` |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| `Long` | `$"ts".cast(TimestampType))` |'
- en: '| `String` with default format *yyyy-MM-dd HH:mm:ss* | `$"ts".cast(TimestampType)`
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 默认格式为*yyyy-MM-dd HH:mm:ss*的`String` | `$"ts".cast(TimestampType)` |'
- en: '| `String` with default format *yyyy-MM-dd HH:mm:ss* (alternative) | to_timestamp($"ts”)
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 使用默认格式*yyyy-MM-dd HH:mm:ss*的`String`（备选） | `to_timestamp($"ts”)` |'
- en: '| `String` with a custom format. eg.*dd-MM-yyyy HH:mm:ss* | `to_timestamp($"ts",
    "dd-MM-yyyy HH:mm:ss")` |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 使用自定义格式的`String`，例如*dd-MM-yyyy HH:mm:ss* | `to_timestamp($"ts", "dd-MM-yyyy
    HH:mm:ss")` |'
- en: Processing Time
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理时间
- en: As we discussed in the introduction of this section, we make a distinction between
    event-time and processing-time processing. Event time relates to the timeline
    at which events were produced and is independent of the time of processing. In
    contrast, processing time is the timeline when events are ingested by the engine,
    and it is based on the clock of the computers processing the event stream. It’s
    is the “now” when the events enter the processing engine.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本节介绍中讨论的那样，我们区分事件时间和处理时间处理之间的区别。事件时间指的是事件产生时的时间轴，与处理时间无关。相反，处理时间是事件流被处理引擎摄取时的时间轴，基于处理事件流的计算机时钟。这是事件进入处理引擎时的“现在”。
- en: There are cases in which the event data does not contain time information, but
    we still want to take advantage of the native time-based functions offered by
    Structured Streaming. In those cases, we can add a *processing-time* timestamp
    to the event data and use that timestamp as the event time.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有些情况下，事件数据不包含时间信息，但我们仍然希望利用结构化流提供的本地基于时间的函数。在这些情况下，我们可以向事件数据添加*处理时间*时间戳，并将该时间戳用作事件时间。
- en: 'Continuing with the same example, we can add processing-time information using
    the `current_timestamp` SQL function:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 继续使用相同的示例，我们可以使用`current_timestamp` SQL函数添加处理时间信息：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Watermarks
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 水印
- en: At the beginning of the chapter, we learned that external factors can affect
    the delivery of event messages and, hence, when using event time for processing,
    we didn’t have a guarantee of order or delivery. Events might be late or never
    arrive at all. How late is too late? For how long do we hold partial aggregations
    before considering them complete? To answer these questions, the concept of watermarks
    was introduced in Structured Streaming. A watermark is a time threshold that dictates
    how long we wait for events before declaring that they are too late. Events that
    are considered late beyond the watermark are discarded.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章开头，我们学到外部因素可能影响事件消息的传递，因此，在使用事件时间进行处理时，我们无法保证顺序或传递。事件可能会延迟或根本不到达。延迟多久才算太晚？我们在考虑它们完整之前要保持部分聚合多长时间？为了回答这些问题，结构化流引入了水印的概念。水印是一个时间阈值，指定我们在声明事件太晚之前等待多长时间。超过水印视为过期的事件将被丢弃。
- en: Watermarks are computed as a threshold based on the internal time representation.
    As we can appreciate in [Figure 12-2](#watermark-timeline), the watermark line
    is a shifted line from the event-time timeline inferred from the event’s time
    information. In this chart, we can observe that all events falling in the “gray
    area” below the *watermark* line are considered “too late” and will not be taken
    into consideration in the computations consuming this event stream.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 水印是基于内部时间表示的阈值计算的。正如我们可以在[图 12-2](#watermark-timeline)中看到的，水印线是从事件时间线推断出的时间线的一条移动线。在这个图表中，我们可以观察到所有落在“灰色区域”下方的事件都被认为“太晚”，并且在消费该事件流的计算中将不予考虑。
- en: '![spas 1202](Images/spas_1202.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![spas 1202](Images/spas_1202.png)'
- en: Figure 12-2\. Watermark with the internal event timeline
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-2\. 内部事件时间轴上的水印
- en: 'We declare a watermark by linking our `timestamp` field with the time threshold
    corresponding to the watermark. Continuing with the [Table 12-1](#obtaining_timestamp_field),
    we declare a watermark like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将`timestamp`字段与水印对应的时间阈值链接来声明水印。继续使用[表 12-1](#obtaining_timestamp_field)的示例，我们可以这样声明水印：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Time-Based Window Aggregations
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于时间窗口的聚合
- en: A natural question that we want to pose to streams of data is aggregated information
    at regular intervals of time. As streams are potentially never-ending, instead
    of asking “how many X are there?” in a stream-processing context, we are more
    interested in knowing “how many X were there in 15-minute intervals.”
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对数据流想要提出的一个自然问题是在固定时间间隔内的聚合信息。由于流可能永无止境，所以在流处理上下文中，我们更感兴趣的是知道在15分钟间隔内“有多少个X”。
- en: With the use of event-time processing, Structured Streaming removes the usual
    complexity of dealing with intermediate state in the face of the event delivery
    challenges that we have discussed in this chapter. Structured Streaming takes
    care of keeping partial aggregates of data and of updating the downstream consumer
    using the semantics corresponding to the chosen output mode.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用事件时间处理，结构化流处理消除了在面对我们在本章讨论过的事件传递挑战时处理中间状态的通常复杂性。结构化流处理负责保持数据的部分聚合，并使用与选择的输出模式相对应的语义更新下游消费者。
- en: Defining Time-Based Windows
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义基于时间的窗口
- en: We discussed the concept of window-based aggregations in [“Window Aggregations”](ch02.xhtml#windows-discussion),
    in which we presented the definitions of *tumbling* and *sliding* windows. In
    Structured Streaming, the built-in event-time support makes it easy to define
    and use such window-based operations.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[“窗口聚合”](ch02.xhtml#windows-discussion)中讨论了基于窗口的聚合概念，介绍了*tumbling*和*sliding*窗口的定义。在结构化流处理中，内置的事件时间支持使得定义和使用此类基于窗口的操作变得简单。
- en: From the API perspective, window aggregations are declared using a `window`
    function as grouping criteria. The `window` function must be applied to the field
    that we want to use as event time.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从API的角度来看，窗口聚合使用`window`函数作为分组条件来声明。`window`函数必须应用于我们希望用作事件时间的字段。
- en: Continuing with our weather station scenario, in [Example 12-1](#computing_totalized_averages)
    we can compute the average pressure each 10 minutes totalized across all reporting
    stations.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续我们的气象站场景时，在[示例 12-1](#computing_totalized_averages)中，我们可以计算每10分钟全报告站点的平均压力。
- en: Example 12-1\. Computing totalized averages
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 12-1\. 计算总平均数
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this example, we observe that the resulting schema of a windowed aggregation
    contains the window period, indicated with `start` and `end` timestamp for each
    resulting window, together with the corresponding computed values.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们观察到窗口聚合的结果模式包含窗口期，用`start`和`end`时间戳指示每个生成的窗口，以及相应的计算数值。
- en: Understanding How Intervals Are Computed
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解如何计算间隔
- en: The window intervals are aligned to the start of the second/minute/hour/day
    that corresponds to the next upper time magnitude of the time unit used. For example,
    a `window($"timestamp", "15 minutes")` will produce 15-minute intervals aligned
    to the start of the hour.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口间隔与开始小时对应的第二/分钟/小时/天对齐。例如，`window($"timestamp", "15 minutes")`将生成以小时开始对齐的15分钟间隔。
- en: The start time of the first interval is in the past to adjust the window alignment
    without any data loss. This implies that the first interval might contain only
    a fraction of the usual interval worth of data. So, if we are receiving about
    100 messages per second, we expect to see about 90,000 messages in 15 minutes,
    whereas our first window might be just a fraction of that.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个间隔的开始时间是在过去，以调整窗口对齐而没有任何数据丢失。这意味着第一个间隔可能只包含通常间隔数据的一小部分。因此，如果我们每秒接收大约100条消息，那么在15分钟内我们预计会看到大约90,000条消息，而我们的第一个窗口可能只是这些数据的一小部分。
- en: The time intervals in a window are inclusive at the start and exclusive at the
    end. In *interval notation*, this is written as `[start-time, end-time)`. Using
    the 15-minute intervals as defined earlier, a data point that arrives with timestamp
    `11:30:00.00` will belong to the `11:30-11:45` window interval.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口中的时间间隔在开始时包含，结束时不包含。在*间隔表示法*中，这写作`[start-time, end-time)`。根据之前定义的15分钟间隔，具有时间戳`11:30:00.00`的数据点将属于`11:30-11:45`的窗口间隔。
- en: Using Composite Aggregation Keys
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用复合聚合键
- en: In [Example 12-1](#computing_totalized_averages), we calculated globally aggregated
    values for the pressure and temperature sensors. We are also interested in computing
    aggregated values for each weather station. We can achieve that by creating a
    composite aggregation key where we add the `stationId` to the aggregation criteria
    in the same way that we would do that with the static `DataFrame` API. [Example 12-2](#computing_per_id_averages)
    illustrates how we do this.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 12-1](#computing_totalized_averages)中，我们为压力和温度传感器计算了全局聚合值。我们还对每个气象站计算聚合值感兴趣。我们可以通过创建一个复合聚合键来实现这一点，其中我们将`stationId`添加到聚合条件中，就像我们在静态`DataFrame`
    API中处理一样。[示例 12-2](#computing_per_id_averages)说明了我们如何做到这一点。
- en: Example 12-2\. Computing averages per station
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 12-2\. 每个站点的平均数计算
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Tumbling and Sliding Windows
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Tumbling和Sliding窗口
- en: '`window` is a SQL function that takes a `timeColumn` of `TimestampType` type
    and additional parameters to specify the duration of the window:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`window`是一个SQL函数，接受`TimestampType`类型的`timeColumn`和额外的参数来指定窗口的持续时间：'
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Overloaded definitions of this method make `slideDuration` and `startTime` optional.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法的过载定义使`slideDuration`和`startTime`成为可选项。
- en: 'This API lets us specify two kinds of windows: tumbling and sliding windows.
    The optional `startTime` can delay the creation of the window, for example, when
    we want to allow the stream throughput to stabilize after a ramp-up period.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此API允许我们指定两种窗口类型：滚动窗口和滑动窗口。可选的`startTime`可以延迟窗口的创建，例如当我们希望在流量稳定之后允许一个上升期之后。
- en: Tumbling windows
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 滚动窗口
- en: 'Tumbling windows segment the time in nonoverlapping, contiguous periods. They
    are the natural window operation when we refer to a “total count each 15 minutes”
    or “production level per generator each hour.” We specify a tumbling window by
    only providing the `windowDuration` parameter:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动窗口将时间段分割为不重叠的连续周期。当我们需要“每15分钟的总计”或“每小时每个发电机的生产水平”时，它们是自然的窗口操作。我们通过仅提供`windowDuration`参数来指定滚动窗口：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This `window` definition produces one result every five minutes.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 此`window`定义每五分钟生成一个结果。
- en: Sliding windows
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 滑动窗口
- en: 'In contrast with tumbling windows, sliding windows are overlapping intervals
    of time. The size of the interval is determined by the `windowDuration` time.
    All values from the stream in that interval come into consideration for the aggregate
    operation. For the next slice, we add the elements arriving during `slideDuration`,
    remove the elements corresponding to the oldest *slice*, and apply the aggregation
    to the data within the window, producing a result at each `slideDuration`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与滚动窗口相比，滑动窗口是重叠的时间间隔。间隔的大小由`windowDuration`确定。在该间隔内流中的所有值都将考虑在内进行聚合操作。对于下一个切片，我们添加在`slideDuration`期间到达的元素，移除对应于最旧*切片*的元素，并对窗口内的数据应用聚合，每个`slideDuration`生成一个结果：
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This window definition uses 10 minutes’ worth of data to produce a result every
    minute.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此窗口定义使用10分钟的数据每分钟生成一个结果。
- en: 'It’s worth noting that a tumbling window is a particular case of a sliding
    window in which `windowDuration` and `slideDuration` have equal values:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，滚动窗口是滑动窗口的一种特例，其中`windowDuration`和`slideDuration`具有相等的值：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It is illegal to use a `slideInterval` larger than the `windowDuration`. Structured
    Streaming will throw an `org.apache.spark.sql.AnalysisException` error if such
    a case occurs.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`slideInterval`大于`windowDuration`，使用这种情况会导致Structured Streaming抛出`org.apache.spark.sql.AnalysisException`错误是非法的。
- en: Interval offset
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 时间间隔偏移
- en: The third parameter in the window definition, called `startTime`, provides a
    way to offset the window alignment. In [“Understanding How Intervals Are Computed”](#computing_intervals)
    we saw that the window intervals are aligned to the upper-next time magnitude.
    `startTime` (a misnomer in our opinion) lets us offset the window intervals by
    the indicated time.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口定义的第三个参数称为`startTime`，提供了一种偏移窗口对齐的方式。在[“理解如何计算间隔”](#computing_intervals)中，我们看到窗口间隔对齐到上一个时间量级。`startTime`（在我们看来是一个误称）允许我们按照指定的时间偏移窗口间隔。
- en: In the following window definition, we offset a 10-minute window with a slide
    duration of 5 minutes by 2 minutes, resulting in time intervals like `00:02-00:12,
    00:07-00:17, 00:12-00:22, ...`
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下窗口定义中，我们通过2分钟偏移一个10分钟窗口，滑动间隔为5分钟，结果是时间间隔如`00:02-00:12, 00:07-00:17, 00:12-00:22,
    ...`
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`startTime` must strictly be less than `slideDuration`. Structured Streaming
    will throw an `org.apache.spark.sql.AnalysisException` error if an invalid configuration
    is provided. Intuitively, given that `slideDuration` provides the periodicity
    at which the window is reported, we can offset that period for only a time that
    is less than the period itself.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`startTime`必须严格小于`slideDuration`。如果提供了无效的配置，Structured Streaming将抛出`org.apache.spark.sql.AnalysisException`错误。直观地说，鉴于`slideDuration`提供了报告窗口的周期性，我们可以偏移该周期仅一段小于该周期本身的时间。'
- en: Record Deduplication
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录去重
- en: Structured Streaming offers a built-in function that removes duplicate records
    in the stream. It is possible to specify a watermark that determines when it is
    safe to discard previously seen keys.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化流处理提供了一个内置函数，用于移除流中的重复记录。可以指定一个水印，确定何时安全丢弃先前见过的键。
- en: 'The base form is quite simple:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 基本形式相当简单：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Nevertheless, this base method is discouraged, as it requires you to store all
    received values for the set of fields defining a unique record, which can potentially
    be unbounded.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这种基本方法并不被鼓励，因为它要求您存储定义唯一记录的字段集合的所有接收到的值，这可能会导致无界的情况。
- en: 'A more robust alternative involves specifying a watermark on the stream before
    the `dropDuplicates` function:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 更健壮的替代方案是在`dropDuplicates`函数之前在流上指定水印：
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: When using a watermark, keys older than the watermark become eligible for deletion,
    allowing the state store to keep its storage needs bounded.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使用水印时，早于水印的键变得符合删除条件，使状态存储能够保持其存储需求有界。
- en: Summary
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter we explored how Structured Streaming implements the concept
    of event time and the facilities the API offers to make use of time embedded in
    the event data:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了结构化流如何实现事件时间的概念以及API提供的使用事件数据中嵌入的时间的设施：
- en: We learned how to use event time and how to fall back on processing time, when
    needed.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们学习了如何使用事件时间，以及在需要时如何回退到处理时间。
- en: We explored watermarks, an important concept that lets us determine which events
    are too late and when state-related data might be evicted from the store.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们探讨了水印，这是一个重要的概念，让我们能够确定哪些事件已经太迟，以及何时可能从存储中删除与状态相关的数据。
- en: We saw the different configuration for window operations and their link with
    event time.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们看到了窗口操作的不同配置及其与事件时间的关联。
- en: Finally, we learned about the deduplication function in how it uses watermarks
    to keep its state bounded.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们学习了关于去重函数如何使用水印来保持其状态有界的内容。
- en: Event-time processing is a powerful set of features built into Structured Streaming
    that encapsulates the complexity of dealing with time, ordering, and lateness
    into an easy-to-use API.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 事件时间处理是结构化流中内置的一组强大特性，它封装了处理时间、顺序和延迟的复杂性，提供了易于使用的API。
- en: Nevertheless, there are cases when the built-in functions are not sufficient
    to implement certain stateful processes. For those cases, Structured Streaming
    offers advanced functions to implement arbitrary stateful processes, as we see
    in the next chapter.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，在某些情况下内置函数无法足够实现特定的有状态处理。对于这些情况，结构化流提供了高级函数来实现任意的有状态处理，正如我们在下一章中所见。
