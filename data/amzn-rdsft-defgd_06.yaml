- en: Chapter 5\. Scaling and Performance Optimizations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 扩展与性能优化
- en: If we told you that the only constant is change, then most likely we would be
    “preaching to the choir.” The challenge today is how fast your data warehouse
    can adapt to the change. With traditional data warehousing systems, this change
    is often difficult because of lead time to provision resources. With Amazon Redshift,
    adapting to change is easy, be it changes in storage needs or changes in compute
    needs. There are no expensive wrong decisions as you can quickly scale with the
    increase or decrease in demand.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们告诉您唯一不变的是变化，那么很可能我们只是“对牛弹琴”。今天的挑战是您的数据仓库能够多快地适应变化。传统的数据仓库系统，由于资源预配的提前时间，往往很难适应这种变化。通过
    Amazon Redshift，适应变化变得容易，无论是存储需求的变化还是计算需求的变化。您可以快速根据需求的增加或减少来进行扩展，而不会产生昂贵的错误决策。
- en: 'The objective of scaling is to meet changes in your workload to maintain current
    performance levels and associated SLA. If you add new workloads to your warehouse,
    then existing workload SLAs can get impacted; this is where scaling comes in.
    Scaling could also be required if you are analyzing more data than before, which
    has caused a visible impact to your workload SLAs. To achieve your scaling goals
    using Amazon Redshift, there are two strategies to consider: ensuring your data
    warehouse is sized correctly and ensuring that your workloads are tuned for performance.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展的目标是为了满足工作负载的变化，以维持当前的性能水平和相关的 SLA。如果您向数据仓库添加新的工作负载，则现有的工作负载 SLA 可能会受到影响；这就是扩展发挥作用的地方。如果您分析的数据比以前多，这可能导致工作负载
    SLA 显著影响，也可能需要扩展。为了通过 Amazon Redshift 实现您的扩展目标，有两种策略需要考虑：确保您的数据仓库大小正确，并确保您的工作负载经过性能调优。
- en: With Amazon Redshift, you can size your data warehouse by scaling the compute
    vertically as well as horizontally (see [Figure 5-1](#scaling_5_1)). *Vertical
    scaling* is when you scale “up” by having additional compute that is operating
    on a single query. Scaling up results in the total number of vCPUs or memory increasing.
    If you need to retain the SLAs of existing workloads and still take on additional
    workloads, then you typically will scale “up” your data warehouse. Scaling up
    is typically used when your workload changes are predictable and allows you to
    run larger queries that are pulling lots of rows, handling more connections, and
    managing longer transactions. *Horizontal scaling* is when you scale “out” by
    adding more replicas to handle additional workload. When you scale out, each query
    may be served by isolated compute reading from the shared data. Scaling out is
    typically used when your workload changes are unpredictable as each individual
    query receives the same compute, but the system can handle more concurrent workload.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Amazon Redshift，您可以通过垂直和水平扩展来调整数据仓库的大小（参见 [Figure 5-1](#scaling_5_1)）。*垂直扩展*
    是指通过在单个查询上运行的额外计算来进行“向上”扩展。向上扩展导致 vCPU 或内存总数增加。如果您需要保持现有工作负载的 SLA 并处理额外的工作负载，则通常会“向上”扩展您的数据仓库。垂直扩展通常用于工作负载变化可预测的情况，允许您运行拉取大量行、处理更多连接并管理更长事务的更大查询。*水平扩展*
    是指通过添加更多副本来处理额外工作负载的“向外”扩展。当您进行水平扩展时，每个查询可能由独立计算提供服务，从共享数据中读取。水平扩展通常用于工作负载变化不可预测的情况，因为每个单独的查询都会接收相同的计算资源，但系统可以处理更多并发工作负载。
- en: In this chapter, we’ll show you how Amazon Redshift will automatically [“Scale
    Storage”](#storage_scaling) if you’re using servlerless or an RA3 provisioned
    data warehouse. In addition, we’ll see how for a serverless data warehouse, Amazon
    Redshift will [“Autoscale Your Serverless Data Warehouse”](#scale_serverless)
    in either direction based on the workload and for a provisioned data warehouse,
    how you can choose when and in which direction to [“Scale Your Provisioned Data
    Warehouse”](#scale_provisioned).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将向您展示，如果您使用无服务器或者 RA3 预配置的数据仓库，Amazon Redshift 将会自动[“扩展存储”](#storage_scaling)。此外，我们将看到，对于无服务器数据仓库，Amazon
    Redshift 将会根据工作负载[“自动扩展您的无服务器数据仓库”](#scale_serverless)，可以是向任何方向。而对于预配置的数据仓库，您可以选择何时以及何种方向[“扩展您的预配置数据仓库”](#scale_provisioned)。
- en: '![Vertical versus horizontal scaling](assets/ardg_0501.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![竖向与横向扩展](assets/ardg_0501.png)'
- en: Figure 5-1\. Vertical versus horizontal scaling
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-1\. 竖向与横向扩展
- en: While ensuring your Amazon Redshift data warehouse is sized correctly is very
    important, equally important is ensuring your workloads are tuned for performance.
    The combination of activities will ensure you are making the best use of your
    resources and you are getting the best price performance. To tune your workload
    for performance, there are many features in Amazon Redshift that apply to both
    serverless and provisioned data warehouses. In this chapter, we’ll cover some
    of the best practices. We will describe [“WLM, Queues, and QMR”](#wlm_qmr), which
    is a feature specific to provisioned data warehouses. We will show you how [“Materialized
    Views”](#mv) can support different access patterns, how [“Autonomics”](#Autonomics)
    will ensure your tables are well maintained, and how [“Workload Isolation”](#workload_isolation)
    can ensure mixed workloads have the compute they need. We will then provide a
    detailed look at how queries are executed and how you should think about [“Query
    Tuning”](#query_tuning). Finally, we’ll describe a few [“Additional Optimizations
    for Achieving the Best Price and Performance”](#optimizing_price_performance).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你的Amazon Redshift数据仓库大小设置正确非常重要，同样重要的是确保你的工作负载经过调优以提升性能。这两者的结合将确保你充分利用资源，并获得最佳性价比。为了提升工作负载的性能，Amazon
    Redshift提供了许多功能，适用于无服务器和预置数据仓库。在本章中，我们将介绍一些最佳实践。我们将描述[“WLM，队列和QMR”](#wlm_qmr)，这是预置数据仓库特有的功能。我们将展示[“Materialized
    Views”](#mv)如何支持不同的访问模式，[“Autonomics”](#Autonomics)如何确保表的良好维护，以及[“Workload Isolation”](#workload_isolation)如何确保混合工作负载获得所需的计算资源。接下来，我们将详细介绍查询的执行方式以及如何考虑[“Query
    Tuning”](#query_tuning)。最后，我们将描述几种[“实现最佳性价比的额外优化”](#optimizing_price_performance)。
- en: Scale Storage
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展存储
- en: In [Chapter 2, “Getting Started with Amazon Redshift”](ch02.html#AR_TGD_CH2)
    we described how Amazon Redshift is backed by RMS when using serverless or an
    RA3 provisioned data warehouse. The benefit of RMS is storage elasticity, meaning
    you don’t need to resize your compute simply to accommodate additional historical
    data. Consider that your data warehouse is typically executing analytical workloads
    on the last 12 months of data. New data is being added every day, but your compute
    needs are limited to analyzing the last 12 months. In this scenario, your compute
    costs will stay the same irrespective of whether your warehouse contains two years
    of data or five years of data. Since your storage demand has increased, you shall
    only be paying for additional storage. This is a more common scenario where a
    data warehouse ends up being a long-term repository of all data, but for analytics
    only the recent data is queried.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章，“开始使用Amazon Redshift”](ch02.html#AR_TGD_CH2)中，我们描述了在使用无服务器或RA3预置数据仓库时，Amazon
    Redshift由RMS支持的情况。使用RMS的好处在于存储弹性，这意味着你不需要简单地调整计算能力来适应额外的历史数据。考虑到你的数据仓库通常仅对最近12个月的数据执行分析工作负载。每天都会添加新数据，但你的计算需求仅限于分析最近12个月的数据。在这种情况下，无论你的仓库包含两年数据还是五年数据，你的计算成本都将保持不变。由于你的存储需求增加，你只需支付额外的存储费用。这种情况更为常见，数据仓库最终变成长期存储所有数据的库，但仅对最近的数据进行分析查询。
- en: Let’s assume that you store 100 GB of data in managed storage with RA3 node
    types for the first 15 days in April, and 100 TB of data for the final 15 days
    in April.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在四月份的前15天内使用RA3节点类型的托管存储中存储了100 GB的数据，并在四月份的最后15天内存储了100 TB的数据。
- en: Let’s calculate the usage in GB-hours for April.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来计算四月份的GB-hours使用量。
- en: 'For the first 15 days, you will have the following usage: `100 GB` × `15 days`
    × `24 hours/day` = `36,000 GB-Hours`.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在四月份的前15天，你将有如下使用量：`100 GB` × `15 天` × `24 小时/天` = `36,000 GB-Hours`。
- en: 'For the last 15 days, you will have the following usage: `100 TB` × `1024 GB/TB`
    × `15 days` × `24 hours/day` = `36,864,000 GB-hours`.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的15天中，你将会有如下使用量：`100 TB` × `1024 GB/TB` × `15 天` × `24 小时/天` = `36,864,000
    GB-hours`。
- en: 'At the end of April, total usage in GB-hours is: `36,000 GB-Hours` + `36,864,000
    GB-hours` = `36,900,000 GB-hours`'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 四月份结束时，GB-hours的总使用量是：`36,000 GB-Hours` + `36,864,000 GB-hours` = `36,900,000
    GB-hours`。
- en: 'Convert this to GB-months: `36,900,000 GB-hours` / `720 hours/month` in April
    = `51,250 GB-months`.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 将其转换为GB-month：`36,900,000 GB-hours` / 四月份的 `720 小时/月` = `51,250 GB-months`。
- en: 'Consider us-east-1 region, where managed storage will be charged at `$0.024/GB-Month`.
    Monthly storage charges for `51,250 GB-month` will be: `51,250 GB-month` × `$0.024
    per GB-month` = `$1,230`.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑us-east-1区域，在这里托管存储将按照`$0.024/GB-Month`收费。对于`51,250 GB-month`的月度存储费用将是：`51,250
    GB-month` × `$0.024 每GB-Month` = `$1,230`。
- en: Total RMS fee for April = `$1,230`
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 四月份的总RMS费用为`$1,230`。
- en: We haven’t shown compute costs here, but they will remain the same irrespective
    of your data growth. If you have paused your cluster and no queries are executing,
    then only RMS cost will apply. Note that you will be billed for storage until
    you delete your cluster, even if no queries are executing.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这里没有展示计算成本，但无论您的数据增长如何，计算成本都将保持不变。如果您暂停了集群并且没有查询在执行，那么只会应用 RMS 成本。请注意，即使没有查询在执行，直到您删除集群，存储费用也会计入账单。
- en: Autoscale Your Serverless Data Warehouse
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动缩放您的无服务器数据仓库
- en: Amazon Redshift serverless automatically scales your data warehouse capacity
    whether you need to scale *up* or scale *out*. Compute resources automatically
    shut down behind the scenes when there is no activity and resume when you are
    loading data or there are queries coming in. With Amazon Redshift serverless,
    you do not need to predict your workload demands or size your compute as it adjusts
    the compute to meet your workload changes. In many cases, the overall compute
    needed to execute your workload may decrease using serverless. With serverless,
    Amazon Redshift will size the compute to meet your workload needs. Queries that
    were previously paging to disk because the compute was undersized will complete
    faster, and queries that were queued will no longer wait.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 无服务器会自动调整您的数据仓库容量，无论您需要扩展还是扩展。在没有活动时，计算资源会在幕后自动关闭，并在加载数据或查询进入时恢复。通过
    Amazon Redshift 无服务器，您无需预测工作负载需求或调整计算大小，因为它会根据工作负载变化调整计算资源。在许多情况下，使用无服务器可能会减少执行工作负载所需的总体计算。使用无服务器，Amazon
    Redshift 将调整计算资源以满足您的工作负载需求。以前因计算资源不足而导致磁盘分页的查询将更快完成，排队等待的查询将不再等待。
- en: Compute capacity is measured in RPUs, and you pay for the workloads in RPU-hours
    with per-second billing. To control your costs, you can specify usage limits and
    define actions that Amazon Redshift automatically takes if those limits are reached.
    You can specify usage limits in RPU-hours and associate the limit to be checked
    either daily, weekly, or monthly. Setting higher usage limits can improve the
    overall throughput of the system, especially for workloads that need to handle
    high concurrency while maintaining consistently high performance. See [Chapter 2,
    “Getting Started with Amazon Redshift”](ch02.html#AR_TGD_CH2), for Amazon Redshift
    serverless pricing examples.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 计算能力以 RPUs 衡量，并且您按照 RPU-hours 计费，采用每秒计费方式。为了控制成本，您可以指定使用限制，并定义当达到这些限制时 Amazon
    Redshift 将自动采取的措施。您可以按照 RPU-hours 指定使用限制，并将限制关联到每日、每周或每月的检查。设置更高的使用限制可以提高系统的整体吞吐量，特别是对需要处理高并发同时保持高性能的工作负载而言。详见
    [第二章，“开始使用 Amazon Redshift”](ch02.html#AR_TGD_CH2)，以了解 Amazon Redshift 无服务器定价示例。
- en: Scale Your Provisioned Data Warehouse
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展您的预配置数据仓库
- en: When you provision your Amazon Redshift cluster, you choose a particular node
    type and a number of nodes. The power of when to scale up by adding more nodes
    or changing the node type and when you scale out by adding parallel compute is
    put in your hands. Typically you will scale up when you have [“Evolving Compute
    Demand”](#evolving_compute) or [“Predictable workload changes”](#predictable_workload),
    and you will also scale up when you have [“Unpredictable Workload Changes”](#unpredictable_workload).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当您配置 Amazon Redshift 集群时，您可以选择特定的节点类型和节点数量。何时扩展（通过添加更多节点或更改节点类型）以及何时扩展（通过添加并行计算）完全由您决定。通常情况下，当您面对[“进化中的计算需求”](#evolving_compute)或[“可预测的工作负载变化”](#predictable_workload)时，您会选择扩展，并且在面对[“不可预测的工作负载变化”](#unpredictable_workload)时也会选择扩展。
- en: Evolving Compute Demand
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进化中的计算需求
- en: To understand the scenario of evolving compute, let’s consider your data warehouse
    project has been immensely successful and you are adding new analytical workloads
    to it, but the data in your warehouse is still the same as you are rolling off
    older data to your data lake. So here your compute needs are growing as you have
    more users querying the data warehouse to get business insights. To maintain the
    same user experience and SLAs to your business users, you can scale your cluster
    up by adding more nodes or migrating to a larger node type.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解进化中计算的情况，让我们假设您的数据仓库项目非常成功，您正在向其中添加新的分析工作负载，但是您的仓库中的数据仍然与以前一样，因为您正在将旧数据转移到数据湖中。因此，在这种情况下，由于有更多用户查询数据仓库以获取业务见解，您的计算需求正在增长。为了保持与业务用户的相同用户体验和服务级别协议，您可以通过添加更多节点或迁移到更大的节点类型来扩展集群。
- en: When scaling up your cluster, your storage cost stays the same as there is no
    change in your data volume.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在扩展您的集群时，您的存储成本保持不变，因为数据量没有变化。
- en: Scaling up by adding nodes or changing the node type of your cluster is a quick
    process and can be done via the AWS console, CLI, or API. For example, if you
    change from a 2-node ra3.4xl cluster to a 2-node ra3.16xl cluster, you have scaled
    up the node four times, from 24 vCPUs to 96 vCPUs, and you get four times the
    compute and memory. Similarly, if you expand your cluster from a 2-node ra3.4xl
    to an 8-node ra3.4xl, you get 96 vCPUs. Scaling up by changing your node type
    can be beneficial if you’ve reached the limits for the current node type. For
    example, imagine you are running a 64-node ra3.4xl cluster. Scaling up to a 16-node
    ra3.16xl cluster will give you the same total compute resources but with a larger
    leader node.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通过增加节点或更改集群的节点类型来扩展是一个快速的过程，可以通过AWS控制台、CLI或API完成。例如，如果您从一个2节点ra3.4xl集群改为一个2节点ra3.16xl集群，您的节点规模增加了四倍，从24个vCPU增加到96个vCPU，并且获得了四倍的计算和内存。同样地，如果您将您的集群从一个2节点ra3.4xl扩展到一个8节点ra3.4xl，您将获得96个vCPU。通过更改节点类型来扩展可以带来益处，如果您已经达到当前节点类型的限制。例如，想象一下您正在运行一个64节点ra3.4xl集群。将其扩展为一个16节点ra3.16xl集群将为您提供相同的总计算资源，但有一个更大的领导节点。
- en: Changing node type requires physical data movement from one type of compute
    to another. You have to plan for downtime, coordinate across teams, and communicate
    schedules to limit impact to systems, applications, and your users.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 更改节点类型需要从一种计算类型到另一种计算类型的物理数据移动。您必须计划停机时间，跨团队协调，并且向系统、应用程序和用户通报日程，以限制影响。
- en: To illustrate how scaling would impact pricing, let’s say that you started with
    2-node ra3.4xlarge cluster and added new projects that needed you to resize to
    5-node cluster on the 15th of the month.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明扩展如何影响定价，假设您从2节点ra3.4xlarge集群开始，并增加了新项目，需要在月中的第15天调整大小到5节点集群。
- en: 'For the first 15 days, you will have the following usage: `$3.26 per node-hour`
    × `2 nodes` × `5 hours/day` × `15 days` = `$489`'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在前15天，您的使用情况如下：`$3.26每个节点小时` × `2节点` × `每天5小时` × `15天` = `$489`
- en: 'For the last 15 days, you will have the following usage: `$3.26 per node-hour`
    × `5 nodes` × `10 hours/day` × `15 days` = `$2,445`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在后15天，您的使用情况如下：`$3.26每个节点小时` × `5节点` × `每天10小时` × `15天` = `$2,445`
- en: Total compute fee for April = `$2,934`
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 四月的总计算费用 = `$2,934`
- en: The following (see [Example 5-1](#scaling_cli)) AWS CLI commands show how to
    scale up by either adding more nodes or choosing a larger node type.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 下列（见[示例 5-1](#scaling_cli)）AWS CLI命令展示如何通过增加节点或选择更大的节点类型来扩展。
- en: Example 5-1\. Scaling provisioned cluster using the CLI
  id: totrans-34
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-1\. 使用CLI扩展预配置集群
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Predictable workload changes
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可预测的工作负载变化
- en: Predictable workload changes are when you expect the change, have some idea
    of timelines, and can come up with a plan to adopt. The predictable change could
    be one-time as explained in the previous examples, or be recurring periodically.
    Let’s say that your steady state workload is processing daily incremental files.
    But on the first of every month you are additionally required to process a reconciliation
    file for the previous month. Now you have optimally sized your Amazon Redshift
    data warehouse for daily files processing, but you need additional compute on
    the first of the month to continue the timely processing of daily incremental
    files and additionally be able to process the reconciliation file.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 可预测的工作负载变化是指您预期的变化，有一些时间线的概念，并且可以制定采纳计划。可预测的变化可以是前面示例中解释的一次性变化，也可以是定期重复的。比如说，您的稳态工作负载每天处理增量文件。但是每月第一天，您还需要处理上个月的对账文件。现在您已经为每日文件处理优化了您的亚马逊Redshift数据仓库，但是您需要在每月的第一天额外的计算来继续及时处理每日增量文件，并且还能处理对账文件。
- en: To handle such a scenario, you can either incorporate the resize as part of
    the monthly processing job workflow or you can schedule a resize to upsize (up
    to 4x) on the first of the month and on the third of the month you downsize back
    to the original node count. Once scheduled, Amazon Redshift will scale up/down
    per your established schedule.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理这种情况，您可以将调整大小作为月度处理作业工作流的一部分，或者您可以计划在每月的第一天进行调整大小（最多增加4倍），并在月的第三天将节点数调整回原始数量。一旦计划好，亚马逊Redshift将根据您建立的日程表进行缩放。
- en: 'Amazon Redshift cron expression format for scheduler is:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊Redshift计划程序的cron表达式格式为：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can also use the built-in scheduler to schedule the resize as shown in [Figure 5-2](#schedule_resize).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用内置调度程序安排调整操作，如 [Figure 5-2](#schedule_resize) 所示。
- en: '![Schedule Resize](assets/ardg_0502.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![定时调整](assets/ardg_0502.png)'
- en: Figure 5-2\. Schedule resize
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-2\. 定时调整
- en: Amazon Redshift offers two methods of [resizing clusters](https://oreil.ly/UEo9E).
    Elastic resize is preferred for such periodic resizes. For permanent resizing
    you can choose classic resize or elastic resize.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 提供两种 [调整集群大小的方法](https://oreil.ly/UEo9E)。弹性调整适合周期性调整。对于永久调整，您可以选择经典调整或弹性调整。
- en: The undocumented table `stv_xrestore_alter_queue_state` can be queried to monitor
    the resize operation progress. Note that the table in [Example 5-2](#monitor_resize)
    captures details only for large-scale resize that are greater than 5 TBs.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 可以查询未记录的表 `stv_xrestore_alter_queue_state` 以监视调整操作的进度。请注意，示例 5-2 中的表仅捕获大于 5
    TB 的大规模调整的详细信息。
- en: Example 5-2\. Monitor the resize operation
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 5-2\. 监视调整操作
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '| db_id | status | count |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| db_id | 状态 | 计数 |'
- en: '| --- | --- | --- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 654321 | Waiting | 456 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 654321 | 等待中 | 456 |'
- en: '| 654321 | Finished | 23 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 654321 | 已完成 | 23 |'
- en: '| 654321 | Applying | 1 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 654321 | 应用中 | 1 |'
- en: Unpredictable Workload Changes
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不可预测的工作负载变化
- en: Predictable changes to workload can be handled by resizing your Amazon Redshift
    data warehouse, but unpredictable workload spikes can become a challenge since
    they can be intermittent by nature. If you provision your cluster to meet the
    peak demand, then this wastes resources during off-peak hours. Your other option
    is to size for typical workloads, which could mean longer waits for important
    business decisions at times when unexpected queries show up. This is where Concurrency
    Scaling (CS) steps in.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整您的亚马逊 Redshift 数据仓库大小，可以处理可预测的工作负载变化，但不可预测的工作负载峰值可能会成为挑战，因为它们可能具有间歇性的特性。如果您为满足峰值需求而配置集群，则在非高峰时段浪费资源。另一种选择是为典型工作负载进行大小调整，这可能意味着在意外查询出现时需要更长时间以作出重要的业务决策。这就是并发缩放（CS）发挥作用的地方。
- en: Amazon Redshift automatically spins off additional scaling clusters to meet
    unpredictable workload spikes, as seen in [Figure 5-3](#concurrency_scaling_5_2).
    Amazon Redshift offers CS for read queries on all its node types, and for RA3
    node types you also get CS for write queries. Subsequent sections cover where
    and how to turn on this feature.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 自动启动额外的扩展集群，以满足不可预测的工作负载峰值，如 [Figure 5-3](#concurrency_scaling_5_2)
    所示。亚马逊 Redshift 在其所有节点类型上为读取查询提供 CS，对于 RA3 节点类型，还可以为写入查询提供 CS。后续章节详细介绍如何启用此功能以及其位置。
- en: You get to choose which queries leverage Concurrency Scaling by configuring
    workload management (WLM) queues, which is covered in [“WLM, Queues, and QMR”](#wlm_qmr).
    CS is triggered when the total wait time for all waiting queries in CS–enabled
    queues is more than a minute. This one-minute setting can be changed by working
    with AWS Support for instances when you want more aggressive CS. Once a CS cluster
    has been launched, then any new queries coming in the CS enabled queues do not
    wait anymore and instead are sent directly to the CS cluster.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通过配置工作负载管理（WLM）队列来选择哪些查询利用并发缩放，详情请参阅 [“WLM、队列和 QMR”](#wlm_qmr)。当所有 CS 启用队列中所有等待查询的总等待时间超过一分钟时，将触发
    CS。对于那些需要更积极的 CS 的情况，可以通过与 AWS 支持合作来更改这一分钟设置。一旦启动了 CS 集群，那么任何新的查询进入 CS 启用队列时都不再等待，而是直接发送到
    CS 集群。
- en: '![Amazon Redshift Concurrency Scaling](assets/ardg_0503.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![亚马逊 Redshift 并发缩放](assets/ardg_0503.png)'
- en: Figure 5-3\. Amazon Redshift Concurrency Scaling
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-3\. 亚马逊 Redshift 并发缩放
- en: Concurrency Scaling is controlled by navigating to the “Workload management”
    section of the Amazon Redshift console, as shown in [Figure 5-4](#max_cs_5). While
    you cannot edit the `default.redshift-1.0` parameter group, you can create a new
    parameter group and modify the `max_concurrency_scaling_clusters` parameter to
    control the number of CS clusters that can be spun up. Note that the maximum is
    10, although you can request an increase if your workloads need more. We will
    cover parameter groups in depth in [“Parameter Group”](#wlm_param_group).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过访问亚马逊 Redshift 控制台的“工作负载管理”部分来控制并发缩放，如 [Figure 5-4](#max_cs_5) 所示。虽然您无法编辑
    `default.redshift-1.0` 参数组，但可以创建新的参数组并修改 `max_concurrency_scaling_clusters` 参数以控制可以启动的
    CS 集群数量。请注意，最多可以为 10 个，但如果您的工作负载需要更多，可以申请增加。我们将在 [“参数组”](#wlm_param_group) 中深入介绍参数组。
- en: The Concurrency Scaling cluster operates independently to execute the queries
    that were assigned for execution. Each query to be executed needs to be compiled
    first, and note that the compile cache on the main cluster and the CS cluster
    is independent. During query processing, Amazon Redshift generates query segments
    and checks if the query segments are available in the cluster’s local cache. If
    they are not available, then it checks if the query segments are available in
    the external code compilation cache, i.e., the global cache. If they are available,
    then the compiled object gets downloaded from the global cache to the local cache;
    otherwise, the query segments are sent to the external compilation farm to be
    compiled with massive parallelism and then stored in the external code compilation
    cache and respective local compilation cache. So even though the CS cluster does
    not have the query segments when it is spun up, it still can leverage the global
    cache if available, or else it will need to recompile the query from scratch.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Concurrency Scaling 集群独立运行以执行分配的查询。每个要执行的查询首先需要编译，并且请注意主集群和 CS 集群上的编译缓存是独立的。在查询处理过程中，Amazon
    Redshift 生成查询段，并检查集群本地缓存中是否有查询段。如果没有，则检查外部代码编译缓存（全局缓存）中是否有查询段。如果有，则从全局缓存下载编译对象到本地缓存；否则，将查询段发送到外部编译农场以使用大规模并行编译，然后存储在外部代码编译缓存和相应的本地编译缓存中。因此，即使
    CS 集群在启动时没有查询段，仍然可以利用全局缓存（如果可用），否则将需要从头开始重新编译查询。
- en: '![Max Concurrency Scaling clusters](assets/ardg_0504.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![最大并发扩展集群](assets/ardg_0504.png)'
- en: Figure 5-4\. Max Concurrency Scaling clusters
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-4\. 最大并发扩展集群
- en: With Concurrency Scaling, the user queries run against the most current data
    irrespective of whether it runs on the main or CS cluster. Amazon Redshift keeps
    refreshing the CS cluster with the latest data as long as it is servicing queries.
    Note that there is a cost associated with CS but Amazon Redshift provides one
    hour of free CS credits for every 24 hours of your main cluster uptime.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Concurrency Scaling，用户查询运行在最新数据上，无论其在主集群还是 CS 集群上运行。只要服务查询，Amazon Redshift
    就会不断刷新 CS 集群的最新数据。请注意，CS 有相关成本，但 Amazon Redshift 每 24 小时主集群运行时提供一小时免费 CS 信用。
- en: Concurrency Scaling clusters are stood up in minutes, are billed on a per second
    usage, and billed only for the time they are actively running queries, not while
    they are being provisioned or released. Once CS clusters are released, they go
    back to the Amazon EC2 pool, where these EC2 virtual machines are fully cleansed
    and reset before being brought back into the CS fleet for subsequent usage. This
    ensures no residual objects are accidentally left behind across CS usage from
    one to another.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Concurrency Scaling 集群在几分钟内启动，按秒计费，仅在活动查询时计费，而不是在其被提供或释放时。一旦释放 CS 集群，它们将返回到
    Amazon EC2 池中，其中这些 EC2 虚拟机在被重新引入 CS 集群前会进行完全清理和重置。这确保没有残留对象从一个 CS 使用到另一个 CS 使用。
- en: Concurrency Scaling usage is billed at on-demand rates, and Amazon Redshift
    provides discounts with Reserved Instances (RI) pricing. So if you see high Concurrency
    Scaling usage then you should evaluate if you are better off by adding nodes to
    your RI cluster instead.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Concurrency Scaling 使用按需定价计费，Amazon Redshift 提供预留实例（RI）定价折扣。因此，如果您发现高 Concurrency
    Scaling 使用率，则应评估是否通过向 RI 集群添加节点来提升效果更佳。
- en: Concurrency Scaling cost controls can be set up right in the Amazon Redshift
    console. Once your defined limits have been reached then Amazon Redshift can write
    log records into the system table or completely turn the Concurrency Scaling feature
    off. Any query that was executing when the usage limit is reached will be executed
    to completion in the Concurrency Scaling cluster, but subsequent queries will
    stay on the main cluster and be queued until executed.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Concurrency Scaling 成本控制可以直接在 Amazon Redshift 控制台中设置。一旦达到定义的限制，Amazon Redshift
    可以将日志记录写入系统表，或者完全关闭 Concurrency Scaling 功能。在达到使用限制时正在执行的任何查询将在 Concurrency Scaling
    集群中完成执行，但随后的查询将留在主集群中排队，直到执行。
- en: The Concurrency Scaling limits can be changed dynamically without needing a
    cluster reboot. As of this writing, the Concurrency Scaling feature is available
    in commercial regions only, and is not available in AWS GovCloud regions.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Concurrency Scaling 限制可以动态更改，无需重新启动集群。截至目前，Concurrency Scaling 功能仅在商业地区可用，并且在
    AWS GovCloud 地区不可用。
- en: WLM, Queues, and QMR
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: WLM、队列和 QMR
- en: A typical organization would have various type of users with different performance
    expectations. The *workload management* (WLM) feature of Amazon Redshift provisioned
    clusters offers capability to run workloads based on business priorities (see
    [Figure 5-5](#wlm_queue_5.3.3)). WLM provides you the necessary controls to maximize
    the warehouse throughput, i.e., the number of queries processed in a given time
    duration. You can define up to eight queues to logically segregate the queries
    being executed. Each queue has a unique service class identifier. Identifiers
    1 through 4 are reserved for system use, 5 is for the superuser queue, and 15
    for housekeeping activities by Amazon Redshift. Refer to the [WLM system tables
    and views](https://oreil.ly/7nZea) for more details.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的组织可能有多种类型的用户，对性能有不同的期望。亚马逊 Redshift 预配置集群的 *工作负载管理*（WLM）功能提供了根据业务优先级运行工作负载的能力（见
    [图 5-5](#wlm_queue_5.3.3)）。WLM 提供了必要的控制来最大化数据仓库的吞吐量，即在给定时间内处理的查询数量。您可以定义最多八个队列来逻辑上分离正在执行的查询。每个队列都有一个唯一的服务类标识符。标识符
    1 到 4 保留用于系统使用，5 用于超级用户队列，15 用于亚马逊 Redshift 的日常运维活动。更多详情请参阅 [WLM 系统表和视图](https://oreil.ly/7nZea)。
- en: '![Amazon Redshift WLM Queues](assets/ardg_0505.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift WLM 队列](assets/ardg_0505.png)'
- en: Figure 5-5\. Amazon Redshift WLM queues
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-5\. Amazon Redshift WLM 队列
- en: In [Figure 5-5](#wlm_queue_5.3.3), you can see three queues have been defined,
    and WLM allocates the queries coming from the left to specific WLM queues on the
    right based on queue assignment rules.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 5-5](#wlm_queue_5.3.3) 中，您可以看到已定义了三个队列，WLM 根据队列分配规则将从左侧进入的查询分配到右侧特定的 WLM
    队列。
- en: Queue Assignment
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 队列分配
- en: Amazon Redshift default configuration comes with one queue, the default queue,
    and all queries will execute in it unless the query is routed to another queue
    based off of assignment rules.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 的默认配置包含一个队列，即默认队列，除非根据分配规则将查询路由到另一个队列，否则所有查询都将在其中执行。
- en: 'WLM assigns a query to a queue based on matching logic as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 根据匹配逻辑，WLM 将查询分配给队列，方法如下：
- en: If a user with superuser privilege submits a query and query group has been
    set to superuser, then assign to superuser queue.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果具有超级用户特权的用户提交查询，并且查询组已设置为超级用户，则分配到超级用户队列。
- en: If regular user submits a query and user group is matched, then assign to the
    matching queue.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果普通用户提交查询，并且匹配到用户组，则分配到匹配的队列。
- en: If regular user submits a query and query group is matched, then assign to the
    matching queue.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果普通用户提交查询，并且匹配到查询组，则分配到匹配的队列。
- en: If no matches are found, then assign to default queue.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有找到匹配项，则分配到默认队列。
- en: Refer to the [WLM queue assignment rules](https://oreil.ly/nnBdx) for a flowchart
    and examples for queue assignment.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅 [WLM 队列分配规则](https://oreil.ly/nnBdx) 以获取队列分配的流程图和示例。
- en: If a query matches multiple queues, then it gets allocated to the first queue
    that it is matched to.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个查询匹配多个队列，则将其分配给首个匹配的队列。
- en: Each query gets allocated a single slot for execution. A slot is a portion of
    your cluster’s memory or RAM. Superuser queue always has concurrency of one irrespective
    of manual WLM or auto WLM. And you must manually set the query group as superuser
    to run your query in the superuser queue (see [Example 5-3](#superuser_queue)).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 每个查询被分配一个执行插槽。插槽是您集群内存或 RAM 的一部分。超级用户队列始终具有并发度为一，无论是手动 WLM 还是自动 WLM。您必须手动将查询组设置为超级用户，才能将您的查询运行在超级用户队列中（见
    [示例 5-3](#superuser_queue)）。
- en: Example 5-3\. Superuser queue
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-3\. 超级用户队列
- en: '[PRE3]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Each queue can map to either user group or query group. User group is nothing
    but a logical grouping of users, for example, a user group `etl_group` in which
    all individual applications etl users, `app_1_etl_usr`,`app_2_etl_usr`, are put
    together. Query group is a text label that is set at runtime (see [Example 5-4](#query_group)).
    This is typically used by a BI tool that uses a single database user ID but wants
    to prioritize a certain dashboard query over other queries.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 每个队列可以映射到用户组或查询组。用户组只是用户的逻辑分组，例如，一个名为 `etl_group` 的用户组，其中包含所有个别应用的 ETL 用户，如
    `app_1_etl_usr`、`app_2_etl_usr`。查询组是在运行时设置的文本标签（见 [示例 5-4](#query_group)）。这通常由使用单个数据库用户
    ID 的 BI 工具使用，但希望将某个仪表板查询优先于其他查询。
- en: Example 5-4\. Set query group
  id: totrans-86
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-4\. 设置查询组
- en: '[PRE4]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: By default each query gets allocated a single slot, and if the query is able
    to complete its execution within the allocated memory then you will see faster
    performance compared to when the query spills to disk.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，每个查询被分配一个单独的插槽，如果查询能够在分配的内存内完成执行，那么性能会比查询溢出到磁盘时更快。
- en: Use the [Example 5-5](#check_disk_spill) query to check on disk spill queries.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 [示例 5-5](#check_disk_spill) 查询来检查磁盘溢出的查询。
- en: Example 5-5\. Check disk spill
  id: totrans-90
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-5\. 检查磁盘溢出
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The number of slots and amount of memory allocated per slot are crucial for
    query execution performance.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 分配的插槽数量和每个插槽分配的内存量对查询执行性能至关重要。
- en: You can use the `wlm_query_slot_count` parameter to allocate more slots to speed
    up large queries, like `VACUUM`. This temporarily reduces the concurrency on your
    cluster until you reset the query slot count. This works in manual WLM as well
    as auto WLM mode.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`wlm_query_slot_count`参数来为大查询（如`VACUUM`）分配更多的插槽，这会暂时降低集群的并发性，直到重置查询插槽计数。这在手动WLM以及自动WLM模式下均适用。
- en: You can choose to set up these slots yourself in manual WLM or let Amazon Redshift
    manage them with auto WLM.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择在手动WLM中自行设置这些插槽，或者让Amazon Redshift在自动WLM模式下管理它们。
- en: Short Query Acceleration
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 短查询加速
- en: There also is a special queue for queries that are short-running, called the
    *short query acceleration (SQA) queue*. Amazon Redshift estimates the execution
    time for each query and if eligible sends to SQA. If the actual query runtime
    exceeds SQA time, then the query gets moved out to one of the matching WLM queues.
    Only read-only queries are eligible for SQA. The service class identifier for
    SQA is 14.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个专门用于短时查询的队列，称为*短查询加速（SQA）队列*。Amazon Redshift会估计每个查询的执行时间，如果符合条件，则将其发送到SQA队列。如果实际查询运行时间超过SQA时间，则将查询移到匹配的WLM队列之一。只有只读查询符合SQA资格。SQA的服务类标识符为14。
- en: With manual WLM you can specify the maximum runtime (in seconds) to qualify
    a query for SQA, but in auto WLM this is automatically determined by Amazon Redshift
    based on your query patterns.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在手动WLM中，您可以指定使查询符合SQA资格所需的最大运行时间（秒），但在自动WLM中，这将根据您的查询模式由Amazon Redshift自动确定。
- en: If you are using manual WLM, then you can use SQL [Example 5-6](#sqa_threshold)
    to analyze your workload queues and choose between 70th to 90th percentile to
    set an SQA threshold.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用手动的WLM，那么可以使用SQL [示例 5-6](#sqa_threshold) 分析你的工作负载队列，并选择在第70到90百分位之间设置一个SQA阈值。
- en: Example 5-6\. SQA threshold
  id: totrans-99
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-6\. SQA阈值
- en: '[PRE6]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '| queue | queries | avg_q_sec | min_q_sec | max_q_sec | p70_sec | p90_sec |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 队列 | 查询数 | 平均查询时间（秒） | 最小查询时间（秒） | 最大查询时间（秒） | p70时间（秒） | p90时间（秒） |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 5 | 20103 | 23 | 0 | 95 | 15 | 19 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 20103 | 23 | 0 | 95 | 15 | 19 |'
- en: '| 6 | 3421 | 42 | 15 | 32 | 18 | 23 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 3421 | 42 | 15 | 32 | 18 | 23 |'
- en: '| 7 | 42 | 178 | 109 | 466 | 176 | 261 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 42 | 178 | 109 | 466 | 176 | 261 |'
- en: '| 8 | 196 | 398 | 99 | 1399 | 108 | 206 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 196 | 398 | 99 | 1399 | 108 | 206 |'
- en: In the previous example, setting SQA between 15 and 18 will allow most queries
    to take advantage of SQA.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，设置SQA在15到18之间将允许大多数查询利用SQA的优势。
- en: Query Monitoring Rules
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询监控规则
- en: In both WLM modes Amazon Redshift provides *query monitoring rules* (QMR) to
    control the cluster behavior based on certain rules for query execution. You have
    16 system-defined metrics available to define QMR conditions, and Amazon Redshift
    also provides 5 system-defined templates for you to get started with QMR quickly.
    Once an executing query breaches the defined boundary, the defined action is triggered.
    The actions can be to abort, log, change query priority (auto WLM only), or hop
    (manual WLM only) the query to another matching queue. You can define up to 25
    QMR across all queues, and each QMR can evaluate up to 3 conditions. When all
    of a rule’s conditions are met, WLM writes a row to the `STL_WLM_RULE_ACTION`
    system table. This row contains details for the query that triggered the rule
    and the resulting action.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在Amazon Redshift的两种WLM模式中，都提供了*查询监控规则*（QMR），用于根据某些查询执行规则控制集群行为。您可以使用16个系统定义的度量来定义QMR条件，Amazon
    Redshift还提供了5个系统定义的模板，帮助您快速开始使用QMR。一旦执行中的查询触发了定义的边界，就会触发定义的动作。动作可以是中止、记录、更改查询优先级（仅自动WLM）、或将查询（仅手动WLM）跳转到另一个匹配的队列。您可以在所有队列中定义最多25个QMR，每个QMR可以评估最多3个条件。当规则的所有条件都满足时，WLM会向`STL_WLM_RULE_ACTION`系统表写入一行。此行包含触发规则的查询的详细信息及其结果动作。
- en: Amazon Redshift serverless does not have WLM, but it does have [Query Limits](https://oreil.ly/jywZ-),
    which follow the same rule logic as QMR. Use these to ensure that users don’t
    issue runaway queries.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift无服务器没有WLM，但它确实有[查询限制](https://oreil.ly/jywZ-)，其遵循与QMR相同的规则逻辑。使用这些功能确保用户不会发出运行失控的查询。
- en: The QMR metrics are evaluated every 10 seconds, so you might see some rules
    take time to fire.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: QMR指标每10秒进行评估，因此可能会看到一些规则需要一段时间才能触发。
- en: You can set up QMR to get notified of bad queries and proactively take action
    instead of reactively handling it when your user complains after experiencing
    slowness. With QMR you can also identify areas of learning for your user community
    and help them grow their technical skills by logging poorly written queries and
    having follow-up discussions and workshops for educating your warehouse users.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以设置QMR以获得有关糟糕查询的通知，并主动采取行动，而不是在用户投诉后再处理延迟问题。使用QMR还可以识别用户社区的学习领域，并通过记录编写不佳的查询并进行后续讨论和工作坊来帮助他们提升技术技能。
- en: Leverage system tables and views to determine threshold values for defining
    QMR. The table `STV_QUERY_METRICS` displays the metrics for *currently running*
    queries, table `STL_QUERY_METRICS` records the metrics for *completed* queries,
    view `SVL_QUERY_METRICS` shows the metrics for *completed* queries, and view `SVL_QUERY_M⁠E⁠T⁠R⁠I⁠C⁠S⁠_​S⁠U⁠M⁠M⁠A⁠R⁠Y`
    shows the *maximum values* of metrics for completed queries.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 利用系统表和视图来确定定义QMR的阈值。表`STV_QUERY_METRICS`显示*当前运行*查询的指标，表`STL_QUERY_METRICS`记录*已完成*查询的指标，视图`SVL_QUERY_METRICS`显示*已完成*查询的指标，视图`SVL_QUERY_M⁠E⁠T⁠R⁠I⁠C⁠S⁠_​S⁠U⁠M⁠M⁠A⁠R⁠Y`显示*已完成*查询的指标的*最大值*。
- en: For a typical `BI queue` you should set up QMR for a nested loop join, which
    often results in a large Cartesian product due to a missing joins predicate. Use
    a low row count to find a potentially runaway query early. If you dedicate a queue
    to simple, short-running queries, then include a rule that finds queries returning
    an abnormally high row count. Use the `unload` option instead of returning billions
    of rows.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于典型的`BI队列`，应设置QMR以处理嵌套循环连接，这通常由于缺少连接谓词而导致大型笛卡尔积。使用低行数早期查找潜在的运行失控查询。如果专门为简单且运行时间短的查询设置了队列，则包括一个规则，查找返回异常高行数的查询。使用`unload`选项而不是返回数十亿行。
- en: For a typical `Analyst queue` you should set up QMR for joins with a high number
    of rows, which might indicate a need for more restrictive filters. Or high disk
    usage when writing intermediate result that can be the result of a rogue query,
    which usually is also the query that uses the most disk space.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于典型的`分析师队列`，应设置QMR以处理行数较多的连接，这可能表明需要更严格的过滤器。或者在写入中间结果时使用高磁盘使用量，这可能是一个恶意查询的结果，通常也是使用最多磁盘空间的查询。
- en: For severe violation cases, for example, a `Dashboard queue` where queries finish
    under 10 seconds, set up QMR on query execution time greater than 20 seconds,
    which can indicate an erroneous query, with the action of `abort`.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于严重违规情况，例如`仪表板队列`，其中查询在10秒内完成，应设置QMR以在查询执行时间超过20秒时中止，这可能表明存在错误查询。
- en: For a typical `Data scientist queue` where long-running queries are expected,
    set up QMR for query queue time to limit the number of queries being submitted
    and sitting in the queue.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于典型的`数据科学家队列`，预期存在长时间运行的查询，请设置QMR以限制提交到队列并在队列中等待的查询数量。
- en: To get you started with QMR, Amazon Redshift provides ready templates where
    you just need to customize the threshold value for each QMR. See [query monitoring
    rules templates](https://oreil.ly/qjn8u) for additional details.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用QMR，Amazon Redshift提供了准备好的模板，您只需为每个QMR自定义阈值。有关详细信息，请参阅[查询监控规则模板](https://oreil.ly/qjn8u)。
- en: Initially, you start with the `log` action for various rules. Have a weekly
    cadence with your user community to review the queries that have been logged and
    provide means for tuning the queries. If things do not improve, then you can change
    the action to `abort` after giving your users a warning.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，您可以使用`log`操作记录各种规则。每周与用户社区进行定期交流，审查已记录的查询并提供调整查询的手段。如果没有改善，然后可以在提醒用户后将操作更改为`abort`。
- en: Use the following SQL [Example 5-7](#workload_queues_breakdown) to reveal the
    last seven days’ usage pattern of you data warehouse, which can help you determine
    the optimal WLM configuration setting. The query will provide a breakdown by workload
    queues (referred to as service class) and display data by hour-of-day for `Select`,
    `UPDATE`, `INSERT`, `DELETE`, `CURSOR`, `CACHED`, `COPY`, `UNLOAD`, `VACUUM`,
    and `SYSTEM` queries executing on your data warehouse.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下 SQL [示例 5-7](#workload_queues_breakdown) 揭示数据仓库过去七天的使用模式，这可以帮助您确定最佳的 WLM
    配置设置。该查询将按服务类别（也称为工作负载队列）和每小时数据展示`Select`、`UPDATE`、`INSERT`、`DELETE`、`CURSOR`、`CACHED`、`COPY`、`UNLOAD`、`VACUUM`
    和 `SYSTEM` 在您的数据仓库上执行的查询。
- en: Example 5-7\. Workload queues breakdown
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-7\. 工作负载队列详细信息
- en: '[PRE7]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Automatic WLM
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动 WLM
- en: '*Auto WLM* is the default mode that is enabled when you launch Amazon Redshift.
    With auto WLM, you let Amazon Redshift dynamically allocate the total number of
    slots and memory to each slot automatically. You can create up to eight queues
    with the service class identifiers 100 to 107\. You associate each queue with
    a priority from lowest to highest, and if there are queries contending for resources
    across multiple queues, then your higher priority queries will take precedence
    over the lower priority queries to ensure that the most important queries are
    not starved resources by lesser importance queries. During times when resource-heavy
    queries are executing, you want lower concurrency and more memory per query, and
    conversely, when lighter queries are executing, you want higher concurrency to
    execute more queries. This key purpose of auto WLM is to accommodate and execute
    as many queries as it can at any point in time.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*自动 WLM* 是启动 Amazon Redshift 时启用的默认模式。使用自动 WLM，您让 Amazon Redshift 动态地自动分配总插槽数和内存到每个插槽。您可以创建最多八个队列，服务类别标识符为
    100 到 107\. 您为每个队列分配从最低到最高的优先级，如果有查询在多个队列之间争夺资源，则优先级较高的查询将优先于优先级较低的查询，以确保最重要的查询不会被较不重要的查询耗尽资源。在执行资源密集型查询时，您希望较低的并发性和每个查询更多的内存，反之，当执行较轻的查询时，您希望更高的并发性以执行更多的查询。自动
    WLM 的关键目的是在任何时间点容纳和执行尽可能多的查询。'
- en: Although not shown in the AWS console, serverless data warehouses use auto WLM
    to ensure each query is allocated resources that are appropriate for the query
    needs.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在 AWS 控制台中未显示，但无服务器数据仓库使用自动 WLM 确保为每个查询分配适合其需求的资源。
- en: Auto WLM respects the priority you have associated with the queue and accordingly
    prioritizes higher priority queries. So you have to ensure you associate the business
    priority to the queue priority. For example, say the business priority is getting
    the most up-to-date data, then you can define the ETL queue with higher priority
    than the reporting queue. Amazon Redshift will throttle the cluster concurrency
    as needed depending on the relative size of the queries being executed. If heavy
    ETL queries are being executed, Amazon Redshift will detect the high resource
    needs per query and fewer queries will run concurrently. In contrast, when lighter
    dashboard queries are executing, Amazon Redshift will detect the low resource
    needs per query and more queries will run concurrently. You can also enable Concurrency
    Scaling for each queue and achieve higher throughput by scaling out your clusters.
    If your cluster is executing, all higher priority queries and new queries come
    in then; without Concurrency Scaling, those new queries will have to wait for
    the current queries to finish.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 自动 WLM 尊重您为队列关联的优先级，并相应地优先处理优先级较高的查询。因此，您必须确保将业务优先级与队列优先级关联起来。例如，假设业务优先级是获取最新数据，那么可以定义
    ETL 队列的优先级高于报告队列。Amazon Redshift 将根据正在执行的查询的相对大小需要调节集群并发性。如果正在执行重型 ETL 查询，Amazon
    Redshift 将检测到每个查询的高资源需求，并减少同时运行的查询数。相反，当执行较轻的仪表板查询时，Amazon Redshift 将检测到每个查询的低资源需求，并增加同时运行的查询数。您还可以为每个队列启用并发扩展，并通过扩展您的集群实现更高的吞吐量。如果您的集群正在执行所有较高优先级查询和新查询，则在没有并发扩展的情况下，这些新查询将必须等待当前查询完成。
- en: 'There are six priorities offered by Amazon Redshift, as listed here:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 提供了六种优先级，如下所列：
- en: Lowest
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最低
- en: Low
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 低
- en: Normal
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 普通
- en: High
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高
- en: Highest
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最高
- en: Critical
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 临界
- en: You can associate any of the first five to WLM queues. The critical priority
    can be applied only by a superuser, at query or session level. Only one query
    can execute at Critical priority.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将前五个任意关联到 WLM 队列。关键优先级只能由超级用户在查询或会话级别应用。只有一个查询可以以关键优先级执行。
- en: Auto WLM by default defines five heavy slots and five light slots to begin with.
    The heavy slots are allocated 95% of cluster memory, and the light slots get the
    remaining 5% memory. These slots get utilized as the workload queries come in,
    and if required, more slots are created. Fewer slots implies increasing the memory
    per slot, which is good for heavy queries, and more slots implies reducing memory
    per slot, which is for light queries. The five light slots are reserved for short-running
    queries, and heavy queries cannot utilize those slots. But the five heavy slots,
    if unoccupied, can be used by light queries.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，自动 WLM 定义了五个重型槽和五个轻型槽。重型槽分配了集群内存的95%，轻型槽获得剩余的5%内存。随着工作负载查询的到来，这些槽会被利用，并在需要时创建更多槽。较少的槽意味着每个槽的内存增加，这对于重型查询是有利的；而更多的槽意味着减少每个槽的内存，适用于轻型查询。五个轻型槽专门为短时间运行的查询保留，而重型查询无法使用这些槽。但是，如果五个重型槽空闲，轻型查询可以使用这些槽。
- en: You can query the undocumented view `stl_wlm_auto_concurrency` to gain insights
    about your auto WLM concurrency.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查询未记录的视图 `stl_wlm_auto_concurrency`，以了解有关自动 WLM 并发性的信息。
- en: Example 5-8\. Check auto WLM concurrency
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-8\. 检查自动 WLM 并发性
- en: '[PRE8]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '| now | hs | hqf | hqe | hqq | ls | lqf | lqe | lqq |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| now | hs | hqf | hqe | hqq | ls | lqf | lqe | lqq |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1/16/23 9:09:53 PM | 5 | 17 | 1.78 | 0 | 5 | 4 | 0.03 | 0 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:09:53 PM | 5 | 17 | 1.78 | 0 | 5 | 4 | 0.03 | 0 |'
- en: '| 1/16/23 9:11:54 PM | 20 | 411 | 683.69 | 12 | 5 | 96 | 14.73 | 10 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:11:54 PM | 20 | 411 | 683.69 | 12 | 5 | 96 | 14.73 | 10 |'
- en: '| 1/16/23 9:13:55 PM | 20 | 375 | 562.20 | 23 | 5 | 113 | 15.60 | 16 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:13:55 PM | 20 | 375 | 562.20 | 23 | 5 | 113 | 15.60 | 16 |'
- en: '| 1/16/23 9:15:58 PM | 17 | 418 | 552.47 | 11 | 5 | 152 | 21.61 | 18 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:15:58 PM | 17 | 418 | 552.47 | 11 | 5 | 152 | 21.61 | 18 |'
- en: '| 1/16/23 9:19:00 PM | 20 | 352 | 720.27 | 63 | 5 | 90 | 15.30 | 10 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:19:00 PM | 20 | 352 | 720.27 | 63 | 5 | 90 | 15.30 | 10 |'
- en: '| 1/16/23 9:22:02 PM | 20 | 445 | 757.10 | 44 | 5 | 119 | 17.91 | 38 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:22:02 PM | 20 | 445 | 757.10 | 44 | 5 | 119 | 17.91 | 38 |'
- en: '| 1/16/23 9:24:03 PM | 20 | 414 | 719.95 | 25 | 5 | 87 | 13.24 | 12 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:24:03 PM | 20 | 414 | 719.95 | 25 | 5 | 87 | 13.24 | 12 |'
- en: '| 1/16/23 9:26:05 PM | 20 | 356 | 335.15 | 13 | 5 | 98 | 6.45 | 9 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:26:05 PM | 20 | 356 | 335.15 | 13 | 5 | 98 | 6.45 | 9 |'
- en: '| 1/16/23 9:28:06 PM | 13 | 482 | 355.50 | 9 | 5 | 130 | 9.05 | 9 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:28:06 PM | 13 | 482 | 355.50 | 9 | 5 | 130 | 9.05 | 9 |'
- en: '| 1/16/23 9:30:07 PM | 10 | 217 | 183.45 | 1 | 5 | 91 | 6.33 | 0 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:30:07 PM | 10 | 217 | 183.45 | 1 | 5 | 91 | 6.33 | 0 |'
- en: '| 1/16/23 9:31:08 PM | 7 | 131 | 79.04 | 0 | 5 | 44 | 3.83 | 0 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:31:08 PM | 7 | 131 | 79.04 | 0 | 5 | 44 | 3.83 | 0 |'
- en: '| 1/16/23 9:32:06 PM | 5 | 27 | 33.81 | 0 | 5 | 8 | 1.43 | 0 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 1/16/23 9:32:06 PM | 5 | 27 | 33.81 | 0 | 5 | 8 | 1.43 | 0 |'
- en: Auto WLM has the potential to kill a lower priority query that has not yet started
    returning data, if a higher priority query needs resources and none are available.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果高优先级查询需要资源而没有可用资源，则自动 WLM 有可能终止尚未开始返回数据的低优先级查询。
- en: It is recommended to use auto WLM when your workloads are dynamic and you want
    to drive your workloads based off of the business priority of various users or
    workloads. Auto WLM maximizes the cluster resources and pushes through as many
    queries as can be executed concurrently. It is highly recommended to set up QMR,
    which is covered in [“Query Monitoring Rules”](#qmr), when using auto WLM as you
    do not want a rogue query to consume all your resources.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的工作负载动态变化且希望根据不同用户或工作负载的业务优先级来驱动工作负载时，建议使用自动 WLM。自动 WLM 可以最大化集群资源，并尽可能并发执行尽可能多的查询。强烈建议在使用自动
    WLM 时设置QMR，详见[“查询监控规则”](#qmr)，以防止某个恶意查询耗尽所有资源。
- en: Manual WLM
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动 WLM
- en: With *manual WLM*, you get more control over the concurrency and memory allocation
    for each query. If you have a workload that requires dedicated resources 24-7,
    then you can use manual WLM. An example would be when you have a consistent ETL
    ingestion pipeline, where you ingest data throughout the day; you can set up a
    queue with a percentage of memory allocated. Similar to auto WLM, you can create
    a maximum of eight queues with manual WLM. The key difference is that you can
    manually control the number of slots and the percentage of memory allocated to
    each queue. You can create up to eight queues with the service class identifiers
    6 to 13\. The recommended total slots is 15 across all your manual WLM queues.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用*手动 WLM*，你可以更好地控制每个查询的并发性和内存分配。如果你有一个需要24-7专用资源的工作负载，那么你可以使用手动 WLM。例如，当你有一个一直进行数据摄取的
    ETL 流水线时，你可以设置一个分配了一定百分比内存的队列。与自动 WLM 类似，你可以创建最多八个手动 WLM 队列。主要区别在于你可以手动控制每个队列的槽位数量和分配的内存百分比。你可以创建八个队列，服务类别标识符为6至13。建议在所有手动
    WLM 队列中总共使用15个槽位。
- en: Manual WLM is available only for provisioned data warehouses. Serverless data
    warehouses use auto WLM.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 手动 WLM 仅适用于专用数据仓库。无服务器数据仓库使用自动 WLM。
- en: If your warehouse has `300 GiB` memory and you have set `40%` memory to `ETL`
    queue with `3 slots`, then each query will get `300 x 0.40 / 3 = 40 GiB` of memory
    allocated. If the query needs more than 40 GiB, then queries will spill to disk
    and take longer to execute. In manual WLM mode the memory is reserved for each
    queue slot, and if more queries than the slots defined come in, then they are
    queued up for execution. To scale beyond the allocated memory for each queue,
    you can enable Concurrency Scaling. Concurrency Scaling is enabled for each queue,
    and only if that particular queue is filled, queries will be routed to the scaling
    clusters.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的仓库有`300 GiB`内存，并且你已经为`ETL`队列设置了`40%`的内存，每个查询将分配`300 x 0.40 / 3 = 40 GiB`的内存。如果查询需要超过40
    GiB，那么查询将溢出到磁盘并且执行时间会变长。在手动 WLM 模式下，内存为每个队列槽位保留，如果超过定义的槽位的查询进来，它们将排队等待执行。要扩展每个队列分配的内存，你可以启用并发扩展。并发扩展针对每个队列启用，并且只有当特定队列填满时，查询才会路由到扩展集群。
- en: With manual WLM, once all slots of a queue are occupied, subsequent queries
    have to wait even if another queue has free slots available.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在手动 WLM 模式下，一旦一个队列的所有槽位被占用，后续查询必须等待，即使另一个队列有可用的空闲槽位。
- en: It is recommended to use manual WLM when you are very familiar with your workloads
    and you want the most control over your cluster resources. But it has the potential
    of leaving resources underutilized. Instances with very consistent and repeatable
    workloads are candidates for manual WLM, but every time a new workload gets introduced
    you should reevaluate the manual slot and memory allocation if the workload has
    any defined SLAs. If the new workload does not have strict SLAs, then it can go
    to the default queue and will get completed as it gets its turn for execution.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐在你非常熟悉工作负载并且希望最大程度控制集群资源时使用手动 WLM。但它可能导致资源利用率不高。具有非常一致和可重复工作负载的实例是手动 WLM 的候选者，但每次引入新的工作负载时，如果工作负载有定义的
    SLA，应重新评估手动槽位和内存分配。如果新的工作负载没有严格的 SLA，则可以进入默认队列，并在执行时完成。
- en: You should consider manual WLM when you notice (using the [Example 5-5](#check_disk_spill)
    query) that auto WLM is spilling a lot to disk or, not spilling but instead queuing
    a lot and your system can use more slots. Note that while it will take more effort
    to manage manual WLM it could give better cost optimization. In the spilling-a-lot
    scenario, a costlier but easier to manage option would be to scale up your cluster.
    In the never-spilling-but-queuing scenario, one option would be to use more Concurrency
    Scaling, but that can turn expensive, so instead manual WLM can give you better
    cost optimization.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当你注意到自动 WLM 大量向磁盘溢出或者大量排队而系统可以使用更多槽位时，你应考虑使用手动 WLM。请注意，虽然手动 WLM 需要更多的管理工作，但它可能会提供更好的成本优化。在大量溢出的情况下，成本更高但更容易管理的选项是扩展集群。在不溢出但排队大量的情况下，一种选择是使用更多的并发扩展，但这可能会变得昂贵，因此手动
    WLM 可以提供更好的成本优化。
- en: If you define manual WLM and do not allocate 100% of total memory, then Amazon
    Redshift will allocate the unallocated portion to any queue that needs more memory.
    This can be considered as a hybrid WLM mode where you are starting off with a
    minimum memory allocation per queue and letting Amazon Redshift do some automatic
    memory allocation on top of your manual setup.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您定义了手动 WLM 并且未分配 100% 的总内存，则 Amazon Redshift 将未分配的部分分配给需要更多内存的任何队列。这可以被视为一种混合
    WLM 模式，在此模式下，您从每个队列的最小内存分配开始，并允许 Amazon Redshift 在您的手动设置之上进行一些自动内存分配。
- en: '[Table 5-1](#auto_vs_manual) summarizes the features of auto WLM and manual
    WLM.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 5-1](#auto_vs_manual) 总结了自动 WLM 和手动 WLM 的特性。'
- en: Table 5-1\. Auto WLM versus manual WLM
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-1\. 自动 WLM 对比手动 WLM
- en: '| Characteristic | Auto WLM | Manual WLM | Additional info |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 特性 | 自动 WLM | 手动 WLM | 附加信息 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Define queue priority | Yes | No | Queue priority is available only in auto
    WLM. |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 定义队列优先级 | 是 | 否 | 队列优先级仅在自动 WLM 中可用。 |'
- en: '| Define queue concurrency | No | Yes | Number of slots in queue is available
    only in manual WLM. |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 定义队列并发性 | 否 | 是 | 队列中的槽位数量仅在手动 WLM 中可用。 |'
- en: '| Define queue memory allocation | No | Yes | Amount of memory for the queue
    in available only in manual WLM. |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 定义队列内存分配 | 否 | 是 | 队列内存量仅在手动 WLM 中可用。 |'
- en: '| Over-allocate memory per query | No | Yes | If you define too few slots in
    manual WLM. |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 每个查询过度分配内存 | 否 | 是 | 如果您在手动 WLM 中定义的槽位过少。 |'
- en: '| Under-allocate memory per query | No | Yes | If you define too many slots
    in manual WLM. |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 每个查询过度分配内存 | 否 | 是 | 如果您在手动 WLM 中定义的槽位过多。 |'
- en: '| Maximum number of queries executing concurrently | Dynamic | Fixed | In manual
    WLM the total slots defined across all queues is the maximum number of queries
    that will execute. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 同时执行的最大查询数 | 动态 | 固定 | 在手动 WLM 中，所有队列定义的总槽位数是将执行的最大查询数。 |'
- en: '| Define query priority by queue | Yes | No | In manual WLM more slots on a
    queue implies lower priority, and fewer slots implies higher priority. |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 按队列定义查询优先级 | 是 | 否 | 在手动 WLM 中，队列上的更多槽位意味着更低的优先级，而较少的槽位意味着更高的优先级。 |'
- en: '| Query spilled to disk | Lower | Higher | Auto WLM throttles the concurrency
    to allow fewer queries so more memory gets allocated per query. In manual WLM
    you must allocate more slots per query basis. |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 查询溢出到磁盘 | 较低 | 较高 | 自动 WLM 通过限制并发性来允许更少的查询，因此更多的内存被分配给每个查询。在手动 WLM 中，您必须基于每个查询分配更多的槽位。
    |'
- en: '| Define short query time | Auto | Yes | You can choose between 1 and 20 seconds
    in manual WLM. |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 定义短查询时间 | 自动 | 是 | 在手动 WLM 中，您可以选择 1 到 20 秒之间的时间。 |'
- en: '| QMR action: Hop | No | Yes | WLM attempts to route the query to the next
    matching queue based on the WLM queue assignment rules. However, the query is
    canceled if no other queue definition is matched; it is not assigned to the default
    queue. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| QMR 操作：跳跃 | 否 | 是 | WLM 会根据 WLM 队列分配规则尝试将查询路由到下一个匹配的队列。但是，如果没有匹配到其他队列定义，则查询会被取消，而不会分配到默认队列。
    |'
- en: '| Concurrency Scaling (CS) | CS cluster uses auto WLM | CS cluster capped at
    5 slots | If multiple CS clusters are enabled, then additional clusters can be
    created for the main cluster. |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 并发扩展 (CS) | CS 集群使用自动 WLM | CS 集群限制为 5 个槽位 | 如果启用了多个 CS 集群，则可以为主集群创建额外的集群。
    |'
- en: The objective of WLM is to manage resources for the queries executing on your
    warehouse. You can query Amazon Redshift system tables to analyze your workloads
    and set up the WLM configuration accordingly.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: WLM 的目标是管理在您的数据仓库上执行的查询的资源。您可以查询 Amazon Redshift 系统表以分析您的工作负载，并相应地设置 WLM 配置。
- en: Use query [Example 5-9](#hourly_query_stats) to see hourly query execution statistics.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用查询 [示例 5-9](#hourly_query_stats) 来查看每小时的查询执行统计信息。
- en: Example 5-9\. Hourly query execution statistics
  id: totrans-180
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-9\. 每小时查询执行统计
- en: '[PRE9]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Use query [Example 5-10](#peak_memory) to understand the peak memory per queue
    or service class. Note you can also filter by column `service_class_start_time`
    for a particular date–time range as required.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用查询 [示例 5-10](#peak_memory) 来了解每个队列或服务类的峰值内存。注意，您还可以按 `service_class_start_time`
    列过滤特定日期和时间范围。
- en: Example 5-10\. Peak memory estimate
  id: totrans-183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-10\. 峰值内存估算
- en: '[PRE10]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you need to ensure that multiple workloads are executing at the same time,
    and you cannot set different priorities for these workload queues, then you have
    two choices. One option is to use manual WLM, and the second is to create two
    separate clusters, thus isolating the two workloads, and use data sharing with
    auto WLM on each of these clusters. With the second approach you get to maximize
    the throughput for each workload on their own isolated cluster and still ensure
    there is full utilization of resources. [Chapter 7](ch07.html#AR_TGD_CH7) covers
    this at length.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要确保多个工作负载同时执行，并且不能为这些工作负载队列设置不同的优先级，那么您有两个选择。一个选项是使用手动 WLM，第二个选项是创建两个单独的集群，从而隔离这两个工作负载，并在每个集群上使用自动
    WLM 进行数据共享。通过第二种方法，您可以最大化每个工作负载在其自己隔离的集群上的吞吐量，并仍然确保资源的充分利用。[第 7 章](ch07.html#AR_TGD_CH7)
    对此进行了详细讨论。
- en: Parameter Group
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数组
- en: A *parameter* is a value of a setting, for example `auto_mv`, which can be `true`
    or `false`. And a *parameter group* is a collection of such parameters (refer
    back to [Figure 5-4](#max_cs_5)). Parameter groups are only applicable to provisioned
    data warehouses. A parameter group applies to all of the databases on the cluster
    that the parameter group is associated with. Amazon Redshift comes with a default
    parameter group that cannot be edited, but you can create a new parameter group
    and customize your database settings.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*参数* 是设置的一个值，例如 `auto_mv`，可以是 `true` 或 `false`。而 *参数组* 则是这些参数的集合（参见 [图 5-4](#max_cs_5)）。参数组仅适用于预置数据仓库。参数组适用于与参数组关联的集群上的所有数据库。Amazon
    Redshift 自带一个无法编辑的默认参数组，但您可以创建一个新的参数组并自定义数据库设置。'
- en: You can create multiple parameter groups, each one having different values for
    various database parameter settings. You can associate a parameter group to one
    or more clusters. By modifying a parameter group, you can change the configuration
    of all clusters that use the same parameter group. Some WLM properties are static,
    which requires a reboot, while other properties are dynamic and take effect immediately.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以创建多个参数组，每个参数组具有不同的数据库参数设置值。您可以将参数组关联到一个或多个集群。通过修改参数组，您可以更改使用相同参数组的所有集群的配置。某些
    WLM 属性是静态的，需要重新启动，而其他属性是动态的，并立即生效。
- en: In [Example 5-11](#example510) you can see how to use the the modify-cluster
    CLI command to change the parameter group.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 5-11](#example510) 中，您可以看到如何使用 modify-cluster CLI 命令来更改参数组。
- en: Example 5-11\. AWS CLI command to modify-cluster
  id: totrans-190
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-11\. 修改集群的 AWS CLI 命令
- en: '[PRE11]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can set up a parameter group for write-heavy ETL workloads and another parameter
    group for read-heavy BI workloads. If you carefully choose only the dynamic properties
    in these two parameter groups, then you can effectively switch the cluster from
    one configuration to the other without needing a reboot. This strategy is applied
    to configure your cluster in a workload-specific configuration based on ETL/BI
    time windows, although auto WLM does this dynamically for you.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为写重的 ETL 工作负载设置一个参数组，并为读重的 BI 工作负载设置另一个参数组。如果在这两个参数组中仅仅选择动态属性，则可以有效地在不需要重新启动的情况下将集群从一种配置切换到另一种配置。这种策略被应用于基于
    ETL/BI 时间窗口配置您的集群，尽管自动 WLM 会动态地为您执行此操作。
- en: WLM Dynamic Memory Allocation
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WLM 动态内存分配
- en: In each queue, WLM creates as many slots as the concurrency limit set for the
    queue. The memory allocated to the queue is then divided equally per slot. If
    you change the memory allocation or concurrency, Amazon Redshift dynamically manages
    the transition to the new WLM configuration. Active queries continue toward completion
    using the memory that has already been allocated.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个队列中，WLM 创建与队列设置的并发限制相同数量的槽。然后，分配给队列的内存会按照每个槽平均分配。如果更改了内存分配或并发性，Amazon Redshift
    将动态管理向新 WLM 配置的过渡。活动查询继续使用已经分配的内存直至完成。
- en: 'The workload manager performs the transition in following steps:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 工作负载管理器执行以下步骤进行转换：
- en: Calculate the new memory allocation for each slot.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个槽的新内存分配。
- en: Unoccupied slot releases the memory it was previously allocated.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 空闲槽释放其先前分配的内存。
- en: Active slots execute until query finishes and the associated memory is subsequently
    released.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 活动槽在查询完成并随后释放关联内存时执行。
- en: New slots are added as soon as enough memory becomes available.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只要有足够的内存可用，新的槽就会立即添加。
- en: Once all previously running queries have finished, the transition to the new
    WLM configuration is complete and the slot count equals the new concurrency level.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有先前运行的查询完成，新的WLM配置的过渡就完成了，插槽数等于新的并发级别。
- en: In effect, queries that are running when the change takes place continue to
    use the original memory allocation. Queries that are queued when the change takes
    place are routed to new slots as they become available. Because of the dynamic
    nature of memory allocation by Amazon Redshift, you can change the memory allocation
    percentage for the WLM queue in the parameter group without needing a reboot.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在发生变化时正在运行的查询继续使用原始的内存分配。当变化发生时排队的查询将被路由到新的插槽，随着可用的插槽变多。由于亚马逊Redshift的内存分配的动态特性，您可以在参数组中更改WLM队列的内存分配百分比，而无需重新启动。
- en: Materialized Views
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 物化视图
- en: '*Materialized views* (MV) are a powerful tool to speed up resource-intensive
    join queries that are repetitive and predictable. Typical use cases are dashboard
    queries with expensive joins and aggregations. The materialized view stores the
    results from the base query. This is different from a normal database view, where
    only the query definition is stored and the view query is executed every time
    the view is accessed.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '*物化视图*（MV）是加速资源密集型连接查询的强大工具，这些查询具有重复性和可预测性。典型用例包括具有昂贵连接和聚合的仪表板查询。物化视图存储基础查询的结果。这与普通数据库视图不同，后者仅存储查询定义，每次访问视图时执行视图查询。'
- en: The Amazon Redshift query optimizer automatically recognizes when an existing
    materialized view can be used to satisfy a request. It then transparently rewrites
    the request to use the materialized view. Queries go directly to the materialized
    view and not to the underlying detail tables. This automatic query rewrite feature
    means your application queries once written do not need to be changed to take
    advantage of newly created MVs.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊Redshift查询优化器会自动识别可以使用的现有物化视图以满足请求。然后透明地重写请求以使用物化视图。查询直接访问物化视图，而不是底层详细表。这种自动查询重写功能意味着一旦编写应用程序查询，就无需更改即可利用新创建的MV。
- en: MVs can be built on top of other MVs, thus allowing you to create different
    MVs for different levels of aggregation so any flavor of aggregation, from an
    end-user query can be satisfied faster using one or the other MV. Note that refreshing
    an MV is not a cascading process, so you should start with refreshing the deepest
    MV first, and keep refreshing MVs working upward.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: MV可以建立在其他MV之上，因此允许您为不同的聚合级别创建不同的MV，因此可以使用一个或另一个MV更快地满足最终用户查询的任何聚合形式。请注意，刷新MV不是一个级联过程，因此应从最深的MV开始刷新，并保持MV向上工作刷新。
- en: The MV holds point-in-time data as of its last refresh timestamp. Amazon Redshift
    supports fast incremental refresh where it tracks changes to base tables and only
    pulls in impacted records. If an MV is not incremental refresh eligible, then
    it will be recomputed fully when it is refreshed. You can refresh the MV right
    after the base tables have been loaded so you know the MVs will always have the
    most up-to-date results and can always be used to provide query results with the
    automatic query rewrite feature.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: MV保持截至其上次刷新时间戳的数据点。亚马逊Redshift支持快速增量刷新，它跟踪基表的变化并仅拉取受影响的记录。如果一个MV不符合增量刷新条件，则在刷新时将完全重新计算。您可以在加载基表后立即刷新MV，以确保MV始终具有最新结果，并始终可以使用自动查询重写功能提供查询结果。
- en: 'The following tables provide crucial information about MVs:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表提供有关MV的关键信息：
- en: '`STV_MV_INFO` table'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`STV_MV_INFO` 表'
- en: Contains a row for every MV, whether the data is stale, and its state information
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 每个MV的行，无论数据是否过时，以及其状态信息
- en: '`STL_MV_STATE` view'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`STL_MV_STATE` 视图'
- en: Contains a row for every state transition of a materialized view
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 每个物化视图的每个状态转换都包含一行
- en: '`SVL_MV_REFRESH_STATUS` view'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`SVL_MV_REFRESH_STATUS` 视图'
- en: Contains a row for the refresh activity of materialized views
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 每个物化视图刷新活动的行
- en: When querying external tables from your data lake, performing large table joins
    can be an expensive operation. One optimization technique is to create materialized
    views in Amazon Redshift with aggregated data from external tables. If row-level
    data is required for deeper analysis, then the individual files can always be
    accessed via an external table query.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 当从数据湖中的外部表查询外部表时，执行大表连接可能是一个昂贵的操作。一种优化技术是在Amazon Redshift中创建带有外部表聚合数据的物化视图。如果需要更深入的分析的行级数据，则可以通过外部表查询随时访问各个文件。
- en: Autonomics
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自主性
- en: Amazon Redshift’s auto-tuning capabilities are empowered by machine learning.
    Amazon Redshift is establishing smart defaults for many of its architectural settings
    based on best practices, and it is auto-tuning the physical data layout based
    on heuristics. These are covered under the umbrella of autonomics in this section.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift的自动调整能力由机器学习赋予。Amazon Redshift根据最佳实践为其许多架构设置建立智能默认值，并根据启发式自动调整物理数据布局。这些在本节中归入自主性的范畴。
- en: Table `SVL_AUTO_WORKER_ACTION` records all the automatic optimization activities
    done by Amazon Redshift.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 表`SVL_AUTO_WORKER_ACTION`记录了Amazon Redshift执行的所有自动优化活动。
- en: Auto Table Optimizer and Smart Defaults
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动表优化器和智能默认值
- en: '*Automatic table optimization* is a self-tuning capability that automatically
    optimizes the design of tables by applying sort and distribution keys without
    the need for administrator intervention. Auto Table Optimizer (ATO) automatically
    picks the best distribution style and sort key for your tables defined with `AUTO`
    for distribution style and sort key.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '*自动表优化* 是一种自动调整能力，通过应用排序和分布键自动优化表的设计，无需管理员干预。自动表优化器（ATO）会自动选择使用`AUTO`分布样式和排序键来定义您的表的最佳分布样式和排序键。'
- en: By using automation to tune the design of tables, you can get started more easily
    and get the fastest performance quickly without needing to invest time to manually
    tune and implement table optimizations. Primary key (PK) defined on tables is
    generally a good high cardinality column with no duplicates. Thus the primary
    key is a good candidate to be used as distribution key and the Smart Defaults
    algorithms will apply it as the Auto Distribution Key for the table.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用自动化调整表的设计，您可以更轻松地开始，并快速获得最快的性能，而无需投入时间手动调整和实施表优化。通常在表上定义的主键（PK）是一个没有重复项的高基数列，因此主键是作为分布键使用的一个良好候选项，并且智能默认算法会将其应用为表的自动分布键。
- en: Also, Amazon Redshift Advisor will apply heuristics by using the primary key
    to make the recommendation even if the PK has not yet participated in joins. This
    will ensure that recommendations are made sooner rather than later. Once more
    workload data is available, Advisor can make a better recommendation. Tables with
    composite primary keys, typically the fact table, will not be made a recommendation
    based on heuristic, since foreign keys for fact tables typically reference primary
    keys of dimension tables, and when there are multiple dimension tables it is better
    to make a recommendation based on the actual joins applied in the workloads. Once
    this workload pattern can be analyzed, the ATO worker may choose a distribution
    key that is used most often in joins.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，即使主键尚未参与连接，Amazon Redshift Advisor也会应用启发式方法来进行推荐。这将确保尽早做出推荐而不是之后。一旦有更多的工作负载数据可用，顾问可以做出更好的建议。具有复合主键的表，通常是事实表，不会基于启发式方法做出推荐，因为事实表的外键通常引用维表的主键，并且当存在多个维表时，根据工作负载中实际的连接来做出推荐更好。一旦可以分析这种工作负载模式，ATO工作程序可能会选择在连接中最常使用的分布键。
- en: Another optimization the ATO worker will implement, if Auto DK is chosen, is
    to migrate from a PK-based distribution to an ALL-type distribution for small
    tables. This is an effective optimization because typically dimension tables,
    which are used in many joins, have lesser rows when compared to fact tables. Modifying
    the distribution style for small tables ensures join co-location and better performance,
    for example, calendar dimension with ALL distribution style.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果选择了自动DK，ATO工作程序将实施的另一种优化是从基于PK的分布迁移到小表的ALL类型分布。这是一种有效的优化，因为通常维表在许多连接中使用，与事实表相比，行数较少。修改小表的分布样式可确保连接共同位置和更好的性能，例如使用ALL分布样式的日历维度。
- en: Auto Vacuum
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动真空
- en: The auto vacuum worker background process performs two tasks. First is auto
    vacuum delete, to reclaim disk space occupied by rows that were marked for deletion
    by previous Update and Delete operations. Second is auto vacuum sort, to sort
    the physical data blocks by the sort key columns defined for the table. If more
    than 95% of a table is already sorted, then the auto vacuum worker will skip sorting
    this table.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 自动清理工作者后台进程执行两项任务。首先是自动清理删除，用于回收被前面的更新和删除操作标记为删除的行占用的磁盘空间。其次是自动清理排序，按照表格定义的排序关键列对物理数据块进行排序。如果一个表已经有95%以上是排序的，那么自动清理工作者将跳过对该表的排序。
- en: The [Example 5-12](#unsortedness) query provides unsortedness of sample tables.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 5-12](#unsortedness)查询提供了样本表格的无序度。'
- en: Example 5-12\. Table sort benefit
  id: totrans-226
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-12\. 表格排序效益
- en: '[PRE12]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The sales table is heavily unsorted (86%), but there is very little benefit
    (5%) from vacuum sort. The `event` table is relatively lesser unsorted (35%),
    but sorting rows can benefit a lot (67%) for queries.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 销售表格非常无序（86%），但从排序清理中获益很少（5%）。`event`表格相对较少无序（35%），但对查询的排序行为有很大的好处（67%）。
- en: Amazon Redshift continues to look for opportunity to perform vacuum every hour,
    and the auto vacuum worker threshold is based on the number of WLM slots occupied
    by user queries. As long as more than half the WLM slots are available, the auto
    vacuum worker will allocate itself 100 MB of memory, load 100 blocks of a table,
    and begin its operation. After each iteration it will assess the WLM state and
    go for another batch. If user queries arrive and more than 50% of WLM slots get
    occupied by user queries, then the auto vacuum worker will terminate. Any partial
    work done gets discarded, and the auto vacuum worker will reallocate 100 MB next
    time, but previously completed work is saved. In contrast, if a user issues a
    `VACUUM` command, then the same vacuum worker will begin its work but this time
    there is no check for 50% WLM slots, and instead it will take the vacuum job to
    completion.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 每小时都会继续寻找执行清理的机会，而自动清理工作者的阈值基于用户查询占用的 WLM 槽位数量。只要超过一半的 WLM 槽位可用，自动清理工作者将分配自身100
    MB的内存，加载表格的100个数据块，并开始操作。每次迭代后，它会评估 WLM 状态并继续另一批处理。如果用户查询到达并且超过50%的 WLM 槽位被用户查询占用，则自动清理工作者将终止。任何部分完成的工作将被丢弃，下次自动清理工作者将重新分配100
    MB，但之前完成的工作将被保存。相比之下，如果用户发出`VACUUM`命令，则同一清理工作者将开始工作，但这次不会检查50%的 WLM 槽位，而是会一直执行清理工作直至完成。
- en: The vacuum `recluster` option sorts the portions of the table that are unsorted.
    Portions of the table that are already sorted by automatic vacuum sort are left
    intact. This option does not merge the newly sorted data with the sorted region,
    nor reclaim all space that is marked for deletion. If you have frequent data ingestion
    and your queries access only the most recent data, then use the `recluster` option.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '`recluster`选项对部分无序的表格进行排序。已经通过自动清理排序的表格部分将保持不变。该选项不会将新排序的数据与已排序区域合并，也不会回收所有标记为删除的空间。如果你有频繁的数据导入，并且查询只访问最新数据，那么使用`recluster`选项。'
- en: User queries can access the tables while they are being vacuumed by the auto
    or manual vacuum process. You can perform both `select` and `insert` operations
    while a table is being vacuumed, but if you run `update` or `delete` while a `VACUUM`
    is running, both the `VACUUM` and the `update` or `delete` operations might take
    longer.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 用户查询可以在自动或手动清理过程中访问表格。在表格被清理时，你可以执行`select`和`insert`操作，但如果在清理过程中运行`update`或`delete`，那么`VACUUM`和`update`或`delete`操作可能会花费更长时间。
- en: If you need to prioritize vacuum for a particular table and you have free compute
    resources, then use the `BOOST` option, which allocates multiple slots to the
    vacuum operation so that it completes sooner.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要为特定表格优先进行清理，并且有空闲的计算资源，那么使用`BOOST`选项，它会为清理操作分配多个槽位，以便更快地完成。
- en: If a large table is heavily unsorted, then a deep copy can be a faster operation
    than a vacuum, as the deep copy operates on an entire table in one go compared
    to vacuum, which operates on chunks. This also means that your storage is doubled
    for the duration of the deep copy operation.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个大表格非常无序，那么深拷贝可能比空操作更快，因为深拷贝一次性操作整个表格，而空操作则分块进行。这也意味着在深拷贝操作期间，你的存储空间会加倍。
- en: Sample deep copy for table `my_tbl` is provided in [Example 5-13](#example512).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了表格`my_tbl`的深拷贝示例，详见[示例 5-13](#example512)。
- en: Example 5-13\. Deep copy
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-13\. 深拷贝
- en: '[PRE13]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Any data changes to `my_tbl` during the `insert` step are not visible to the
    deep copy operation. So during deep copy operations, you will need to track changes
    and apply them yourself. A better option is to perform this operation during minimal
    to no activity, like your scheduled maintenance window.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在`insert`步骤期间对`my_tbl`进行的任何数据更改对深度复制操作不可见。因此，在深度复制操作期间，您需要跟踪更改并自行应用它们。更好的选择是在最小或无活动期间执行此操作，例如您的计划维护窗口。
- en: Auto Vacuum Sort
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动真空排序
- en: The auto vacuum sort keeps the table data in sorted order by the defined sort
    key columns for the table. It also checks for 50% of WLM slots free, and when
    available it borrows 3 GB memory from WLM. It then performs physical sorting of
    data in the data blocks and works in tandem with auto vacuum worker. It prioritizes
    which blocks of the table to sort by analyzing query patterns using machine learning.
    Amazon Redshift Advisor will provide a recommendation if there is a benefit to
    explicitly run vacuum sort on a given table. Refer back to [Example 5-12](#unsortedness)
    for the vacuum sort benefit.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 自动真空排序通过表的定义排序键列保持表数据按排序顺序排列。它还检查50%的WLM槽空闲情况，并在可用时从WLM借用3 GB内存。然后在数据块中执行物理数据排序，并与自动真空工作器协同工作。它通过分析查询模式使用机器学习优先对表的哪些块进行排序。如果明确在给定表上运行真空排序有益处，则Amazon
    Redshift Advisor将提供建议。请参考[示例 5-12](#unsortedness)获取真空排序的效益。
- en: Auto Analyze
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动分析
- en: The auto analyze worker generates or updates the table statistics metadata that
    is used to choose the optimal query execution plan for better query performance.
    It runs when your data warehouse is idle with over 10 minutes of inactivity. Auto
    analyze works incrementally, and a user-issued analyze command will automatically
    skip tables which have up-to-date statistics.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 自动分析工作器生成或更新用于选择更好查询性能的最佳查询执行计划的表统计元数据。在数据仓库空闲且超过10分钟无活动时运行。自动分析是增量进行的，用户发出的分析命令将自动跳过已经是最新统计数据的表。
- en: Typical data warehouse tables have many columns that are used predominantly
    in the `SELECT` clause, and relatively fewer columns used for `JOIN` and `FILTER`.
    Use the analyze command option `PREDICATE COLUMNS` to analyze only those columns
    that have been used as predicates in queries, like dist key column, sort key columns,
    and columns used in `JOIN`, `FILTER`, or `GROUP BY` clauses. This option provides
    the most benefit by gathering statistics of the column that will have the most
    impact on query performance. If no columns are marked as predicate columns, for
    example because the table has not yet been queried, then all of the columns are
    analyzed, so this is a very safe option to use by default.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的数据仓库表具有许多列，这些列主要在`SELECT`子句中使用，而在`JOIN`和`FILTER`中使用的列相对较少。使用分析命令选项`PREDICATE
    COLUMNS`来分析仅在查询中用作谓词的列，例如分布键列、排序键列以及在`JOIN`、`FILTER`或`GROUP BY`子句中使用的列。此选项通过收集对查询性能影响最大的列的统计信息提供最大的收益。如果没有列被标记为谓词列，例如因为尚未查询表，则将分析所有列，因此这是一个非常安全的默认使用选项。
- en: Amazon Redshift automatically runs analyze on tables that you create with `CREATE
    [TEMP] TABLE AS` or `SELECT INTO` commands. The default analyze threshold is 10%
    of rows changed. But you can choose to set a different analyze threshold at session
    level to fine-tune this behavior.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift会自动在使用`CREATE [TEMP] TABLE AS`或`SELECT INTO`命令创建的表上运行分析。默认的分析阈值是更改的行数的10%。但您可以选择在会话级别设置不同的分析阈值来微调此行为。
- en: You may want to explicitly analyze tables as part of ETL when subsequent steps
    could benefit from latest statistics, or when Amazon Redshift doesn’t auto analyze
    because your data warehouse is heavily utilized and there are no periods of inactivity
    for Amazon Redshift to run auto analyze background tasks.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能希望在ETL的一部分明确分析表，当后续步骤可以从最新的统计数据中获益时，或者当Amazon Redshift没有自动分析因为您的数据仓库被大量使用且没有空闲时段来运行自动分析后台任务时。
- en: Auto Materialized Views (AutoMV)
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动物化视图（AutoMV）
- en: We covered use cases for materialized views in [“Materialized Views”](#mv),
    and the AutoMV feature now builds, refreshes, and drops MVs on your behalf based
    on it’s built-in ML algorithms identifying query patterns that will benefit from
    new materialized views. Your end-user queries do not need to change as Amazon
    Redshift seamlessly fetches results from MV to provide faster query response times.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [“物化视图”](#mv) 中介绍了物化视图的用例，AutoMV 功能现在根据其内置的 ML 算法识别查询模式来构建、刷新和删除 MV。您的最终用户查询无需更改，因为
    Amazon Redshift 会无缝地从 MV 中获取结果，以提供更快的查询响应时间。
- en: Amazon Redshift uses a technique called predicate elevation to create generalized
    AutoMVs by moving the filtered columns from user queries into the `GROUP BY` clause
    for AutoMV. Thus Amazon Redshift stores the full range of data in the materialized
    view, which allows similar queries to use the same materialized view. This approach
    is driven by dashboard-like workloads that often issue identical queries with
    different filter predicates.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 使用一种称为谓词提升的技术来通过将用户查询中的过滤列移动到 AutoMV 的 `GROUP BY` 子句中，从而创建通用的自动化物化视图。因此，Amazon
    Redshift 在物化视图中存储完整的数据范围，允许类似的查询使用同一个物化视图。这种方法是由仪表板样式的工作负载驱动的，这些工作负载经常发出具有不同过滤谓词的相同查询。
- en: Amazon Redshift applies AI to calculate which candidate materialized view provides
    the best performance benefit and system-wide performance optimization. In addition,
    it calculates a cost for system resources required to create and maintain the
    candidate MV. Existing manual materialized views are also considered, and an AutoMV
    will not be created if a manual materialized view already exists that covers the
    same scope. Manual materialized views have higher auto refresh priority over AutoMVs.
    Also AutoMVs related to queries on a higher priority queue are created before
    AutoMVs related to queries on a lower priority queue. The created AutoMVs are
    then monitored by a background process that checks their activity, such as how
    often they have been queried and refreshed. If Amazon Redshift determines that
    an AutoMV is not being used or refreshed, for example due to changes in the base
    table structure or change in query pattern, then the AutoMV is automatically dropped.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 应用 AI 来计算哪个候选物化视图提供最佳的性能优势和系统范围的性能优化。此外，它还计算创建和维护候选 MV 所需的系统资源成本。现有的手动物化视图也会被考虑在内，如果已经存在一个覆盖相同范围的手动物化视图，则不会创建
    AutoMV。手动物化视图具有比 AutoMV 更高的自动刷新优先级。同时，与高优先级队列上的查询相关的 AutoMV 将优先于与低优先级队列上的查询相关的
    AutoMV。创建的 AutoMV 然后由后台进程监控其活动，例如它们被查询和刷新的频率。如果 Amazon Redshift 确定一个 AutoMV 没有被使用或刷新，例如由于基表结构的变化或查询模式的变化，则该
    AutoMV 会被自动删除。
- en: The refresh of AutoMVs is handled in the background automatically. If for some
    reason Amazon Redshift is unable to refresh an AutoMV, then it is marked as stale
    and it is not used to provide query results. Later on, when it is refreshed, then
    the AutoMV is again used for queries.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: AutoMV 的刷新由后台自动处理。如果由于某些原因 Amazon Redshift 无法刷新 AutoMV，则将其标记为过时，并且不用来提供查询结果。稍后，当刷新完成后，AutoMV
    再次用于查询。
- en: Amazon Redshift Advisor
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Redshift 顾问
- en: Amazon Redshift Advisor is like having a 24-7 DBA who is monitoring your workloads
    and offers you specific recommendations related to operations and data warehouse
    settings to improve the throughput of your warehouse and save on operating costs.
    It also prioritizes the recommendations and ranks them in order of performance
    impact to your workloads.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 顾问就像拥有一位全天候的数据库管理员，监视您的工作负载并为您提供与操作和数据仓库设置相关的具体建议，以改善仓库的吞吐量并节省运营成本。它还优先考虑建议并按照对工作负载性能影响的顺序对其进行排名。
- en: Amazon Redshift Advisor recommendations are based on observations regarding
    performance statistics and operational data for your specific workloads. It develops
    recommendations by running tests on your data warehouse to determine if a suspect
    value is within a specified range. If the test result is outside of that range,
    Advisor generates recommendations for your data warehouse. At the same time, Advisor
    provides actionable steps for how to bring the deviated value back into the best-practice
    range. Advisor only displays recommendations that would have a significant impact
    on performance. It also removes recommendation from your recommendations list
    once you have addressed it.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊Redshift Advisor的建议是基于对您特定工作负载的性能统计和操作数据的观察。它通过在您的数据仓库上运行测试来生成建议，以确定疑似值是否在指定范围内。如果测试结果超出该范围，Advisor会为您的数据仓库生成建议。同时，Advisor提供可行的步骤，帮助将偏离值调整回最佳实践范围。Advisor仅显示对性能有显著影响的建议。一旦您处理了建议，它还会从您的建议列表中删除建议。
- en: See [Amazon Redshift Advisor](https://oreil.ly/YfSA_) best practices on working
    with recommendations from Amazon Redshift Advisor.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 参见[亚马逊Redshift Advisor](https://oreil.ly/YfSA_)关于如何处理来自亚马逊Redshift Advisor的建议的最佳实践。
- en: 'Currently it covers the following topics:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 目前它涵盖了以下主题：
- en: Compress Amazon S3 file objects loaded by `COPY`
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`COPY`压缩亚马逊S3文件对象
- en: Isolate multiple active databases
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隔离多个活动数据库
- en: Reallocate workload management (WLM) memory
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新分配工作负载管理（WLM）内存
- en: Skip compression analysis during `COPY`
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`COPY`期间跳过压缩分析
- en: Split Amazon S3 objects loaded by `COPY`
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`COPY`加载分割亚马逊S3对象
- en: Update table statistics
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新表统计信息
- en: Enable short query acceleration
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用短查询加速
- en: Alter distribution keys on tables
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在表上修改分布键
- en: Alter sort keys on tables
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在表上修改排序键
- en: Alter compression encodings on columns
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在列上修改压缩编码
- en: Data type recommendations
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据类型建议
- en: Each recommendation is provided with the analysis performed, time range of data
    that was analyzed, and either a query to implement the recommendation or a query
    to list impacted objects.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 每个建议都附带进行的分析、分析的数据时间范围，以及要实施建议的查询或列出受影响对象的查询。
- en: If you don’t see a recommendation, that doesn’t necessarily mean that your current
    table setup is the most appropriate. Advisor doesn’t provide recommendations when
    there isn’t enough data or the expected benefit of making changes is small.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您看不到建议，并不一定意味着您当前的表设置是最合适的。当数据不足或者预期的变更效益较小时，Advisor不会提供建议。
- en: The time when Advisor runs is not under user control. It kicks in when your
    data warehouse isn’t busy and Amazon Redshift can use some empty cycles and resources
    to perform its analysis. This is similar to when your warehouse is very busy and
    auto-tuning activities like auto vacuum, auto table optimization (ATO), and auto
    analyze may not run.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Advisor运行的时间不受用户控制。当您的数据仓库不忙时，Amazon Redshift可以利用一些空闲周期和资源来执行其分析。这类似于您的数据仓库非常繁忙时，自动调整活动如自动清理、自动表优化（ATO）和自动分析可能不会运行。
- en: As of 2022, Amazon Redshift Advisor needs at least 100 queries to be executed
    on a table to be able to make a recommendation. This requirement will relax going
    into the future, and you will see recommendations even sooner.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2022年，亚马逊Redshift Advisor需要在表上执行至少100个查询才能提出建议。这一要求将来会放宽，您将更早地看到建议。
- en: Workload Isolation
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作负载隔离
- en: A *workload* is a set of queries run by a team, department, or group. And to
    be able to support multiple workloads on a single Amazon Redshift cluster, you
    need to design for workload isolation. *Workload isolation* is how to make sure
    that one workload does not consume resources in a way that it impacts other workload
    execution. You have seen earlier how WLM queues and associated QMR provide controls
    and a method for workload isolation. In these cases the resources of one cluster
    are being shared for multiple user workloads. Such a design can lead to conflicts,
    especially if each workload is owned by a different team and these teams are forced
    to share the resources of that single cluster. You can define only eight queues,
    and for complex multiuser workloads eight queues might not be enough for segregation.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '*工作负载* 是由团队、部门或群组运行的一组查询。为了能够在单个亚马逊Redshift集群上支持多个工作负载，您需要设计工作负载隔离。*工作负载隔离*
    是如何确保一个工作负载不会以影响其他工作负载执行方式消耗资源。您已经看到之前WLM队列和相关的QMR如何提供控制和工作负载隔离的方法。在这些情况下，一个集群的资源被多个用户工作负载共享。这样的设计可能会导致冲突，特别是如果每个工作负载由不同团队拥有，并且这些团队被迫共享单个集群的资源。您只能定义八个队列，对于复杂的多用户工作负载，八个队列可能不足以进行隔离。'
- en: With the Data Sharing feature you can achieve even more workload isolation and
    tighter control over resource allocation by segregating workloads into their own
    Amazon Redshift data warehouses. Each warehouse can then implement its own WLM
    queues and further allocate compute resources. You can even mix and match provisioned
    and serverless data warehouses based on workload duration and have multiple consumers
    for the same data shared by producer. Refer to [Chapter 7](ch07.html#AR_TGD_CH7)
    to learn more about how to use data sharing for workload isolation.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据共享功能，您可以通过将工作负载隔离到其自己的亚马逊Redshift数据仓库中，实现更高的工作负载隔离和更紧密的资源分配控制。然后，每个仓库可以实施自己的WLM队列并进一步分配计算资源。您甚至可以基于工作负载的持续时间混合和匹配预配和无服务器数据仓库，并且由生产者共享的相同数据可以有多个消费者。请参考[第7章](ch07.html#AR_TGD_CH7)了解更多关于如何使用数据共享来进行工作负载隔离的信息。
- en: Additional Optimizations for Achieving the Best Price and Performance
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为实现最佳价格和性能的额外优化
- en: Today’s analytics environments are very demanding, and workloads are continuously
    evolving with data volumes only increasing over time. [“Autonomics”](#Autonomics)
    discussed how Amazon Redshift is making it easier by automating more and more
    tasks. Here are some considerations where you can optimize for achieving the best
    balance between price and performance of your warehouse.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的分析环境非常苛刻，工作负载随着时间推移不断演变，数据量也在持续增加。["自动化"](#Autonomics) 讨论了亚马逊Redshift通过自动化更多任务来简化操作。以下是一些考虑因素，您可以优化数据仓库，实现最佳价格和性能的平衡。
- en: Database Versus Data Warehouse
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库与数据仓库
- en: Consider your data volume and evaluate Amazon Aurora, specially for data volumes
    in GBs, even for analytics workloads. Amazon Redshift is good for processing large
    volumes of data, and it comes at a higher cost for smaller workloads. For workloads
    with relaxed query response time requirements, you can even consider offloading
    the final transposed analytical data to the Amazon S3 data lake in open formats
    like Parquet and leverage Amazon Athena query capabilities.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑您的数据量，并评估适合GB级数据量的亚马逊Aurora，甚至用于分析工作负载。亚马逊Redshift适合处理大数据量，并且对于较小的工作负载来说成本较高。对于对查询响应时间要求较为宽松的工作负载，甚至可以考虑将最终转置的分析数据转移到亚马逊S3数据湖中，使用Parquet等开放格式，并利用亚马逊Athena的查询功能。
- en: Amazon Redshift Serverless
  id: totrans-277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊Redshift无服务器
- en: If you’re not already using Amazon Redshift serverless, it is a good choice
    when it is difficult to predict compute needs because you have variable workloads,
    periodic workloads with intermittent idle time, or spikes in between steady-state
    workloads. Amazon Redshift serverless scales automatically as your query pattern
    changes with more concurrent users and new workloads. And you are billed for compute
    only when user query is executed on user data; queries that execute on metadata
    or system tables are not billable.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您尚未使用亚马逊Redshift无服务器，当难以预测计算需求时，这是一个不错的选择，因为您具有可变的工作负载、周期性的工作负载和间歇空闲时间的峰值。亚马逊Redshift无服务器会根据查询模式的变化自动扩展，随着更多并发用户和新工作负载的出现。只有在执行用户数据上的用户查询时，您才会收到计算费用；对元数据或系统表执行的查询是不计费的。
- en: If you are starting out with analyzing a dataset, then Amazon Redshift serverless
    provides you with a fast and easy way to get started without having to size or
    choose an appropriate cluster configuration. With serverless, your set compute
    is measured in Redshift Processing Units (RPUs), which equate to a certain processor
    and memory configuration. Serverless sets a default RPU, and you can change the
    default based on your workload requirement. Serverless takes care of automatically
    scaling RPUs based on the incoming workloads. The effort to maintain an appropriately
    sized provisioned cluster tuned to performance could be outweighed by the benefits
    of autoscaling RPUs.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在分析数据集，那么Amazon Redshift无服务器提供了一种快速简便的方式，无需选择或配置适当的集群配置即可开始。在无服务器环境下，您的计算设置以Redshift处理单元（RPU）为单位，这相当于某种处理器和内存配置。无服务器设置了默认的RPU，您可以根据工作负载需求更改默认值。无服务器会根据传入的工作负载自动调整RPU的规模。与维护调整到性能的预配置集群相比，自动扩展RPU的好处可能更胜一筹。
- en: Multi-Warehouse Environment
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多仓库环境
- en: Instead of trying to manage one huge cluster, it might be beneficial to break
    down your data warehouse environment into many smaller data warehouses. Along
    with workload isolation, you can also get granularity for budgets, accounting,
    and ownership. Each team, department, and organizational unit can independently
    size and pay for compute as they see fit for their use case and still leverage
    data sharing to democratize their data.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 与试图管理一个巨大的集群相比，将数据仓库环境分解为许多较小的数据仓库可能更有利。除了工作负载隔离外，您还可以获得预算、会计和所有权的细粒度。每个团队、部门和组织单位都可以独立地根据其用例大小和付费计算，并利用数据共享来民主化其数据。
- en: Amazon Redshift supports setting up multi-warehouse environments with provisioned
    as well as serverless data warehouses using the data-sharing feature. The producer
    as well as the consumer can either be provisioned or serverless. This flexibility
    coupled with AWS Lake Formation integration for all data catalogs, data access,
    and data governance will enable your organization to easily and quickly build
    a data mesh architecture across the organization; refer to the [AWS blog](https://oreil.ly/VhBwX)
    for details.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift支持使用数据共享功能设置多仓库环境，既可以是预配置的数据仓库，也可以是无服务器数据仓库。生产者和消费者可以是预配置或无服务器的。这种灵活性结合AWS
    Lake Formation集成所有数据目录、数据访问和数据治理，将使您的组织能够轻松快速地在整个组织中构建数据网格架构；详情请参阅[AWS博客](https://oreil.ly/VhBwX)。
- en: AWS Data Exchange
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS数据交换
- en: AWS Data Exchange makes it easy to get the data you need with unified billing.
    You can search through the catalog of all listed products and filter by industry,
    vendor, or delivery method. AWS Data Exchange (ADX) offers free as well as paid
    subscription options for you to first try out the data before committing to a
    subscription. It also offers public pricing and private pricing agreements so
    you can negotiate the terms and conditions for the product before purchase. ADX
    will automatically revoke access once subscription lapses so data provider and
    data consumer can both be assured that only authorized data products are accessible.
    You can also monetize your Amazon Redshift data by creating an ADX Data Share
    and listing it as a product on AWS Marketplace.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: AWS数据交换通过统一计费，使您轻松获取所需数据。您可以搜索所有列出产品的目录，并按行业、供应商或交付方式进行过滤。AWS数据交换（ADX）提供免费和付费订阅选项，供您在订阅之前先尝试数据。它还提供公共定价和私人定价协议，以便您在购买之前就可以协商产品的条款和条件。ADX将在订阅到期后自动撤销访问权限，因此数据提供者和数据消费者都可以确保只有授权的数据产品可访问。您还可以通过创建ADX数据共享并将其列为AWS市场上的产品来获取Amazon
    Redshift数据的收益。
- en: If your workload needs third-party data, then you should leverage ADX to simplify
    the data procurement process. You can get data in Amazon S3 files, Amazon Redshift
    datashares, or live data via APIs. Refer to [AWS Data Exchange](https://oreil.ly/fsRC_)
    for details.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的工作负载需要第三方数据，则应利用ADX简化数据采购过程。您可以从Amazon S3文件、Amazon Redshift数据共享或通过API获取实时数据。详情请参阅[AWS数据交换](https://oreil.ly/fsRC_)。
- en: Table Design
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 表设计
- en: If you are coming from other databases to Amazon Redshift, then take particular
    note of the technical differences between these two technologies.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您从其他数据库迁移到Amazon Redshift，则应特别注意这两种技术之间的技术差异。
- en: When choosing key distribution style, you are limited to a single column. If
    your tables are being joined on multiple columns, you can fabricate a new column
    with concatenated data from all original join columns and use that as distribution
    key. If the base columns contain variable length string fields, then you hash
    the concatenated result to get a fixed-length column as distribution key. This
    will ensure co-located joins, minimize internode data movement, and thus provide
    best performance.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择关键分布样式时，您仅限于单列。如果您的表在多列上进行连接，则可以创建一个新列，其中包含所有原始连接列的连接数据，并将其用作分布键。如果基础列包含可变长度字符串字段，则对连接结果进行哈希处理以获得固定长度的列作为分布键。这将确保联合连接位于同一位置，最小化节点间数据移动，从而提供最佳性能。
- en: Amazon Redshift has automated most aspects of data architecture, and you need
    not worry too much about table design. But this is based off of machine learning
    and it needs data to draw inferences, so there is a lag before Amazon Redshift
    tunes the tables for you. Follow the [table design best practices](https://oreil.ly/tjjaO)
    so you can get good performance from the very beginning of your data warehouse
    journey.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift已自动化大部分数据架构方面的工作，因此您无需过多担心表设计。但这是基于机器学习的，并且需要数据来推断，因此在Amazon
    Redshift为您调整表之前会有一定的滞后。遵循[表设计最佳实践](https://oreil.ly/tjjaO)，以便从数据仓库旅程的最开始就获得良好的性能。
- en: Indexes Versus Zone Maps
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 索引与区域映射
- en: Amazon Redshift does not offer indexes or table partitions. It uses Zone Maps,
    which are min and max column values for each data block, to locate the data for
    you. Zone maps are most effective when data is sorted. For small tables, you can
    skip defining a sort key. For larger tables with even distribution style, choose
    most frequently filtered upon column for the sort key. If using key distribution,
    then you can specify the join column as both the sort key and the distribution
    key, which enables the faster sort merge join.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift不提供索引或表分区。它使用区域映射来定位数据，区域映射是每个数据块的最小和最大列值。当数据排序时，区域映射最为有效。对于小表，您可以跳过定义排序键。对于具有均匀分布样式的大表，选择最频繁过滤的列作为排序键。如果使用关键分布，则可以将连接列指定为排序键和分布键，从而实现更快的排序合并连接。
- en: Drivers
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 驱动程序
- en: Always use the latest [drivers](https://oreil.ly/QWgZW) from Amazon Redshift
    so you can keep up with the latest features provided. If your third-party software
    provides its own driver for Amazon Redshift, then use that. You should use a previous
    version of the Amazon Redshift driver only if your tool requires a specific version
    of the driver.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 始终使用最新的[驱动程序](https://oreil.ly/QWgZW)来自Amazon Redshift，以便跟上提供的最新功能。如果您的第三方软件为Amazon
    Redshift提供自己的驱动程序，则使用该驱动程序。仅在您的工具需要特定版本的驱动程序时才使用Amazon Redshift的先前版本驱动程序。
- en: Simplify ETL
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简化ETL
- en: Leverage features like [Amazon Redshift federated query](https://oreil.ly/zuJIB)
    to simplify ETL by tapping into operational data directly or replicating it to
    your warehouse and implementing the ELT approach. To reduce data movement over
    the network and improve performance, Amazon Redshift distributes part of the computation
    for federated queries directly into the remote operational databases.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 利用类似[Amazon Redshift联合查询](https://oreil.ly/zuJIB)的功能简化ETL，直接利用运营数据或将其复制到数据仓库，并实施ELT方法。为了减少网络数据传输并提高性能，Amazon
    Redshift直接将联合查询的部分计算分布到远程操作数据库中。
- en: '[Amazon Redshift integration for Apache Spark](https://oreil.ly/kO62y) makes
    it easy to build and run Spark applications on Amazon Redshift. Your Spark applications
    can read from and write to your Amazon Redshift data warehouse without compromising
    on transactional consistency of the data or performance by leveraging the Amazon
    Redshift push-down optimizations.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '[Amazon Redshift与Apache Spark集成](https://oreil.ly/kO62y)使得在Amazon Redshift上构建和运行Spark应用程序变得容易。您的Spark应用程序可以读取和写入您的Amazon
    Redshift数据仓库，同时利用Amazon Redshift的推送优化，无需牺牲数据的事务一致性或性能。'
- en: The feature for [Amazon Aurora zero-ETL integration with Amazon Redshift](https://oreil.ly/-9Yal)
    can be leveraged if you are loading entire transactional data from Amazon Aurora
    into Amazon Redshift for running analytics. This zero-ETL is a storage-level replication
    mechanism and is more efficient than exporting or copying rows from source to
    target.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您要加载来自Amazon Aurora的整个事务数据到Amazon Redshift进行分析，则可以利用[Amazon Aurora与Amazon
    Redshift零ETL集成](https://oreil.ly/-9Yal)的功能。这种零ETL是一种存储级别的复制机制，比从源到目标的导出或复制行更有效率。
- en: Query Editor V2
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询编辑器V2
- en: Amazon Redshift Query Editor V2 is a fully managed SQL editor in your browser.
    It will automatically scale as your user community grows. There is no desktop
    software to install, and it reduces the number of steps required to be able to
    run your first query. As a additional team scalability feature, it improves collaboration
    with saved queries and the ability to share results and analyses between users.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 查询编辑器 V2 是一个完全托管的 SQL 编辑器，可以在您的浏览器中使用。随着用户社区的增长，它会自动扩展。无需安装桌面软件，并减少运行第一个查询所需的步骤。作为额外的团队可扩展功能，它通过保存的查询和共享结果以及用户之间的分析来提高协作。
- en: In this chapter, you have learned how to scale your Amazon Redshift data warehouse,
    how to set up workload management, and optimize for best price and performance
    of your workloads.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您已经学习了如何扩展您的 Amazon Redshift 数据仓库，如何设置工作负载管理，并优化工作负载的最佳价格和性能。
- en: Query Tuning
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询调优
- en: Amazon Redshift uses queries based on structured query language (SQL) to interact
    with data and objects in the system. *Data manipulation language* (DML) is the
    subset of SQL that you use to view, add, change, and delete data. *Data definition
    language* (DDL) is the subset of SQL that you use to add, change, and delete database
    objects such as tables and views. Before we dive into query writing best practices
    and performance tuning your queries, let’s first understand how Amazon Redshift
    processes queries.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 使用基于结构化查询语言（SQL）的查询与系统中的数据和对象交互。*数据操作语言*（DML）是您用来查看、添加、更改和删除数据的
    SQL 的子集。*数据定义语言*（DDL）是您用来添加、更改和删除数据库对象（如表和视图）的 SQL 的子集。在我们深入了解查询写作的最佳实践和优化查询性能之前，让我们先了解一下
    Amazon Redshift 如何处理查询。
- en: Query Processing
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询处理
- en: All queries submitted to Amazon Redshift are first parsed and then the optimizer
    develops a query execution plan (see [Figure 5-6](#query_processing_ch5)).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 所有提交到 Amazon Redshift 的查询都首先被解析，然后优化器开发查询执行计划（参见 [图 5-6](#query_processing_ch5)）。
- en: 'The three steps for each query are:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 每个查询的三个步骤是：
- en: Query planning
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询规划
- en: Query compilation
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询编译
- en: Query execution
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询执行
- en: '![Amazon Redshift Query Processing](assets/ardg_0506.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift 查询处理](assets/ardg_0506.png)'
- en: Figure 5-6\. Amazon Redshift query processing
  id: totrans-310
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-6\. Amazon Redshift 查询处理
- en: Query planning and execution workflow
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查询规划和执行工作流程
- en: The Amazon Redshift leader node receives the query and parses the SQL query.
    Any syntax errors are reported, and if parsing succeeds then the parser produces
    a logical representation of the original query. This initial query tree is sent
    to the query optimizer.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 领导节点接收查询并解析 SQL 查询。报告任何语法错误，如果解析成功，则解析器生成原始查询的逻辑表示。这个初始查询树被发送给查询优化器。
- en: The query optimizer evaluates the query, analyzes table statistics to determine
    join order and predicate selectivity, and rewrites the query to maximize its efficiency.
    The query optimizer generates a query plan that describes execution order and
    network operations to be performed, and examples join types, join order, aggregation
    options, and data distribution requirements. The optimized query plan is then
    submitted as input to the execution engine.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 查询优化器评估查询，分析表统计信息以确定连接顺序和谓词选择性，并重新编写查询以最大化其效率。查询优化器生成描述执行顺序和网络操作以及示例连接类型、连接顺序、聚合选项和数据分布要求的查询计划。优化后的查询计划然后作为输入提交给执行引擎。
- en: The execution engine first checks the compile cache for a query-plan match.
    If none is found, then the execution engine translates the query plan into steps,
    segments, and streams. The execution engine generates compiled C++ code based
    on steps, segments, and streams as shown in [Figure 5-7](#query_steps_ch5). This
    compiled code is added to the cache and then broadcast to the compute nodes.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 执行引擎首先检查编译缓存以查找查询计划匹配项。如果找不到匹配项，则执行引擎将查询计划转换为步骤、段和流。执行引擎基于步骤、段和流生成编译后的 C++ 代码，如
    [图 5-7](#query_steps_ch5) 所示。编译后的代码被添加到缓存中，然后广播到计算节点。
- en: '![Amazon Redshift Query Steps](assets/ardg_0507.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift 查询步骤](assets/ardg_0507.png)'
- en: Figure 5-7\. Amazon Redshift query steps
  id: totrans-316
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-7\. Amazon Redshift 查询步骤
- en: The compute node slices execute the query segments in parallel. When compute
    nodes are done with the execution, they return the query results to the leader
    node for final processing. The leader node merges the results from the compute
    nodes into a single result set and addresses any needed sorting or aggregation
    before returning the results to the query submitter.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 计算节点切片并行执行查询段。当计算节点完成执行后，它们将查询结果返回给领导节点进行最终处理。领导节点将从计算节点合并结果到单一结果集，并在返回给查询提交者之前进行任何必要的排序或聚合。
- en: Query stages and system tables
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查询阶段和系统表
- en: Now we will take a look at the details for each stage and the associated system
    tables that will capture the particulars.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将详细查看每个阶段及相关的系统表以捕获具体信息。
- en: 'Stage 1: Parsing and validation'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 第1阶段：解析和验证
- en: During query planning the SQL query is first parsed and syntax is validated.
    If the query is valid, then a query tree is generated. At this point an entry
    is made in the [`STV_RECENTS`](https://oreil.ly/XRDLl) system table. Also, at
    this stage, if Redshift identifies that the query can be cached, the cache will
    be checked for any existing entry and if found, the results are fetched from the
    Redshift cache and sent to the client by the leader node without the query going
    through the following stages. The information on query caching can be found in
    the [`SVL_QLOG`](https://oreil.ly/rZeZq) system table.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询规划期间，SQL查询首先被解析和语法验证。如果查询有效，则生成查询树。此时，将在[`STV_RECENTS`](https://oreil.ly/XRDLl)系统表中记录条目。此外，在此阶段，如果Redshift识别到可以缓存查询，将检查任何现有条目，并且如果找到，则结果将通过领导节点从Redshift缓存中获取并发送给客户端，而无需经过后续阶段。关于查询缓存的信息可以在[`SVL_QLOG`](https://oreil.ly/rZeZq)系统表中找到。
- en: 'Stage 2: Query requests locks'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 第2阶段：查询请求锁定
- en: The query tree then is sent to acquire locks. The current locking status of
    the Redshift cluster can be found in the [`STV_LOCKS`](https://oreil.ly/bRo5n)
    system table.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，查询树被发送以获取锁。可以在[`STV_LOCKS`](https://oreil.ly/bRo5n)系统表中找到Redshift集群的当前锁定状态。
- en: 'Stage 3: Planner and optimizer'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 第3阶段：规划器和优化器
- en: After the locks are acquired, the Redshift optimizer will rewrite the query
    to the optimal form for Redshift. The output of this stage is a plan tree, which
    is PostgreSQL compliant. At this stage the query plan will be logged in [`STL_EXPLAIN`](https://oreil.ly/YPo9j)
    and the query text in the [`STL_QUERYTEXT`](https://oreil.ly/mb1Ln) system tables.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 获取锁之后，Redshift优化器将查询重写为适合Redshift的最佳形式。此阶段的输出是计划树，与PostgreSQL兼容。在此阶段，查询计划将记录在[`STL_EXPLAIN`](https://oreil.ly/YPo9j)中，而查询文本则记录在[`STL_QUERYTEXT`](https://oreil.ly/mb1Ln)系统表中。
- en: 'Stage 4: WLM scheduler'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 第4阶段：WLM调度器
- en: After successful plan generation, the query enters the WLMscheduler. Here, the
    query will wait for a queue slot, which when available will be sent for execution
    based on the [queue assignment](https://oreil.ly/kMvtF). At this stage, the query
    makes an entry in the [`STV_WLM_QUERY_STATE`](https://oreil.ly/sFzSz) system table
    for details on the query queue state and check the [`STV_WLM_QUERY_QUEUE_STATE`](https://oreil.ly/CdFQu)
    system table.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 计划生成成功后，查询进入WLM调度器。在这里，查询将等待队列槽位，一旦可用，将根据[队列分配](https://oreil.ly/kMvtF)将其发送到执行。此阶段，查询在[`STV_WLM_QUERY_STATE`](https://oreil.ly/sFzSz)系统表中记录详细的查询队列状态，并检查[`STV_WLM_QUERY_QUEUE_STATE`](https://oreil.ly/CdFQu)系统表。
- en: 'Stage 5: Code generator/compiler'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 第5阶段：代码生成器/编译器
- en: After acquiring the WLM slot for execution, an entry is made in the [`STV_INFLIGHT`](https://oreil.ly/KWfG0)
    system table. Now, the Redshift execution planner will make the generated plan
    tree compliant with the Redshift distributive architecture, i.e. the query is
    now divided into streams, segments, and steps. After this, the segments are sent
    for compilation; here we can check the [`SVL_COMPILE`](https://oreil.ly/FZoD1)
    system table for the compile time records and location of each query segment.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 执行`WLM`槽位后，[`STV_INFLIGHT`](https://oreil.ly/KWfG0)系统表中会记录一个条目。现在，Redshift执行计划器将生成的计划树符合Redshift的分布式架构，即将查询分成流、段和步骤。完成后，段将被发送进行编译；在这里，我们可以检查[`SVL_COMPILE`](https://oreil.ly/FZoD1)系统表，获取编译时间记录及每个查询段的位置。
- en: 'Stage 6: Distribution'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 第6阶段：分布
- en: The leader node distributes the code to the compute node. All segments of a
    stream are sent for execution through all slices since the data is distributed
    across the slices. Once the segments of the first stream complete execution through
    all slices, the second stream’s segments will be executed.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点将代码分发到计算节点。由于数据分布在各个片段中，流的所有段通过所有切片进行执行。一旦第一个流的段通过所有切片完成执行，第二个流的段将被执行。
- en: 'Stage 7: Query execution'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '阶段 7: 查询执行'
- en: The compute node performs computations and processes the query. The information
    about query execution at this stage can be found in [`STV_EXEC_STATE`](https://oreil.ly/mxgBz)
    (when in Running state) and post execution, in [`SVL_QUERY_REPORT`](https://oreil.ly/mhu-U)
    and [`SVL_QUERY_SUMMARY`](https://oreil.ly/igWRB) system tables.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 计算节点执行计算并处理查询。在此阶段的查询执行信息可以在 [`STV_EXEC_STATE`](https://oreil.ly/mxgBz)（处于运行状态时）和执行后的
    [`SVL_QUERY_REPORT`](https://oreil.ly/mhu-U) 以及 [`SVL_QUERY_SUMMARY`](https://oreil.ly/igWRB)
    系统表中找到。
- en: 'Stage 8: Final computation/aggregation'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '阶段 8: 最终计算/聚合'
- en: At this stage, the compute node sends results to the leader node. The leader
    node performs the final computation and sends results back to the client. After
    this stage you can find the query information in the [`STL_QUERY`](https://oreil.ly/A_Iox)
    and [`STL_WLM_QUERY`](https://oreil.ly/56idm) system tables.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在此阶段，计算节点将结果发送给主节点。主节点执行最终计算并将结果发送回客户端。在此阶段之后，您可以在 [`STL_QUERY`](https://oreil.ly/A_Iox)
    和 [`STL_WLM_QUERY`](https://oreil.ly/56idm) 系统表中找到查询信息。
- en: 'Stage 9: Commit queue (if needed)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '阶段 9: 提交队列（如有需要）'
- en: The query enters commit queue. For queries that require commit operation (for
    example, DDL commands), the query undergoes this additional stage before returning
    the results to the client. This information is logged in [`STL_COMMIT_STATS`](https://oreil.ly/gDAM9).
    After the commit operation is performed on all CNs, the LN sends the results to
    the client.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 查询进入提交队列。对于需要提交操作的查询（例如DDL命令），查询在返回结果给客户端之前会经历这个额外的阶段。此信息记录在 [`STL_COMMIT_STATS`](https://oreil.ly/gDAM9)
    中。在所有计算节点上执行提交操作后，LN 将结果发送给客户端。
- en: To get an overview of the query execution runtime, please use the [`SYS_QUERY_HISTORY`](https://oreil.ly/76IZa)
    system table.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解查询执行运行时的概述，请使用 [`SYS_QUERY_HISTORY`](https://oreil.ly/76IZa) 系统表。
- en: Cached compile code is shared across sessions, so subsequent executions of the
    same query will be faster, even with different parameters. Query plan compilation
    and execution of compiled code happen only once for each stream.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存的编译代码在会话之间共享，因此即使使用不同的参数，对相同查询的后续执行也将更快。查询计划编译和编译代码的执行仅在每个流中执行一次。
- en: Understanding the query plan
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解查询计划
- en: You can run the `explain` command to view the query execution plan as shown
    in [Example 5-14](#example513). It gives you the information for the operations
    the execution engine performs. Reading the plan is from bottom to top, innermost
    step to outer. You will see which tables and columns are used in each operation
    and how much data, in terms of row count and row width in bytes, is processed
    in each operation. You also see the cost of each operation. It is important to
    note that this cost does not provide any precise information about actual execution
    times or memory consumption. The query optimizer compares cost across various
    execution plans and picks the best one for execution. The cost for each step gives
    you an indication of which particular operation within a given query is estimated
    to consume the most resources.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以运行 `explain` 命令来查看查询执行计划，如 [示例 5-14](#example513) 所示。它为执行引擎执行的操作提供信息。阅读计划是从底部到顶部，从内到外的最内步骤开始。您将看到每个操作中使用的表和列，以及每个操作中处理的数据量（以行数和字节的行宽表示）。您还会看到每个操作的成本。需要注意的是，这些成本并不提供关于实际执行时间或内存消耗的精确信息。查询优化器比较各种执行计划的成本，并选择最佳执行计划。每个步骤的成本指示了估计为每个给定查询中的特定操作消耗最多资源的情况。
- en: Example 5-14\. Query execution plan
  id: totrans-342
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-14\. 查询执行计划
- en: '[PRE14]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The `XN Seq Scan` indicates a sequential scan operator on the particular table.
    `Seq Scan` scans each selected column in the table sequentially from beginning
    to end and evaluates any query predicates specified in the `WHERE` clause, for
    every row scanned.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '`XN Seq Scan` 表示特定表上的顺序扫描操作符。`Seq Scan` 顺序扫描表中的每个选定列，从开头到结尾依次扫描，并评估在`WHERE`子句中指定的任何查询谓词，对于每一行扫描的情况。'
- en: The cost is provided as `(cost=0.00..37.66 rows=3766 width=12)`; here the cost
    is shown for fetching the first row and for fetching the last row; the estimated
    row count and the row width is also displayed.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 成本显示为`(cost=0.00..37.66 rows=3766 width=12)`；这里显示了获取第一行和获取最后一行的成本；还显示了估计的行数和行宽度。
- en: The `XN Hash` operator creates the hash table for the inner table in the join.
    The `XN Hash Join` operator is used for inner joins and left and right outer joins.
    The hash join operator reads the outer table, hashes the joining column, and finds
    matches in the inner hash table.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '`XN Hash` 操作符用于创建连接中内表的哈希表。`XN Hash Join` 操作符用于内连接、左连接和右连接。哈希连接操作符读取外表，对连接列进行哈希处理，并在内部哈希表中查找匹配项。'
- en: The cost is provided as `XN Hash Join DS_DIST_NONE (cost=47.08..6340.89 rows=3766
    width=16)`; here `rows=3766` represents the estimated rows resulting from the
    join operation.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 成本显示为 `XN Hash Join DS_DIST_NONE (cost=47.08..6340.89 rows=3766 width=16)`；这里的
    `rows=3766` 表示连接操作的预计行数。
- en: Review the plan to see if the rows from the join operation are in the anticipated
    range. Too high a number here can indicate missing statistics or missing primary-key
    or foreign-key constraints. These can aid the query planner in producing better
    row estimates.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看计划，以确定连接操作的行数是否在预期范围内。此处的数字过高可能表示缺少统计信息或缺少主键或外键约束。这些信息可以帮助查询规划器生成更好的行估计。
- en: Amazon Redshift also has the nested loop join, which is used mainly for cross-joins
    (Cartesian products) and some inequality joins.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift还具有嵌套循环连接，主要用于交叉连接（笛卡尔积）和一些不等连接。
- en: The nested loop join is the least optimal join in Amazon Redshift.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌套循环连接是Amazon Redshift中最不理想的连接方式。
- en: Amazon Redshift also has the merge join, which is used for inner joins and outer
    joins but not used for full joins. Merge is typically the fastest join operator,
    used when joining tables where the join columns are both distribution keys and
    sort keys, and when less than 20% of the joining tables are unsorted.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift还具有合并连接（merge join），用于内连接和外连接，但不用于全连接。合并连接通常是最快的连接操作符，用于连接表，其中连接列既是分布键又是排序键，并且连接的表中不超过20%未排序。
- en: The `XN Aggregate` operator is for queries that involve aggregate functions
    and `GROUP BY` operations. You can view the query execution plan for the aggregate
    functions as in [Example 5-15](#example514).
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '`XN Aggregate` 操作符用于涉及聚合函数和 `GROUP BY` 操作的查询。您可以查看聚合函数的查询执行计划，例如 [示例 5-15](#example514)。'
- en: Example 5-15\. Query execution plan for aggregate operator
  id: totrans-354
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-15。聚合操作符的查询执行计划
- en: '[PRE16]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[Figure 5-8](#query_streams_ch5) shows the preceding query and associated query
    plan. It displays how the query operations involved map to steps that Amazon Redshift
    uses to generate compiled code for the compute node slices. Each query plan operation
    maps to multiple steps within the segments, and sometimes to multiple segments
    within the streams.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-8](#query_streams_ch5)显示了前述查询及其相关查询计划。它展示了查询操作如何映射到Amazon Redshift用于生成计算节点片段编译代码的步骤。每个查询计划操作映射到多个段内的多个步骤，有时也映射到流内的多个段。'
- en: '![Amazon Redshift query streams](assets/ardg_0508.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift查询流](assets/ardg_0508.png)'
- en: Figure 5-8\. Amazon Redshift query streams
  id: totrans-359
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-8。Amazon Redshift查询流
- en: 'The query optimizer runs the query plan as follows:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 查询优化器按以下方式运行查询计划：
- en: In Stream 0, the query runs Segment 0 with a sequential scan operation to scan
    the events table. The query continues to Segment 1 with a hash operation to create
    the hash table for the inner table in the join.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Stream 0 中，查询运行 Segment 0，执行顺序扫描操作以扫描事件表。查询继续到 Segment 1，使用哈希操作创建连接中内表的哈希表。
- en: In Stream 1, the query runs Segment 2 with a sequential scan operation to scan
    the sales table. It continues with Segment 2 with a hash join to join tables where
    the join columns are not both distribution keys and sort keys. It again continues
    with Segment 2 with a hash aggregate to aggregate results. Then the query runs
    Segment 3 with a hash aggregate operation to perform unsorted grouped aggregate
    functions, and a sort operation to evaluate the `ORDER BY` clause and other sort
    operations.
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Stream 1 中，查询运行 Segment 2，执行顺序扫描操作以扫描销售表。它继续使用哈希连接操作执行 Segment 2，以连接不同时作为分布键和排序键的表。然后再次使用哈希聚合操作执行
    Segment 2，以聚合结果。然后查询运行 Segment 3，使用哈希聚合操作执行无序分组聚合函数，并使用排序操作评估 `ORDER BY` 子句和其他排序操作。
- en: In Stream 2, the query runs a network operation in Segment 4 and Segment 5 to
    send intermediate results to the leader node for further processing.
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在流2中，查询在Segment 4和Segment 5中运行网络操作，将中间结果发送到领导节点进行进一步处理。
- en: The last segment of a query returns the data. If the return set is aggregated
    or sorted, the compute nodes each send their piece of the intermediate result
    to the leader node. The leader node then merges the data and provides the final
    result back to the query submitter.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 查询的最后一个段返回数据。如果返回集合是聚合的或排序的，则计算节点各自将它们的中间结果片段发送到领导节点。然后领导节点合并数据并将最终结果返回给查询提交者。
- en: Factors affecting query performance
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 影响查询性能的因素
- en: 'The following aspects of your data warehouse and overall database operations
    determine how quickly your queries execute:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据仓库和整体数据库操作的以下方面决定了查询执行速度：
- en: Number of nodes
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 节点数量
- en: More nodes means more processors and more slices, which enables your queries
    to process faster by running portions of the query concurrently across the slices,
    but you need to find a good balance between performance and cost.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 更多节点意味着更多的处理器和更多的切片，这使得您的查询可以通过在切片之间并行运行查询的部分来更快地处理，但您需要在性能和成本之间找到一个良好的平衡。
- en: Node types
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 节点类型
- en: Amazon Redshift provisioned cluster offers different node type, each with different
    sizes and limits to help you scale your cluster appropriately. These node types
    determine the storage capacity, memory, CPU, and price of each node in the cluster.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift预置集群提供不同的节点类型，每种节点类型具有不同的大小和限制，帮助您适当扩展集群。这些节点类型确定了集群中每个节点的存储容量、内存、CPU和价格。
- en: Data distribution
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分布
- en: When you run a query, the query optimizer redistributes the data to the compute
    nodes as needed to perform any joins and aggregations. Choosing the right distribution
    style for a table helps minimize the impact of the redistribution step by locating
    the data where it needs to be before the joins are performed.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行查询时，查询优化器根据需要将数据重新分配给计算节点以执行任何连接和聚合。为表选择合适的分布方式有助于通过将数据放置在连接执行之前的位置来最小化重新分配步骤的影响。
- en: Sort order
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 排序顺序
- en: The query optimizer and the query processor use the information about where
    the data is located to reduce the number of blocks that need to be scanned and
    thereby improve query speed.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 查询优化器和查询处理器使用数据位置信息来减少需要扫描的块数，从而提高查询速度。
- en: Dataset volume
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的容量
- en: Queries on large data volume can impact query performance, because more rows
    need to be scanned and redistributed. Running regular vacuums, archiving of infrequently
    queried data, and restricting the query dataset by using predicates can improve
    performance.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据量上的查询可能会影响查询性能，因为需要扫描和重新分配更多的行。定期运行vacuum操作、归档不经常查询的数据以及使用谓词限制查询数据集可以改善性能。
- en: WLM setup
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: WLM设置
- en: Each query operation takes one or more slots in an available query queue and
    uses the memory associated with those slots. If other operations are running,
    enough query queue slots might not be available. In this case, the query has to
    wait for slots to open before it can begin processing.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 每个查询操作占据一个或多个可用查询队列中的插槽，并使用与这些插槽相关联的内存。如果其他操作正在运行，则可能没有足够的查询队列插槽可用。在这种情况下，查询必须等待插槽开放才能开始处理。
- en: Code compilation
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 代码编译
- en: Amazon Redshift generates and compiles code for each query execution plan, and
    caches this information for subsequent invocations. You will have some overhead
    cost the first time code is generated and compiled. The compiled code segments
    are cached locally on the cluster and in a virtually unlimited cache. This cache
    persists after cluster reboots. Subsequent executions of the same query run faster
    because they can skip the compilation phase.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift为每个查询执行计划生成和编译代码，并为后续调用缓存此信息。首次生成和编译代码会产生一些额外开销。编译的代码段在集群上本地缓存和在一个几乎无限的缓存中。此缓存在集群重新启动后仍然存在。由于可以跳过编译阶段，因此后续执行相同查询的速度更快。
- en: Analyzing Queries
  id: totrans-381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析查询
- en: If a query is taking longer than expected, you need to identify and correct
    issues that might be negatively affecting the query’s performance. Sometimes a
    query that should run quickly is forced to wait until another, longer-running
    query finishes. In such a case you can improve overall system performance by creating
    and using query queues for different types of queries.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 如果查询花费的时间比预期长，您需要识别和纠正可能对查询性能产生负面影响的问题。有时候，本应快速运行的查询被迫等待另一个运行时间较长的查询完成。在这种情况下，您可以通过创建和使用不同类型查询的查询队列来提高整体系统性能。
- en: Reviewing query alerts
  id: totrans-383
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查询警报审查
- en: Use the [`STL_ALERT_EVENT_LOG`](https://oreil.ly/o5wOu) system table to identify
    and correct potential performance issues with your query. This table captures
    the potential issue for the query, and also provides recommended solutions to
    resolve the alert.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[`STL_ALERT_EVENT_LOG`](https://oreil.ly/o5wOu)系统表来识别和纠正查询可能存在的性能问题。此表捕获查询的潜在问题，并提供建议的解决方案以解决警报。
- en: Analyzing the query plan
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析查询计划
- en: Use the `explain` command and analyze the query plan. Concentrate on optimizing
    the steps with the highest cost. Look at the joins being executed, `merge` being
    the best; `hash` are fairly common and OK for inner tables, whereas `nested loop`
    are to be avoided except for a small number of rows or loops.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`explain`命令并分析查询计划。集中优化具有最高成本的步骤。查看正在执行的连接，`merge`是最好的；`hash`对于内部表来说是相当常见且可以接受的，而`nested
    loop`则应避免，除非是少量行或循环。
- en: Amazon Redshift chooses the smaller table for the inner join and the larger
    table for the outer join. If you see otherwise, then likely your table statistics
    are not updated.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift选择较小的表进行内连接，并选择较大的表进行外连接。如果情况不同，则可能是表统计数据没有更新。
- en: During join steps, a slice may need to work with data not stored locally, and
    network transmission is by far the most expensive operation for a query.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 在连接步骤中，一个切片可能需要处理未本地存储的数据，而对于查询来说，网络传输远远是最昂贵的操作。
- en: Table 5-2\. Distribution joins
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-2\. 分布连接
- en: '| Join type | Description |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 连接类型 | 描述 |'
- en: '| --- | --- |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| DS_DIST_NONE | This is the ideal situation that indicates that the data for
    the join is co-located on the same slice. This is the most efficient option as
    no network transfer will occur. |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| DS_DIST_NONE | 这是理想的情况，表明连接数据位于同一切片上。这是最有效的选项，因为不会发生网络传输。'
- en: '| DS_DIST_ALL_NONE | Indicates that the join is occurring with a table that
    has `DISTSTYLE ALL` and also does not incur network transfer. |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| DS_DIST_ALL_NONE | 表示正在使用`DISTSTYLE ALL`的表进行连接，并且不涉及网络传输。'
- en: '| DS_DIST_ALL_INNER | Indicates that the *inner* join table is being sent to
    a single node because the join table uses `DISTSTYLE ALL`. This join is executed
    on a single node and will likely be slow. |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| DS_DIST_ALL_INNER | 表示*内部*连接表由于使用了`DISTSTYLE ALL`而被发送到单个节点。这种连接在单个节点上执行，可能会很慢。'
- en: '| DS_DIST_INNER, DS_DIST_OUTER | Indicates which table is being redistributed
    when using an outer join (inner or outer table); if one of the tables is much
    smaller or infrequently updated, consider changing it to `DISTSTYLE ALL`. |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| DS_DIST_INNER, DS_DIST_OUTER | 表示在使用外部连接时重新分配哪个表（内部或外部表）；如果其中一个表要小得多或者更新不频繁，请考虑将其更改为`DISTSTYLE
    ALL`。'
- en: '| DS_BCAST_INNER | Indicates that the *inner* join table is being broadcast
    to all nodes. |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| DS_BCAST_INNER | 表示*内部*连接表正在广播到所有节点。'
- en: '| DS_BCAST_BOTH | Indicates that both tables in the join are being broadcast
    to all nodes. This is the worst possible option. |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| DS_BCAST_BOTH | 表示连接中的两个表都正在广播到所有节点。这是最糟糕的选择。'
- en: Identifying Queries for Performance Tuning
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别性能调整的查询
- en: The first three joins from [Table 5-2](#dist_join_types) are where you will
    see minimal performance deterioration, so if you see queries that are frequently
    run or have a business SLA falling under the bottom three, then these queries
    are good candidates for performance tuning.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-2中的前三个连接是您将看到最小性能下降的地方，因此如果发现频繁运行的查询或业务SLA属于最后三个，则这些查询是性能调整的良好候选。
- en: Lets take the example of a trading company’s data warehouse that has two main
    fact tables, `fact_executions` for all the trade executions, and `fact_allocation`
    for all the trade allocations, as in [Figure 5-9](#multi_fact_ch5). The thicker
    lines represent a co-located join because of matching distribution keys for these
    tables.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个交易公司的数据仓库为例，其主要有两个事实表，`fact_executions` 用于所有交易执行，`fact_allocation` 用于所有交易分配，如图
    [5-9](#multi_fact_ch5) 所示。较粗的线表示由于匹配的分布键而进行的共同分布连接。
- en: '![Multifact schema](assets/ardg_0509.png)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
  zh: '![多事实模式](assets/ardg_0509.png)'
- en: Figure 5-9\. Multifact schema
  id: totrans-402
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-9\. 多事实模式
- en: Consider that most of the time you analyze the executions by the security dimension,
    and you analyze the allocations by the account dimension. Note that the security
    dimension still joins to the allocations fact since every allocation is for a
    particular traded security.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到大多数情况下，您通过安全维度分析执行情况，而通过账户维度分析分配情况。请注意，安全维度仍然加入到分配事实，因为每个分配都是针对特定的交易安全性。
- en: Based on this design most of your execution reports will perform well since
    you join mostly with security dimension. Most of your allocations reports will
    also perform well since you mostly join with account dimension. But you will see
    redistribution of security dimension data if you need to perform some analysis
    on allocations by security, since this is not a co-located join. If this analysis
    is not done often, then it is less business critical and a slower query response
    should be tolerable. But if this analysis is deemed business critical and has
    strict SLAs defined, then you might need to change the security dimension to distribution
    style of `ALL` so the analysis, allocations by security, and executions by security,
    becomes a co-located join. In this case, to be able to meet the performance needs,
    you can be paying more for storage.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此设计，您的大多数执行报告将表现良好，因为您主要与安全维度连接。大多数您的分配报告也将表现良好，因为您主要与账户维度连接。但是，如果您需要对按安全性进行的分配进行一些分析，由于这不是一个共同分布连接，您将看到安全维度数据的重新分配。如果这种分析不经常进行，则其业务影响较小，可以容忍较慢的查询响应。但是，如果这种分析被视为业务关键并且有严格的SLA定义，则可能需要将安全维度更改为
    `ALL` 的分布样式，以便分析，按安全性分配和按安全性执行成为共同分布连接。在这种情况下，为了满足性能需求，您可能需要为存储支付更多的费用。
- en: Not all queries need to be or can be tuned for performance. Based on the business
    priority of the query, you need to weigh the trade-offs for time spent on tuning
    and the cost to achieve the performance.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有的查询都需要或者可以为了性能而调优。根据查询的业务优先级，您需要权衡在调优上花费的时间和达到性能所需的成本。
- en: Additionally, refer to [top candidates for tuning](https://oreil.ly/dYmc0) to
    identify priority queries amongst all your queries, [tables with data skew or
    unsorted rows](https://oreil.ly/IJd66) to identify candidate tables for considering
    a different distribution strategy and manual vacuum needs, [queries with nested
    loops](https://oreil.ly/csbQS) to identify possibly ill-written queries and candidates
    for implementing query monitoring rules on specific queues, [queue wait times
    for queries](https://oreil.ly/eY_GK) to identify opportunities for changing WLM
    setup and leverage Concurrency Scaling to reduce queue waits, [query alerts](https://oreil.ly/hmGvH)
    to identify table alerts and recommendations for fixing queries, and [tables with
    missing statistics](https://oreil.ly/cRTmL) to identify tables for manual statistics
    gathering.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请参考 [调优的前几名候选](https://oreil.ly/dYmc0) 来确定所有查询中的优先查询，[数据倾斜或未排序行的表](https://oreil.ly/IJd66)
    来确定考虑不同分布策略和手动抽真空需求的候选表，[嵌套循环的查询](https://oreil.ly/csbQS) 来确定可能写得不好的查询和实施特定队列上的查询监控规则的候选者，[查询等待时间](https://oreil.ly/eY_GK)
    来确定更改 WLM 设置和利用并发扩展以减少队列等待的机会，[查询警报](https://oreil.ly/hmGvH) 来确定表警报和修复查询建议，以及
    [缺失统计信息的表](https://oreil.ly/cRTmL) 来确定手动收集统计信息的表。
- en: Summary
  id: totrans-407
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered scaling for predictable demand as well as dealing
    with unpredictable spiky workloads, went through how to set up workload management
    and query monitoring rules to minimize the blast radius of bad queries and protecting
    your Amazon Redshift data warehouse. We also covered how to leverage the materialized
    views, various automations offered by Amazon Redshift, and how to implement workload
    isolation using the data sharing feature. The chapter ended with a discussion
    of the optimizations for balancing price-performance and performance tuning techniques
    for queries and how to identify and tune queries.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了针对可预测需求的扩展以及处理不可预测的尖峰工作负载，介绍了如何设置工作负载管理和查询监控规则，以减少糟糕查询的影响范围，并保护您的亚马逊Redshift数据仓库。我们还讨论了如何利用材料化视图、亚马逊Redshift提供的各种自动化功能，以及如何使用数据共享功能实现工作负载隔离。本章最后讨论了在平衡价格性能和查询性能调优技术方面的优化，并介绍了如何识别和调优查询。
- en: In the next chapter, we’ll cover machine learning. We will describe the different
    problem sets that data scientists have to solve and the types of algorithms they
    apply to solve these problems. Finally, we’ll show how Amazon Redshift demystifies
    predictive analytics by enabling data scientists, data engineers, and even data
    analysts with tools to build, train, and run predictions using Amazon Redshift.
    We’ll show how users can run the entire machine learning lifecycle directly using
    SQL commands and how advanced users can integrate Amazon Redshift with Amazon
    SageMaker.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将涵盖机器学习。我们将描述数据科学家需要解决的不同问题集，以及他们应用的算法类型来解决这些问题。最后，我们将展示亚马逊Redshift如何通过提供工具来构建、训练和运行预测分析，解密预测分析过程，使数据科学家、数据工程师甚至数据分析师能够使用亚马逊Redshift进行预测分析。我们将展示用户如何直接使用SQL命令运行整个机器学习生命周期，以及高级用户如何将亚马逊Redshift与亚马逊SageMaker集成。
