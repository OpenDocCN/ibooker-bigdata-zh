- en: 14  Sklearn and Feature Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14  Sklearn和特征工程
- en: 原文：[https://ds100.org/course-notes/feature_engineering/feature_engineering.html](https://ds100.org/course-notes/feature_engineering/feature_engineering.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://ds100.org/course-notes/feature_engineering/feature_engineering.html]'
- en: '*Learning Outcomes* ***   Apply the `sklearn` library for model creation and
    training'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*学习成果* ***   应用`sklearn`库进行模型创建和训练'
- en: Recognize the value of feature engineering as a tool to improve model performance
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 认识到特征工程作为提高模型性能的工具的价值
- en: Implement polynomial feature generation and one hot encoding
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现多项式特征生成和独热编码
- en: Understand the interactions between model complexity, model variance, and training
    error**  **At this point, we’ve grown quite familiar with the modeling process.
    We’ve introduced the concept of loss, used it to fit several types of models,
    and, most recently, extended our analysis to multiple regression. Along the way,
    we’ve forged our way through the mathematics of deriving the optimal model parameters
    in all its gory detail. It’s time to make our lives a little easier – let’s implement
    the modeling process in code!
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解模型复杂性、模型方差和训练误差之间的相互作用**  **到目前为止，我们已经对建模过程非常熟悉。我们介绍了损失的概念，用它来拟合多种类型的模型，并且最近扩展了我们的分析到多元回归。在这个过程中，我们通过推导出最佳模型参数的数学细节，艰难地走过了一段路。现在是时候让我们的生活变得更轻松一些了-让我们在代码中实现建模过程！
- en: 'In this lecture, we’ll explore two techniques for model fitting:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本讲座中，我们将探讨两种模型拟合技术：
- en: Translating our derived formulas for regression to `python`
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将我们推导出的回归公式翻译成`python`
- en: Using `python`’s `sklearn` package
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`python`的`sklearn`包
- en: With our new programming frameworks in hand, we will also add sophistication
    to our models by introducing more complex features to enhance model performance.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有了我们手头的新编程框架，我们还将通过引入更复杂的特征来增强模型性能，为我们的模型增加复杂性。
- en: 14.1 Implementing Derived Formulas in Code
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.1 在代码中实现推导出的公式
- en: Throughout this lecture, we’ll refer to the `penguins` dataset.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本讲座中，我们将引用`penguins`数据集。
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '|  | species | island | bill_length_mm | bill_depth_mm | flipper_length_mm
    | body_mass_g | sex |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '|  | 物种 | 岛屿 | 嘴长（毫米） | 嘴深（毫米） | 鳍长（毫米） | 体重（克） | 性别 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | Adelie | Torgersen | 39.1 | 18.7 | 181.0 | 3750.0 | Male |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 0 | Adelie | Torgersen | 39.1 | 18.7 | 181.0 | 3750.0 | 雄性 |'
- en: '| 1 | Adelie | Torgersen | 39.5 | 17.4 | 186.0 | 3800.0 | Female |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Adelie | Torgersen | 39.5 | 17.4 | 186.0 | 3800.0 | 雌性 |'
- en: '| 2 | Adelie | Torgersen | 40.3 | 18.0 | 195.0 | 3250.0 | Female |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Adelie | Torgersen | 40.3 | 18.0 | 195.0 | 3250.0 | 雌性 |'
- en: '| 4 | Adelie | Torgersen | 36.7 | 19.3 | 193.0 | 3450.0 | Female |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 4 | Adelie | Torgersen | 36.7 | 19.3 | 193.0 | 3450.0 | 雌性 |'
- en: '| 5 | Adelie | Torgersen | 39.3 | 20.6 | 190.0 | 3650.0 | Male |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 5 | Adelie | Torgersen | 39.3 | 20.6 | 190.0 | 3650.0 | 雄性 |'
- en: Our goal will be to predict the value of the `"bill_depth_mm"` for a particular
    penguin given its `"flipper_length_mm"` and `"body_mass_g"`. We’ll also add a
    bias column of all ones to represent the intercept term of our models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是预测给定企鹅的“flipper_length_mm”和“body_mass_g”时，“bill_depth_mm”的值。我们还将添加一个全为1的偏置列来表示我们模型的截距项。
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the lecture on ordinary least squares, we expressed multiple linear regression
    using matrix notation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在普通最小二乘法的讲座中，我们使用矩阵表示法表示多元线性回归。
- en: \[\hat{\mathbb{Y}} = \mathbb{X}\theta\]
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{\mathbb{Y}} = \mathbb{X}\theta\]
- en: 'We used a geometric approach to derive the following expression for the optimal
    model parameters:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了几何方法来推导出最佳模型参数的以下表达式：
- en: \[\hat{\theta} = (\mathbb{X}^T \mathbb{X})^{-1}\mathbb{X}^T \mathbb{Y}\]
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{\theta} = (\mathbb{X}^T \mathbb{X})^{-1}\mathbb{X}^T \mathbb{Y}\]
- en: That’s a whole lot of matrix manipulation. How do we implement it in `python`?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是大量的矩阵操作。我们如何在`python`中实现它呢？
- en: 'There are three operations we need to perform here: multiplying matrices, taking
    transposes, and finding inverses.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有三个操作我们需要执行：矩阵相乘、求转置和求逆。
- en: To perform matrix multiplication, use the `@` operator
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要进行矩阵乘法，使用`@`运算符
- en: To take a transpose, call the `.T` attribute of an `NumPy` array or `DataFrame`
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要进行转置，调用`NumPy`数组或`DataFrame`的`.T`属性
- en: To compute an inverse, use `NumPy`’s in-built method `np.linalg.inv`
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要计算逆矩阵，使用`NumPy`的内置方法`np.linalg.inv`
- en: Putting this all together, we can compute the OLS estimate for the optimal model
    parameters, stored in the array `theta_hat`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 将这一切放在一起，我们可以计算存储在数组`theta_hat`中的最佳模型参数的OLS估计值。
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To make predictions using our optimized parameter values, we matrix-multiply
    the design matrix with the parameter vector:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用我们优化的参数值进行预测，我们将设计矩阵与参数向量进行矩阵乘法：
- en: \[\hat{\mathbb{Y}} = \mathbb{X}\theta\]
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{\mathbb{Y}} = \mathbb{X}\theta\]
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '|  | 0 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | 0 |'
- en: '| --- | --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0 | 18.322561 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 18.322561 |'
- en: '| 1 | 18.445578 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 18.445578 |'
- en: '| 2 | 17.721412 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 17.721412 |'
- en: '| 3 | 17.997254 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 17.997254 |'
- en: '| 4 | 18.263268 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 18.263268 |'
- en: 14.2 `sklearn`
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.2 `sklearn`
- en: We’ve already saved a lot of time (and avoided tedious calculations) by translating
    our derived formulas into code. However, we still had to go through the process
    of writing out the linear algebra ourselves.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将我们推导出的公式转化为代码，我们已经节省了大量时间（并避免了繁琐的计算）。但是，我们仍然需要自己编写线性代数的过程。
- en: To make life *even easier*, we can turn to the `sklearn` [`python` library](https://scikit-learn.org/stable/).
    `sklearn` is a robust library of machine learning tools used extensively in research
    and industry. It gives us a wide variety of in-built modeling frameworks and methods,
    so we’ll keep returning to `sklearn` techniques as we progress through Data 100.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让生活变得*更加轻松*，我们可以转向`sklearn`[`python`库](https://scikit-learn.org/stable/)。`sklearn`是一个强大的机器学习工具库，在研究和工业中被广泛使用。它为我们提供了各种内置的建模框架和方法，因此在我们进行Data
    100的过程中，我们将不断返回`sklearn`技术。
- en: Regardless of the specific type of model being implemented, `sklearn` follows
    a standard set of steps for creating a model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 无论实现的具体模型类型是什么，`sklearn`都遵循一套标准的创建模型步骤。
- en: 'Create a model object. This generates a new instance of the model class. You
    can think of it as making a new “copy” of a standard “template” for a model. In
    code, this looks like:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个模型对象。这将生成模型类的一个新实例。你可以把它看作是对模型的标准“模板”进行新的“复制”。在代码中，这看起来像：
- en: '[PRE5]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Fit the model to the `X` design matrix and `Y` target vector. This calculates
    the optimal model parameters “behind the scenes” without us explicitly working
    through the calculations ourselves. The fitted parameters are then stored within
    the model for use in future predictions:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到`X`设计矩阵和`Y`目标向量。这将在不需要显式进行计算的情况下“在后台”计算出最佳的模型参数。然后，拟合的参数将存储在模型中以备将来进行预测使用：
- en: '[PRE6]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Use the fitted model to make predictions on the `X` input data using `.predict`.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用拟合的模型对`X`输入数据进行预测，使用`.predict`。
- en: '[PRE7]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To extract the fitted parameters, we can use:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要提取拟合的参数，我们可以使用：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Let’s put this into action with our multiple regression task.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在多元回归任务中将其付诸实践。
- en: '**1\. Initialize an instance of the model class**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 初始化模型类的一个实例**'
- en: '`sklearn` stores “templates” of useful models for machine learning. We begin
    the modeling process by making a “copy” of one of these templates for our own
    use. Model initialization looks like `ModelClass()`, where `ModelClass` is the
    type of model we wish to create.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn`存储了用于机器学习的有用模型的“模板”。我们通过制作一个这些模板的“副本”来开始建模过程以供我们自己使用。模型初始化看起来像`ModelClass()`，其中`ModelClass`是我们希望创建的模型类型。'
- en: For now, let’s create a linear regression model using `LinearRegression()`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`LinearRegression()`创建一个线性回归模型。
- en: '`my_model` is now an instance of the `LinearRegression` class. You can think
    of it as the “idea” of a linear regression model. We haven’t trained it yet, so
    it doesn’t know any model parameters and cannot be used to make predictions. In
    fact, we haven’t even told it what data to use for modeling! It simply waits for
    further instructions.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`my_model`现在是`LinearRegression`类的一个实例。你可以把它看作是线性回归模型的“想法”。我们还没有对它进行训练，所以它不知道任何模型参数，也不能用来进行预测。事实上，我们甚至还没有告诉它要用什么数据进行建模！它只是等待进一步的指示。'
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**2\. Train the model using `.fit`**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 使用`.fit`训练模型**'
- en: Before the model can make predictions, we will need to fit it to our training
    data. When we fit the model, `sklearn` will run gradient descent behind the scenes
    to determine the optimal model parameters. It will then save these model parameters
    to our model instance for future use.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型可以进行预测之前，我们需要将其拟合到我们的训练数据中。当我们拟合模型时，`sklearn`将在后台运行梯度下降来确定最佳的模型参数。然后它会将这些模型参数保存到我们的模型实例中以备将来使用。
- en: 'All `sklearn` model classes include a `.fit` method, which is used to fit the
    model. It takes in two inputs: the design matrix, `X`, and the target variable,
    `Y`.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 所有`sklearn`模型类都包括一个`.fit`方法，用于拟合模型。它接受两个输入：设计矩阵`X`和目标变量`Y`。
- en: 'Let’s start by fitting a model with just one feature: the flipper length. We
    create a design matrix `X` by pulling out the `"flipper_length_mm"` column from
    the `DataFrame`.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从只有一个特征的模型开始：脚蹼长度。我们通过从`DataFrame`中提取`"flipper_length_mm"`列来创建一个设计矩阵`X`。
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**In a Jupyter environment, please rerun this cell to show the HTML representation
    or trust the notebook.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**在Jupyter环境中，请重新运行此单元格以显示HTML表示或信任笔记本。'
- en: On GitHub, the HTML representation is unable to render, please try loading this
    page with nbviewer.org.**
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitHub上，HTML表示无法呈现，请尝试使用nbviewer.org加载此页面。**
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Notice that we use **double brackets** to extract this column. Why double brackets
    instead of just single brackets? The `.fit` method, by default, expects to receive
    **2-dimensional** data – some kind of data that includes both rows and columns.
    Writing `penguins["flipper_length_mm"]` would return a 1D `Series`, causing `sklearn`
    to error. We avoid this by writing `penguins[["flipper_length_mm"]]` to produce
    a 2D `DataFrame`.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们使用**双括号**来提取这一列。为什么使用双括号而不是单括号？`.fit`方法默认期望接收**二维**数据 - 一种包含行和列的数据。写`penguins["flipper_length_mm"]`会返回一个1D`Series`，导致`sklearn`出错。我们通过写`penguins[["flipper_length_mm"]]`来产生一个2D`DataFrame`来避免这种情况。
- en: 'And in just three lines of code, our model has run gradient descent to determine
    the optimal model parameters! Our single-feature model takes the form:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型只用了三行代码就运行了梯度下降来确定最佳的模型参数！我们的单特征模型采用以下形式：
- en: \[\text{bill depth} = \theta_0 + \theta_1 \text{flipper length}\]
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: \[\text{bill depth} = \theta_0 + \theta_1 \text{flipper length}\]
- en: Note that `LinearRegression` will automatically include an intercept term.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`LinearRegression`将自动包括一个截距项。
- en: The fitted model parameters are stored as attributes of the model instance.
    `my_model.intercept_` will return the value of \(\hat{\theta}_0\) as a scalar.
    `my_model.coef_` will return all values \(\hat{\theta}_1, \hat{\theta}_1, ...\)
    in an array. Because our model only contains one feature, we see just the value
    of \(\hat{\theta}_1\) in the cell below.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合的模型参数被存储为模型实例的属性。`my_model.intercept_`将返回\(\hat{\theta}_0\)的值作为标量。`my_model.coef_`将以数组的形式返回所有值\(\hat{\theta}_1,
    \hat{\theta}_1, ...\)。因为我们的模型只包含一个特征，所以下面的单元格中只会看到\(\hat{\theta}_1\)的值。
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**3\. Use the fitted model to make predictions**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 使用拟合的模型进行预测**'
- en: 'Now that the model has been trained, we can use it to make predictions! To
    do so, we use the `.predict` method. `.predict` takes in one argument: the design
    matrix that should be used to generate predictions. To understand how the model
    performs on the training set, we would pass in the training data. Alternatively,
    to make predictions on unseen data, we would pass in a new dataset that wasn’t
    used to train the model.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经训练好了，我们可以用它进行预测！为此，我们使用`.predict`方法。`.predict`接受一个参数：应该用来生成预测的设计矩阵。为了了解模型在训练集上的表现，我们会传入训练数据。或者，为了对未见过的数据进行预测，我们会传入一个未用于训练模型的新数据集。
- en: Below, we call `.predict` to generate model predictions on the original training
    data. As before, we use double brackets to ensure that we extract 2-dimensional
    data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，我们调用`.predict`来在原始训练数据上生成模型预测。与之前一样，我们使用双括号来确保我们提取的是二维数据。
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: What if we wanted a model with two features?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要一个具有两个特征的模型呢？
- en: \[\text{bill depth} = \theta_0 + \theta_1 \text{flipper length} + \theta_2 \text{body
    mass}\]
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: \[\text{bill depth} = \theta_0 + \theta_1 \text{flipper length} + \theta_2 \text{body
    mass}\]
- en: We repeat this three-step process by intializing a new model object, then calling
    `.fit` and `.predict` as before.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过初始化一个新的模型对象，然后像以前一样调用`.fit`和`.predict`来重复这个三步过程。
- en: '[PRE19]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We can also see that we obtain the same predictions using `sklearn` as we did
    when applying the ordinary least squares formula before!
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到，我们使用`sklearn`得到的预测与之前应用普通最小二乘公式时得到的预测相同！
- en: <details><summary>Code</summary>
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE21]</details>'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE21]</details>'
- en: '|  | Y_hat from OLS | Y_hat from sklearn |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | OLS的Y_hat | sklearn的Y_hat |'
- en: '| --- | --- | --- |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0 | 18.322561 | 18.322561 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 18.322561 | 18.322561 |'
- en: '| 1 | 18.445578 | 18.445578 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 18.445578 | 18.445578 |'
- en: '| 2 | 17.721412 | 17.721412 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 17.721412 | 17.721412 |'
- en: '| 3 | 17.997254 | 17.997254 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 17.997254 | 17.997254 |'
- en: '| 4 | 18.263268 | 18.263268 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 18.263268 | 18.263268 |'
- en: 14.3 Feature Engineering
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.3 特征工程
- en: At this point in the course, we’ve equipped ourselves with some powerful techniques
    to build and optimize models. We’ve explored how to develop models of multiple
    variables, as well as how to transform variables to help **linearize** a dataset
    and fit these models to maximize their performance.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在课程的这一阶段，我们已经掌握了一些强大的技术来构建和优化模型。我们已经探讨了如何开发多变量模型，以及如何转换变量以帮助**线性化**数据集，并拟合这些模型以最大化它们的性能。
- en: 'All of this was done with one major caveat: the regression models we’ve worked
    with so far are all **linear in the input variables**. We’ve assumed that our
    predictions should be some combination of linear variables. While this works well
    in some cases, the real world isn’t always so straightforward. We’ll learn an
    important method to address this issue – feature engineering – and consider some
    new problems that can arise when we do so.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都是在一个主要的警告下完成的：到目前为止，我们所使用的回归模型都是**输入变量的线性**。我们假设我们的预测应该是一些线性变量的组合。虽然在某些情况下这很有效，但现实世界并不总是那么简单。我们将学习一种重要的方法来解决这个问题
    - 特征工程 - 并考虑在这样做时可能出现的一些新问题。
- en: Feature engineering is the process of *transforming* raw features into *more
    informative features* that can be used in modeling or EDA tasks and improve model
    performance.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程是将原始特征转换为*更具信息性的特征*的过程，这些特征可以用于建模或EDA任务，并提高模型性能。
- en: 'Feature engineering allows you to:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程允许您：
- en: Capture domain knowledge
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕获领域知识
- en: Express non-linear relationships using linear models
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线性模型表达非线性关系
- en: Use non-numeric features in models
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型中使用非数值特征
- en: 14.4 Feature Functions
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.4 特征函数
- en: 'A **feature function** describes the transformations we apply to raw features
    in a dataset to create a design matrix of transformed features. We typically denote
    the feature function as \(\Phi\) (think to yourself: “phi”-ture function). When
    we apply the feature function to our original dataset \(\mathbb{X}\), the result,
    \(\Phi(\mathbb{X})\), is a transformed design matrix ready to be used in modeling.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征函数**描述了我们对数据集中的原始特征应用的转换，以创建一个转换特征的设计矩阵。我们通常将特征函数表示为\(\Phi\)（想想：“phi”-ture函数）。当我们将特征函数应用于我们的原始数据集\(\mathbb{X}\)时，结果\(\Phi(\mathbb{X})\)是一个经过转换的设计矩阵，可以用于建模。'
- en: For example, we might design a feature function that computes the square of
    an existing feature and adds it to the design matrix. In this case, our existing
    matrix \([x]\) is transformed to \([x, x^2]\). Its *dimension* increases from
    1 to 2\. Often, the dimension of the *featurized* dataset increases as seen here.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以设计一个特征函数，计算现有特征的平方并将其添加到设计矩阵中。在这种情况下，我们现有的矩阵\([x]\)被转换为\([x, x^2]\)。其*维度*从1增加到2。通常，*特征化*数据集的维度会增加，如此处所示。
- en: '![phi](../Images/4b402c84ec97c6ed7aad8cd18f1b5e2b.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![phi](../Images/4b402c84ec97c6ed7aad8cd18f1b5e2b.png)'
- en: The new features introduced by the feature function can then be used in modeling.
    Often, we use the symbol \(\phi_i\) to represent transformed features after feature
    engineering.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 特征函数引入的新特征然后可以用于建模。通常，我们使用符号\(\phi_i\)表示特征工程后的转换特征。
- en: \[\hat{y} = \theta_1 x + \theta_2 x^2\] \[\hat{y}= \theta_1 \phi_1 + \theta_2
    \phi_2\]
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y} = \theta_1 x + \theta_2 x^2\] \[\hat{y}= \theta_1 \phi_1 + \theta_2
    \phi_2\]
- en: In matrix notation, the symbol \(\Phi\) is sometimes used to denote the design
    matrix after feature engineering has been performed. Note that in the usage below,
    \(\Phi\) is now a feature-engineered matrix, rather than a function.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在矩阵表示中，符号\(\Phi\)有时用于表示特征工程后的设计矩阵。请注意，在下面的用法中，\(\Phi\)现在是一个经过特征工程处理的矩阵，而不是一个函数。
- en: \[\hat{\mathbb{Y}} = \Phi \theta\]
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{\mathbb{Y}} = \Phi \theta\]
- en: More formally, we describe a feature function as transforming the original \(\mathbb{R}^{n
    \times p}\) dataset \(\mathbb{X}\) to a featurized \(\mathbb{R}^{n \times p'}\)
    dataset \(\mathbb{\Phi}\), where \(p'\) is typically greater than \(p\).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地，我们将特征函数描述为将原始的\(\mathbb{R}^{n \times p}\)数据集\(\mathbb{X}\)转换为一个经过特征处理的\(\mathbb{R}^{n
    \times p'}\)数据集\(\mathbb{\Phi}\)的过程，其中\(p'\)通常大于\(p\)。
- en: \[\mathbb{X} \in \mathbb{R}^{n \times p} \longrightarrow \Phi \in \mathbb{R}^{n
    \times p'}\]
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathbb{X} \in \mathbb{R}^{n \times p} \longrightarrow \Phi \in \mathbb{R}^{n
    \times p'}\]
- en: 14.5 One Hot Encoding
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.5 独热编码
- en: Feature engineering opens up a whole new set of possibilities for designing
    better-performing models. As you will see in lab and homework, feature engineering
    is one of the most important parts of the entire modeling process.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程为设计更好的性能模型打开了一整套新的可能性。正如您将在实验室和家庭作业中看到的那样，特征工程是整个建模过程中最重要的部分之一。
- en: A particularly powerful use of feature engineering is to allow us to perform
    regression on *non-numeric* features. **One hot encoding** is a feature engineering
    technique that generates numeric features from categorical data, allowing us to
    use our usual methods to fit a regression model on the data.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程的一个特别强大的用途是允许我们对*非数值*特征执行回归。**独热编码**是一种特征工程技术，它从分类数据生成数值特征，使我们能够使用通常的方法在数据上拟合回归模型。
- en: 'To illustrate how this works, we’ll refer back to the `tips` dataset from previous
    lectures. Consider the `"day"` column of the dataset:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这是如何工作的，我们将回顾以前讲座中的“小费”数据集。考虑数据集的“day”列：
- en: <details><summary>Code</summary>
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE22]</details>'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE22]</details>'
- en: '|  | total_bill | tip | sex | smoker | day | time | size |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|  | total_bill | tip | sex | smoker | day | time | size |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 16.99 | 1.01 | Female | No | Sun | Dinner | 2 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 16.99 | 1.01 | 女性 | 否 | 太阳 | 晚餐 | 2 |'
- en: '| 1 | 10.34 | 1.66 | Male | No | Sun | Dinner | 3 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 10.34 | 1.66 | 男性 | 否 | 太阳 | 晚餐 | 3 |'
- en: '| 2 | 21.01 | 3.50 | Male | No | Sun | Dinner | 3 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 21.01 | 3.50 | 男性 | 否 | 太阳 | 晚餐 | 3 |'
- en: '| 3 | 23.68 | 3.31 | Male | No | Sun | Dinner | 2 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 23.68 | 3.31 | 男性 | 否 | 太阳 | 晚餐 | 2 |'
- en: '| 4 | 24.59 | 3.61 | Female | No | Sun | Dinner | 4 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 24.59 | 3.61 | 女性 | 否 | 太阳 | 晚餐 | 4 |'
- en: At first glance, it doesn’t seem possible to fit a regression model to this
    data – we can’t directly perform any mathematical operations on the entry “Sun”.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，似乎不可能对这些数据拟合回归模型——我们无法直接对“太阳”进行任何数学运算。
- en: To resolve this, we instead create a new table with a feature for each unique
    value in the original `"day"` column. We then iterate through the `"day"` column.
    For each entry in `"day"` we fill the corresponding feature in the new table with
    1\. All other features are set to 0.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们创建一个新表，其中包含原始“day”列中每个唯一值的特征。然后我们迭代“day”列。对于“day”中的每个条目，我们将新表中对应的特征填充为1。所有其他特征都设置为0。
- en: '![ohe](../Images/ea7d6d2438940c8e423c552dae9a8c77.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![ohe](../Images/ea7d6d2438940c8e423c552dae9a8c77.png)'
- en: 'The `OneHotEncoder` class of `sklearn` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder.get_feature_names_out))
    offers a quick way to perform this one-hot encoding. You will explore its use
    in detail in the lab. For now, recognize that we follow a very similar workflow
    to when we were working with the `LinearRegression` class: we initialize a `OneHotEncoder`
    object, fit it to our data, then use `.transform` to apply the fitted encoder.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn`的`OneHotEncoder`类（[文档](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder.get_feature_names_out)）提供了一种快速执行这种独热编码的方法。您将在实验室中详细探讨它的用法。现在，要认识到我们遵循的工作流程与我们使用`LinearRegression`类时非常相似：我们初始化一个`OneHotEncoder`对象，将其拟合到我们的数据，然后使用`.transform`来应用拟合的编码器。'
- en: '[PRE23]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '|  | day_Fri | day_Sat | day_Sun | day_Thur |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|  | day_Fri | day_Sat | day_Sun | day_Thur |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.0 | 0.0 | 1.0 | 0.0 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.0 | 0.0 | 1.0 | 0.0 |'
- en: '| 1 | 0.0 | 0.0 | 1.0 | 0.0 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.0 | 0.0 | 1.0 | 0.0 |'
- en: '| 2 | 0.0 | 0.0 | 1.0 | 0.0 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.0 | 0.0 | 1.0 | 0.0 |'
- en: '| 3 | 0.0 | 0.0 | 1.0 | 0.0 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.0 | 0.0 | 1.0 | 0.0 |'
- en: '| 4 | 0.0 | 0.0 | 1.0 | 0.0 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.0 | 0.0 | 1.0 | 0.0 |'
- en: 'The one-hot encoded features can then be used in the design matrix to train
    a model:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，独热编码的特征可以用于设计矩阵来训练模型：
- en: '![ohemodel](../Images/0628075930b3f917b0ce8f1b274f6b3a.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![ohemodel](../Images/0628075930b3f917b0ce8f1b274f6b3a.png)'
- en: \[\hat{y} = \theta_1 (\text{total}\textunderscore\text{bill}) + \theta_2 (\text{size})
    + \theta_3 (\text{day}\textunderscore\text{Fri}) + \theta_4 (\text{day}\textunderscore\text{Sat})
    + \theta_5 (\text{day}\textunderscore\text{Sun}) + \theta_6 (\text{day}\textunderscore\text{Thur})\]
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y} = \theta_1 (\text{total}\textunderscore\text{bill}) + \theta_2 (\text{size})
    + \theta_3 (\text{day}\textunderscore\text{Fri}) + \theta_4 (\text{day}\textunderscore\text{Sat})
    + \theta_5 (\text{day}\textunderscore\text{Sun}) + \theta_6 (\text{day}\textunderscore\text{Thur})\]
- en: 'Or in shorthand:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 或者简写为：
- en: \[\hat{y} = \theta_1\phi_1 + \theta_2\phi_2 + \theta_3\phi_3 + \theta_4\phi_4
    + \theta_5\phi_5 + \theta_6\phi_6\]
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y} = \theta_1\phi_1 + \theta_2\phi_2 + \theta_3\phi_3 + \theta_4\phi_4
    + \theta_5\phi_5 + \theta_6\phi_6\]
- en: Now, the `day` feature (or rather, the four new boolean features that represent
    day) can be used to fit a model.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，“day”特征（或者说，代表天的四个新布尔特征）可以用来拟合模型。
- en: Using `sklearn` to fit the new model, we can determine the model coefficients,
    allowing us to understand how each feature impacts the predicted tip.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`sklearn`来拟合新模型，我们可以确定模型系数，从而了解每个特征对预测小费的影响。
- en: '[PRE24]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '|  | Feature | Model Coefficient |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '|  | 特征 | 模型系数 |'
- en: '| --- | --- | --- |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0 | total_bill | 0.092994 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 0 | total_bill | 0.092994 |'
- en: '| 1 | size | 0.187132 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 大小 | 0.187132 |'
- en: '| 2 | day_Fri | 0.745787 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 2 | day_Fri | 0.745787 |'
- en: '| 3 | day_Sat | 0.621129 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 3 | day_Sat | 0.621129 |'
- en: '| 4 | day_Sun | 0.732289 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 4 | day_Sun | 0.732289 |'
- en: '| 5 | day_Thur | 0.668294 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 5 | day_Thur | 0.668294 |'
- en: For example, when looking at the coefficient for `day_Fri`, we can understand
    how much the fact that it is Friday impacts the predicted tip.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当查看`day_Fri`的系数时，我们可以了解星期五的事实对预测小费的影响有多大。
- en: When one-hot encoding, keep in mind that any set of one-hot encoded columns
    will always sum to a column of all ones, representing the bias column. More formally,
    the bias column is a linear combination of the OHE columns.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在独热编码时，要记住任何一组独热编码的列总是会加和为全为1的一列，表示偏置列。更正式地说，偏置列是OHE列的线性组合。
- en: '![bias](../Images/4938e607e68fccc0e7a035fb3e96c73c.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![bias](../Images/4938e607e68fccc0e7a035fb3e96c73c.png)'
- en: We must be careful not to include this bias column in our design matrix. Otherwise,
    there will be linear dependence in the model, meaning \(\mathbb{X}^T\mathbb{X}\)
    would no longer be invertible, and our OLS estimate \(\hat{\theta} = (\mathbb{X}^T\mathbb{X})^{-1}\mathbb{X}^T\mathbb{Y}\)
    fails.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须小心不要在我们的设计矩阵中包含这个偏置列。否则，模型中将存在线性依赖，这意味着\(\mathbb{X}^T\mathbb{X}\)将不再可逆，我们的OLS估计\(\hat{\theta}
    = (\mathbb{X}^T\mathbb{X})^{-1}\mathbb{X}^T\mathbb{Y}\)将失败。
- en: To resolve this issue, we simply omit one of the one-hot encoded columns *or*
    do not include an intercept term.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们简单地省略了一个独热编码的列*或*不包括截距项。
- en: '![remove](../Images/77ee071e23035aaffe79fd73d0f3a9ad.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![remove](../Images/77ee071e23035aaffe79fd73d0f3a9ad.png)'
- en: Either approach works — we still retain the same information as the omitted
    column being a linear combination of the remaining columns.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 任何一种方法都可以——我们仍然保留了与省略列相同的信息，即省略列是剩余列的线性组合。
- en: 14.6 Polynomial Features
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.6 多项式特征
- en: We have encountered a few cases now where models with linear features have performed
    poorly on datasets that show clear non-linear curvature.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经遇到了几种情况，其中具有线性特征的模型在显示明显非线性曲率的数据集上表现不佳。
- en: As an example, consider the `vehicles` dataset, which contains information about
    cars. Suppose we want to use the `hp` (horsepower) of a car to predict its `"mpg"`
    (gas mileage in miles per gallon). If we visualize the relationship between these
    two variables, we see a non-linear curvature. Fitting a linear model to these
    variables results in a high (poor) value of RMSE.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，考虑包含有关汽车信息的`vehicles`数据集。假设我们想要使用汽车的`hp`（马力）来预测其`"mpg"`（每加仑英里数的汽油里程）。如果我们可视化这两个变量之间的关系，我们会看到一个非线性的曲率。将线性模型拟合到这些变量会导致高（差）的RMSE值。
- en: \[\hat{y} = \theta_0 + \theta_1 (\text{hp})\]
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y} = \theta_0 + \theta_1 (\text{hp})\]
- en: <details><summary>Code</summary>
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE25]</details>'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE25]</details>'
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](../Images/bef0af0b0ca9d1fe393aaab9d15875d4.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bef0af0b0ca9d1fe393aaab9d15875d4.png)'
- en: 'To capture non-linearity in a dataset, it makes sense to incorporate **non-linear**
    features. Let’s introduce a **polynomial** term, \(\text{hp}^2\), into our regression
    model. The model now takes the form:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉数据集中的非线性，将**非线性**特征纳入其中是有意义的。让我们在回归模型中引入一个**多项式**项，\(\text{hp}^2\)。模型现在的形式是：
- en: \[\hat{y} = \theta_0 + \theta_1 (\text{hp}) + \theta_2 (\text{hp}^2)\] \[\hat{y}
    = \theta_0 + \theta_1 \phi_1 + \theta_2 \phi_2\]
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{y} = \theta_0 + \theta_1 (\text{hp}) + \theta_2 (\text{hp}^2)\] \[\hat{y}
    = \theta_0 + \theta_1 \phi_1 + \theta_2 \phi_2\]
- en: 'How can we fit a model with non-linear features? We can use the exact same
    techniques as before: ordinary least squares, gradient descent, or `sklearn`.
    This is because our new model is still a **linear model**. Although it contains
    non-linear *features*, it is linear with respect to the model *parameters*. All
    of our previous work on fitting models was done under the assumption that we were
    working with linear models. Because our new model is still linear, we can apply
    our existing methods to determine the optimal parameters.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何拟合具有非线性特征的模型？我们可以使用与以前完全相同的技术：普通最小二乘法、梯度下降或`sklearn`。这是因为我们的新模型仍然是一个**线性模型**。尽管它包含非线性*特征*，但它在模型*参数*方面是线性的。我们以前所有拟合模型的工作都是在假设我们正在处理线性模型的情况下进行的。因为我们的新模型仍然是线性的，我们可以应用我们现有的方法来确定最佳参数。
- en: '[PRE27]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](../Images/31e2893c6b7a81904ba20a08f390e2fb.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31e2893c6b7a81904ba20a08f390e2fb.png)'
- en: Looking a lot better! By incorporating a squared feature, we are able to capture
    the curvature of the dataset. Our model is now a parabola centered on our data.
    Notice that our new model’s error has decreased relative to the original model
    with linear features. .
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来好多了！通过引入一个平方特征，我们能够捕捉数据集的曲率。我们的模型现在是一个以我们的数据为中心的抛物线。请注意，相对于具有线性特征的原始模型，我们的新模型的误差已经减少了。
- en: 14.7 Complexity and Overfitting
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.7 复杂性和过拟合
- en: 'We’ve seen now that feature engineering allows us to build all sorts of features
    to improve the performance of the model. In particular, we saw that designing
    a more complex feature (squaring `hp` in the `vehicles` data previously) substantially
    improved the model’s ability to capture non-linear relationships. To take full
    advantage of this, we might be inclined to design increasingly complex features.
    Consider the following three models, each of different order (the maximum exponent
    power of each model):'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经看到，特征工程使我们能够构建各种特征来提高模型的性能。特别是，我们看到设计更复杂的特征（在先前的`vehicles`数据中对`hp`进行平方）大大提高了模型捕捉非线性关系的能力。为了充分利用这一点，我们可能倾向于设计越来越复杂的特征。考虑以下三个不同阶数的模型（每个模型的最大指数幂）：
- en: 'Model with order 2: \(\hat{\text{mpg}} = \theta_0 + \theta_1 (\text{hp}) +
    \theta_2 (\text{hp}^2)\)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二次模型：\(\hat{\text{mpg}} = \theta_0 + \theta_1 (\text{hp}) + \theta_2 (\text{hp}^2)\)
- en: 'Model with order 3: \(\hat{\text{mpg}} = \theta_0 + \theta_1 (\text{hp}) +
    \theta_2 (\text{hp}^2) + \theta_3 (\text{hp}^3)\)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三次模型：\(\hat{\text{mpg}} = \theta_0 + \theta_1 (\text{hp}) + \theta_2 (\text{hp}^2)
    + \theta_3 (\text{hp}^3)\)
- en: 'Model with order 4: \(\hat{\text{mpg}} = \theta_0 + \theta_1 (\text{hp}) +
    \theta_2 (\text{hp}^2) + \theta_3 (\text{hp}^3) + \theta_4 (\text{hp}^4)\)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四次模型：\(\hat{\text{mpg}} = \theta_0 + \theta_1 (\text{hp}) + \theta_2 (\text{hp}^2)
    + \theta_3 (\text{hp}^3) + \theta_4 (\text{hp}^4)\)
- en: '![degree_comparison](../Images/aeff31528678a2886762cf0c496f8068.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![degree_comparison](../Images/aeff31528678a2886762cf0c496f8068.png)'
- en: 'As we can see in the plots above, MSE continues to decrease with each additional
    polynomial term. To visualize it further, let’s plot models as the complexity
    increases from 0 to 6:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上面的图中所看到的，随着每个额外的多项式项，均方误差继续减小。为了进一步可视化，让我们将模型从复杂度0增加到6进行绘制：
- en: '![degree_comparison](../Images/e1df10e114aea4b30ba6adfc9c3846b7.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![degree_comparison](../Images/e1df10e114aea4b30ba6adfc9c3846b7.png)'
- en: When we use our model to make predictions on the same data that was used to
    fit the model, we find that the MSE decreases with each additional polynomial
    term (as our model gets more complex). The **training error** is the model’s error
    when generating predictions from the same data that was used for training purposes.
    We can conclude that the training error goes down as the complexity of the model
    increases.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用我们的模型对用于拟合模型的相同数据进行预测时，我们发现随着每个额外的多项式项（随着我们的模型变得更复杂），MSE会减少。**训练误差**是模型在生成来自用于训练目的的相同数据的预测时的误差。我们可以得出结论，随着模型复杂度的增加，训练误差会下降。
- en: '![train_error](../Images/2e051d542ff30dc27f353339dcd5f756.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![train_error](../Images/2e051d542ff30dc27f353339dcd5f756.png)'
- en: This seems like good news – when working on the **training data**, we can improve
    model performance by designing increasingly complex models.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来像是个好消息 - 在处理**训练数据**时，我们可以通过设计越来越复杂的模型来提高模型性能。
- en: '**Math Fact**: given \(N\) overlapping data points, we can always find a polynomial
    of degree \(N-1\) that goes through all those points.'
  id: totrans-192
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**数学事实**：给定\(N\)个重叠的数据点，我们总是可以找到一个通过所有这些点的\(N-1\)次多项式。'
- en: ''
  id: totrans-193
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'For example: there always exists a degree-4 polynomial curve that can perfectly
    model a dataset of 5 datapoints![train_error](../Images/06b47c32bc7ba078801b2b21a5dc0ee7.png)'
  id: totrans-194
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如：总是存在一个4次多项式曲线，可以完美地模拟一个包含5个数据点的数据集！[train_error](../Images/06b47c32bc7ba078801b2b21a5dc0ee7.png)
- en: However, high model complexity comes with its own set of issues. When building
    the `vehicles` models above, we trained the models on the *entire* dataset and
    then evaluated their performance on this same dataset. In reality, we are likely
    to instead train the model on a *sample* from the population, then use it to make
    predictions on data it didn’t encounter during training.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，高模型复杂性也带来了自己的一系列问题。在构建上述`vehicles`模型时，我们在*整个*数据集上训练了模型，然后评估了它们在同一数据集上的性能。实际上，我们很可能会在*样本*中训练模型，然后使用它对在训练期间未遇到的数据进行预测。
- en: Let’s walk through a more realistic example. Say we are given a training dataset
    of just 6 datapoints and want to train a model to then make predictions on a *different*
    set of points. We may be tempted to make a highly complex model (e.g., degree
    5), especially given it makes perfect predictions on the training data as clear
    on the left. However, as shown in the graph on the right, this model would perform
    *horribly* on the rest of the population!
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个更现实的例子来看看。假设我们有一个仅包含6个数据点的训练数据集，并希望训练一个模型，然后对*不同*的数据点进行预测。我们可能会倾向于制作一个非常复杂的模型（例如，5次方），特别是考虑到它在左侧清晰地对训练数据进行了完美的预测。然而，如右侧图表所示，这个模型在整个数据集上的表现会非常糟糕！
- en: '![complex](../Images/ca2af6c23932412268e24d54757b3681.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![complex](../Images/ca2af6c23932412268e24d54757b3681.png)'
- en: The phenomenon above is called **overfitting**. The model effectively just memorized
    the training data it encountered when it was fitted, leaving it unable to **generalize**
    well to data it didn’t encounter during training.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 上述现象被称为**过拟合**。该模型实际上只是记住了它在拟合时遇到的训练数据，导致它无法很好地对在训练期间未遇到的数据进行**泛化**。
- en: Additionally, since complex models are sensitive to the specific dataset used
    to train them, they have high **variance**. A model with high variance tends to
    *vary* more dramatically when trained on different datasets. Going back to our
    example above, we can see our degree-5 model varies erratically when we fit it
    to different samples of 6 points from `vehicles`.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于复杂模型对用于训练它们的特定数据集敏感，它们具有高**方差**。具有高方差的模型在训练不同数据集时往往会产生更大的变化。回到上面的例子，我们可以看到我们的5次方模型在拟合来自`vehicles`的不同6点样本时变化不稳定。
- en: '![resamples](../Images/221b21ee8e0d0d7015b8046aac682f34.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![resamples](../Images/221b21ee8e0d0d7015b8046aac682f34.png)'
- en: 'We now face a dilemma: we know that we can **decrease training error** by increasing
    model complexity, but models that are *too* complex start to overfit and can’t
    be reapplied to new datasets due to **high variance**.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们面临一个两难选择：我们知道我们可以通过增加模型复杂性来**减少训练误差**，但是过于复杂的模型开始过拟合，并且由于**高方差**无法重新应用于新的数据集。
- en: '![bvt](../Images/a05e9ed156737231686d1648a6d585c6.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![bvt](../Images/a05e9ed156737231686d1648a6d585c6.png)'
- en: We can see that there is a clear trade-off that comes from the complexity of
    our model. As model complexity increases, the model’s error on the training data
    decreases. At the same time, the model’s variance tends to increase.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，模型复杂性带来了明显的权衡。随着模型复杂性的增加，模型在训练数据上的误差减少。与此同时，模型的方差往往会增加。
- en: 'The takeaway here: we need to strike a balance in the complexity of our models;
    we want models that are generalizable to “unseen” data. A model that is too simple
    won’t be able to capture the key relationships between our variables of interest;
    a model that is too complex runs the risk of overfitting.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的要点是：我们需要在模型的复杂性上取得平衡；我们希望模型能够泛化到“未见过”的数据。一个太简单的模型将无法捕捉我们感兴趣的变量之间的关键关系；一个太复杂的模型则有过拟合的风险。
- en: 'This begs the question: how do we control the complexity of a model? Stay tuned
    for our Lecture 16 on Cross-Validation and Regularization!**'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了一个问题：我们如何控制模型的复杂性？请关注我们的第16讲，交叉验证和正则化！**
