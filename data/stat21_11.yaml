- en: Chapter 10 Quantifying effects and designing studies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章 量化效应和设计研究
- en: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/ci-effect-size-power.html](https://statsthinking21.github.io/statsthinking21-core-site/ci-effect-size-power.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/ci-effect-size-power.html](https://statsthinking21.github.io/statsthinking21-core-site/ci-effect-size-power.html)
- en: 'In the previous chapter we discussed how we can use data to test hypotheses.
    Those methods provided a binary answer: we either reject or fail to reject the
    null hypothesis. However, this kind of decision overlooks a couple of important
    questions. First, we would like to know how much uncertainty we have about the
    answer (regardless of which way it goes). In addition, sometimes we don’t have
    a clear null hypothesis, so we would like to see what range of estimates are consistent
    with the data. Second, we would like to know how large the effect actually is,
    since as we saw in the weight loss example in the previous chapter, a statistically
    significant effect is not necessarily a practically important effect.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了如何使用数据来检验假设。这些方法提供了一个二元答案：我们要么拒绝要么未能拒绝零假设。然而，这种决定忽略了一些重要的问题。首先，我们想知道答案有多大的不确定性（无论结果如何）。此外，有时我们没有一个明确的零假设，因此我们想看到与数据一致的估计范围。其次，我们想知道效应实际上有多大，因为正如我们在上一章中的减重示例中看到的，统计上显著的效应未必是实际上重要的效应。
- en: 'In this chapter we will discuss methods to address these two questions: confidence
    intervals to provide a measure of our uncertainty about our estimates, and effect
    sizes to provide a standardized way to understand how large the effects are. We
    will also discuss the concept of *statistical power* which tells us how likely
    we are to find any true effects that actually exist.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论解决这两个问题的方法：置信区间提供我们对估计的不确定性的度量，以及效应大小提供了一种标准化的方式来理解效应的大小。我们还将讨论*统计功效*的概念，它告诉我们我们有多大可能发现实际存在的任何真实效应。
- en: 10.1 Confidence intervals
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 置信区间
- en: 'So far in the book we have focused on estimating a single value statistic.
    For example, let’s say we want to estimate the mean weight of adults in the NHANES
    dataset, so we take a sample from the dataset and estimate the mean. In this sample,
    the mean weight was 79.92 kilograms. We refer to this as a *point estimate* since
    it provides us with a single number to describe our estimate of the population
    parameter. However, we know from our earlier discussion of sampling error that
    there is some uncertainty about this estimate, which is described by the standard
    error. You should also remember that the standard error is determined by two components:
    the population standard deviation (which is the numerator), and the square root
    of the sample size (which is in the denominator). The population standard deviation
    is a generally unknown but fixed parameter that is not under our control, whereas
    the sample size *is* under our control. Thus, we can decrease our uncertainty
    about the estimate by increasing our sample size – up to the limit of the entire
    population size, at which point there is no uncertainty at all because we can
    just calculate the population parameter directly from the data of the entire population.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本书中我们一直专注于估计单个数值统计量。例如，假设我们想要估计NHANES数据集中成年人的平均体重，因此我们从数据集中抽取样本并估计平均值。在这个样本中，平均体重为79.92公斤。我们将这称为*点估计*，因为它为我们提供了一个单一的数字来描述我们对总体参数的估计。然而，根据我们之前对抽样误差的讨论，我们知道对这个估计存在一定的不确定性，这由标准误差描述。您还应该记住，标准误差由两个组成部分确定：总体标准差（分子）和样本大小的平方根（分母）。总体标准差是一个通常未知但固定的参数，不在我们的控制范围内，而样本大小*在*我们的控制范围内。因此，我们可以通过增加样本大小来减少对估计的不确定性-直到整个人口规模的极限，此时没有任何不确定性，因为我们可以直接从整个人口的数据中计算出总体参数。
- en: We would often like to have a way to more directly describe our uncertainty
    about a statistical estimate, which we can accomplish using a *confidence interval*.
    Most people are familiar with confidence intervals through the idea of a “margin
    of error” for political polls. These polls usually try to provide an answer that
    is accurate within +/- 3 percent. For example, when a candidate is estimated to
    win an election by 9 percentage points with a margin of error of 3, the percentage
    by which they will win is estimated to fall within 6-12 percentage points. In
    statistics we refer to this kind of range of values as a confidence interval,
    which provides a range of values for our parameter estimate that are consistent
    with our sample data, rather than just giving us a single estimate based on the
    data. The wider the confidence interval, the more uncertain we are about our parameter
    estimate.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常希望有一种更直接地描述我们对统计估计的不确定性的方法，这可以通过使用*置信区间*来实现。大多数人通过政治民意调查中“误差范围”的概念熟悉置信区间。这些调查通常试图提供一个在+/-
    3%内准确的答案。例如，当估计候选人在选举中以9个百分点的优势获胜，误差范围为3时，他们将获胜的百分比估计在6-12个百分点之间。在统计学中，我们将这种数值范围称为置信区间，它提供了一系列与我们的样本数据一致的参数估计值，而不仅仅是基于数据给出一个单一的估计。置信区间越宽，我们对参数估计的不确定性就越大。
- en: 'Confidence intervals are notoriously confusing, primarily because they don’t
    mean what we might intuitively think they mean. If I tell you that I have computed
    a “95% confidence interval” for my statistic, then it would seem natural to think
    that we can have 95% confidence that the true parameter value falls within this
    interval. However, as we will see throughout the course, concepts in statistics
    often don’t mean what we think they should mean. In the case of confidence intervals,
    we can’t interpret them in this way because the population parameter has a fixed
    value – it either is or isn’t in the interval, so it doesn’t make sense to talk
    about the probability of that occurring. Jerzy Neyman, the inventor of the confidence
    interval, said:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间因其含义常常令人困惑，主要是因为它们的含义并不是我们直觉上认为的含义。如果我告诉你我已经计算出了我的统计量的“95%置信区间”，那么似乎自然地认为我们可以有95%的信心，真实的参数值落在这个区间内。然而，正如我们在整个课程中将看到的那样，统计学中的概念通常并不是我们认为它们应该是的。在置信区间的情况下，我们不能以这种方式解释它们，因为总体参数具有固定值
    - 它要么在区间内，要么不在区间内，因此谈论发生这种情况的概率是没有意义的。置信区间的发明者Jerzy Neyman说过：
- en: “The parameter is an unknown constant and no probability statement concerning
    its value may be made.”([J. Neyman 1937](#ref-Neyman37))
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “参数是一个未知的常数，关于它的值不可能做出概率陈述。”([J. Neyman 1937](#ref-Neyman37))
- en: 'Instead, we have to view the confidence interval procedure from the same standpoint
    that we viewed hypothesis testing: As a procedure that in the long run will allow
    us to make correct statements with a particular probability. Thus, the proper
    interpretation of the 95% confidence interval is that it is an interval that will
    contain the true population mean 95% of the time, and in fact we can confirm that
    using simulation, as you will see below.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们必须从与我们观察假设检验相同的角度来看待置信区间过程：作为一个长期来看，它将允许我们以特定概率做出正确的陈述的过程。因此，95%置信区间的正确解释是，它是一个区间，将在95%的时间内包含真实的总体均值，事实上，我们可以使用模拟来确认这一点，如下所示。
- en: 'The confidence interval for the mean is computed as:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 均值的置信区间计算如下：
- en: \[ CI = \text{point estimate} \pm \text{critical value} * \text{standard error}
    \]
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \[ CI = \text{点估计} \pm \text{临界值} * \text{标准误差} \]
- en: where the critical value is determined by the sampling distribution of the estimate.
    The important question, then, is how we obtain our estimate for that sampling
    distribution.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 其中临界值由估计的抽样分布确定。那么，重要的问题是我们如何获得我们的估计值的抽样分布。
- en: 10.1.1 Confidence intervals using the normal distribution
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 正态分布下的置信区间
- en: If we know the population standard deviation, then we can use the normal distribution
    to compute a confidence interval. We usually don’t, but for our example of the
    NHANES dataset we do, since we are treating the entire dataset as the population
    (it’s 21.3 for weight).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们知道总体标准差，那么我们可以使用正态分布来计算置信区间。我们通常不知道，但对于NHANES数据集的示例，我们知道，因为我们将整个数据集视为总体（体重为21.3）。
- en: 'Let’s say that we want to compute a 95% confidence interval for the mean. The
    critical value would then be the values of the standard normal distribution that
    capture 95% of the distribution; these are simply the 2.5th percentile and the
    97.5th percentile of the distribution, which we can compute using our statistical
    software, and come out to \(\pm 1.96\). Thus, the confidence interval for the
    mean (\(\bar{X}\)) is:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要计算均值的95%置信区间。临界值将是标准正态分布的值，这些值捕获了分布的95%；这些值只是分布的第2.5百分位数和第97.5百分位数，我们可以使用统计软件计算出来，结果为\(\pm
    1.96\)。因此，均值（\(\bar{X}\)）的置信区间是：
- en: \[ CI = \bar{X} \pm 1.96*SE \]
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: \[ CI = \bar{X} \pm 1.96*SE \]
- en: Using the estimated mean from our sample (79.92) and the known population standard
    deviation, we can compute the confidence interval of [77.28,82.56].
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用样本的估计均值（79.92）和已知的总体标准差，我们可以计算出置信区间为[77.28,82.56]。
- en: 10.1.2 Confidence intervals using the t distribution
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.2 使用t分布的置信区间
- en: As stated above, if we knew the population standard deviation, then we could
    use the normal distribution to compute our confidence intervals. However, in general
    we don’t – in which case the *t* distribution is more appropriate as a sampling
    distribution. Remember that the t distribution is slightly broader than the normal
    distribution, especially for smaller samples, which means that the confidence
    intervals will be slightly wider than they would if we were using the normal distribution.
    This incorporates the extra uncertainty that arises when we estimate parameters
    based on small samples.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，如果我们知道总体标准差，那么我们可以使用正态分布来计算置信区间。然而，一般情况下我们不知道 - 在这种情况下，*t*分布更适合作为抽样分布。请记住，t分布比正态分布略宽，特别是对于较小的样本，这意味着置信区间将比使用正态分布时稍微宽一些。这包括了在我们基于小样本估计参数时产生的额外不确定性。
- en: 'We can compute the 95% confidence interval in a way similar to the normal distribution
    example above, but the critical value is determined by the 2.5th percentile and
    the 97.5th percentile of the *t* distribution with the appropriate degrees of
    freedom. Thus, the confidence interval for the mean (\(\bar{X}\)) is:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以以与上面正态分布示例类似的方式计算95%置信区间，但临界值由适当自由度的*t*分布的第2.5百分位数和第97.5百分位数确定。因此，均值（\(\bar{X}\)）的置信区间是：
- en: \[ CI = \bar{X} \pm t_{crit}*SE \]
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: \[ CI = \bar{X} \pm t_{crit}*SE \]
- en: where \(t_{crit}\) is the critical t value. For the NHANES weight example (with
    sample size of 250), the confidence interval would be 79.92 +/- 1.97 * 1.41 [77.15
    - 82.69].
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(t_{crit}\)是临界t值。对于NHANES体重示例（样本量为250），置信区间将是79.92 +/- 1.97 * 1.41 [77.15
    - 82.69]。
- en: Remember that this doesn’t tell us anything about the probability of the true
    population value falling within this interval, since it is a fixed parameter (which
    we know is 81.77 because we have the entire population in this case) and it either
    does or does not fall within this specific interval (in this case, it does). Instead,
    it tells us that in the long run, if we compute the confidence interval using
    this procedure, 95% of the time that confidence interval will capture the true
    population parameter.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这并不告诉我们真实总体值落入此区间的概率，因为它是一个固定参数（在这种情况下，我们知道是81.77，因为我们在这种情况下有整个总体），它要么在这个特定的区间内，要么不在（在这种情况下，它在）。相反，它告诉我们，从长远来看，如果我们使用这个程序计算置信区间，有95%的时间置信区间将捕获真实的总体参数。
- en: We can see this using the NHANES data as our population; in this case, we know
    the true value of the population parameter, so we can see how often the confidence
    interval ends up capturing that value across many different samples. Figure [10.1](ci-effect-size-power.html#fig:CIcoverage)
    shows the confidence intervals for estimated mean weight computed for 100 samples
    from the NHANES dataset. Of these, 95 captured the true population mean weight,
    showing that the confidence interval procedure performs as it should.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用NHANES数据作为我们的总体；在这种情况下，我们知道总体参数的真实值，因此我们可以看到在许多不同的样本中置信区间最终捕获该值的频率。图[10.1](ci-effect-size-power.html#fig:CIcoverage)显示了从NHANES数据集中计算的估计平均体重的100个样本的置信区间。其中有95个捕获了真实的总体平均体重，表明置信区间程序的执行效果如预期。
- en: '![Samples were repeatedly taken from the NHANES dataset, and the 95% confidence
    interval of the mean was computed for each sample.  Intervals shown in red did
    not capture the true population mean (shown as the dotted line).](../Images/93512ef54480ccbcdd6c3da97640e18a.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![从NHANES数据集中重复取样，为每个样本计算了平均值的95%置信区间。红色区间未捕获真实的总体均值（显示为虚线）。](../Images/93512ef54480ccbcdd6c3da97640e18a.png)'
- en: 'Figure 10.1: Samples were repeatedly taken from the NHANES dataset, and the
    95% confidence interval of the mean was computed for each sample. Intervals shown
    in red did not capture the true population mean (shown as the dotted line).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：从NHANES数据集中重复取样，为每个样本计算了平均值的95%置信区间。红色区间未捕获真实的总体均值（显示为虚线）。
- en: 10.1.3 Confidence intervals and sample size
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.3 置信区间和样本量
- en: Because the standard error decreases with sample size, the confidence interval
    should get narrower as the sample size increases, providing progressively tighter
    bounds on our estimate. Figure [10.2](ci-effect-size-power.html#fig:CISampSize)
    shows an example of how the confidence interval would change as a function of
    sample size for the weight example. From the figure it’s evident that the confidence
    interval becomes increasingly tighter as the sample size increases, but increasing
    samples provide diminishing returns, consistent with the fact that the denominator
    of the confidence interval term is proportional to the square root of the sample
    size.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由于标准误差随样本量的减少而减少，因此随着样本量的增加，置信区间应该变得更窄，为我们的估计提供逐渐更紧的界限。图[10.2](ci-effect-size-power.html#fig:CISampSize)显示了置信区间在体重示例中随样本量变化的示例。从图中可以明显看出，随着样本量的增加，置信区间变得越来越紧，但增加样本提供的回报递减，这与置信区间项的分母与样本量的平方根成比例的事实一致。
- en: '![An example of the effect of sample size on the width of the confidence interval
    for the mean.](../Images/4c153c0a4d12839c76c24013cb9a197f.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![样本量对平均值置信区间宽度的影响的示例。](../Images/4c153c0a4d12839c76c24013cb9a197f.png)'
- en: 'Figure 10.2: An example of the effect of sample size on the width of the confidence
    interval for the mean.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：样本量对平均值置信区间宽度的影响的示例。
- en: 10.1.4 Computing confidence intervals using the bootstrap
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.4 使用自助法计算置信区间
- en: 'In some cases we can’t assume normality, or we don’t know the sampling distribution
    of the statistic. In these cases, we can use the bootstrap (which we introduced
    in Chapter [8](resampling-and-simulation.html#resampling-and-simulation)). As
    a reminder, the bootstrap involves repeatedly resampling the data *with replacement*,
    and then using the distribution of the statistic computed on those samples as
    a surrogate for the sampling distribution of the statistic.These are the results
    when we use the built-in bootstrapping function in R to compute the confidence
    interval for weight in our NHANES sample:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们不能假设正态性，或者我们不知道统计量的抽样分布。在这些情况下，我们可以使用自助法（我们在第[8]章中介绍过）。提醒一下，自助法涉及重复使用*有替换*的数据进行重新抽样，然后使用在这些样本上计算的统计量的分布作为统计量的抽样分布的替代品。这是我们在R中使用内置的自助法函数来计算NHANES样本中体重的置信区间的结果：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: These values are fairly close to the values obtained using the t distribution
    above, though not exactly the same.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值与上面使用t分布获得的值非常接近，尽管不完全相同。
- en: 10.1.5 Relation of confidence intervals to hypothesis tests
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.5 置信区间与假设检验的关系
- en: There is a close relationship between confidence intervals and hypothesis tests.
    In particular, if the confidence interval does not include the null hypothesis,
    then the associated statistical test would be statistically significant. For example,
    if you are testing whether the mean of a sample is greater than zero with \(\alpha
    = 0.05\), you could simply check to see whether zero is contained within the 95%
    confidence interval for the mean.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '置信区间与假设检验之间有着密切的关系。特别是，如果置信区间不包括零假设，那么相关的统计检验将具有统计显著性。例如，如果您正在测试样本的平均值是否大于零，\(\alpha
    = 0.05\)，您可以简单地检查零是否包含在平均值的95%置信区间内。 '
- en: Things get trickier if we want to compare the means of two conditions ([Schenker
    and Gentleman 2001](#ref-sche:gent:2001)). There are a couple of situations that
    are clear. First, if each mean is contained within the confidence interval for
    the other mean, then there is definitely no significant difference at the chosen
    confidence level. Second, if there is no overlap between the confidence intervals,
    then there is certainly a significant difference at the chosen level; in fact,
    this test is substantially *conservative*, such that the actual error rate will
    be lower than the chosen level. But what about the case where the confidence intervals
    overlap one another but don’t contain the means for the other group? In this case
    the answer depends on the relative variability of the two variables, and there
    is no general answer. However, one should in general avoid using the “eyeball
    test” for overlapping confidence intervals.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要比较两个条件的均值（[Schenker and Gentleman 2001](#ref-sche:gent:2001)），事情就会变得更加棘手。有一些情况是明确的。首先，如果每个均值都包含在另一个均值的置信区间内，那么在所选的置信水平下肯定没有显著差异。其次，如果置信区间之间没有重叠，那么在所选的水平上肯定存在显著差异；事实上，这个测试实际上是*保守*的，这样实际的错误率将低于所选的水平。但是如果置信区间彼此重叠但不包含另一组的均值呢？在这种情况下，答案取决于两个变量的相对变异性，没有通用的答案。然而，一般来说，应该避免使用“目测法”来判断重叠的置信区间。
- en: 10.2 Effect sizes
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 效应量
- en: “Statistical significance is the least interesting thing about the results.
    You should describe the results in terms of measures of magnitude – not just,
    does a treatment affect people, but how much does it affect them.” Gene Glass,
    quoted in ([Sullivan and Feinn 2012](#ref-Sullivan:2012ta))
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “统计显著性是关于结果最不重要的事情。你应该用量级的度量来描述结果——不仅仅是，治疗是否影响人们，而是它对他们产生了多大影响。” Gene Glass在([Sullivan
    and Feinn 2012](#ref-Sullivan:2012ta))中引用。
- en: In the previous chapter, we discussed the idea that statistical significance
    may not necessarily reflect practical significance. In order to discuss practical
    significance, we need a standard way to describe the size of an effect in terms
    of the actual data, which we refer to as an *effect size*. In this section we
    will introduce the concept and discuss various ways that effect sizes can be calculated.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们讨论了统计显著性可能并不一定反映实际显著性的想法。为了讨论实际显著性，我们需要一种标准的方式来描述效应的大小，我们称之为*效应量*。在本节中，我们将介绍这个概念，并讨论计算效应量的各种方法。
- en: An effect size is a standardized measurement that compares the size of some
    statistical effect to a reference quantity, such as the variability of the statistic.
    In some fields of science and engineering, this idea is referred to as a “signal
    to noise ratio”. There are many different ways that the effect size can be quantified,
    which depend on the nature of the data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 效应量是一种标准化的测量，它将某种统计效应的大小与参考数量（如统计的变异性）进行比较。在一些科学和工程领域，这个想法被称为“信噪比”。效应量可以用许多不同的方式来量化，这取决于数据的性质。
- en: 10.2.1 Cohen’s D
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 Cohen's D
- en: 'One of the most common measures of effect size is known as *Cohen’s d*, named
    after the statistician Jacob Cohen (who is most famous for his 1994 paper titled
    “The Earth Is Round (p < .05)”). It is used to quantify the difference between
    two means, in terms of their standard deviation:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 效应量的最常见测量之一被称为*Cohen's d*，以统计学家雅各布·科恩（以他1994年的论文“地球是圆的（p < .05）”而闻名）命名。它用于量化两个均值之间的差异，以它们的标准偏差为单位：
- en: \[ d = \frac{\bar{X}_1 - \bar{X}_2}{s} \]
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: \[ d = \frac{\bar{X}_1 - \bar{X}_2}{s} \]
- en: 'where \(\bar{X}_1\) and \(\bar{X}_2\) are the means of the two groups, and
    \(s\) is the pooled standard deviation (which is a combination of the standard
    deviations for the two samples, weighted by their sample sizes):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: \(\bar{X}_1\)和\(\bar{X}_2\)是两组的均值，\(s\)是合并标准偏差（这是两个样本的标准偏差的组合，按其样本大小加权）：
- en: \[ s = \sqrt{\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2 }{n_1 +n_2 -2}} \] where
    \(n_1\) and \(n_2\) are the sample sizes and \(s^2_1\) and \(s^2_2\) are the standard
    deviations for the two groups respectively. Note that this is very similar in
    spirit to the t statistic — the main difference is that the denominator in the
    t statistic is based on the standard error of the mean, whereas the denominator
    in Cohen’s D is based on the standard deviation of the data. This means that while
    the t statistic will grow as the sample size gets larger, the value of Cohen’s
    D will remain the same.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: \[ s = \sqrt{\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2 }{n_1 +n_2 -2}} \] 其中\(n_1\)和\(n_2\)是样本大小，\(s^2_1\)和\(s^2_2\)分别是两组的标准偏差。请注意，这在精神上与t统计量非常相似——主要区别在于t统计量的分母是基于均值的标准误差，而Cohen's
    D的分母是基于数据的标准偏差。这意味着随着样本量的增加，t统计量会增长，而Cohen's D的值将保持不变。
- en: 'Table 10.1: Interpetation of Cohen’s D'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1：Cohen's D的解释
- en: '| D | Interpretation |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| D | 解释 |'
- en: '| :-- | :-- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- |'
- en: '| 0.0 - 0.2 | neglibible |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 0.0 - 0.2 | 可忽略的 |'
- en: '| 0.2 - 0.5 | small |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 0.2 - 0.5 | 小 |'
- en: '| 0.5 - 0.8 | medium |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 0.5 - 0.8 | 中等 |'
- en: '| 0.8 - | large |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 0.8 - | 大 |'
- en: There is a commonly used scale for interpreting the size of an effect in terms
    of Cohen’s d, shown in Table [10.1](ci-effect-size-power.html#tab:dInterp). It
    can be useful to look at some commonly understood effects to help understand these
    interpretations. For example, the effect size for gender differences in adult
    height (d = 2.05) is very large by reference to our table above. We can also see
    this by looking at the distributions of male and female heights in a sample from
    the NHANES dataset. Figure [10.3](ci-effect-size-power.html#fig:genderHist) shows
    that the two distributions are quite well separated, though still overlapping,
    highlighting the fact that even when there is a very large effect size for the
    difference between two groups, there will be individuals from each group that
    are more like the other group.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 解释效应大小的常用尺度是科恩的d，如表[10.1](ci-effect-size-power.html#tab:dInterp)所示。查看一些常见的效应可以帮助理解这些解释是很有用的。例如，成年人身高的性别差异的效应大小（d
    = 2.05）根据我们上面的表格是非常大的。我们也可以通过查看NHANES数据集中样本中男性和女性身高的分布来看到这一点。图[10.3](ci-effect-size-power.html#fig:genderHist)显示，这两个分布相当分开，但仍有重叠，突出了即使两个群体之间存在非常大的效应大小，仍会有一些个体更像另一群体。
- en: '![Smoothed histogram plots for male and female heights in the NHANES dataset,
    showing clearly distinct but also clearly overlapping distributions.](../Images/2a7966baf8e7cb660263ccf4f570ae3f.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![NHANES数据集中男性和女性身高的平滑直方图，显示出明显不同但也有明显重叠的分布。](../Images/2a7966baf8e7cb660263ccf4f570ae3f.png)'
- en: 'Figure 10.3: Smoothed histogram plots for male and female heights in the NHANES
    dataset, showing clearly distinct but also clearly overlapping distributions.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '图10.3: NHANES数据集中男性和女性身高的平滑直方图，显示出明显不同但也有明显重叠的分布。'
- en: It is also worth noting that we rarely encounter effects of this magnitude in
    science, in part because they are such obvious effects that we don’t need scientific
    research to find them. As we will see in Chapter [18](doing-reproducible-research.html#doing-reproducible-research)
    on reproducibility, very large reported effects in scientific research often reflect
    the use of questionable research practices rather than truly huge effects in nature.
    It is also worth noting that even for such a huge effect, the two distributions
    still overlap - there will be some females who are taller than the average male,
    and vice versa. For most interesting scientific effects, the degree of overlap
    will be much greater, so we shouldn’t immediately jump to strong conclusions about
    individuals from different populations based on even a large effect size.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我们在科学中很少遇到这种程度的效应，部分原因是它们是如此明显的效应，我们不需要科学研究来发现它们。正如我们将在第[18](doing-reproducible-research.html#doing-reproducible-research)章中看到的，科学研究中报告的非常大的效应往往反映了可疑的研究做法，而不是自然界中真正巨大的效应。值得注意的是，即使对于如此巨大的效应，两个分布仍然有重叠
    - 会有一些女性比平均男性更高，反之亦然。对于大多数有趣的科学效应，重叠程度会更大，因此我们不应该立即根据即使是很大的效应大小就对来自不同群体的个体做出强烈的结论。
- en: 10.2.2 Pearson’s r
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 皮尔逊相关系数r
- en: Pearson’s *r*, also known as the *correlation coefficient*, is a measure of
    the strength of the linear relationship between two continuous variables. We will
    discuss correlation in much more detail in Chapter [13](modeling-continuous-relationships.html#modeling-continuous-relationships),
    so we will save the details for that chapter; here, we simply introduce *r* as
    a way to quantify the relation between two variables.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 皮尔逊*r*，也称为*相关系数*，是衡量两个连续变量之间线性关系强度的指标。我们将在第[13](modeling-continuous-relationships.html#modeling-continuous-relationships)章中更详细地讨论相关性，所以我们将详细内容留到那一章；在这里，我们只是介绍*r*作为量化两个变量之间关系的一种方式。
- en: '*r* is a measure that varies from -1 to 1, where a value of 1 represents a
    perfect positive relationship between the variables, 0 represents no relationship,
    and -1 represents a perfect negative relationship. Figure [10.4](ci-effect-size-power.html#fig:corrFig)
    shows examples of various levels of correlation using randomly generated data.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*r*是一个从-1到1变化的度量，其中1表示变量之间的完全正相关关系，0表示没有关系，-1表示完全负相关关系。图[10.4](ci-effect-size-power.html#fig:corrFig)使用随机生成的数据显示了不同水平的相关性的示例。'
- en: '![Examples of various levels of Pearson''s r.](../Images/b984dc47c3edcc1d306b6a7b4fe7ab1f.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![不同水平的皮尔逊相关系数r的示例。](../Images/b984dc47c3edcc1d306b6a7b4fe7ab1f.png)'
- en: 'Figure 10.4: Examples of various levels of Pearson’s r.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '图10.4: 不同水平的皮尔逊相关系数r的示例。'
- en: 10.2.3 Odds ratio
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.3 赔率比
- en: 'In our earlier discussion of probability we discussed the concept of odds –
    that is, the relative likelihood of some event happening versus not happening:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前对概率的讨论中，我们讨论了赔率的概念 - 也就是某个事件发生与不发生的相对可能性：
- en: \[ odds\ of\ A = \frac{P(A)}{P(\neg A)} \]
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: \[ A的赔率 = \frac{P(A)}{P(\neg A)} \]
- en: We also discussed the *odds ratio*, which is simply the ratio of two odds. The
    odds ratio is a useful way to describe effect sizes for binary variables.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了*赔率比*，它只是两个赔率的比率。赔率比是描述二元变量效应大小的一种有用方式。
- en: For example, let’s take the case of smoking and lung cancer. A study published
    in the International Journal of Cancer in 2012 ([Pesch et al. 2012](#ref-pesc:kend:gust:2012))
    combined data regarding the occurrence of lung cancer in smokers and individuals
    who have never smoked across a number of different studies. Note that these data
    come from case-control studies, which means that participants in the studies were
    recruited because they either did or did not have cancer; their smoking status
    was then examined. These numbers (shown in Table [10.2](ci-effect-size-power.html#tab:smokingData))
    thus do not represent the prevalence of cancer amongst smokers in the general
    population – but they can tell us about the relationship between cancer and smoking.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们以吸烟和肺癌为例。2012年发表在《国际癌症杂志》上的一项研究（[Pesch et al. 2012](#ref-pesc:kend:gust:2012)）结合了关于吸烟者和从未吸烟者在许多不同研究中肺癌发生情况的数据。请注意，这些数据来自病例对照研究，这意味着研究参与者之所以被招募，是因为他们有或没有癌症；然后检查了他们的吸烟状况。因此，这些数字（在表[10.2](ci-effect-size-power.html#tab:smokingData)中显示）并不代表一般人群中吸烟者患癌症的患病率-但它们可以告诉我们癌症和吸烟之间的关系。
- en: 'Table 10.2: Lung cancer occurrence separately for current smokers and those
    who have never smoked'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.2：吸烟者和从未吸烟者的肺癌发生率分别
- en: '| Status | NeverSmoked | CurrentSmoker |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 状态 | 从未吸烟 | 现在吸烟者 |'
- en: '| :-- | --: | --: |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| :-- | --: | --: |'
- en: '| No Cancer | 2883 | 3829 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 无癌症 | 2883 | 3829 |'
- en: '| Cancer | 220 | 6784 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 癌症 | 220 | 6784 |'
- en: 'We can convert these numbers to odds ratios for each of the groups. The odds
    of a non-smoker having lung cancer are 0.08 whereas the odds of a current smoker
    having lung cancer are 1.77\. The ratio of these odds tells us about the relative
    likelihood of cancer between the two groups: The odds ratio of 23.22 tells us
    that the odds of lung cancer in smokers are roughly 23 times higher than never-smokers.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些数字转换为每个组的几率比。从未吸烟者患肺癌的几率为0.08，而现在吸烟者患肺癌的几率为1.77。这些几率的比率告诉我们关于两组之间癌症相对发生率的情况：23.22的几率比告诉我们吸烟者患肺癌的几率大约是从未吸烟者的23倍。
- en: 10.3 Statistical power
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 统计学力量
- en: 'Remember from the previous chapter that under the Neyman-Pearson hypothesis
    testing approach, we have to specify our level of tolerance for two kinds of errors:
    False positives (which they called *Type I error*) and false negatives (which
    they called *Type II error*). People often focus heavily on Type I error, because
    making a false positive claim is generally viewed as a very bad thing; for example,
    the now discredited claims by Wakefield ([1999](#ref-wake:1999)) that autism was
    associated with vaccination led to anti-vaccine sentiment that has resulted in
    substantial increases in childhood diseases such as measles. Similarly, we don’t
    want to claim that a drug cures a disease if it really doesn’t. That’s why the
    tolerance for Type I errors is generally set fairly low, usually at \(\alpha =
    0.05\). But what about Type II errors?'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住前一章中提到的，根据Neyman-Pearson假设检验方法，我们必须指定我们对两种错误的容忍水平：假阳性（他们称之为*第一类错误*）和假阴性（他们称之为*第二类错误*）。人们经常非常关注第一类错误，因为做出假阳性声明通常被视为一件非常糟糕的事情；例如，Wakefield（[1999](#ref-wake:1999)）声称自闭症与疫苗接种有关导致了反疫苗情绪，从而导致麻疹等儿童疾病大幅增加。同样，我们也不想声称一种药物治愈了一种疾病，如果实际上并非如此。这就是为什么对第一类错误的容忍通常设置得相当低，通常为\(\alpha
    = 0.05\)。但第二类错误呢？
- en: 'The concept of *statistical power* is the complement of Type II error – that
    is, it is the likelihood of finding a positive result given that it exists:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学力量的概念是第二类错误的补充-也就是说，它是在存在积极结果的情况下找到积极结果的可能性：
- en: \[ power = 1 - \beta \]
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 力量 = 1 - \beta \]
- en: Another important aspect of the Neyman-Pearson model that we didn’t discuss
    earlier is the fact that in addition to specifying the acceptable levels of Type
    I and Type II errors, we also have to describe a specific alternative hypothesis
    – that is, what is the size of the effect that we wish to detect? Otherwise, we
    can’t interpret \(\beta\) – the likelihood of finding a large effect is always
    going to be higher than finding a small effect, so \(\beta\) will differ depending
    on the size of effect we are trying to detect.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Neyman-Pearson模型的另一个重要方面是我们之前没有讨论的，即除了指定可接受的第一类和第二类错误水平外，我们还必须描述一个特定的备择假设-也就是说，我们希望检测的效应大小是多少？否则，我们无法解释\(\beta\)
    - 发现大效应的可能性总是比发现小效应的可能性要高，因此\(\beta\)将取决于我们试图检测的效应大小。
- en: 'There are three factors that can affect statistical power:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个因素可以影响统计学力量：
- en: 'Sample size: Larger samples provide greater statistical power'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本量：较大的样本提供更大的统计学力量
- en: 'Effect size: A given design will always have greater power to find a large
    effect than a small effect (because finding large effects is easier)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 效应大小：给定的设计总是比小效应具有更大的功率来发现大效应（因为发现大效应更容易）
- en: 'Type I error rate: There is a relationship between Type I error and power such
    that (all else being equal) decreasing Type I error will also decrease power.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一类错误率：第一类错误与力量之间存在关系，即（其他条件相等）降低第一类错误也会降低力量。
- en: We can see this through simulation. First let’s simulate a single experiment,
    in which we compare the means of two groups using a standard t-test. We will vary
    the size of the effect (specified in terms of Cohen’s d), the Type I error rate,
    and the sample size, and for each of these we will examine how the proportion
    of significant results (i.e. power) is affected. Figure [10.5](ci-effect-size-power.html#fig:plotPowerSim)
    shows an example of how power changes as a function of these factors.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过模拟来看到这一点。首先让我们模拟一个单一实验，其中我们使用标准t检验比较两组的平均值。我们将改变效应大小（以Cohen的d表示），第一类错误率和样本量，对于每个这些因素，我们将检查显著结果的比例（即力量）如何受到影响。图[10.5](ci-effect-size-power.html#fig:plotPowerSim)显示了力量如何随这些因素的变化而变化的示例。
- en: '![Results from power simulation, showing power as a function of sample size,
    with effect sizes shown as different colors, and alpha shown as line type. The
    standard criterion of 80 percent power is shown by the dotted black line.](../Images/ce848a3a6109c0a3ab696b2c258ae00b.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![来自功率模拟的结果，显示功率作为样本大小的函数，效应大小显示为不同的颜色，α显示为线型。标准的80%功率标准由虚线黑线表示。](../Images/ce848a3a6109c0a3ab696b2c258ae00b.png)'
- en: 'Figure 10.5: Results from power simulation, showing power as a function of
    sample size, with effect sizes shown as different colors, and alpha shown as line
    type. The standard criterion of 80 percent power is shown by the dotted black
    line.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：来自功率模拟的结果，显示功率作为样本大小的函数，效应大小显示为不同的颜色，α显示为线型。标准的80%功率标准由虚线黑线表示。
- en: This simulation shows us that even with a sample size of 96, we will have relatively
    little power to find a small effect (\(d = 0.2\)) with \(\alpha = 0.005\). This
    means that a study designed to do this would be *futile* – that is, it is almost
    guaranteed to find nothing even if a true effect of that size exists.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模拟告诉我们，即使样本大小为96，我们也几乎没有足够的功效来发现一个小效应（\(d = 0.2\)），\(\alpha = 0.005\)。这意味着设计这样一个研究将是*徒劳*的
    - 也就是说，即使存在这样大小的真实效应，几乎肯定找不到任何东西。
- en: There are at least two important reasons to care about statistical power. First,
    if you are a researcher, you probably don’t want to spend your time doing futile
    experiments. Running an underpowered study is essentially futile, because it means
    that there is a very low likelihood that one will find an effect, even if it exists.
    Second, it turns out that any positive findings that come from an underpowered
    study are more likely to be false compared to a well-powered study, a point we
    discuss in more detail in Chapter [18](doing-reproducible-research.html#doing-reproducible-research).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 关于统计功效有至少两个重要的原因。首先，如果你是一名研究人员，你可能不想浪费时间做徒劳的实验。进行功效不足的研究基本上是徒劳的，因为这意味着很低的可能性会发现一个效应，即使它存在。其次，结果表明，与功效充足的研究相比，来自功效不足的研究的任何积极发现更有可能是错误的，这一点我们在第[18](doing-reproducible-research.html#doing-reproducible-research)章中会更详细地讨论。
- en: 10.3.1 Power analysis
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.1 功效分析
- en: Fortunately, there are tools available that allow us to determine the statistical
    power of an experiment. The most common use of these tools is in planning an experiment,
    when we would like to determine how large our sample needs to be in order to have
    sufficient power to find our effect of interest.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有可用的工具可以帮助我们确定实验的统计功效。这些工具最常见的用途是在规划实验时，我们想确定我们的样本需要多大才能有足够的功效来找到我们感兴趣的效应。
- en: 'Let’s say that we are interested in running a study of how a particular personality
    trait differs between users of iOS versus Android devices. Our plan is collect
    two groups of individuals and measure them on the personality trait, and then
    compare the two groups using a t-test. In this case, we would think that a medium
    effect (\(d = 0.5\)) is of scientific interest, so we will use that level for
    our power analysis. In order to determine the necessary sample size, we can use
    power function from our statistical software:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有兴趣进行一项研究，研究iOS用户和Android用户之间某种个性特征的差异。我们的计划是收集两组个体，并在个性特征上对他们进行测量，然后使用t检验比较这两组。在这种情况下，我们认为中等效应（\(d
    = 0.5\)）是科学上感兴趣的，因此我们将在我们的功效分析中使用这个水平。为了确定必要的样本量，我们可以使用统计软件中的功效函数：
- en: '[PRE1]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This tells us that we would need at least 64 subjects in each group in order
    to have sufficient power to find a medium-sized effect. It’s always important
    to run a power analysis before one starts a new study, to make sure that the study
    won’t be futile due to a sample that is too small.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，为了有足够的功效找到中等大小的效应，每组至少需要64名受试者。在开始新研究之前进行功效分析总是很重要的，以确保研究不会因为样本太小而徒劳。
- en: It might have occurred to you that if the effect size is large enough, then
    the necessary sample will be very small. For example, if we run the same power
    analysis with an effect size of d=2, then we will see that we only need about
    5 subjects in each group to have sufficient power to find the difference.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想到，如果效应大小足够大，那么所需的样本将会非常小。例如，如果我们使用d=2运行相同的功效分析，那么我们将看到我们只需要每组大约5个受试者就足够有能力找到差异。
- en: '[PRE2]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: However, it’s rare in science to be doing an experiment where we expect to find
    such a large effect – just as we don’t need statistics to tell us that 16-year-olds
    are taller than than 6-year-olds. When we run a power analysis, we need to specify
    an effect size that is plausible and/or scientifically interesting for our study,
    which would usually come from previous research. However, in Chapter [18](doing-reproducible-research.html#doing-reproducible-research)
    we will discuss a phenomenon known as the “winner’s curse” that likely results
    in published effect sizes being larger than the true effect size, so this should
    also be kept in mind.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在科学中很少进行预期发现如此大的效应的实验 - 就像我们不需要统计数据告诉我们16岁的人比6岁的人更高一样。当我们进行功效分析时，我们需要指定一个对我们的研究来说是合理和/或科学上有趣的效应大小，这通常来自先前的研究。然而，在第[18](doing-reproducible-research.html#doing-reproducible-research)章中，我们将讨论一个被称为“赢家诅咒”的现象，这可能导致发表的效应大小比真实效应大小更大，因此这也应该牢记在心中。
- en: 10.4 Learning objectives
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 学习目标
- en: 'Having read this chapter, you should be able to:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完本章后，您应该能够：
- en: Describe the proper interpretation of a confidence interval, and compute a confidence
    interval for the mean of a given dataset.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述置信区间的正确解释，并计算给定数据集的均值的置信区间。
- en: Define the concept of effect size, and compute the effect size for a given test.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义效应大小的概念，并计算给定测试的效应大小。
- en: Describe the concept of statistical power and why it is important for research.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述统计功效的概念以及为什么它对研究很重要。
- en: 10.5 Suggested readings
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 建议阅读
- en: '[Robust misinterpretation of confidence intervals, by Hoekstra et al.](http://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hoekstra等人的《置信区间的强偏误解释》](http://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf)'
