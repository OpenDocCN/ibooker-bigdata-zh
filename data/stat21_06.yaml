- en: Chapter 5 Fitting models to data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章 将模型拟合到数据
- en: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/fitting-models.html](https://statsthinking21.github.io/statsthinking21-core-site/fitting-models.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/fitting-models.html](https://statsthinking21.github.io/statsthinking21-core-site/fitting-models.html)
- en: One of the fundamental activities in statistics is creating models that can
    summarize data using a small set of numbers, thus providing a compact description
    of the data. In this chapter we will discuss the concept of a statistical model
    and how it can be used to describe data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学中的一个基本活动是创建能够用少量数字总结数据的模型，从而提供数据的简洁描述。在本章中，我们将讨论统计模型的概念以及如何用它来描述数据。
- en: 5.1 What is a model?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 什么是模型？
- en: In the physical world, “models” are generally simplifications of things in the
    real world that nonetheless convey the essence of the thing being modeled. A model
    of a building conveys the structure of the building while being small and light
    enough to pick up with one’s hands; a model of a cell in biology is much larger
    than the actual thing, but again conveys the major parts of the cell and their
    relationships.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在物理世界中，“模型”通常是对现实世界中的事物的简化，但仍然传达了被建模事物的本质。建筑物的模型传达了建筑物的结构，同时足够小和轻，可以用一只手拿起；生物学中细胞的模型比实际的细胞大得多，但同样传达了细胞的主要部分及其关系。
- en: 'In statistics, a model is meant to provide a similarly condensed description,
    but for data rather than for a physical structure. Like physical models, a statistical
    model is generally much simpler than the data being described; it is meant to
    capture the structure of the data as simply as possible. In both cases, we realize
    that the model is a convenient fiction that necessarily glosses over some of the
    details of the actual thing being modeled. As the statistician George Box famously
    said: “All models are wrong but some are useful.” It can also be useful to think
    of a statistical model as a theory of how the observed data were generated; our
    goal then becomes to find the model that most efficiently and accurately summarizes
    the way in which the data were actually generated. But as we will see below, the
    desires of efficiency and accuracy will often be diametrically opposed to one
    another.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，模型的目的是提供一个类似的简洁描述，但是针对的是数据而不是物理结构。与物理模型一样，统计模型通常比所描述的数据简单得多；它的目的是尽可能简单地捕捉数据的结构。在这两种情况下，我们意识到模型是一个方便的虚构，必然忽略了被建模的实际细节。正如统计学家George
    Box所说：“所有模型都是错误的，但有些是有用的。”将统计模型视为观察数据生成方式的理论也是有用的；我们的目标是找到最有效和准确地总结数据生成方式的模型。但正如我们将在下面看到的，效率和准确性的要求通常是截然相反的。
- en: 'The basic structure of a statistical model is:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 统计模型的基本结构是：
- en: \[ data = model + error \]
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 数据 = 模型 + 误差 \]
- en: 'This expresses the idea that the data can be broken into two portions: one
    portion that is described by a statistical model, which expresses the values that
    we expect the data to take given our knowledge, and another portion that we refer
    to as the *error* that reflects the difference between the model’s predictions
    and the observed data.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这表达了这样一个观点：数据可以分为两部分：一部分由统计模型描述，它表达了我们根据我们的知识期望数据采取的值，另一部分我们称之为*误差*，它反映了模型预测和观察数据之间的差异。
- en: 'In essence we would like to use our model to predict the value of the data
    for any given observation. We would write the equation like this:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，我们希望使用我们的模型来预测任何给定观察的数据值。我们会这样写方程：
- en: '\[ \widehat{data_i} = model_i \] The “hat” over the data denotes that it’s
    our prediction rather than the actual value of the data.This means that the predicted
    value of the data for observation \(i\) is equal to the value of the model for
    that observation. Once we have a prediction from the model, we can then compute
    the error:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \widehat{data_i} = model_i \] 数据上的“帽子”表示这是我们的预测，而不是数据的实际值。这意味着观察\(i\)的数据的预测值等于该观察的模型值。一旦我们从模型得到预测，我们就可以计算误差：
- en: \[ error_i = data_i - \widehat{data_i} \] That is, the error for any observation
    is the difference between the observed value of the data and the predicted value
    of the data from the model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \[ error_i = data_i - \widehat{data_i} \] 也就是说，任何观察的误差是数据的观察值与模型预测值之间的差异。
- en: '5.2 Statistical modeling: An example'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 统计建模：一个例子
- en: Let’s look at an example of building a model for data, using the data from NHANES.
    In particular, we will try to build a model of the height of children in the NHANES
    sample. First let’s load the data and plot them (see Figure [5.1](fitting-models.html#fig:childHeight)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个建立数据模型的例子，使用NHANES的数据。特别是，我们将尝试建立NHANES样本中儿童身高的模型。首先让我们加载数据并绘制它们（参见图[5.1](fitting-models.html#fig:childHeight)）。
- en: '![Histogram of height of children in NHANES.](../Images/b8c45b23ebb2b1199411a158f75be244.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![NHANES儿童身高的直方图。](../Images/b8c45b23ebb2b1199411a158f75be244.png)'
- en: 'Figure 5.1: Histogram of height of children in NHANES.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1：NHANES儿童身高的直方图。
- en: Remember that we want to describe the data as simply as possible while still
    capturing their important features. The simplest model that we can imagine would
    involve only a single number; that is, the model would predict the same value
    for each observation, regardless of what else we might know about those observations.
    We generally describe a model in terms of its *parameters*, which are values that
    we can change in order to modify the predictions of the model. Throughout the
    book we will refer to these using the Greek letter beta (\(\beta\)); when the
    model has more than one parameter, we will use subscripted numbers to denote the
    different betas (e.g. \(\beta_1\)). It’s also customary to refer to the values
    of the data using the letter \(y\), and to use a subscripted version \(y_i\) to
    refer to the individual observations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们希望尽可能简单地描述数据，同时仍然捕捉到它们的重要特征。我们可以想象的最简单的模型将只涉及一个单一的数字；也就是说，该模型将预测每个观察值相同的值，而不管我们可能了解这些观察值的其他信息。我们通常用*参数*来描述模型，这些参数是我们可以改变以修改模型预测的值。在整本书中，我们将使用希腊字母beta（\(\beta\)）来指代这些参数；当模型有多个参数时，我们将使用带下标的数字来表示不同的beta（例如\(\beta_1\)）。习惯上，我们用字母\(y\)来表示数据的值，并使用带下标的版本\(y_i\)来表示个别观察值。
- en: 'We generally don’t know the true values of the parameters, so we have to estimate
    them from the data. For this reason, we will generally put a “hat” over the \(\beta\)
    symbol to denote that we are using an estimate of the parameter value rather than
    its true value (which we generally don’t know). Thus, our simple model for height
    using a single parameter would be:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常不知道参数的真实值，因此我们必须从数据中估计它们。因此，我们通常会在\(\beta\)符号上放一个“帽子”，表示我们使用的是参数值的估计值，而不是它的真实值（通常我们不知道）。因此，我们使用单个参数对身高的简单模型将是：
- en: \[ y_i = \beta + \epsilon \]
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y_i = \beta + \epsilon \]
- en: 'The subscript \(i\) doesn’t appear on the right side of the equation, which
    means that the prediction of the model doesn’t depend on which observation we
    are looking at — it’s the same for all of them. The question then becomes: how
    do we estimate the best values of the parameter(s) in the model? In this particular
    case, what single value is the best estimate for \(\beta\)? And, more importantly,
    how do we even define *best*?'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 方程的右侧没有出现下标\(i\)，这意味着模型的预测不取决于我们正在观察的是哪个观察值——对所有观察值都是相同的。那么问题就变成了：我们如何估计模型参数的最佳值？在这种情况下，什么单个值是\(\beta\)的最佳估计？更重要的是，我们如何定义*最佳*？
- en: 'One very simple estimator that we might imagine is the *mode*, which is simply
    the most common value in the dataset. This redescribes the entire set of 1691
    children in terms of a single number. If we wanted to predict the height of any
    new children, then our predicted value would be the same number:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能想象的一个非常简单的估计量是*模式*，它只是数据集中最常见的值。这将整个1691个孩子的数据重新描述为一个单一的数字。如果我们想要预测任何新孩子的身高，那么我们的预测值将是相同的数字：
- en: '\[ \hat{y_i} = 166.5 \] The error for each individual would then be the difference
    between the predicted value (\(\hat{y_i}\)) and their actual height (\(y_i\)):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y_i} = 166.5 \] 然后，每个个体的误差将是预测值（\(\hat{y_i}\)）与他们实际身高（\(y_i\)）之间的差异：
- en: \[ error_i = y_i - \hat{y_i} \]
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: \[ error_i = y_i - \hat{y_i} \]
- en: How good of a model is this? In general we define the goodness of a model in
    terms of the magnitude of the error, which represents the degree to which the
    data diverge from the model’s predictions; all things being equal, the model that
    produces lower error is the better model. (Though as we will see later, all things
    are usually not equal…) What we find in this case is that the average individual
    has a fairly large error of -28.8 centimeters when we use the mode as our estimator
    for \(\beta\), which doesn’t seem very good on its face.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型有多好呢？通常我们根据误差的大小来定义模型的好坏，误差代表数据偏离模型预测的程度；其他条件相同，产生较小误差的模型更好。（尽管后面我们会看到，其他条件通常不相同...）在这种情况下，我们发现当我们使用模式作为\(\beta\)的估计量时，平均个体的误差相当大，为-28.8厘米，这在表面上看起来并不好。
- en: 'How might we find a better estimator for our model parameter? We might start
    by trying to find an estimator that gives us an average error of zero. One good
    candidate is the arithmetic mean (that is, the *average*, often denoted by a bar
    over the variable, such as \(\bar{X}\)), computed as the sum of all of the values
    divided by the number of values. Mathematically, we express this as:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何找到一个更好的模型参数估计量？我们可以尝试找到一个使平均误差为零的估计量。一个很好的选择是算术平均值（即*平均值*，通常用变量上方的横线表示，如\(\bar{X}\)），计算为所有值的总和除以值的数量。在数学上，我们表示为：
- en: \[ \bar{X} = \frac{\sum_{i=1}^{n}x_i}{n} \]
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \bar{X} = \frac{\sum_{i=1}^{n}x_i}{n} \]
- en: It turns out that if we use the arithmetic mean as our estimator then the average
    error will indeed be zero (see the simple proof at the end of the chapter if you
    are interested). Even though the average of errors from the mean is zero, we can
    see from the histogram in Figure [5.2](fitting-models.html#fig:meanError) that
    each individual still has some degree of error; some are positive and some are
    negative, and those cancel each other out to give an average error of zero.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，如果我们使用算术平均值作为我们的估计量，那么平均误差确实将为零（如果您感兴趣，可以在本章末尾看到简单的证明）。尽管从平均值的误差是零，但我们可以从图[5.2](fitting-models.html#fig:meanError)的直方图中看到，每个个体仍然有一定程度的误差；有些是正的，有些是负的，它们相互抵消，使平均误差为零。
- en: '![Distribution of errors from the mean.](../Images/13ebb19c82a8d745a0c0519b3562204a.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![从平均值的误差分布。](../Images/13ebb19c82a8d745a0c0519b3562204a.png)'
- en: 'Figure 5.2: Distribution of errors from the mean.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2：从平均值的误差分布。
- en: The fact that the negative and positive errors cancel each other out means that
    two different models could have errors of very different magnitude in absolute
    terms, but would still have the same average error. This is exactly why the average
    error is not a good criterion for our estimator; we want a criterion that tries
    to minimize the overall error regardless of its direction. For this reason, we
    generally summarize errors in terms of some kind of measure that counts both positive
    and negative errors as bad. We could use the absolute value of each error value,
    but it’s more common to use the squared errors, for reasons that we will see later
    in the book.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 负误差和正误差相互抵消的事实意味着两个不同的模型在绝对值上可能具有非常不同的误差量，但仍然具有相同的平均误差。这正是为什么平均误差不是我们估计器的良好标准的原因；我们希望一个试图最小化总体误差的标准，而不考虑其方向。因此，我们通常根据某种计算正负误差的度量来总结错误。我们可以使用每个误差值的绝对值，但更常见的是使用平方误差，原因我们将在本书的后面看到。
- en: There are several common ways to summarize the squared error that you will encounter
    at various points in this book, so it’s important to understand how they relate
    to one another. First, we could simply add them up; this is referred to as the
    *sum of squared errors*. The reason we don’t usually use this is that its magnitude
    depends on the number of data points, so it can be difficult to interpret unless
    we are looking at the same number of observations. Second, we could take the mean
    of the squared error values, which is referred to as the *mean squared error (MSE)*.
    However, because we squared the values before averaging, they are not on the same
    scale as the original data; they are in \(centimeters^2\). For this reason, it’s
    also common to take the square root of the MSE, which we refer to as the *root
    mean squared error (RMSE)*, so that the error is measured in the same units as
    the original values (in this example, centimeters).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种常见的方法来总结平方误差，您将在本书的各个部分遇到，因此了解它们之间的关系很重要。首先，我们可以简单地将它们相加；这被称为*平方误差的总和*。我们通常不使用它的原因是它的大小取决于数据点的数量，因此除非我们观察相同数量的观察结果，否则很难解释。其次，我们可以取平方误差值的平均值，这被称为*均方误差（MSE）*。然而，由于我们在平均值之前对值进行了平方，它们与原始数据不在同一尺度上；它们是在\(厘米^2\)。因此，通常也会取均方误差的平方根，我们称之为*均方根误差（RMSE）*，以便误差以与原始值相同的单位（在本例中为厘米）来衡量。
- en: The mean has a pretty substantial amount of error – any individual data point
    will be about 27 cm from the mean on average – but it’s still much better than
    the mode, which has a root mean squared error of about 39 cm.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 均值有相当大的误差-任何个体数据点平均将偏离均值约27厘米-但仍然比众数要好得多，众数的均方根误差约为39厘米。
- en: 5.2.1 Improving our model
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 改进我们的模型
- en: Can we imagine a better model? Remember that these data are from all children
    in the NHANES sample, who vary from 2 to 17 years of age. Given this wide age
    range, we might expect that our model of height should also include age. Let’s
    plot the data for height against age, to see if this relationship really exists.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能想象一个更好的模型吗？请记住，这些数据来自NHANES样本中所有2至17岁的儿童，他们的年龄变化很大。鉴于这一广泛的年龄范围，我们可能期望我们的身高模型也应包括年龄。让我们绘制身高与年龄的数据，看看这种关系是否真的存在。
- en: '![Height of children in NHANES, plotted without a model (A), with a linear
    model including only age (B) or age and a constant (C), and with a linear model
    that fits separate effects of age for males and females (D).](../Images/5e6bb65eaa175cd53bbd0c355bd9aef7.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![NHANES中儿童的身高，没有模型绘制（A），只包括年龄的线性模型（B）或年龄和常数的线性模型（C），以及适合男女年龄的线性模型（D）。](../Images/5e6bb65eaa175cd53bbd0c355bd9aef7.png)'
- en: 'Figure 5.3: Height of children in NHANES, plotted without a model (A), with
    a linear model including only age (B) or age and a constant (C), and with a linear
    model that fits separate effects of age for males and females (D).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3：NHANES中儿童的身高，没有模型绘制（A），只包括年龄的线性模型（B）或年龄和常数的线性模型（C），以及适合男女年龄的线性模型（D）。
- en: 'The black points in Panel A of Figure [5.3](fitting-models.html#fig:childHeightLine)
    show individuals in the dataset, and there seems to be a strong relationship between
    height and age, as we would expect. Thus, we might build a model that relates
    height to age:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图[5.3](fitting-models.html#fig:childHeightLine)的面板A中的黑点显示了数据集中的个体，身高和年龄之间似乎存在着很强的关系，这是我们所期望的。因此，我们可能会建立一个将身高与年龄相关联的模型：
- en: \[ \hat{y_i} = \hat{\beta} * age_i \]
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{y_i} = \hat{\beta} * age_i \]
- en: where \(\hat{\beta}\) is our estimate of the parameter that we multiply by age
    to generate the model prediction.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其中\(\hat{\beta}\)是我们估计的参数，我们将其乘以年龄以生成模型预测。
- en: 'You may remember from algebra that a line is defined as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得代数中定义线的方式：
- en: \[ y = slope*x + intercept \]
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: \[ y = 斜率*x + 截距 \]
- en: 'If age is the \(X\) variable, then that means that our prediction of height
    from age will be a line with a slope of \(\beta\) and an intercept of zero - to
    see this, let’s plot the best fitting line in blue on top of the data (Panel B
    in Figure [5.3](fitting-models.html#fig:childHeightLine)). Something is clearly
    wrong with this model, as the line doesn’t seem to follow the data very well.
    In fact, the RMSE for this model (39.16) is actually higher than the model that
    only includes the mean! The problem comes from the fact that our model only includes
    age, which means that the predicted value of height from the model must take on
    a value of zero when age is zero. Even though the data do not include any children
    with an age of zero, the line is mathematically required to have a y-value of
    zero when x is zero, which explains why the line is pulled down below the younger
    datapoints. We can fix this by including an intercept in our model, which basically
    represents the estimated height when age is equal to zero; even though an age
    of zero is not plausible in this dataset, this is a mathematical trick that will
    allow the model to account for the overall magnitude of the data. The model is:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果年龄是 \(X\) 变量，那么这意味着我们从年龄对身高的预测将是一条斜率为 \(\beta\) 截距为零的直线——为了看到这一点，让我们在数据上用蓝色绘制最佳拟合线（图[5.3](fitting-models.html#fig:childHeightLine)的B面板）。显然，这个模型有明显的问题，因为这条线似乎并不很好地跟随数据。事实上，这个模型的均方根误差（39.16）实际上比只包括均值的模型还要高！问题在于我们的模型只包括年龄，这意味着模型对于年龄为零时的身高预测值必须为零。即使数据中没有任何年龄为零的儿童，数学上要求这条线在
    x 为零时有一个 y 值为零，这就解释了为什么这条线被拉到了年轻数据点的下方。我们可以通过在模型中包括一个截距来解决这个问题，这基本上代表了当年龄等于零时的估计身高；即使在这个数据集中年龄为零是不合理的，这是一个数学技巧，可以让模型考虑到数据的整体幅度。模型是：
- en: \[ \widehat{y_i} = \hat{\beta_0} + \hat{\beta_1} * age_i \]
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \widehat{y_i} = \hat{\beta_0} + \hat{\beta_1} * age_i \]
- en: where \(\hat{\beta_0}\) is our estimate for the *intercept*, which is a constant
    value added to the prediction for each individual; we call it the intercept because
    it maps onto the intercept in the equation for a straight line. We will learn
    later how it is that we actually estimate these parameter values for a particular
    dataset; for now, we will use our statistical software to estimate the parameter
    values that give us the smallest error for these particular data. Panel C in Figure
    [5.3](fitting-models.html#fig:childHeightLine) shows this model applied to the
    NHANES data, where we see that the line matches the data much better than the
    one without a constant.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 \(\hat{\beta_0}\) 是我们对 *截距* 的估计，它是添加到每个个体预测值的常数值；我们称之为截距，因为它映射到直线方程中的截距。我们将在后面学习如何为特定数据集估计这些参数值；现在，我们将使用我们的统计软件来估计给出这些特定数据最小误差的参数值。图[5.3](fitting-models.html#fig:childHeightLine)的C面板显示了这个模型应用于NHANES数据，我们可以看到，这条线比没有常数的那条线更好地匹配了数据。
- en: Our error is much smaller using this model – only 8.36 centimeters on average.
    Can you think of other variables that might also be related to height? What about
    gender? In Panel D of Figure [5.3](fitting-models.html#fig:childHeightLine) we
    plot the data with lines fitted separately for males and females. From the plot,
    it seems that there is a difference between males and females, but it is relatively
    small and only emerges after the age of puberty. In Figure [5.4](fitting-models.html#fig:msePlot)
    we plot the root mean squared error values across the different models, including
    one with an additional parameter that models the effect of gender. From this we
    see that the model got a little bit better going from mode to mean, much better
    going from mean to mean + age, and only very slightly better by including gender
    as well.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个模型的误差要小得多——平均只有8.36厘米。你能想到其他可能与身高有关的变量吗？性别呢？在图[5.3](fitting-models.html#fig:childHeightLine)的D面板中，我们分别为男性和女性绘制了拟合线的数据。从图中看，似乎男性和女性之间存在差异，但这种差异相对较小，并且只在青春期后才显现。在图[5.4](fitting-models.html#fig:msePlot)中，我们绘制了不同模型的均方根误差值，包括一个额外参数来模拟性别的影响。从中我们可以看到，模型从模式到均值变得更好了一点，从均值到均值+年龄变得更好了很多，而包括性别后只稍微变得更好了一点。
- en: '![Mean squared error plotted for each of the models tested above.](../Images/e62009a21b859949dc28d1b760439fad.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![对上面测试的每个模型绘制的均方误差。](../Images/e62009a21b859949dc28d1b760439fad.png)'
- en: 'Figure 5.4: Mean squared error plotted for each of the models tested above.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4：对上面测试的每个模型绘制的均方误差。
- en: 5.3 What makes a model “good”?
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 什么使一个模型“好”？
- en: There are generally two different things that we want from our statistical model.
    First, we want it to describe our data well; that is, we want it to have the lowest
    possible error when modeling our data. Second, we want it to generalize well to
    new datasets; that is, we want its error to be as low as possible when we apply
    it to a new dataset in order to make a prediction. It turns out that these two
    features can often be in conflict.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常希望从我们的统计模型中得到两种不同的东西。首先，我们希望它能很好地描述我们的数据；也就是说，我们希望在对数据建模时，它的误差尽可能低。其次，我们希望它能很好地推广到新的数据集；也就是说，当我们将其应用于新的数据集以进行预测时，我们希望它的误差尽可能低。事实证明，这两个特性经常会发生冲突。
- en: To understand this, let’s think about where error comes from. First, it can
    occur if our model is wrong; for example, if we inaccurately said that height
    goes down with age instead of going up, then our error will be higher than it
    would be for the correct model. Similarly, if there is an important factor that
    is missing from our model, that will also increase our error (as it did when we
    left age out of the model for height). However, error can also occur even when
    the model is correct, due to random variation in the data, which we often refer
    to as “measurement error” or “noise”. Sometimes this really is due to error in
    our measurement – for example, when the measurements rely on a human, such as
    using a stopwatch to measure elapsed time in a footrace. In other cases, our measurement
    device is highly accurate (like a digital scale to measure body weight), but the
    thing being measured is affected by many different factors that cause it to be
    variable. If we knew all of these factors then we could build a more accurate
    model, but in reality that’s rarely possible.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一点，让我们思考误差的来源。首先，如果我们的模型是错误的，误差就会产生；例如，如果我们错误地说身高随着年龄下降而不是上升，那么我们的误差将比正确模型的误差更大。同样，如果我们的模型中缺少一个重要因素，那也会增加我们的误差（就像我们在身高模型中没有考虑年龄时那样）。然而，即使模型是正确的，误差也可能发生，这是由于数据的随机变化造成的，我们通常称之为“测量误差”或“噪音”。有时，这确实是由于我们测量的错误
    - 例如，当测量依赖于人类时，比如使用秒表来测量足球比赛中的经过时间。在其他情况下，我们的测量设备非常精确（比如用于测量体重的数字秤），但被测量的物体受到许多不同因素的影响，导致它变化。如果我们知道所有这些因素，那么我们就可以建立一个更准确的模型，但实际上这很少可能。
- en: Let’s use an example to show this. Rather than using real data, we will generate
    some data for the example using a computer simulation (about which we will have
    more to say in a few chapters). Let’s say that we want to understand the relationship
    between a person’s blood alcohol content (BAC) and their reaction time on a simulated
    driving test. We can generate some simulated data and plot the relationship (see
    Panel A of Figure [5.5](fitting-models.html#fig:BACrt)).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来说明这一点。我们将使用计算机模拟生成一些数据来进行示例，而不是使用真实数据（关于这一点我们将在几章后详细讨论）。假设我们想要了解一个人的血液酒精含量（BAC）与他们在模拟驾驶测试中的反应时间之间的关系。我们可以生成一些模拟数据并绘制关系（参见图[5.5](fitting-models.html#fig:BACrt)的A面）。
- en: '![Simulated relationship between blood alcohol content and reaction time on
    a driving test, with best-fitting linear model represented by the line. A: linear
    relationship with low measurement error.  B: linear relationship with higher measurement
    error.  C: Nonlinear relationship with low measurement error and (incorrect) linear
    model](../Images/24e1a034cfa6a9f75886aa6ddb482cfc.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![在驾驶测试中血液酒精含量和反应时间之间的模拟关系，最佳拟合线性模型由线表示。A：与低测量误差的线性关系。B：与较高测量误差的线性关系。C：与低测量误差和（不正确的）线性模型的非线性关系](../Images/24e1a034cfa6a9f75886aa6ddb482cfc.png)'
- en: 'Figure 5.5: Simulated relationship between blood alcohol content and reaction
    time on a driving test, with best-fitting linear model represented by the line.
    A: linear relationship with low measurement error. B: linear relationship with
    higher measurement error. C: Nonlinear relationship with low measurement error
    and (incorrect) linear model'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5：在驾驶测试中血液酒精含量和反应时间之间的模拟关系，最佳拟合线性模型由线表示。A：与低测量误差的线性关系。B：与较高测量误差的线性关系。C：与低测量误差和（不正确的）线性模型的非线性关系
- en: In this example, reaction time goes up systematically with blood alcohol content
    – the line shows the best fitting model, and we can see that there is very little
    error, which is evident in the fact that all of the points are very close to the
    line.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，反应时间随着血液酒精含量的增加而系统性增加 - 线条显示了最佳拟合模型，我们可以看到误差非常小，这在所有点都非常接近线条的事实中是显而易见的。
- en: We could also imagine data that show the same linear relationship, but have
    much more error, as in Panel B of Figure [5.5](fitting-models.html#fig:BACrt).
    Here we see that there is still a systematic increase of reaction time with BAC,
    but it’s much more variable across individuals.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以想象出现相同线性关系的数据，但误差更大，就像图[5.5](fitting-models.html#fig:BACrt)的B面所示。在这里，我们可以看到反应时间随着血液酒精含量的增加仍然存在系统性增加，但在个体之间的变异性更大。
- en: These were both examples where the relationship between the two variables appears
    to be linear, and the error reflects noise in our measurement. On the other hand,
    there are other situations where the relationship between the variables is not
    linear, and error will be increased because the model is not properly specified.
    Let’s say that we are interested in the relationship between caffeine intake and
    performance on a test. The relation between stimulants like caffeine and test
    performance is often *nonlinear* - that is, it doesn’t follow a straight line.
    This is because performance goes up with smaller amounts of caffeine (as the person
    becomes more alert), but then starts to decline with larger amounts (as the person
    becomes nervous and jittery). We can simulate data of this form, and then fit
    a linear model to the data (see Panel C of Figure [5.5](fitting-models.html#fig:BACrt)).
    The blue line shows the straight line that best fits these data; clearly, there
    is a high degree of error. Although there is a very lawful relation between test
    performance and caffeine intake, it follows a curve rather than a straight line.
    The model that assumes a linear relationship has high error because it’s the wrong
    model for these data.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是两个变量之间关系呈现线性的例子，误差反映了我们测量中的噪音。另一方面，还有其他情况下，变量之间的关系不是线性的，误差会增加，因为模型没有正确规定。比如，我们对咖啡因摄入量和测试表现之间的关系感兴趣。咖啡因等兴奋剂与测试表现之间的关系通常是*非线性*的
    - 也就是说，它不是一条直线。这是因为测试表现随着较小剂量的咖啡因而提高（人变得更警觉），但随着较大剂量的咖啡因而开始下降（人变得紧张和焦虑）。我们可以模拟这种形式的数据，然后对数据进行线性模型拟合（参见图[5.5](fitting-models.html#fig:BACrt)的C面板）。蓝线显示了最适合这些数据的直线；显然，误差很大。尽管测试表现和咖啡因摄入之间存在非常合法的关系，但它遵循的是曲线而不是直线。假设线性关系的模型由于这些数据而产生了高误差，因为它对这些数据来说是错误的模型。
- en: 5.4 Can a model be too good?
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 模型是否可能太好？
- en: Error sounds like a bad thing, and usually we will prefer a model that has lower
    error over one that has higher error. However, we mentioned above that there is
    a tension between the ability of a model to accurately fit the current dataset
    and its ability to generalize to new datasets, and it turns out that the model
    with the lowest error often is much worse at generalizing to new datasets!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 误差听起来像是一件坏事，通常我们会更喜欢具有较低误差的模型，而不是具有较高误差的模型。然而，我们上面提到，模型在准确拟合当前数据集和泛化到新数据集之间存在紧张关系，事实证明，具有最低误差的模型通常在泛化到新数据集时要比较差！
- en: To see this, let’s once again generate some data so that we know the true relation
    between the variables. We will create two simulated datasets, which are generated
    in exactly the same way – they just have different random noise added to them.
    That is, the equation for both of them is \(y = \beta * X + \epsilon\); the only
    difference is that different random noise was used for \(\epsilon\) in each case.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到这一点，让我们再次生成一些数据，以便我们知道变量之间的真实关系。我们将创建两个模拟数据集，它们以完全相同的方式生成 - 只是它们分别添加了不同的随机噪声。也就是说，它们的方程式都是\(y
    = \beta * X + \epsilon\)；唯一的区别是在每种情况下，\(\epsilon\)使用了不同的随机噪声。
- en: '![An example of overfitting. Both datasets were generated using the same model,
    with different random noise added to generate each set.  The left panel shows
    the data used to fit the model, with a simple linear fit in blue and a complex
    (8th order polynomial) fit in red.  The root mean square error (RMSE) values for
    each model are shown in the figure; in this case, the complex model has a lower
    RMSE than the simple model.  The right panel shows the second dataset, with the
    same model overlaid on it and the RMSE values computed using the model obtained
    from the first dataset.  Here we see that the simpler model actually fits the
    new dataset better than the more complex model, which was overfitted to the first
    dataset.](../Images/53a556f02db563467be00ae1ff82ea68.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![过度拟合的一个例子。两个数据集都是使用相同的模型生成的，每个集合都添加了不同的随机噪声。左面板显示了用于拟合模型的数据，蓝色表示简单线性拟合，红色表示复杂（8阶多项式）拟合。图中显示了每个模型的均方根误差（RMSE）值；在这种情况下，复杂模型的RMSE低于简单模型。右面板显示了第二个数据集，上面覆盖了相同的模型，并使用从第一个数据集获得的模型计算了RMSE值。在这里，我们看到简单模型实际上比过度拟合到第一个数据集的更复杂模型更好地适应了新数据集。](../Images/53a556f02db563467be00ae1ff82ea68.png)'
- en: 'Figure 5.6: An example of overfitting. Both datasets were generated using the
    same model, with different random noise added to generate each set. The left panel
    shows the data used to fit the model, with a simple linear fit in blue and a complex
    (8th order polynomial) fit in red. The root mean square error (RMSE) values for
    each model are shown in the figure; in this case, the complex model has a lower
    RMSE than the simple model. The right panel shows the second dataset, with the
    same model overlaid on it and the RMSE values computed using the model obtained
    from the first dataset. Here we see that the simpler model actually fits the new
    dataset better than the more complex model, which was overfitted to the first
    dataset.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6：过度拟合的一个例子。两个数据集都是使用相同的模型生成的，每个集合都添加了不同的随机噪声。左面板显示了用于拟合模型的数据，蓝色表示简单线性拟合，红色表示复杂（8阶多项式）拟合。图中显示了每个模型的均方根误差（RMSE）值；在这种情况下，复杂模型的RMSE低于简单模型。右面板显示了第二个数据集，上面覆盖了相同的模型，并使用从第一个数据集获得的模型计算了RMSE值。在这里，我们看到简单模型实际上比过度拟合到第一个数据集的更复杂模型更好地适应了新数据集。
- en: 'The left panel in Figure [5.6](fitting-models.html#fig:Overfitting) shows that
    the more complex model (in red) fits the data better than the simpler model (in
    blue). However, we see the opposite when the same model is applied to a new dataset
    generated in the same way – here we see that the simpler model fits the new data
    better than the more complex model. Intuitively, we can see that the more complex
    model is influenced heavily by the specific data points in the first dataset;
    since the exact position of these data points was driven by random noise, this
    leads the more complex model to fit badly on the new dataset. This is a phenomenon
    that we call *overfitting*. For now it’s simply important to keep in mind that
    our model fit needs to be good, but not too good. As Albert Einstein (1933) said:
    “It can scarcely be denied that the supreme goal of all theory is to make the
    irreducible basic elements as simple and as few as possible without having to
    surrender the adequate representation of a single datum of experience.” Which
    is often paraphrased as: “Everything should be as simple as it can be, but not
    simpler.”'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图[5.6](fitting-models.html#fig:Overfitting)的左面板显示，更复杂的模型（红色）比更简单的模型（蓝色）更好地拟合了数据。然而，当相同的模型应用于以相同方式生成的新数据集时，我们看到相反的情况-在这里，我们看到更简单的模型比更复杂的模型更好地拟合了新数据。直观地，我们可以看到更复杂的模型受到第一个数据集中特定数据点的影响很大;由于这些数据点的确切位置是由随机噪声驱动的，这导致更复杂的模型在新数据集上拟合不佳。这是我们所说的*过度拟合*现象。现在重要的是要记住，我们的模型拟合需要很好，但不要太好。正如阿尔伯特·爱因斯坦（1933年）所说：“可以毫不夸张地说，所有理论的最高目标是使不可简化的基本元素尽可能简单，尽可能少，而不必放弃对单个经验数据的充分表征。”这经常被改编为：“一切都应该尽可能简单，但不要太简单。”
- en: 5.5 Summarizing data using the mean
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 使用均值总结数据
- en: We have already encountered the mean (or average) above, and in fact most people
    know about the average even if they have never taken a statistics class. It is
    commonly used to describe what we call the “central tendency” of a dataset – that
    is, what value are the data centered around? Most people don’t think of computing
    a mean as fitting a model to data. However, that’s exactly what we are doing when
    we compute the mean.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经遇到了均值（或平均值），实际上大多数人都知道平均值，即使他们从未上过统计课。它通常用来描述我们所说的数据集的“中心趋势”-也就是说，数据以什么值为中心？大多数人并不认为计算均值是将模型拟合到数据。然而，当我们计算均值时，这正是我们正在做的。
- en: 'We have already seen the formula for computing the mean of a sample of data:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了计算样本数据均值的公式：
- en: \[ \bar{X} = \frac{\sum_{i=1}^{n}x_i}{n} \]
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \bar{X} = \frac{\sum_{i=1}^{n}x_i}{n} \]
- en: 'Note that I said that this formula was specifically for a *sample* of data,
    which is a set of data points selected from a larger population. Using a sample,
    we wish to characterize a larger population – the full set of individuals that
    we are interested in. For example, if we are a political pollster our population
    of interest might be all registered voters, whereas our sample might just include
    a few thousand people sampled from this population. In Chapter 7 we will talk
    in more detail about sampling, but for now the important point is that statisticians
    generally like to use different symbols to differentiate *statistics* that describe
    values for a sample from *parameters* that describe the true values for a population;
    in this case, the formula for the population mean (denoted as \(\mu\)) is:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我说过这个公式是特别针对*样本*数据的，这是从更大的人口中选择的一组数据点。使用样本，我们希望描述更大的人口-我们感兴趣的所有个体的完整集合。例如，如果我们是政治民意调查员，我们感兴趣的人口可能是所有注册选民，而我们的样本可能只包括从该人口中抽样的几千人。在第7章中，我们将更详细地讨论抽样，但现在重要的是统计学家通常喜欢使用不同的符号来区分描述样本值的*统计量*和描述人口真实值的*参数*;在这种情况下，人口均值的公式（表示为\(\mu\)）是：
- en: \[ \mu = \frac{\sum_{i=1}^{N}x_i}{N} \] where N is the size of the entire population.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \mu = \frac{\sum_{i=1}^{N}x_i}{N} \] 其中N是整个人口的大小。
- en: We have already seen that the mean is the estimator that is guaranteed to give
    us an average error of zero, but we also learned that the average error is not
    the best criterion; instead, we want an estimator that gives us the lowest sum
    of squared errors (SSE), which the mean also does. We could prove this using calculus,
    but instead we will demonstrate it graphically in Figure [5.7](fitting-models.html#fig:MinSSE).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到均值是一个保证给我们平均误差为零的估计量，但我们也学到了平均误差不是最好的标准；相反，我们希望一个给出最低平方误差和（SSE）的估计量，而均值也能做到。我们可以用微积分来证明这一点，但我们将在图[5.7](fitting-models.html#fig:MinSSE)中用图形来演示它。
- en: '![A demonstration of the mean as the statistic that minimizes the sum of squared
    errors.  Using the NHANES child height data, we compute the mean (denoted by the
    blue bar). Then, we test a range of possible parameter estimates, and for each
    one we compute the sum of squared errors for each data point from that value,
    which are denoted by the black curve.  We see that the mean falls at the minimum
    of the squared error plot.](../Images/09d39ec656848584c95ca9479dcf44ad.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![演示均值作为最小化平方误差和的统计量。使用NHANES儿童身高数据，我们计算均值（用蓝色条表示）。然后，我们测试一系列可能的参数估计值，对于每个值，我们计算每个数据点与该值之间的平方误差和，用黑色曲线表示。我们看到均值落在平方误差图的最小值处。](../Images/09d39ec656848584c95ca9479dcf44ad.png)'
- en: 'Figure 5.7: A demonstration of the mean as the statistic that minimizes the
    sum of squared errors. Using the NHANES child height data, we compute the mean
    (denoted by the blue bar). Then, we test a range of possible parameter estimates,
    and for each one we compute the sum of squared errors for each data point from
    that value, which are denoted by the black curve. We see that the mean falls at
    the minimum of the squared error plot.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7：演示均值作为最小化平方误差和的统计量。使用NHANES儿童身高数据，我们计算均值（用蓝色条表示）。然后，我们测试一系列可能的参数估计值，对于每个值，我们计算每个数据点与该值之间的平方误差和，用黑色曲线表示。我们看到均值落在平方误差图的最小值处。
- en: 'This minimization of SSE is a good feature, and it’s why the mean is the most
    commonly used statistic to summarize data. However, the mean also has a dark side.
    Let’s say that five people are in a bar, and we examine each person’s income (Table
    [5.1](fitting-models.html#tab:income1)):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化SSE是一个很好的特性，这就是为什么平均值是最常用的总结数据的统计量。然而，平均值也有一个不好的一面。比如说有五个人在酒吧，我们检查每个人的收入（表[5.1](fitting-models.html#tab:income1)）：
- en: 'Table 5.1: Income for our five bar patrons'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1：我们五个酒吧顾客的收入
- en: '| income | person |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 收入 | 人 |'
- en: '| --: | :-- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --: | :-- |'
- en: '| 48000 | Joe |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: 48000 | 乔 |
- en: '| 64000 | Karen |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 64000 | 卡伦 |'
- en: '| 58000 | Mark |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 58000 | 马克 |'
- en: '| 72000 | Andrea |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 72000 | 安德烈 |'
- en: '| 66000 | Pat |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 66000 | 帕特 |'
- en: The mean (61600.00) seems to be a pretty good summary of the income of those
    five people. Now let’s look at what happens if Beyoncé Knowles walks into the
    bar (Table [5.2](fitting-models.html#tab:income2)).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值（61600.00）似乎是对这五个人的收入的一个很好的总结。现在让我们看看如果碧昂丝·诺尔斯走进酒吧会发生什么（表[5.2](fitting-models.html#tab:income2)）。
- en: 'Table 5.2: Income for our five bar patrons plus Beyoncé Knowles.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.2：我们五个酒吧顾客加上碧昂丝·诺尔斯的收入。
- en: '| income | person |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 收入 | 人 |'
- en: '| :-- | :-- |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| :-- | :-- |'
- en: '| 48000 | Joe |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 48000 | 乔 |'
- en: '| 64000 | Karen |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 64000 | 卡伦 |'
- en: '| 58000 | Mark |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 58000 | 马克 |'
- en: '| 72000 | Andrea |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 72000 | 安德烈 |'
- en: '| 66000 | Pat |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 66000 | 帕特 |'
- en: '| 54000000 | Beyonce |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 54000000 | 碧昂丝 |'
- en: The mean is now almost 10 million dollars, which is not really representative
    of any of the people in the bar – in particular, it is heavily driven by the outlying
    value of Beyoncé. In general, the mean is highly sensitive to extreme values,
    which is why it’s always important to ensure that there are no extreme values
    when using the mean to summarize data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在平均值接近1000万美元，这实际上并不代表酒吧里的任何人 - 特别是，它受到碧昂丝这个异常值的极大影响。一般来说，平均值对极端值非常敏感，这就是为什么在使用平均值总结数据时，确保没有极端值总是很重要的原因。
- en: 5.5.1 Summarizing data robustly using the median
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5.1 使用中位数稳健地总结数据
- en: If we want to summarize the data in a way that is less sensitive to outliers,
    we can use another statistic called the *median*. If we were to sort all of the
    values in order of their magnitude, then the median is the value in the middle.
    If there is an even number of values then there will be two values tied for the
    middle place, in which case we take the mean (i.e. the halfway point) of those
    two numbers.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想以一种对异常值不太敏感的方式总结数据，我们可以使用另一个叫做*中位数*的统计量。如果我们按照大小顺序对所有值进行排序，那么中位数就是中间的值。如果值的数量是偶数，那么会有两个值并列在中间位置，这种情况下我们取这两个数的平均值（即两个数的中间点）。
- en: 'Let’s look at an example. Say we want to summarize the following values:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们看一个例子。假设我们想总结以下值： '
- en: '[PRE0]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If we sort those values:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对这些值进行排序：
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then the median is the middle value – in this case, the 5th of the 9 values.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后中位数是中间值 - 在这种情况下，是9个值中的第5个。
- en: 'Whereas the mean minimizes the sum of squared errors, the median minimizes
    a slighty different quantity: The sum of the *absolute value* of errors. This
    explains why it is less sensitive to outliers – squaring is going to exacerbate
    the effect of large errors compared to taking the absolute value. We can see this
    in the case of the income example: The median income ($65,000) is much more representative
    of the group as a whole than the mean ($9,051,333), and less sensitive to the
    one large outlier.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 而平均值最小化了平方误差的和，中位数最小化了一个略有不同的数量：误差的绝对值的和。这解释了为什么中位数对异常值不太敏感 - 平方会加剧大误差的影响，而绝对值不会。我们可以从收入的例子中看到这一点：中位收入（$65,000）更能代表整个群体，而不太敏感于一个大的异常值，而平均值（$9,051,333）。
- en: Given this, why would we ever use the mean? As we will see in a later chapter,
    the mean is the “best” estimator in the sense that it will vary less from sample
    to sample compared to other estimators. It’s up to us to decide whether that is
    worth the sensitivity to potential outliers – statistics is all about tradeoffs.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于此，我们为什么还要使用平均值呢？正如我们将在后面的章节中看到的，平均值是“最好的”估计量，因为它在样本之间的变化要比其他估计量小。这取决于我们是否认为这值得对潜在异常值的敏感性
    - 统计学就是关于权衡的。
- en: 5.6 The mode
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.6 众数
- en: Sometimes we wish to describe the central tendency of a dataset that is not
    numeric. For example, let’s say that we want to know which models of iPhone are
    most commonly used. To test this, we could ask a large group of iPhone users which
    model each person owns. If we were to take the average of these values, we might
    see that the mean iPhone model is 9.51, which is clearly nonsensical, since the
    iPhone model numbers are not meant to be quantitative measurements. In this case,
    a more appropriate measure of central tendency is the mode, which is the most
    common value in the dataset, as we discussed above.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们希望描述一个非数值数据集的中心趋势。例如，假设我们想知道哪种型号的iPhone最常用。为了测试这一点，我们可以问一大群iPhone用户每个人拥有哪种型号。如果我们对这些值取平均值，我们可能会发现平均iPhone型号是9.51，这显然是荒谬的，因为iPhone型号并不是量化的测量。在这种情况下，中心趋势的更合适的度量是众数，即数据集中最常见的值，正如我们上面讨论的那样。
- en: '5.7 Variability: How well does the mean fit the data?'
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.7 变异性：平均值对数据拟合得有多好？
- en: Once we have described the central tendency of the data, we often also want
    to describe how variable the data are – this is sometimes also referred to as
    “dispersion”, reflecting the fact that it describes how widely dispersed the data
    are.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们描述了数据的中心趋势，我们通常也想描述数据的变异程度 - 这有时也被称为“离散度”，反映了它描述数据有多广泛分布的事实。
- en: 'We have already encountered the sum of squared errors above, which is the basis
    for the most commonly used measures of variability: the *variance* and the *standard
    deviation*. The variance for a population (referred to as \(\sigma^2\)) is simply
    the sum of squared errors divided by the number of observations - that is, it
    is exactly the same as the *mean squared error* that you encountered earlier:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在上面遇到了平方误差的总和，这是最常用的变异性度量的基础：*方差*和*标准差*。人口的方差（表示为\(\sigma^2\)）简单地是平方误差的总和除以观察次数
    - 也就是说，它与之前遇到的*均方误差*完全相同：
- en: \[ \sigma^2 = \frac{SSE}{N} = \frac{\sum_{i=1}^n (x_i - \mu)^2}{N} \]
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sigma^2 = \frac{SSE}{N} = \frac{\sum_{i=1}^n (x_i - \mu)^2}{N} \]
- en: where \(\mu\) is the population mean. The population standard deviation is simply
    the square root of this – that is, the *root mean squared error* that we saw before.
    The standard deviation is useful because the errors are in the same units as the
    original data (undoing the squaring that we applied to the errors).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '其中\(\mu\)是总体均值。总体标准差简单地是这个的平方根 - 也就是我们之前看到的*均方根误差*。标准差很有用，因为误差与原始数据的单位相同（撤销了我们对误差的平方）。 '
- en: 'We usually don’t have access to the entire population, so we have to compute
    the variance using a sample, which we refer to as \(\hat{\sigma}^2\), with the
    “hat” representing the fact that this is an estimate based on a sample. The equation
    for \(\hat{\sigma}^2\) is similar to the one for \(\sigma^2\):'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 通常我们无法访问整个总体，所以我们必须使用样本来计算方差，我们称之为\(\hat{\sigma}^2\)，其中“帽子”表示这是基于样本的估计。\(\hat{\sigma}^2\)的方程与\(\sigma^2\)的方程类似：
- en: \[ \hat{\sigma}^2 = \frac{\sum_{i=1}^n (x_i - \bar{X})^2}{n-1} \]
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \hat{\sigma}^2 = \frac{\sum_{i=1}^n (x_i - \bar{X})^2}{n-1} \]
- en: 'The only difference between the two equations is that we divide by n - 1 instead
    of N. This relates to a fundamental statistical concept: *degrees of freedom*.
    Remember that in order to compute the sample variance, we first had to estimate
    the sample mean \(\bar{X}\). Having estimated this, one value in the data is no
    longer free to vary. For example, let’s say we have the following data points
    for a variable \(x\): [3, 5, 7, 9, 11], the mean of which is 7\. Because we know
    that the mean of this dataset is 7, we can compute what any specific value would
    be if it were missing. For example, let’s say we were to obscure the first value
    (3). Having done this, we still know that its value must be 3, because the mean
    of 7 implies that the sum of all of the values is \(7 * n = 35\) and \(35 - (5
    + 7 + 9 + 11) = 3\).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 两个方程之间唯一的区别是我们除以n-1而不是N。这涉及到一个基本的统计概念：*自由度*。记住，为了计算样本方差，我们首先必须估计样本均值\(\bar{X}\)。在估计了这个值之后，数据中的一个值就不再自由变化。例如，假设我们有一个变量\(x\)的以下数据点：[3,
    5, 7, 9, 11]，其均值为7。因为我们知道这个数据集的均值是7，我们可以计算如果缺少任何特定值的值。例如，假设我们要隐藏第一个值（3）。这样做之后，我们仍然知道它的值必须是3，因为7的均值意味着所有值的总和是\(7
    * n = 35\)，\(35 - (5 + 7 + 9 + 11) = 3\)。
- en: So when we say that we have “lost” a degree of freedom, it means that there
    is a value that is not free to vary after fitting the model. In the context of
    the sample variance, if we don’t account for the lost degree of freedom, then
    our estimate of the sample variance will be *biased*, causing us to underestimate
    the uncertainty of our estimate of the mean.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 所以当我们说我们“失去”了一个自由度时，这意味着在拟合模型后有一个值不再自由变化。在样本方差的背景下，如果我们不考虑失去的自由度，那么我们对样本方差的估计将是*有偏的*，导致我们低估了对均值估计的不确定性。
- en: 5.8 Using simulations to understand statistics
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.8 使用模拟来理解统计学
- en: I am a strong believer in the use of computer simulations to understand statistical
    concepts, and in later chapters we will dig more deeply into their use. Here we
    will introduce the idea by asking whether we can confirm the need to subtract
    1 from the sample size in computing the sample variance.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我坚信使用计算机模拟来理解统计概念，在后面的章节中我们将更深入地探讨它们的使用。在这里，我们将通过询问是否可以确认在计算样本方差时需要从样本大小中减去1来介绍这个想法。
- en: Let’s treat the entire sample of children from the NHANES data as our “population”,
    and see how well the calculations of sample variance using either \(n\) or \(n-1\)
    in the denominator will estimate variance of this population, across a large number
    of simulated random samples from the data. We will return to the details of how
    to do this in a later chapter.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把NHANES数据中的所有儿童样本作为我们的“总体”，并看看使用分母中的\(n\)或\(n-1\)来计算样本方差会如何估计这个总体的方差，在从数据中模拟的大量随机样本中。我们将在后面的章节中详细介绍如何做到这一点。
- en: 'Table 5.3: Variance estimates using n versus n-1; the estimate using n-1 is
    closer to the population value'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.3：使用n与n-1的方差估计；使用n-1的估计更接近于总体值
- en: '| Estimate | Value |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 估计 | 值 |'
- en: '| :-- | --: |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| :-- | --: |'
- en: '| Population variance | 725 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 总体方差 | 725 |'
- en: '| Variance estimate using n | 710 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 使用n的方差估计 | 710 |'
- en: '| Variance estimate using n-1 | 725 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 使用n-1的方差估计 | 725 |'
- en: 'The results in [5.3](fitting-models.html#tab:varsim) show us that the theory
    outlined above was correct: The variance estimate using \(n - 1\) as the denominator
    is very close to the variance computed on the full data (i.e, the population),
    whereas the variance computed using \(n\) as the denominator is biased (smaller)
    compared to the true value.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[5.3](fitting-models.html#tab:varsim)中的结果告诉我们，上面概述的理论是正确的：使用\(n-1\)作为分母的方差估计非常接近于在完整数据（即总体）上计算的方差，而使用\(n\)作为分母的方差估计是有偏的（较小），与真实值相比。'
- en: 5.9 Z-scores
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.9 Z分数
- en: Having characterized a distribution in terms of its central tendency and variability,
    it is often useful to express the individual scores in terms of where they sit
    with respect to the overall distribution. Let’s say that we are interested in
    characterizing the relative level of crimes across different states, in order
    to determine whether California is a particularly dangerous place. We can ask
    this question using data for 2014 from the [FBI’s Uniform Crime Reporting site](https://www.ucrdatatool.gov/Search/Crime/State/RunCrimeOneYearofData.cfm).
    The left panel of Figure [5.8](fitting-models.html#fig:crimeHist) shows a histogram
    of the number of violent crimes per state, highlighting the value for California.
    Looking at these data, it seems like California is terribly dangerous, with 153709
    crimes in that year. We can visualize these data by generating a map showing the
    distribution of a variable across states, which is presented in the right panel
    of Figure [5.8](fitting-models.html#fig:crimeHist).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在以中心趋势和变异性来表征分布之后，通常有必要以个体得分在整体分布中的位置来表达。假设我们有兴趣描述不同州之间犯罪的相对水平，以确定加利福尼亚是否是一个特别危险的地方。我们可以使用来自[FBI统一犯罪报告网站](https://www.ucrdatatool.gov/Search/Crime/State/RunCrimeOneYearofData.cfm)的2014年数据来提出这个问题。图[5.8](fitting-models.html#fig:crimeHist)的左侧面板显示了每个州暴力犯罪数量的直方图，突出显示了加利福尼亚的值。从这些数据来看，加利福尼亚似乎非常危险，当年有153709起犯罪。我们可以通过生成一张地图来可视化这些数据，显示一个变量在各州之间的分布，这在图[5.8](fitting-models.html#fig:crimeHist)的右侧面板中呈现。
- en: '![Left: Histogram of the number of violent crimes.  The value for CA is plotted
    in blue. Right: A map of the same data, with number of crimes (in thousands) plotted
    for each state in color.](../Images/7d398243bb12c547a236e481fef266df.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![左侧：暴力犯罪数量的直方图。 CA的值以蓝色绘制。右侧：相同数据的地图，以各州的犯罪数量（以千为单位）用颜色表示。](../Images/7d398243bb12c547a236e481fef266df.png)'
- en: 'Figure 5.8: Left: Histogram of the number of violent crimes. The value for
    CA is plotted in blue. Right: A map of the same data, with number of crimes (in
    thousands) plotted for each state in color.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8：左侧：暴力犯罪数量的直方图。 CA的值以蓝色绘制。右侧：相同数据的地图，以各州的犯罪数量（以千为单位）用颜色表示。
- en: It may have occurred to you, however, that CA also has the largest population
    of any state in the US, so it’s reasonable that it will also have a larger number
    of crimes. If we plot the number of crimes against one the population of each
    state (see left panel of Figure [5.9](fitting-models.html#fig:popVsCrime)), we
    see that there is a direct relationship between two variables.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您可能已经意识到，加利福尼亚也是美国人口最多的州，因此它拥有更多的犯罪是合理的。如果我们将每个州的犯罪数量与人口之一绘制成图（参见图[5.9](fitting-models.html#fig:popVsCrime)的左侧面板），我们会发现两个变量之间存在直接关系。
- en: '![Left: A plot of number of violent crimes versus population by state. Right:
    A histogram of per capita violent crime rates, expressed as crimes per 100,000
    people.](../Images/a41be20b87765b3494db4cb154b9d882.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![左侧：按州划分的暴力犯罪数量与人口的图。右侧：以每10万人口的犯罪率表示的暴力犯罪率的直方图。](../Images/a41be20b87765b3494db4cb154b9d882.png)'
- en: 'Figure 5.9: Left: A plot of number of violent crimes versus population by state.
    Right: A histogram of per capita violent crime rates, expressed as crimes per
    100,000 people.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9：左侧：按州划分的暴力犯罪数量与人口的图。右侧：以每10万人口的犯罪率表示的暴力犯罪率的直方图。
- en: Instead of using the raw numbers of crimes, we should instead use the violent
    crime *rate* per capita, which we obtain by dividing the number of crimes per
    state by the population of each state. The dataset from the FBI already includes
    this value (expressed as rate per 100,000 people). Looking at the right panel
    of Figure [5.9](fitting-models.html#fig:popVsCrime), we see that California is
    not so dangerous after all – its crime rate of 396.10 per 100,000 people is a
    bit above the mean across states of 346.81, but well within the range of many
    other states. But what if we want to get a clearer view of how far it is from
    the rest of the distribution?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该使用每人口的暴力犯罪*率*，而不是使用原始犯罪数字，这可以通过将每个州的犯罪数量除以每个州的人口来获得。FBI的数据集已经包括了这个值（以每10万人口的比率表示）。从图[5.9](fitting-models.html#fig:popVsCrime)的右侧面板可以看出，加利福尼亚并不那么危险
    - 其每10万人口的犯罪率为396.10，略高于各州的平均值346.81，但远低于许多其他州。但是，如果我们想更清楚地了解它与其他分布的距离有多远呢？
- en: 'The *Z-score* allows us to express data in a way that provides more insight
    into each data point’s relationship to the overall distribution. The formula to
    compute a Z-score for an individual data point given that we know the value of
    the population mean \(\mu\) and standard deviation \(\sigma\) is:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*Z得分*允许我们以一种更能洞察每个数据点与整体分布关系的方式来表达数据。计算给定个体数据点的Z得分的公式，假设我们知道总体均值\(\mu\)和标准偏差\(\sigma\)的值为：'
- en: \[ Z(x) = \frac{x - \mu}{\sigma} \]
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: \[ Z(x) = \frac{x - \mu}{\sigma} \]
- en: Intuitively, you can think of a Z-score as telling you how far away any data
    point is from the mean, in units of standard deviation. We can compute this for
    the crime rate data, as shown in Figure [5.10](fitting-models.html#fig:crimeZplot),
    which plots the Z-scores against the original scores.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地，您可以将Z得分视为告诉您任何数据点距离平均值有多远，以标准偏差为单位。我们可以计算犯罪率数据的Z得分，如图[5.10](fitting-models.html#fig:crimeZplot)所示，该图将Z得分绘制为原始得分。
- en: '![Scatterplot of original crime rate data against Z-scored data.](../Images/6b59478b56fa5d9d546261b427009c3e.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![原始犯罪率数据与Z得分数据的散点图。](../Images/6b59478b56fa5d9d546261b427009c3e.png)'
- en: 'Figure 5.10: Scatterplot of original crime rate data against Z-scored data.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.10：原始犯罪率数据与Z得分数据的散点图。
- en: The scatterplot shows us that the process of Z-scoring doesn’t change the relative
    distribution of the data points (visible in the fact that the orginal data and
    Z-scored data fall on a straight line when plotted against each other) – it just
    shifts them to have a mean of zero and a standard deviation of one. Figure [5.11](fitting-models.html#fig:crimeZmap)
    shows the Z-scored crime data using the geographical view.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图告诉我们，Z分数的过程并不改变数据点的相对分布（在原始数据和Z分数数据相互绘制时，它们落在一条直线上），它只是将它们移动到具有零均值和标准偏差为一的位置。图[5.11](fitting-models.html#fig:crimeZmap)显示了使用地理视图的Z分数犯罪数据。
- en: '![Crime data rendered onto a US map, presented as Z-scores.](../Images/2ab455a2bdcda4bf306445d78c9d1507.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![犯罪数据呈现为Z分数的美国地图。](../Images/2ab455a2bdcda4bf306445d78c9d1507.png)'
- en: 'Figure 5.11: Crime data rendered onto a US map, presented as Z-scores.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11：犯罪数据呈现为Z分数的美国地图。
- en: This provides us with a slightly more interpretable view of the data. For example,
    we can see that Nevada, Tennessee, and New Mexico all have crime rates that are
    roughly two standard deviations above the mean.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了对数据稍微更易解释的视角。例如，我们可以看到内华达州、田纳西州和新墨西哥州的犯罪率大约是平均值的两个标准偏差。
- en: 5.9.1 Interpreting Z-scores
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.9.1 解释Z分数
- en: The “Z” in “Z-score” comes from the fact that the standard normal distribution
    (that is, a normal distribution with a mean of zero and a standard deviation of
    1) is often referred to as the “Z” distribution. We can use the standard normal
    distribution to help us understand what specific Z scores tell us about where
    a data point sits with respect to the rest of the distribution.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: “Z分数”中的“Z”来自于标准正态分布（即均值为零，标准偏差为1的正态分布）通常被称为“Z”分布。我们可以使用标准正态分布来帮助我们理解特定Z分数告诉我们关于数据点在分布的其余部分中所处位置的信息。
- en: '![Density (top) and cumulative distribution (bottom) of a standard normal distribution,
    with cutoffs at one standard deviation above/below the mean.](../Images/5fa247eeb337b58c7420bbaaa8312a07.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![标准正态分布的密度（上）和累积分布（下），在一个标准偏差以上/以下的均值处有截断。](../Images/5fa247eeb337b58c7420bbaaa8312a07.png)'
- en: 'Figure 5.12: Density (top) and cumulative distribution (bottom) of a standard
    normal distribution, with cutoffs at one standard deviation above/below the mean.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.12：标准正态分布的密度（上）和累积分布（下），在一个标准偏差以上/以下的均值处有截断。
- en: The upper panel in Figure [5.12](fitting-models.html#fig:zDensityCDF) shows
    that we expect about 16% of values to fall in \(Z\ge 1\), and the same proportion
    to fall in \(Z\le -1\).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图[5.12](fitting-models.html#fig:zDensityCDF)的上部显示我们预计大约16%的值落在\(Z\ge 1\)，同样的比例落在\(Z\le
    -1\)。
- en: '![Density (top) and cumulative distribution (bottom) of a standard normal distribution,
    with cutoffs at two standard deviations above/below the mean](../Images/88f891a70eaf71a450cbc9c36a5b6bc0.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![标准正态分布的密度（上）和累积分布（下），在两个标准偏差以上/以下的均值处有截断](../Images/88f891a70eaf71a450cbc9c36a5b6bc0.png)'
- en: 'Figure 5.13: Density (top) and cumulative distribution (bottom) of a standard
    normal distribution, with cutoffs at two standard deviations above/below the mean'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13：标准正态分布的密度（上）和累积分布（下），在两个标准偏差以上/以下的均值处有截断。
- en: Figure [5.13](fitting-models.html#fig:zDensity2SD) shows the same plot for two
    standard deviations. Here we see that only about 2.3% of values fall in \(Z \le
    -2\) and the same in \(Z \ge 2\). Thus, if we know the Z-score for a particular
    data point, we can estimate how likely or unlikely we would be to find a value
    at least as extreme as that value, which lets us put values into better context.
    In the case of crime rates, we see that California has a Z-score of 0.38 for its
    violent crime rate per capita, showing that it is quite near the mean of other
    states, with about 35% of states having higher rates and 65% of states having
    lower rates.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图[5.13](fitting-models.html#fig:zDensity2SD)显示了两个标准偏差的相同图。在这里，我们看到只有大约2.3%的值落在\(Z
    \le -2\)，同样的在\(Z \ge 2\)。因此，如果我们知道特定数据点的Z分数，我们可以估计找到至少与该值一样极端的值的可能性或不可能性，这让我们更好地将值放入上下文中。在犯罪率的情况下，我们看到加利福尼亚的暴力犯罪率人均Z分数为0.38，显示它与其他州的平均值相当接近，大约有35%的州有更高的犯罪率，65%的州有更低的犯罪率。
- en: 5.9.2 Standardized scores
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.9.2 标准化分数
- en: Let’s say that instead of Z-scores, we wanted to generate standardized crime
    scores with a mean of 100 and standard deviation of 10\. This is similar to the
    standardization that is done with scores from intelligence tests to generate the
    intelligence quotient (IQ). We can do this by simply multiplying the Z-scores
    by 10 and then adding 100.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们不是用Z分数，而是想生成平均值为100，标准偏差为10的标准化犯罪分数。这类似于对智力测试分数进行标准化以生成智商指数（IQ）。我们可以通过简单地将Z分数乘以10然后加上100来实现这一点。
- en: '![Crime data presented as standardized scores with mean of  100 and standard
    deviation of 10.](../Images/2d4c9df6c5f740819c3f0dbab177cc50.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![犯罪数据以平均值为100，标准偏差为10呈现为标准化分数。](../Images/2d4c9df6c5f740819c3f0dbab177cc50.png)'
- en: 'Figure 5.14: Crime data presented as standardized scores with mean of 100 and
    standard deviation of 10.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14：犯罪数据以平均值为100，标准偏差为10呈现为标准化分数。
- en: 5.9.2.1 Using Z-scores to compare distributions
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.9.2.1 使用Z分数比较分布
- en: One useful application of Z-scores is to compare distributions of different
    variables. Let’s say that we want to compare the distributions of violent crimes
    and property crimes across states. In the left panel of Figure [5.15](fitting-models.html#fig:crimeTypePlot)
    we plot those against one another, with CA plotted in blue. As you can see, the
    raw rates of property crimes are far higher than the raw rates of violent crimes,
    so we can’t just compare the numbers directly. However, we can plot the Z-scores
    for these data against one another (right panel of Figure [5.15](fitting-models.html#fig:crimeTypePlot))–
    here again we see that the distribution of the data does not change. Having put
    the data into Z-scores for each variable makes them comparable, and lets us see
    that California is actually right in the middle of the distribution in terms of
    both violent crime and property crime.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Z得分的一个有用应用是比较不同变量的分布。假设我们想要比较各州的暴力犯罪和财产犯罪的分布。在图5.15的左面板中，我们将它们相互绘制，CA用蓝色绘制。正如你所看到的，财产犯罪的原始率远高于暴力犯罪的原始率，所以我们不能直接比较这些数字。然而，我们可以将这些数据的Z得分相互绘制（图5.15的右面板）-
    在这里我们再次看到数据的分布没有改变。将每个变量的数据转换为Z得分使它们可以相互比较，并让我们看到加利福尼亚实际上在暴力犯罪和财产犯罪方面都处于分布的中间位置。
- en: '![Plot of violent vs. property crime rates (left) and Z-scored rates (right).](../Images/47ad5ab000fc3989a9657dc1981f14be.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![暴力犯罪率与财产犯罪率的图表（左）和Z得分率（右）。](../Images/47ad5ab000fc3989a9657dc1981f14be.png)'
- en: 'Figure 5.15: Plot of violent vs. property crime rates (left) and Z-scored rates
    (right).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15：暴力犯罪率与财产犯罪率的图表（左）和Z得分率（右）。
- en: 'Let’s add one more factor to the plot: Population. In the left panel of Figure
    [5.16](fitting-models.html#fig:crimeTypePopPlot) we show this using the size of
    the plotting symbol, which is often a useful way to add information to a plot.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在图中再添加一个因素：人口。在图5.16的左面板中，我们使用绘图符号的大小来显示这一点，这通常是向图中添加信息的有用方式。
- en: '![Left: Plot of violent vs. property crime rates, with population size presented
    through the size of the plotting symbol; California is presented in blue. Right:
    Difference scores for violent vs. property crime, plotted against population.
    ](../Images/4d78e5b3a42fbcdc13feec80af5617ef.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![左：暴力犯罪率与财产犯罪率的图表，通过绘图符号的大小呈现人口规模；加利福尼亚以蓝色呈现。右：暴力犯罪与财产犯罪的差异分数，绘制在人口上。](../Images/4d78e5b3a42fbcdc13feec80af5617ef.png)'
- en: 'Figure 5.16: Left: Plot of violent vs. property crime rates, with population
    size presented through the size of the plotting symbol; California is presented
    in blue. Right: Difference scores for violent vs. property crime, plotted against
    population.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16：左：暴力犯罪率与财产犯罪率的图表，通过绘图符号的大小呈现人口规模；加利福尼亚以蓝色呈现。右：暴力犯罪与财产犯罪的差异分数，绘制在人口上。
- en: Because Z-scores are directly comparable, we can also compute a *difference
    score* that expresses the relative rate of violent to non-violent (property) crimes
    across states. We can then plot those scores against population (see right panel
    of Figure [5.16](fitting-models.html#fig:crimeTypePopPlot)). This shows how we
    can use Z-scores to bring different variables together on a common scale.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 因为Z得分是直接可比较的，我们还可以计算一个*差异分数*，它表达了各州暴力与非暴力（财产）犯罪的相对率。然后我们可以将这些分数绘制在人口上（参见图5.16的右面板）。这显示了我们如何使用Z得分将不同的变量放在一个共同的尺度上。
- en: It is worth noting that the smallest states appear to have the largest differences
    in both directions. While it might be tempting to look at each state and try to
    determine why it has a high or low difference score, this probably reflects the
    fact that the estimates obtained from smaller samples are necessarily going to
    be more variable, as we will discuss in Chapter 7.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，最小的州似乎在两个方向上都有最大的差异。虽然可能会诱人地查看每个州并尝试确定为什么它具有高或低的差异分数，但这可能反映了从较小样本中获得的估计值必然会更加变化，正如我们将在第7章中讨论的那样。
- en: 5.10 Learning objectives
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.10 学习目标
- en: Describe the basic equation for statistical models (data=model + error)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述统计模型的基本方程（数据=模型+误差）
- en: Describe different measures of central tendency and dispersion, how they are
    computed, and which are appropriate under what circumstances.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述不同的集中趋势和离散度测量，它们是如何计算的，以及在什么情况下适用。
- en: Compute a Z-score and describe why they are useful.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算Z得分并描述它们为什么有用。
- en: 5.11 Appendix
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.11 附录
- en: 5.11.1 Proof that the sum of errors from the Mean is zero
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.11.1 证明均值误差的总和为零
- en: \[ error = \sum_{i=1}^{n}(x_i - \bar{X}) = 0 \]
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 错误 = \sum_{i=1}^{n}(x_i - \bar{X}) = 0 \]
- en: \[ \sum_{i=1}^{n}x_i - \sum_{i=1}^{n}\bar{X}=0 \]
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^{n}x_i - \sum_{i=1}^{n}\bar{X}=0 \]
- en: \[ \sum_{i=1}^{n}x_i = \sum_{i=1}^{n}\bar{X} \]
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^{n}x_i = \sum_{i=1}^{n}\bar{X} \]
- en: \[ \sum_{i=1}^{n}x_i = n\bar{X} \]
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^{n}x_i = n\bar{X} \]
- en: \[ \sum_{i=1}^{n}x_i = \sum_{i=1}^{n}x_i \]
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \sum_{i=1}^{n}x_i = \sum_{i=1}^{n}x_i \]
