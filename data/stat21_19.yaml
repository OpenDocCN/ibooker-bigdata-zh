- en: Chapter 18 Doing reproducible research
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第18章 进行可重复研究
- en: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/doing-reproducible-research.html](https://statsthinking21.github.io/statsthinking21-core-site/doing-reproducible-research.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 链接：[https://statsthinking21.github.io/statsthinking21-core-site/doing-reproducible-research.html](https://statsthinking21.github.io/statsthinking21-core-site/doing-reproducible-research.html)
- en: Most people think that science is a reliable way to answer questions about the
    world. When our physician prescribes a treatment we trust that it has been shown
    to be effective through research, and we have similar faith that the airplanes
    that we fly in aren’t going to fall from the sky. However, since 2005 there has
    been an increasing concern that science may not always work as well as we have
    long thought that it does. In this chapter we will discuss these concerns about
    reproducibility of scientific research, and outline the steps that one can take
    to make sure that our statistical results are as reproducible as possible.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数人认为科学是回答世界问题的可靠方法。当我们的医生开处方时，我们相信它已经通过研究证明是有效的，我们也同样相信我们乘坐的飞机不会从天上掉下来。然而，自2005年以来，人们越来越担心科学可能并不总是像我们长期以来认为的那样有效。在本章中，我们将讨论关于科学研究可重复性的这些担忧，并概述可以采取的步骤，以确保我们的统计结果尽可能具有可重复性。
- en: 18.1 How we think science should work
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.1 我们认为科学应该如何工作
- en: 'Let’s say that we are interested in a research project on how children choose
    what to eat. This is a question that was asked in a study by the well-known eating
    researcher Brian Wansink and his colleagues in 2012\. The standard (and, as we
    will see, somewhat naive) view goes something like this:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们对一个关于儿童选择吃什么的研究项目感兴趣。这是著名饮食研究员布莱恩·万辛克及其同事在2012年的一项研究中提出的问题。标准（并且，正如我们将看到的，有些天真）观点大致如下：
- en: You start with a hypothesis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你从一个假设开始
- en: Branding with popular characters should cause children to choose “healthy” food
    more often
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用受欢迎角色的品牌可能会导致孩子更频繁地选择“健康”的食物
- en: You collect some data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你收集一些数据
- en: Offer children the choice between a cookie and an apple with either an Elmo-branded
    sticker or a control sticker, and record what they choose
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给孩子提供选择，要么是带有Elmo品牌贴纸的饼干和苹果，要么是带有控制贴纸的饼干和苹果，并记录他们的选择
- en: You do statistics to test the null hypothesis
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你做统计来检验零假设
- en: “The preplanned comparison shows Elmo-branded apples were associated with an
    increase in a child’s selection of an apple over a cookie, from 20.7% to 33.8%
    (\(\chi^2\)=5.158; P=.02)” ([Wansink, Just, and Payne 2012](#ref-wans:just:payn:2012))
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预先计划的比较显示，带有Elmo品牌的苹果与饼干相比，儿童选择苹果的比例从20.7%增加到33.8%（\(\chi^2\)=5.158; P=.02）（[Wansink,
    Just, and Payne 2012](#ref-wans:just:payn:2012)）
- en: You make a conclusion based on the data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你根据数据得出结论
- en: “This study suggests that the use of branding or appealing branded characters
    may benefit healthier foods more than they benefit indulgent, more highly processed
    foods. Just as attractive names have been shown to increase the selection of healthier
    foods in school lunchrooms, brands and cartoon characters could do the same with
    young children.”([Wansink, Just, and Payne 2012](#ref-wans:just:payn:2012))
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “这项研究表明，品牌或有吸引力的品牌角色的使用可能对更健康的食物产生更多好处，而不是对放纵、更加加工的食物产生好处。正如已经证明有吸引力的名称可以增加学校午餐室中更健康食物的选择一样，品牌和卡通角色也可以在年幼儿童中产生同样的效果。”（[Wansink,
    Just, and Payne 2012](#ref-wans:just:payn:2012)）
- en: 18.2 How science (sometimes) actually works
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.2 科学（有时）实际上是如何工作的
- en: 'Brian Wansink is well known for his books on “Mindless Eating”, and his fee
    for corporate speaking engagements was at one point in the tens of thousands of
    dollars. In 2017, a set of researchers began to scrutinize some of his published
    research, starting with a set of papers about how much pizza people ate at a buffet.
    The researchers asked Wansink to share the data from the studies but he refused,
    so they dug into his published papers and found a large number of inconsistencies
    and statistical problems in the papers. The publicity around this analysis led
    a number of others to dig into Wansink’s past, including obtaining emails between
    Wansink and his collaborators. As [reported by Stephanie Lee at Buzzfeed](https://www.buzzfeednews.com/article/stephaniemlee/brian-wansink-cornell-p-hacking),
    these emails showed just how far Wansink’s actual research practices were from
    the naive model:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 布莱恩·万辛克以他的《无意识进食》一书而闻名，他的企业演讲费曾一度高达数万美元。2017年，一组研究人员开始审查他发表的一些研究，首先是一组关于人们在自助餐厅吃了多少比萨的论文。研究人员要求万辛克分享研究数据，但他拒绝了，所以他们深入研究了他发表的论文，并在论文中发现了大量的不一致和统计问题。围绕这一分析的公开报道引起了其他许多人对万辛克过去的关注，包括获取万辛克和他的合作者之间的电子邮件。正如Buzzfeed的Stephanie
    Lee报道的那样，这些电子邮件显示了万辛克的实际研究实践与天真模型有多么不同：
- en: '…back in September 2008, when Payne was looking over the data soon after it
    had been collected, he found no strong apples-and-Elmo link — at least not yet.
    … “I have attached some initial results of the kid study to this message for your
    report,” Payne wrote to his collaborators. “Do not despair. It looks like stickers
    on fruit may work (with a bit more wizardry).” … Wansink also acknowledged the
    paper was weak as he was preparing to submit it to journals. The p-value was 0.06,
    just shy of the gold standard cutoff of 0.05\. It was a “sticking point,” as he
    put it in a Jan. 7, 2012, email. … “It seems to me it should be lower,” he wrote,
    attaching a draft. “Do you want to take a look at it and see what you think. If
    you can get the data, and it needs some tweeking, it would be good to get that
    one value below .05.” … Later in 2012, the study appeared in the prestigious JAMA
    Pediatrics, the 0.06 p-value intact. But in September 2017, it was retracted and
    replaced with a version that listed a p-value of 0.02\. And a month later, it
    was retracted yet again for an entirely different reason: Wansink admitted that
    the experiment had not been done on 8- to 11-year-olds, as he’d originally claimed,
    but on preschoolers.'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ……回到2008年9月，当Payne在数据收集后不久查看数据时，他并没有发现明显的苹果和艾尔莫之间的联系——至少目前还没有。……“我在这封邮件中附上了儿童研究的一些初步结果，供您的报告使用，”Payne写道。
    “不要绝望。看起来水果上的贴纸可能有效（需要更多的魔法）。 ”……Wansink在准备提交论文时也承认了论文的薄弱之处。P值为0.06，刚好低于0.05的黄金标准。正如他在2012年1月7日的一封电子邮件中所说的那样，这是一个“瓶颈”。……“在我看来，它应该更低，”他在附上一份草案的时候写道。“你想看看它，看看你的想法。如果你能得到数据，并且需要一些调整，那么将这个值降低到0.05以下将是很好的。”……2012年晚些时候，这项研究发表在著名的《JAMA儿科学》，0.06的P值保持不变。但在2017年9月，它被撤回，并以一个列出P值为0.02的版本取而代之。一个月后，它因为完全不同的原因再次被撤回：Wansink承认实验并不是在8至11岁的孩子身上进行的，正如他最初所声称的那样，而是在学龄前儿童身上进行的。
- en: This kind of behavior finally caught up with Wansink; [fifteen of his research
    studies have been retracted](https://www.vox.com/science-and-health/2018/9/19/17879102/brian-wansink-cornell-food-brand-lab-retractions-jama)
    and in 2018 he resigned from his faculty position at Cornell University.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这种行为最终让Wansink受到了惩罚；[他的15项研究被撤回](https://www.vox.com/science-and-health/2018/9/19/17879102/brian-wansink-cornell-food-brand-lab-retractions-jama)，并且在2018年，他辞去了康奈尔大学的教职。
- en: 18.3 The reproducibility crisis in science
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.3 科学中的可重复性危机
- en: 'While we think that the kind of frauduent behavior seen in Wansink’s case is
    relatively rare, it has become increasingly clear that problems with reproducibility
    are much more widespread in science than previously thought. This became particularly
    evident in 2015, when a large group of researchers published a study in the journal
    *Science* titled “Estimating the reproducibility of psychological science”([Open
    Science Collaboration 2015](#ref-open:2015)). In this paper, the researchers took
    100 published studies in psychology and attempted to reproduce the results originally
    reported in the papers. Their findings were shocking: Whereas 97% of the original
    papers had reported statistically significant findings, only 37% of these effects
    were statistically significant in the replication study. Although these problems
    in psychology have received a great deal of attention, they seem to be present
    in nearly every area of science, from cancer biology ([Errington et al. 2014](#ref-erri:iorn:gunn:2014))
    and chemistry ([Baker 2017](#ref-bake:2017)) to economics ([Christensen and Miguel
    2016](#ref-NBERw22989)) and the social sciences ([Camerer et al. 2018](#ref-Camerer2018EvaluatingTR)).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们认为Wansink案中出现的欺诈行为相对罕见，但越来越清楚的是，科学中的可重复性问题比以前想象的要普遍得多。这在2015年变得特别明显，当时一大群研究人员在《科学》杂志上发表了一篇题为“估计心理科学可重复性”的研究（[Open
    Science Collaboration 2015](#ref-open:2015)）。在这篇论文中，研究人员选取了100篇心理学领域的已发表研究，并试图重现这些论文中最初报告的结果。他们的发现令人震惊：原始论文中有97%报告了统计显著的发现，但在复制研究中，只有37%的效应在统计上是显著的。尽管心理学中存在这些问题已经引起了很多关注，但似乎几乎每个科学领域都存在这些问题，从癌症生物学（[Errington
    et al. 2014](#ref-erri:iorn:gunn:2014)）和化学（[Baker 2017](#ref-bake:2017)）到经济学（[Christensen
    and Miguel 2016](#ref-NBERw22989)）和社会科学（[Camerer et al. 2018](#ref-Camerer2018EvaluatingTR)）。
- en: The reproducibility crisis that emerged after 2010 was actually predicted by
    John Ioannidis, a physician from Stanford who wrote a paper in 2005 titled “Why
    most published research findings are false”([Ioannidis 2005](#ref-ioan:2005)).
    In this article, Ioannidis argued that the use of null hypothesis statistical
    testing in the context of modern science will necessarily lead to high levels
    of false results.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 2010年后出现的可重复性危机实际上是由斯坦福大学的医生约翰·约阿尼迪斯预测的，他在2005年写了一篇名为“为什么大多数发表的研究结果是错误的”（[Ioannidis
    2005](#ref-ioan:2005)）的论文。在这篇文章中，约阿尼迪斯认为，在现代科学背景下使用零假设统计检验必然会导致高水平的错误结果。
- en: 18.3.1 Positive predictive value and statistical significance
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.3.1 阳性预测值和统计显著性
- en: 'Ioannidis’ analysis focused on a concept known as the *positive predictive
    value*, which is defined as the proportion of positive results (which generally
    translates to “statistically significant findings”) that are true:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Ioannidis的分析集中在一个称为“阳性预测值”的概念上，它被定义为阳性结果（通常翻译为“统计显著的发现”）中真实的比例：
- en: '\[ PPV = \frac{p(true\ positive\ result)}{p(true\ positive\ result) + p(false\
    positive\ result)} \] Assuming that we know the probability that our hypothesis
    is true (\(p(hIsTrue)\)), then the probability of a true positive result is simply
    \(p(hIsTrue)\) multiplied by the statistical power of the study:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: \[ PPV = \frac{p(true\ positive\ result)}{p(true\ positive\ result) + p(false\
    positive\ result)} \] 假设我们知道假设为真的概率 (\(p(hIsTrue)\))，那么真正阳性结果的概率就是 \(p(hIsTrue)\)
    乘以研究的统计功效。
- en: '\[ p(true\ positive\ result) = p(hIsTrue) * (1 - \beta) \] were \(\beta\) is
    the false negative rate. The probability of a false positive result is determined
    by \(p(hIsTrue)\) and the false positive rate \(\alpha\):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p(true\ positive\ result) = p(hIsTrue) * (1 - \beta) \] 其中 \(\beta\) 是假阴性率。假阳性结果的概率由
    \(p(hIsTrue)\) 和假阳性率 \(\alpha\) 决定：
- en: \[ p(false\ positive\ result) = (1 - p(hIsTrue)) * \alpha \]
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: \[ p(false\ positive\ result) = (1 - p(hIsTrue)) * \alpha \]
- en: 'PPV is then defined as:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: PPV的定义如下：
- en: \[ PPV = \frac{p(hIsTrue) * (1 - \beta)}{p(hIsTrue) * (1 - \beta) + (1 - p(hIsTrue))
    * \alpha} \]
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: \[ PPV = \frac{p(hIsTrue) * (1 - \beta)}{p(hIsTrue) * (1 - \beta) + (1 - p(hIsTrue))
    * \alpha} \]
- en: 'Let’s first take an example where the probability of our hypothesis being true
    is high, say 0.8 - though note that in general we cannot actually know this probability.
    Let’s say that we perform a study with the standard values of \(\alpha=0.05\)
    and \(\beta=0.2\). We can compute the PPV as:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先举一个概率假设为真的概率很高的例子，比如说0.8 - 尽管一般来说我们实际上无法知道这个概率。假设我们进行了一项研究，使用标准值\(\alpha=0.05\)和\(\beta=0.2\)。我们可以计算PPV如下：
- en: \[ PPV = \frac{0.8 * (1 - 0.2)}{0.8 * (1 - 0.2) + (1 - 0.8) * 0.05} = 0.98 \]
    This means that if we find a positive result in a study where the hypothesis is
    likely to be true and power is high, then its likelihood of being true is high.
    Note, however, that a research field where the hypotheses have such a high likelihood
    of being true is probably not a very interesting field of research; research is
    most important when it tells us something unexpected!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: \[ PPV = \frac{0.8 * (1 - 0.2)}{0.8 * (1 - 0.2) + (1 - 0.8) * 0.05} = 0.98 \]
    这意味着如果我们在假设可能为真且功效高的研究中发现了积极的结果，那么它的真实性很高。然而，请注意，假设一个研究领域的假设有如此高的真实可能性可能并不是一个非常有趣的研究领域；当研究告诉我们一些意外的事情时，研究是最重要的！
- en: 'Let’s do the same analysis for a field where \(p(hIsTrue)=0.1\) – that is,
    most of the hypotheses being tested are false. In this case, PPV is:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对\(p(hIsTrue)=0.1\)的领域进行相同的分析 - 也就是说，大多数被测试的假设都是错误的。在这种情况下，PPV是：
- en: \[ PPV = \frac{0.1 * (1 - 0.2)}{0.1 * (1 - 0.2) + (1 - 0.1) * 0.05} = 0.307
    \]
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: \[ PPV = \frac{0.1 * (1 - 0.2)}{0.1 * (1 - 0.2) + (1 - 0.1) * 0.05} = 0.307
    \]
- en: This means that in a field where most of the hypotheses are likely to be wrong
    (that is, an interesting scientific field where researchers are testing risky
    hypotheses), even when we find a positive result it is more likely to be false
    than true! In fact, this is just another example of the base rate effect that
    we discussed in the context of hypothesis testing – when an outcome is unlikely,
    then it’s almost certain that most positive outcomes will be false positives.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在一个大部分假设可能是错误的领域（也就是说，一个有趣的科学领域，研究人员正在测试冒险的假设），即使我们发现了积极的结果，它更可能是假的而不是真的！事实上，这只是我们在假设检验的背景下讨论的基本率效应的另一个例子
    - 当结果不太可能时，几乎可以肯定大多数积极的结果都是假阳性。
- en: We can simulate this to show how PPV relates to statistical power, as a function
    of the prior probability of the hypothesis being true (see Figure [18.1](doing-reproducible-research.html#fig:PPVsim))
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以模拟这一点，展示PPV如何与统计功效和假设真实的先验概率相关（见图[18.1](doing-reproducible-research.html#fig:PPVsim)）。
- en: '![A simulation of posterior predictive value as a function of statistical power
    (plotted on the x axis) and prior probability of the hypothesis being true (plotted
    as separate lines).](../Images/88b6ca7297448ac046bf8abd11869c81.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![后验预测值的模拟，作为统计功效的函数（绘制在x轴上），以及假设真实的先验概率（作为单独的线绘制）。](../Images/88b6ca7297448ac046bf8abd11869c81.png)'
- en: 'Figure 18.1: A simulation of posterior predictive value as a function of statistical
    power (plotted on the x axis) and prior probability of the hypothesis being true
    (plotted as separate lines).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.1：后验预测值的模拟，作为统计功效的函数（绘制在x轴上），以及假设真实的先验概率（作为单独的线绘制）。
- en: Unfortunately, statistical power remains low in many areas of science ([Smaldino
    and McElreath 2016](#ref-smal:mcel:2016)), suggesting that many published research
    findings are false.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在许多科学领域，统计功效仍然很低（[Smaldino and McElreath 2016](#ref-smal:mcel:2016)），这表明许多发表的研究结果是错误的。
- en: An amusing example of this was seen in a paper by Jonathan Schoenfeld and John
    Ioannidis, titled “Is everything we eat associated with cancer? A systematic cookbook
    review”([Schoenfeld and Ioannidis 2013](#ref-scho:ioan:2013)). They examined a
    large number of papers that had assessed the relation between different foods
    and cancer risk, and found that 80% of ingredients had been associated with either
    increased or decreased cancer risk. In most of these cases, the statistical evidence
    was weak, and when the results were combined across studies, the result was null.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的例子是乔纳森·肖恩菲尔德和约翰·约阿尼迪斯的一篇论文，题为“我们吃的一切都与癌症有关吗？系统的食谱评论”（[Schoenfeld and Ioannidis
    2013](#ref-scho:ioan:2013)）。他们检查了大量评估不同食物与癌症风险关系的论文，发现80%的成分与增加或减少癌症风险有关。在大多数情况下，统计证据很弱，当结果在研究中结合时，结果为零。
- en: 18.3.2 The winner’s curse
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.3.2 胜者诅咒
- en: 'Another kind of error can also occur when statistical power is low: Our estimates
    of the effect size will be inflated. This phenomenon often goes by the term “winner’s
    curse”, which comes from economics, where it refers to the fact that for certain
    types of auctions (where the value is the same for everyone, like a jar of quarters,
    and the bids are private), the winner is guaranteed to pay more than the good
    is worth. In science, the winner’s curse refers to the fact that the effect size
    estimated from a significant result (i.e. a winner) is almost always an overestimate
    of the true effect size.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当统计功效低时，还会发生另一种错误：我们对效应大小的估计会被夸大。这种现象通常被称为“胜者诅咒”，这个术语来自经济学，在那里它指的是对于某些类型的拍卖（其中价值对每个人都是相同的，比如一罐季度，出价是私人的），获胜者保证要支付比商品价值更多的钱。在科学上，胜者诅咒指的是从显著结果（即获胜者）中估计的效应大小几乎总是真实效应大小的夸大。
- en: We can simulate this in order to see how the estimated effect size for significant
    results is related to the actual underlying effect size. Let’s generate data for
    which there is a true effect size of d = 0.2, and estimate the effect size for
    those results where there is a significant effect detected. The left panel of
    Figure [18.2](doing-reproducible-research.html#fig:CurseSim) shows that when power
    is low, the estimated effect size for significant results can be highly inflated
    compared to the actual effect size.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以模拟这个，以查看显著结果的估计效应大小与实际基础效应大小的关系。让我们生成一个真实效应大小为d = 0.2的数据，并估计检测到显著效应的结果的效应大小。图[18.2](doing-reproducible-research.html#fig:CurseSim)的左面板显示，当功效低时，显著结果的估计效应大小可能与实际效应大小相比高度膨胀。
- en: '![Left: A simulation of the winner''s curse as a function of statistical power
    (x axis). The solid line shows the estimated effect size, and the dotted line
    shows the actual effect size. Right: A histogram showing effect size estimates
    for a number of samples from a dataset, with significant results shown in blue
    and non-significant results in red. ](../Images/537285b874ca6fc4a5254d19ad842c82.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![左：赢家诅咒的模拟，作为统计功效的函数（x轴）。实线显示估计的效应大小，虚线显示实际效应大小。右：直方图显示了来自数据集的多个样本的效应大小估计，显著结果显示为蓝色，非显著结果显示为红色。](../Images/537285b874ca6fc4a5254d19ad842c82.png)'
- en: 'Figure 18.2: Left: A simulation of the winner’s curse as a function of statistical
    power (x axis). The solid line shows the estimated effect size, and the dotted
    line shows the actual effect size. Right: A histogram showing effect size estimates
    for a number of samples from a dataset, with significant results shown in blue
    and non-significant results in red.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.2：左：赢家诅咒的模拟，作为统计功效的函数（x轴）。实线显示估计的效应大小，虚线显示实际效应大小。右：直方图显示了来自数据集的多个样本的效应大小估计，显著结果显示为蓝色，非显著结果显示为红色。
- en: We can look at a single simulation to see why this is the case. In the right
    panel of Figure [18.2](doing-reproducible-research.html#fig:CurseSim), you can
    see a histogram of the estimated effect sizes for 1000 samples, separated by whether
    the test was statistically significant. It should be clear from the figure that
    if we estimate the effect size only based on significant results, then our estimate
    will be inflated; only when most results are significant (i.e. power is high and
    the effect is relatively large) will our estimate come near the actual effect
    size.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看一个单独的模拟来看为什么会出现这种情况。在图[18.2](doing-reproducible-research.html#fig:CurseSim)的右面板中，您可以看到1000个样本的估计效应大小的直方图，根据检验是否具有统计显著性进行分隔。从图中应该清楚，如果我们仅基于显著结果来估计效应大小，那么我们的估计将会被夸大；只有当大多数结果是显著的（即功效高且效应相对较大）时，我们的估计才会接近实际效应大小。
- en: 18.4 Questionable research practices
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.4 可疑的研究行为
- en: 'A popular book entitled “The Compleat Academic: A Career Guide”, published
    by the American Psychological Association ([Darley, Zanna, and Roediger 2004](#ref-darl:zann:roed:2004)),
    aims to provide aspiring researchers with guidance on how to build a career. In
    a chapter by well-known social psychologist Daryl Bem titled “Writing the Empirical
    Journal Article”, Bem provides some suggestions about how to write a research
    paper. Unfortunately, the practices that he suggests are deeply problematic, and
    have come to be known as *questionable research practices* (QRPs).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '美国心理学协会出版的一本名为《The Compleat Academic: A Career Guide》的畅销书（[Darley, Zanna, and
    Roediger 2004](#ref-darl:zann:roed:2004)）旨在为有抱负的研究人员提供如何建立职业生涯的指导。社会心理学家达里尔·贝姆在一章中提到了“撰写实证期刊文章”，他提供了一些建议关于如何写一篇研究论文。不幸的是，他提出的做法存在严重问题，已经被称为*可疑的研究行为*（QRPs）。'
- en: '**Which article should you write?** There are two possible articles you can
    write: (1) the article you planned to write when you designed your study or (2)
    the article that makes the most sense now that you have seen the results. They
    are rarely the same, and the correct answer is (2).'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你应该写哪篇文章？有两篇可能的文章可以写：（1）你在设计研究时计划写的文章，或者（2）你已经看到结果后现在最有意义的文章。它们很少相同，正确答案是（2）。
- en: 'What Bem suggests here is known as *HARKing* (Hypothesizing After the Results
    are Known)([Kerr 1998](#ref-kerr:1998)). This might seem innocuous, but is problematic
    because it allows the researcher to re-frame a post-hoc conclusion (which we should
    take with a grain of salt) as an a priori prediction (in which we would have stronger
    faith). In essence, it allows the researcher to rewrite their theory based on
    the facts, rather that using the theory to make predictions and then test them
    – akin to moving the goalpost so that it ends up wherever the ball goes. It thus
    becomes very difficult to disconfirm incorrect ideas, since the goalpost can always
    be moved to match the data. Bem continues:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Bem在这里建议的是*HARKing*（在结果已知后进行假设）([Kerr 1998](#ref-kerr:1998))。这可能看起来无害，但是有问题，因为它允许研究人员重新构建事后结论（我们应该持保留态度）作为先验预测（我们会更有信心）。实质上，它允许研究人员根据事实重写他们的理论，而不是使用理论进行预测，然后进行测试——类似于移动球门，使其最终停在任何地方。因此，非常难以证伪不正确的想法，因为球门总是可以移动以匹配数据。Bem继续说道：
- en: '**Analyzing data** Examine them from every angle. Analyze the sexes separately.
    Make up new composite indices. If a datum suggests a new hypothesis, try to find
    further evidence for it elsewhere in the data. If you see dim traces of interesting
    patterns, try to reorganize the data to bring them into bolder relief. If there
    are participants you don’t like, or trials, observers, or interviewers who gave
    you anomalous results,drop them (temporarily). Go on a fishing expedition for
    something — anything — interesting. No, this is not immoral.'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**分析数据** 从各个角度检查它们。分别分析性别。制作新的综合指数。如果一个数据表明一个新的假设，试着在数据的其他地方找到进一步的证据。如果你看到有趣模式的微弱痕迹，试着重新组织数据以使它们更加醒目。如果有你不喜欢的参与者，或者试验、观察者或采访者给你异常结果，暂时放弃它们。进行一次钓鱼远征，寻找一些有趣的东西。不，这不是不道德的。'
- en: 'What Bem suggests here is known as *p-hacking*, which refers to trying many
    different analyses until one finds a significant result. Bem is correct that if
    one were to report every analysis done on the data then this approach would not
    be “immoral”. However, it is rare to see a paper discuss all of the analyses that
    were performed on a dataset; rather, papers often only present the analyses that
    *worked* - which usually means that they found a statistically significant result.
    There are many different ways that one might p-hack:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Bem在这里提出的是*p-hacking*，这意味着尝试许多不同的分析，直到找到一个显着的结果。 Bem正确地指出，如果报告数据上进行的每一项分析，那么这种方法就不会“不道德”。然而，很少看到一篇论文讨论对数据集执行的所有分析;
    相反，论文通常只呈现*有效*的分析 - 这通常意味着他们找到了统计上显着的结果。有许多不同的方法可以进行p-hack：
- en: Analyze data after every subject, and stop collecting data once p<.05
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个受试者之后分析数据，并在p <.05时停止收集数据
- en: Analyze many different variables, but only report those with p<.05
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析许多不同的变量，但只报告那些p <.05的变量
- en: Collect many different experimental conditions, but only report those with p<.05
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集许多不同的实验条件，但只报告那些p <.05的条件
- en: Exclude participants to get p<.05
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 排除参与者以获得p <.05
- en: Transform the data to get p<.05
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换数据以获得p <.05
- en: A well-known paper by Simmons, Nelson, and Simonsohn ([2011](#ref-simm:nels:simo:2011))
    showed that the use of these kinds of p-hacking strategies could greatly increase
    the actual false positive rate, resulting in a high number of false positive results.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Simmons，Nelson和Simonsohn（2011）发表的一篇著名论文表明，使用这些p-hacking策略可以大大增加实际的假阳性率，导致大量的假阳性结果。
- en: 18.4.1 ESP or QRP?
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.4.1 ESP或QRP？
- en: 'In 2011, that same Daryl Bem published an article ([Bem 2011](#ref-bem:2011))
    that claimed to have found scientific evidence for extrasensory perception. The
    article states:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 2011年，同样是Daryl Bem发表了一篇文章（Bem 2011），声称已经找到了超感知的科学证据。文章中指出：
- en: This article reports 9 experiments, involving more than 1,000 participants,
    that test for retroactive influence by “time-reversing” well-established psychological
    effects so that the individual’s responses are obtained before the putatively
    causal stimulus events occur. …The mean effect size (d) in psi performance across
    all 9 experiments was 0.22, and all but one of the experiments yielded statistically
    significant results.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本文报告了9个实验，涉及1000多名参与者，测试了通过“时间逆转”已经建立的心理效应来测试超前影响。 …所有9个实验中的超感知表现的平均效应大小（d）为0.22，除一个实验外，所有实验都产生了统计上显着的结果。
- en: 'As researchers began to examine Bem’s article, it became clear that he had
    engaged in all of the QRPs that he had recommended in the chapter discussed above.
    As Tal Yarkoni pointed out in [a blog post that examined the article](http://www.talyarkoni.org/blog/2011/01/10/the-psychology-of-parapsychology-or-why-good-researchers-publishing-good-articles-in-good-journals-can-still-get-it-totally-wrong/):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当研究人员开始检查Bem的文章时，很明显他已经参与了上面讨论的所有QRPs。正如Tal Yarkoni在一篇审查该文章的博客文章中指出的那样：
- en: Sample sizes varied across studies
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本大小在研究中有所不同
- en: Different studies appear to have been lumped together or split apart
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的研究似乎已经被合并在一起或分开
- en: The studies allow many different hypotheses, and it’s not clear which were planned
    in advance
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些研究允许许多不同的假设，目前尚不清楚事先计划了哪些假设
- en: Bem used one-tailed tests even when it’s not clear that there was a directional
    prediction (so alpha is really 0.1)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bem在没有明确有方向性预测的情况下使用单尾检验（因此α实际上为0.1）
- en: Most of the p-values are very close to 0.05
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数p值非常接近0.05
- en: It’s not clear how many other studies were run but not reported
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前尚不清楚有多少其他研究进行了但没有报告
- en: 18.5 Doing reproducible research
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.5 进行可重复研究
- en: In the years since the reproducibility crisis arose, there has been a robust
    movement to develop tools to help protect the reproducibility of scientific research.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 自可重复性危机爆发以来，已经出现了一个强大的运动，旨在开发工具，以帮助保护科学研究的可重复性。
- en: 18.5.1 Pre-registration
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.5.1 预注册
- en: One of the ideas that has gained the greatest traction is *pre-registration*,
    in which one submits a detailed description of a study (including all data analyses)
    to a trusted repository (such as the [Open Science Framework](http://osf.io) or
    [AsPredicted.org](http://aspredicted.org)). By specifying one’s plans in detail
    prior to analyzing the data, pre-registration provides greater faith that the
    analyses do not suffer from p-hacking or other questionable research practices.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最受欢迎的想法之一是*预注册*，其中将研究的详细描述（包括所有数据分析）提交给受信任的存储库（例如[Open Science Framework](http://osf.io)或[AsPredicted.org](http://aspredicted.org)）。通过在分析数据之前详细说明计划，预注册提供了更大的信心，使分析不会受到p-hacking或其他可疑的研究实践的影响。
- en: The effects of pre-registration in clinical trials in medicine have been striking.
    In 2000, the National Heart, Lung, and Blood Institute (NHLBI) began requiring
    all clinical trials to be pre-registered using the system at [ClinicalTrials.gov](http://clinicaltrials.gov).
    This provides a natural experiment to observe the effects of study pre-registration.
    When Kaplan and Irvin ([2015](#ref-kapl:irvi:2015)) examined clinical trial outcomes
    over time, they found that the number of positive outcomes in clinical trials
    was greatly reduced after 2000 compared to before. While there are many possible
    causes, it seems likely that prior to study registration researchers were able
    to change their methods or hypotheses in order to find a positive result, which
    became more difficult after registration was required.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在医学临床试验中，预先注册的影响是显著的。2000年，国家心脏，肺部和血液研究所（NHLBI）开始要求所有临床试验在[临床试验.gov](http://clinicaltrials.gov)上进行预先注册。这提供了一个自然实验来观察研究预先注册的影响。当Kaplan和Irvin（2015）在一段时间内检查临床试验结果时，他们发现2000年之后临床试验的积极结果数量大大减少，与之前相比。虽然有许多可能的原因，但似乎在研究注册之前，研究人员能够改变他们的方法或假设以找到积极的结果，而在注册后这变得更加困难。
- en: 18.5.2 Reproducible practices
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.5.2 可重复的实践
- en: 'The paper by Simmons, Nelson, and Simonsohn ([2011](#ref-simm:nels:simo:2011))
    laid out a set of suggested practices for making research more reproducible, all
    of which should become standard for researchers:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Simmons, Nelson和Simonsohn（2011）提出了一套建议的实践，使研究更具可重复性，所有这些实践都应该成为研究人员的标准：
- en: Authors must decide the rule for terminating data collection before data collection
    begins and report this rule in the article.
  id: totrans-72
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作者必须在数据收集开始之前决定终止数据收集的规则，并在文章中报告这个规则。
- en: Authors must collect at least 20 observations per cell or else provide a compelling
    cost-of-data-collection justification.
  id: totrans-73
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作者必须每个单元收集至少20个观察结果，否则必须提供令人信服的数据收集成本的理由。
- en: Authors must list all variables collected in a study.
  id: totrans-74
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作者必须列出研究中收集的所有变量。
- en: Authors must report all experimental conditions, including failed manipulations.
  id: totrans-75
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作者必须报告所有实验条件，包括失败的操作。
- en: If observations are eliminated, authors must also report what the statistical
    results are if those observations are included.
  id: totrans-76
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果观察结果被排除，作者必须报告如果包括这些观察结果，统计结果是什么。
- en: If an analysis includes a covariate, authors must report the statistical results
    of the analysis without the covariate.
  id: totrans-77
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果分析包括一个协变量，作者必须报告没有协变量的分析的统计结果。
- en: 18.5.3 Replication
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.5.3 复制
- en: One of the hallmarks of science is the idea of *replication* – that is, other
    researchers should be able to perform the same study and obtain the same result.
    Unfortunately, as we saw in the outcome of the Replication Project discussed earlier,
    many findings are not replicable. The best way to ensure replicability of one’s
    research is to first replicate it on your own; for some studies this just won’t
    be possible, but whenever it is possible one should make sure that one’s finding
    holds up in a new sample. That new sample should be sufficiently powered to find
    the effect size of interest; in many cases, this will actually require a larger
    sample than the original.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 科学的一个标志是*复制*的概念-也就是说，其他研究人员应该能够进行相同的研究并获得相同的结果。不幸的是，正如我们在之前讨论的复制项目的结果中看到的那样，许多发现是不可复制的。确保研究的可复制性的最佳方法是首先在自己身上复制它；对于一些研究来说，这可能是不可能的，但每当可能时，应确保自己的发现在新样本中成立。新样本应具有足够的功效来发现感兴趣的效应大小；在许多情况下，这实际上将需要比原始样本更大的样本。
- en: It’s important to keep a couple of things in mind with regard to replication.
    First, the fact that a replication attempt fails does not necessarily mean that
    the original finding was false; remember that with the standard level of 80% power,
    there is still a one in five chance that the result will be nonsignificant, even
    if there is a true effect. For this reason, we generally want to see multiple
    replications of any important finding before we decide whether or not to believe
    it. Unfortunately, many fields including psychology have failed to follow this
    advice in the past, leading to “textbook” findings that turn out to be likely
    false. With regard to Daryl Bem’s studies of ESP, a large replication attempt
    involving 7 studies failed to replicate his findings ([Galak et al. 2012](#ref-gala:lebo:nels:2012)).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在复制方面，有几件事情很重要。首先，复制尝试失败并不一定意味着原始发现是错误的；请记住，以80%的功效水平，即使存在真实效应，结果仍有五分之一的机会是不显著的。因此，我们通常希望在决定是否相信某个重要发现之前看到多次复制。不幸的是，包括心理学在内的许多领域过去未能遵循这一建议，导致“教科书”上的发现最终被证明是错误的。关于Daryl
    Bem对超感知的研究，一个包括7个研究的大型复制尝试未能复制他的发现（Galak等人，2012）。
- en: Second, remember that the p-value doesn’t provide us with a measure of the likelihood
    of a finding to replicate. As we discussed previously, the p-value is a statement
    about the likelihood of one’s data under a specific null hypothesis; it doesn’t
    tell us anything about the probability that the finding is actually true (as we
    learned in the chapter on Bayesian analysis). In order to know the likelihood
    of replication we need to know the probability that the finding is true, which
    we generally don’t know.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，要记住p值并不能提供给我们一个发现复制的可能性的度量。正如我们之前讨论过的，p值是关于特定零假设下数据的可能性的陈述；它并不能告诉我们关于发现实际上是真实的概率（正如我们在贝叶斯分析的章节中学到的）。为了知道复制的可能性，我们需要知道发现是真实的概率，而这通常是我们不知道的。
- en: 18.6 Doing reproducible data analysis
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.6 进行可重复的数据分析
- en: So far we have focused on the ability to replicate other researchers’ findings
    in new experiments, but another important aspect of reproducibility is to be able
    to reproduce someone’s analyses on their own data, which we refer to a *computational
    reproducibility.* This requires that researchers share both their data and their
    analysis code, so that other researchers can both try to reproduce the result
    as well as potentially test different analysis methods on the same data. There
    is an increasing move in psychology towards open sharing of code and data; for
    example, the journal *Psychological Science* now provides “badges” to papers that
    share research materials, data, and code, as well as for pre-registration.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经专注于在新实验中复制其他研究人员的发现的能力，但可再现性的另一个重要方面是能够在其自己的数据上重现某人的分析，我们称之为*计算可再现性*。这要求研究人员分享他们的数据和分析代码，以便其他研究人员既可以尝试重现结果，也可以在相同数据上测试不同的分析方法。心理学领域越来越倾向于公开分享代码和数据；例如，《心理科学》杂志现在为分享研究材料、数据和代码以及预注册的论文提供“徽章”。
- en: The ability to reproduce analyses is one reason that we strongly advocate for
    the use of scripted analyses (such as those using R) rather than using a “point-and-click”
    software package. It’s also a reason that we advocate the use of free and open-source
    software (like R) as opposed to commercial software packages, which would require
    others to buy the software in order to reproduce any analyses.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 能够重现分析是我们强烈主张使用脚本分析（如使用R语言）而不是使用“点与点击”软件包的原因之一。这也是我们主张使用免费开源软件（如R）而不是商业软件包的原因，后者需要其他人购买软件才能重现任何分析。
- en: There are many ways to share both code and data. A common way to share code
    is via web sites that support *version control* for software, such as [Github](http://github.com).
    Small datasets can also be shared via these same sites; larger datasets can be
    shared through data sharing portals such as [Zenodo](https://zenodo.org/), or
    through specialized portals for specific types of data (such as [OpenNeuro](http://openneuro.org)
    for neuroimaging data).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多分享代码和数据的方式。分享代码的常见方式是通过支持软件*版本控制*的网站，例如[Github](http://github.com)。小型数据集也可以通过这些网站分享；较大的数据集可以通过数据共享门户网站（如[Zenodo](https://zenodo.org/)）或专门用于特定类型数据的门户网站（如[OpenNeuro](http://openneuro.org)）进行分享。
- en: '18.7 Conclusion: Doing better science'
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.7 结论：做更好的科学
- en: It is every scientist’s responsibility to improve their research practices in
    order to increase the reproducibility of their research. It is essential to remember
    that the goal of research is not to find a significant result; rather, it is to
    ask and answer questions about nature in the most truthful way possible. Most
    of our hypotheses will be wrong, and we should be comfortable with that, so that
    when we find one that’s right, we will be even more confident in its truth.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 每个科学家都有责任改进他们的研究实践，以增加其研究的可再现性。必须记住，研究的目标不是找到显著结果，而是以最真实的方式提出和回答关于自然的问题。我们的大部分假设都会是错误的，我们应该对此感到舒适，这样当我们找到一个正确的假设时，我们会更加对其真实性有信心。
- en: 18.8 Learning objectives
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.8 学习目标
- en: Describe the concept of P-hacking and its effects on scientific practice
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述P-值操纵的概念及其对科学实践的影响
- en: Describe the concept of positive predictive value and its relation to statistical
    power
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述阳性预测值的概念及其与统计功效的关系
- en: Describe the concept of pre-registration and how it can help protect against
    questionable research practices
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述预注册的概念以及它如何帮助防止可疑的研究实践
- en: 18.9 Suggested Readings
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.9 建议阅读
- en: '[Rigor Mortis: How Sloppy Science Creates Worthless Cures, Crushes Hope, and
    Wastes Billions, by Richard Harris](https://www.amazon.com/dp/B01K3WN72C)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[《严谨之死：草率的科学如何制造毫无价值的治疗，粉碎希望，浪费数十亿》（作者：理查德·哈里斯）](https://www.amazon.com/dp/B01K3WN72C)'
- en: '[Improving your statistical inferences](https://www.coursera.org/learn/statistical-inferences)
    - an online course on how to do better statistical analysis, including many of
    the points raised in this chapter.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[改善您的统计推断](https://www.coursera.org/learn/statistical-inferences) - 一门关于如何进行更好的统计分析的在线课程，包括本章提出的许多要点。'
