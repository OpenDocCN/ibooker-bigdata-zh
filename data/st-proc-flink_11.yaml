- en: Chapter 11\. Where to Go from Here?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章 从这里去哪里？
- en: It has been a long journey and you have made it to the end of this book! But
    your Flink journey has just started, and this chapter points to the possible paths
    you can take from here. We will provide you with a brief tour of the additional
    Flink functionality not included in this book and give you some pointers to further
    Flink resources. There exists a vibrant community around Flink and we encourage
    you to connect with other users, start contributing, or find out what companies
    are building with Flink to help inspire your own work.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个漫长的旅程，你已经完成了本书的阅读！但是你的 Flink 之旅才刚刚开始，本章节将指引你从这里可以走的可能路径。我们将简要介绍一些未包含在本书中的额外
    Flink 功能，并提供一些指向更多 Flink 资源的指引。Flink 周围存在着一个充满活力的社区，我们鼓励你与其他用户建立联系，开始贡献，或者了解正在使用
    Flink 构建什么样的公司，以激发你自己的工作。
- en: The Rest of the Flink Ecosystem
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Flink 生态系统的其他部分
- en: While this book is particularly focused on stream processing, Flink is in fact
    a general-purpose distributed data processing framework and can be used for other
    types of data analysis as well. Further, Flink offers domain-specific libraries
    and APIs for relational queries, complex event processing (CEP), and graph processing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本书特别关注流处理，但实际上 Flink 是一个通用的分布式数据处理框架，也可以用于其他类型的数据分析。此外，Flink 提供了领域特定的库和 API，用于关系查询、复杂事件处理（CEP）和图处理。
- en: The DataSet API for Batch Processing
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于批处理的 DataSet API
- en: Flink is a full-fledged batch processor and can be used to implement use cases
    requiring one-off or periodic queries on bounded input data. DataSet programs
    are specified as a series of transformations just like DataStream programs with
    the difference that a DataSet is a bounded data collection. The DataSet API provides
    operators to perform filtering, mapping, selection, joins, and groupings, as well
    as connectors to read and write datasets from and to external systems, such as
    filesystems and databases. Using the DataSet API you can also define iterative
    Flink programs that execute a loop function for a fixed number of steps or until
    a convergence criterion is met.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Flink 是一个完整的批处理处理器，可用于实现对有界输入数据进行一次性或定期查询的用例。DataSet 程序被指定为一系列转换，就像 DataStream
    程序一样，不同之处在于 DataSet 是有界数据集合。DataSet API 提供运算符来执行过滤、映射、选择、连接和分组，以及用于从外部系统（如文件系统和数据库）读取和写入数据集的连接器。使用
    DataSet API，您还可以定义迭代 Flink 程序，该程序执行固定步数的循环函数，或者直到满足收敛标准为止。
- en: Batch jobs are internally represented as dataflow programs and run on the same
    underlying execution runtime as streaming jobs. Currently, the two APIs use separate
    execution environments and cannot be mixed. However, the Flink community is already
    working on unifying the two, and providing a single API for analysis of bounded
    and unbounded data streams in the same program is a priority in Flink’s future
    roadmap.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理作业在内部被表示为数据流程程序，并在与流处理作业相同的底层执行运行时上运行。目前，这两个 API 使用单独的执行环境，并且不能混合使用。然而，Flink
    社区已经在努力统一这两者，并提供单一 API 以分析有界和无界数据流，这是 Flink 未来路线图中的一个重点。
- en: Table API and SQL for Relational Analysis
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Table API 和 SQL 用于关系分析
- en: 'Even though the underlying DataStream and DataSet APIs are separate, you can
    implement unified stream and batch analytics in Flink using its higher-level relational
    APIs: Table API and SQL.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管底层的 DataStream 和 DataSet API 是分离的，但是您可以使用其更高级别的关系 API（Table API 和 SQL）在 Flink
    中实现统一的流和批量分析。
- en: The Table API is a language-integrated query (LINQ) API for Scala and Java.
    Queries can be executed for batch or streaming analysis without modification.
    It offers common operators to write relational queries including selection, projection,
    aggregations, and joins and further has IDE support for autocompletion and syntax
    validation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Table API 是 Scala 和 Java 的语言集成查询（LINQ）API。查询可以在批处理或流分析中执行，无需修改。它提供了常见的运算符来编写关系查询，包括选择、投影、聚合和连接，并且还具有用于自动完成和语法验证的
    IDE 支持。
- en: Flink SQL follows the ANSI SQL standard and leverages [Apache Calcite](https://calcite.apache.org/) for
    query parsing and optimization. Flink provides unified syntax and semantics for
    batch and streaming queries. Due to extensive support for user-defined functions,
    a wide variety of use cases can be covered by SQL. You can embed SQL queries into
    regular Flink DataSet and DataStream programs or directly submit SQL queries to
    a Flink cluster using the SQL CLI client. The CLI client lets you retrieve and
    visualize query results in the command line, which makes it a great tool to try
    out and debug Flink SQL queries or run exploratory queries on streaming or batch
    data. In addition, you can use the CLI client to submit detached queries that
    directly write their results into external storage systems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Flink SQL遵循ANSI SQL标准，并利用[Apache Calcite](https://calcite.apache.org/)进行查询解析和优化。Flink为批处理和流处理查询提供统一的语法和语义。由于对用户定义函数的广泛支持，SQL可以涵盖各种用例。您可以将SQL查询嵌入到常规的Flink
    DataSet和DataStream程序中，或者直接使用SQL CLI客户端向Flink集群提交SQL查询。CLI客户端允许您在命令行中检索和可视化查询结果，这使其成为尝试和调试Flink
    SQL查询或在流处理或批处理数据上运行探索性查询的强大工具。此外，您还可以使用CLI客户端提交分离的查询，直接将结果写入外部存储系统。
- en: FlinkCEP for Complex Event Processing and Pattern Matching
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于复杂事件处理和模式匹配的FlinkCEP
- en: FlinkCEP is a high-level API and library for complex event pattern detection.
    It is implemented on top of the DataStream API and lets you specify patterns you
    want to detect in your stream. Common CEP use cases include financial applications,
    fraud detection, monitoring and alerting in complex systems, and detecting network
    intrusion or suspicious user behavior.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: FlinkCEP是用于复杂事件模式检测的高级API和库。它建立在DataStream API之上，允许您指定要在流中检测的模式。常见的CEP用例包括金融应用程序、欺诈检测、复杂系统中的监控和警报，以及检测网络入侵或可疑用户行为。
- en: Gelly for Graph Processing
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图处理的Gelly
- en: Gelly is Flink’s graph processing API and library. It builds on top of the DataSet
    API and Flink’s support for efficient batch iterations. Gelly provides high-level
    programming abstractions in both Java and Scala to perform graph transformations,
    aggregations, and iterative processing such as vertex-centric and gather-sum-apply.
    It also includes a set of common graph algorithms ready to use.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Gelly是Flink的图处理API和库。它建立在DataSet API和Flink对高效批处理迭代的支持之上。Gelly在Java和Scala中提供高级编程抽象，用于执行图转换、聚合以及诸如顶点为中心和收集-求和-应用等迭代处理。它还包括一组常见的图算法，可供直接使用。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Flink’s high-level APIs and interfaces are well integrated with each other and
    with the DataStream and DataSet APIs so that you can easily mix them and switch
    between libraries and APIs in the same program. For instance, you could extract
    patterns from a DataStream using the CEP library and later use SQL to analyze
    extracted patterns or you could use the Table API to filter and project tables
    into graphs before analyzing them with a graph algorithm from the Gelly library.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Flink的高级API和接口与DataStream和DataSet API以及彼此之间良好集成，因此您可以轻松混合它们，并在同一程序中在库和API之间切换。例如，您可以使用CEP库从DataStream中提取模式，然后使用SQL分析提取的模式，或者您可以使用Table
    API将表筛选和投影为图，然后使用Gelly库中的图算法进行分析。
- en: A Welcoming Community
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个热情好客的社区
- en: 'Apache Flink has a growing and welcoming community with contributors and users
    all around the world. Here are a few resources you can use to ask questions, attend
    Flink-related events, and learn what people use Flink for:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Flink拥有一个不断增长且热情好客的社区，全球贡献者和用户遍布各地。以下是一些资源，您可以使用这些资源提问、参加与Flink相关的活动，并了解人们如何使用Flink：
- en: Mailing lists
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 邮件列表
- en: '[user@flink.apache.org](mailto:user@flink.apache.org) : user support and questions'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[user@flink.apache.org](mailto:user@flink.apache.org)：用户支持和问题'
- en: '[dev@flink.apache.org](mailto:dev@flink.apache.org) : development, release,
    and community discussions'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[dev@flink.apache.org](mailto:dev@flink.apache.org)：开发、发布和社区讨论'
- en: '[community@flink.apache.org](mailto:community@flink.apache.org) : community
    news and meetups'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[community@flink.apache.org](mailto:community@flink.apache.org)：社区新闻和见面会'
- en: Blogs
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 博客
- en: '[*https://flink.apache.org/blog*](https://flink.apache.org/blog/)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*https://flink.apache.org/blog*](https://flink.apache.org/blog/)'
- en: '[*https://www.ververica.com/blog*](https://www.ververica.com/blog)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*https://www.ververica.com/blog*](https://www.ververica.com/blog)'
- en: Meetups and conferences
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 见面会和会议
- en: '[*https://flink-forward.org*](https://flink-forward.org/)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*https://flink-forward.org*](https://flink-forward.org/)'
- en: '[*https://www.meetup.com/topics/apache-flink*](https://www.meetup.com/topics/apache-flink/)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*https://www.meetup.com/topics/apache-flink*](https://www.meetup.com/topics/apache-flink/)'
- en: Again, we hope you walk away from this book with a better understanding of the
    capabilities and possibilities of Apache Flink. We encourage you to become an
    active part of its community.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们希望您通过本书更好地了解 Apache Flink 的能力和可能性。我们鼓励您成为其社区的积极一员。
