- en: Chapter 6\. Clusters
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 群集
- en: I have a very large army and very large dragons.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我有一支非常庞大的军队和非常庞大的龙。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Daenerys Targaryen
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: —丹妮莉丝·坦格利安
- en: Previous chapters focused on using Spark over a single computing instance, your
    personal computer. In this chapter, we introduce techniques to run Spark over
    multiple computing instances, also known as a *computing* cluster. This chapter
    and subsequent ones will introduce and make use of concepts applicable to computing
    clusters; however, it’s not required to use a computing cluster to follow along,
    so you can still use your personal computer. It’s worth mentioning that while
    previous chapters focused on single computing instances, you can also use all
    the data analysis and modeling techniques we presented in a computing cluster
    without changing any code.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的章节侧重于在单个计算实例（您的个人计算机）上使用Spark。在本章中，我们介绍了在多个计算实例（也称为*计算*集群）上运行Spark的技术。本章及后续章节将介绍并利用适用于计算集群的概念；然而，并不需要使用计算集群来跟随我们的内容，因此您仍然可以使用您的个人计算机。值得一提的是，尽管之前的章节侧重于单个计算实例，您也可以在计算集群中使用我们介绍的所有数据分析和建模技术，而无需更改任何代码。
- en: If you already have a Spark cluster in your organization, you could consider
    skipping to [Chapter 7](ch07.html#connections), which teaches you how to connect
    to an existing cluster. Otherwise, if you don’t have a cluster or are considering
    improvements to your existing infrastructure, this chapter introduces the cluster
    trends, managers, and providers available today.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的组织已经拥有一个Spark集群，您可以考虑跳到[第7章](ch07.html#connections)，该章节将教您如何连接到现有的集群。否则，如果您没有集群或者正在考虑改进您现有的基础设施，本章将介绍当今可用的集群趋势、管理者和供应商。
- en: Overview
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: 'There are three major trends in cluster computing worth discussing: *on-premises*,
    *cloud* computing, and *Kubernetes*. Framing these trends over time will help
    us understand how they came to be, what they are, and what their future might
    be. To illustrate this, [Figure 6-1](#clusters-trends) plots these trends over
    time using data from Google trends.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 簇计算中有三个值得讨论的主要趋势：*本地*、*云*计算和*Kubernetes*。随着时间的推移来描绘这些趋势将帮助我们理解它们是如何形成的，它们是什么，以及它们的未来可能性。为了说明这一点，[图 6-1](#clusters-trends)使用来自谷歌趋势的数据，绘制了这些趋势随时间的变化。
- en: For on-premises clusters, you or someone in your organization purchased physical
    computers that were intended to be used for cluster computing. The computers in
    this cluster are made of *off-the-shelf* hardware, meaning that someone placed
    an order to purchase computers usually found on store shelves, or *high-performance*
    hardware, meaning that a computing vendor provided highly customized computing
    hardware, which also comes optimized for high-performance network connectivity,
    power consumption, and so on.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本地集群，您或您的组织中的某人购买了旨在用于集群计算的物理计算机。该集群中的计算机由*现成的*硬件制成，这意味着某人下单购买了通常可以在商店货架上找到的计算机，或者*高性能*硬件，这意味着计算供应商提供了高度定制的计算硬件，还优化了高性能网络连接、功耗消耗等。
- en: '![Google trends for on-premises (mainframe), cloud computing, and Kubernetes](assets/mswr_0601.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![本地（大型机）、云计算和Kubernetes的谷歌趋势](assets/mswr_0601.png)'
- en: Figure 6-1\. Google trends for on-premises (mainframe), cloud computing, and
    Kubernetes
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-1 本地（大型机）、云计算和Kubernetes的谷歌趋势
- en: When purchasing hundreds or thousands of computing instances, it doesn’t make
    sense to keep them in the usual computing case that we are all familiar with;
    instead, it makes sense to stack them as efficiently as possible on top of one
    another to minimize the space the use. This group of efficiently stacked computing
    instances is known as a [*rack*](https://oreil.ly/zKOr-). After a cluster grows
    to thousands of computers, you will also need to host hundreds of racks of computing
    devices; at this scale, you would also need significant physical space to host
    those racks.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当购买数百或数千个计算实例时，将它们放在我们都熟悉的普通计算箱中是没有意义的；相反，将它们尽可能有效地堆叠在一起以减少使用空间是有意义的。这组高效堆叠的计算实例称为[*机架*](https://oreil.ly/zKOr-)。当一个集群增长到数千台计算机时，您还需要托管数百个机架的计算设备；在这个规模下，您还需要显著的物理空间来托管这些机架。
- en: A building that provides racks of computing instances is usually known as a
    *datacenter*. At the scale of a datacenter, you would also need to find ways to
    make the building more efficient, especially the cooling system, power supplies,
    network connectivity, and so on. Since this is time-consuming, a few organizations
    have come together to open source their infrastructure under the [Open Compute
    Project](http://www.opencompute.org/) initiative, which provides a set of datacenter
    blueprints free for anyone to use.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个提供计算实例机架的建筑通常被称为*数据中心*。在数据中心的规模上，你还需要找到方法使建筑更加高效，特别是冷却系统、电源供应、网络连接等。由于这是耗时的，一些组织联合起来在[Open
    Compute Project](http://www.opencompute.org/)倡议下开源了他们的基础设施，提供了一套数据中心蓝图供任何人免费使用。
- en: There is nothing preventing you from building our own datacenter, and, in fact,
    many organizations have followed this path. For instance, Amazon started as an
    online bookstore, but over the years it grew to sell much more than just books.
    Along with its online store growth, its datacenters also grew in size. In 2002,
    Amazon considered [renting servers in their datacenters to the public](https://oreil.ly/Nx3BD),
    and two years later, Amazon Web Services (AWS) launched as a way to let anyone
    rent servers in the company’s datacenters on demand, meaning that you did not
    need to purchase, configure, maintain, or tear down your own clusters; rather,
    you could rent them directly from AWS.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 没有什么能阻止你建造自己的数据中心，事实上，许多组织已经走上了这条路。例如，亚马逊起初是一家在线书店，但随着时间的推移，它发展到不仅仅销售书籍。随着在线商店的增长，其数据中心也在规模上增长。2002年，亚马逊考虑过在他们的数据中心中[向公众出租服务器](https://oreil.ly/Nx3BD)，两年后，亚马逊网络服务(AWS)作为一种方式推出，让任何人都可以按需租用公司数据中心中的服务器，这意味着您不需要购买、配置、维护或拆除自己的集群，而是可以直接从AWS租用它们。
- en: This on-demand compute model is what we know today as *cloud computing*. In
    the cloud, the cluster you use is not owned by you, and it’s not in your physical
    building; instead it’s a datacenter owned and managed by someone else. Today,
    there are many cloud providers in this space, including AWS, Databricks, Google,
    Microsoft, Qubole, and many others. Most cloud computing platforms provide a user
    interface through either a web application or command line to request and manage
    resources.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这种按需计算模型就是我们今天所知的*云计算*。在云中，您使用的集群不是您拥有的，也不在您的物理建筑中；相反，它是由别人拥有和管理的数据中心。今天，这个领域有许多云服务提供商，包括AWS、Databricks、Google、Microsoft、Qubole等等。大多数云计算平台通过Web应用程序或命令行提供用户界面来请求和管理资源。
- en: While the benefits of processing data in the *cloud* were obvious for many years,
    picking a cloud provider had the unintended side effect of locking in organizations
    with one particular provider, making it hard to switch between providers or back
    to on-premises clusters. *Kubernetes*, announced by Google in 2014, is an [open
    source system for managing containerized applications across multiple hosts](https://oreil.ly/u6H5X).
    In practice, it makes it easier to deploy across multiple cloud providers and
    on-premises as well.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管多年来处理云中数据的好处显而易见，但选择云服务提供商却意外地使组织与特定的提供商锁定在一起，使得在不同提供商之间或者回到本地集群之间切换变得困难。*Kubernetes*由Google于2014年宣布，是一种[用于跨多个主机管理容器化应用程序的开源系统](https://oreil.ly/u6H5X)。在实践中，它使得跨多个云提供商和本地环境部署变得更加容易。
- en: In summary, we have seen a transition from on-premises to cloud computing and,
    more recently, Kubernetes. These technologies are often loosely described as the
    *private cloud*, the *public cloud*, and as one of the orchestration services
    that can enable a *hybrid cloud*, respectively. This chapter walks you through
    each cluster computing trend in the context of Spark and R.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们看到了从本地到云计算，以及最近的Kubernetes的过渡。这些技术通常被宽泛地描述为*私有云*、*公有云*和作为可以实现*混合云*的编排服务之一。本章将带您了解Spark和R在各个集群计算趋势中的背景。
- en: On-Premises
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地环境
- en: As mentioned in the overview section, on-premises clusters represent a set of
    computing instances procured and managed by staff members from your organization.
    These clusters can be highly customized and controlled; however, they can also
    incur higher initial expenses and maintenance costs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如概述部分中提到的，在本地集群代表了一组由您组织的工作人员采购和管理的计算实例。这些集群可以高度定制和控制；然而，它们也可能带来更高的初始费用和维护成本。
- en: 'When using on-premises Spark clusters, there are two concepts you should consider:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用本地Spark集群时，有两个概念您应该考虑：
- en: Cluster manager
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 集群管理器
- en: In a similar way as to how an operating system (like Windows or macOS) allows
    you to run multiple applications in the same computer, a cluster manager allows
    multiple applications to be run in the same cluster. You need to choose one yourself
    when working with on-premises clusters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 就像操作系统（如Windows或macOS）允许您在同一台计算机上运行多个应用程序一样，集群管理器允许在同一集群中运行多个应用程序。在处理本地集群时，您需要自行选择一个集群管理器。
- en: Spark distribution
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Spark分发版本
- en: While you can install Spark from the Apache Spark site, many organizations partner
    with companies that can provide support and enhancements to Apache Spark, which
    we often refer to as Spark *distributions*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以从Apache Spark网站安装Spark，但许多组织与能够为Apache Spark提供支持和增强的公司合作，我们通常称之为Spark的*分发版本*。
- en: Managers
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理器
- en: To run Spark within a computing cluster, you will need to run software capable
    of initializing Spark over each physical machine and register all the available
    computing nodes. This software is known as a [cluster manager](https://oreil.ly/Ye4zH).
    The available cluster managers in Spark are *Spark Standalone*, *YARN*, *Mesos*,
    and *Kubernetes*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要在计算集群中运行Spark，您需要运行能够在每台物理机器上初始化Spark并注册所有可用计算节点的软件。这种软件称为[集群管理器](https://oreil.ly/Ye4zH)。Spark中可用的集群管理器包括*Spark
    Standalone*、*YARN*、*Mesos*和*Kubernetes*。
- en: Note
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In distributed systems and clusters literature, we often refer to each physical
    machine as a *compute instance*, *compute node*, *instance*, or *node*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式系统和集群文献中，我们通常将每台物理机器称为*计算实例*、*计算节点*、*实例*或*节点*。
- en: Standalone
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Standalone
- en: In *Spark Standalone*, Spark uses itself as its own cluster manager, which allows
    you to use Spark without installing additional software in your cluster. This
    can be useful if you are planning to use your cluster to run only Spark applications;
    if this cluster is not dedicated to Spark, a generic cluster manager like YARN,
    Mesos, or Kubernetes would be more suitable. The Spark Standalone [documentation](http://bit.ly/307YtM6)
    contains detailed information on configuring, launching, monitoring, and enabling
    high availability, as illustrated in [Figure 6-2](#clusters-spark-standalone).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Spark Standalone*中，Spark使用自身作为其集群管理器，这使您可以在集群中使用Spark而无需安装其他软件。如果计划仅使用集群运行Spark应用程序，则此方法非常有用；如果此集群不专用于Spark，则像YARN、Mesos或Kubernetes这样的通用集群管理器更适合。Spark
    Standalone的[文档](http://bit.ly/307YtM6)详细介绍了配置、启动、监控和启用高可用性，如[图6-2](#clusters-spark-standalone)所示。
- en: However, since Spark Standalone is contained within a Spark installation, by
    completing [Chapter 2](ch02.html#starting), you have now a Spark installation
    available that you can use to initialize a local Spark Standalone cluster on your
    own machine. In practice, you would want to start the worker nodes on different
    machines, but for simplicity, we present the code to start a standalone cluster
    on a single machine.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，由于Spark Standalone包含在Spark安装中，在完成[第2章](ch02.html#starting)后，您现在可以使用自己的机器上的本地Spark
    Standalone集群初始化可用的Spark安装。实际上，您可能希望在不同的机器上启动工作节点，但为简单起见，我们提供了在单台机器上启动独立集群的代码。
- en: 'First, retrieve the `SPARK_HOME` directory by running **`spark_home_dir()`**,
    and then start the master node and a worker node as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过运行**`spark_home_dir()`**来获取`SPARK_HOME`目录，然后按以下步骤启动主节点和工作节点：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![Spark Standalone website](assets/mswr_0602.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![Spark Standalone网站](assets/mswr_0602.png)'
- en: Figure 6-2\. Spark Standalone website
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-2\. Spark Standalone网站
- en: The previous command initializes the master node. You can access the master
    node interface at [*localhost:8080*](http://localhost:8080), as captured in [Figure 6-3](#clusters-spark-standalone-web).
    Note that the Spark master URL is specified as *spark://address:port*; you will
    need this URL to initialize worker nodes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令初始化了主节点。您可以在[*localhost:8080*](http://localhost:8080)访问主节点界面，如[图6-3](#clusters-spark-standalone-web)所示。请注意，Spark主URL指定为*spark://address:port*；您将需要此URL来初始化工作节点。
- en: 'We then can initialize a single worker using the master URL; however, you could
    use a similar approach to initialize multiple workers by running the code multiple
    times and, potentially, across different machines:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用主URL初始化单个工作节点；但是，您可以通过多次运行代码和潜在地跨不同机器初始化多个工作节点：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![The Spark Standalone web interface](assets/mswr_0603.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![Spark Standalone网页界面](assets/mswr_0603.png)'
- en: Figure 6-3\. The Spark Standalone web interface
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-3\. Spark Standalone网页界面
- en: There is one worker register in Spark Standalone. Click the link to this worker
    node to view details for this particular worker, like available memory and cores,
    as shown in [Figure 6-4](#clusters-spark-standalone-webui).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark独立模式中有一个工作节点注册。点击该工作节点的链接，以查看该特定工作节点的详细信息，如[图6-4](#clusters-spark-standalone-webui)所示。
- en: '![Spark Standalone worker web interface](assets/mswr_0604.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![Spark独立工作节点Web界面](assets/mswr_0604.png)'
- en: Figure 6-4\. Spark Standalone worker web interface
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-4. Spark独立工作节点Web界面
- en: 'After you are done performing computations in this cluster, you will need to
    stop the master and worker nodes. You can use the `jps` command to identify the
    process numbers to terminate. In the following example, `15330` and `15353` are
    the processes that you can terminate to finalize this cluster. To terminate a
    process, you can use `system("Taskkill /PID ##### /F")` in Windows, or `system("kill
    -9 #####")` in macOS and Linux.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '当你完成了在这个集群中的计算后，你需要停止主节点和工作节点。你可以使用`jps`命令来识别需要终止的进程号。在以下示例中，`15330`和`15353`是你可以终止的进程，以完成集群的最终操作。要终止一个进程，你可以在Windows中使用`system("Taskkill
    /PID ##### /F")`，或者在macOS和Linux中使用`system("kill -9 #####")`。'
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can follow a similar approach to configure a cluster by running the initialization
    code over each machine in the cluster.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照类似的方法来配置集群，通过在集群中的每台机器上运行初始化代码来实现。
- en: While it’s possible to initialize a simple standalone cluster, configuring a
    proper Spark Standalone cluster that can recover from computer restarts and failures,
    and supports multiple users, permissions, and so on, is usually a much longer
    process that falls beyond the scope of this book. The following sections present
    several alternatives that can be much easier to manage on-premises or through
    cloud services. We will start by introducing YARN.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以初始化一个简单的独立集群，但配置一个能够从计算机重启和故障中恢复，并支持多个用户、权限等的合适的Spark独立集群通常是一个更长的过程，超出了本书的范围。接下来的章节将介绍几种在本地或通过云服务上更易于管理的替代方案。我们将从介绍YARN开始。
- en: YARN
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: YARN
- en: Hadoop YARN, or simply YARN, as it is commonly called, is the resource manager
    of the Hadoop project. It was originally developed in the Hadoop project but was
    refactored into its own project in Hadoop 2\. As we mentioned in [Chapter 1](ch01.html#intro),
    Spark was built to speed up computation over Hadoop, and therefore it’s very common
    to find Spark installed on Hadoop clusters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop YARN，简称YARN，是Hadoop项目的资源管理器。它最初在Hadoop项目中开发，但在Hadoop 2中重构为独立项目。正如我们在[第一章](ch01.html#intro)中提到的，Spark是为了加速在Hadoop上的计算而构建的，因此在安装了Hadoop集群的地方很常见找到Spark。
- en: One advantage of YARN is that it is likely to be already installed in many existing
    clusters that support Hadoop; this means that you can easily use Spark with many
    existing Hadoop clusters without requesting any major changes to the existing
    cluster infrastructure. It is also very common to find Spark deployed in YARN
    clusters since many started out as Hadoop clusters and were eventually upgraded
    to also support Spark.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: YARN的一个优势是，它很可能已经安装在许多支持Hadoop的现有集群中；这意味着你可以在不需要对现有集群基础设施做出任何重大更改的情况下，轻松地在许多现有的Hadoop集群上使用Spark。由于许多集群最初是Hadoop集群，随后升级以支持Spark，因此在YARN集群中部署Spark也是非常常见的。
- en: 'You can submit YARN applications in two modes: *yarn-client* and *yarn-cluster*.
    In yarn-cluster mode the driver is running remotely (potentially), while in yarn-client
    mode, the driver is running locally. Both modes are supported, and we explain
    them further in [Chapter 7](ch07.html#connections).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以以两种模式提交YARN应用程序：*yarn-client*和*yarn-cluster*。在yarn-cluster模式下，驱动程序可能是远程运行的，而在yarn-client模式下，驱动程序是在本地运行的。两种模式都受支持，我们将在[第7章](ch07.html#connections)中进一步解释它们。
- en: YARN provides a resource management user interface useful to access logs, monitor
    available resources, terminate applications, and more. After you connect to Spark
    from R, you will be able to manage the running application in YARN, as shown in
    [Figure 6-5](#clusters-hadoop-yarn-site).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: YARN提供了一个资源管理用户界面，用于访问日志、监控可用资源、终止应用程序等。当你从R语言连接到Spark后，你将能够在YARN中管理运行的应用程序，如[图6-5](#clusters-hadoop-yarn-site)所示。
- en: Since YARN is the cluster manager from the Hadoop project, you can find YARN’s
    documentation at [hadoop.apache.org](http://bit.ly/2TDGsCX). You can also reference
    the “Running Spark on YARN” guide at [spark.apache.org](http://bit.ly/306WsQx).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于YARN是Hadoop项目的集群管理器，你可以在[hadoop.apache.org](http://bit.ly/2TDGsCX)找到YARN的文档。你还可以参考在[spark.apache.org](http://bit.ly/306WsQx)上的“在YARN上运行Spark”指南。
- en: '![YARN’s Resource Manager running a sparklyr application](assets/mswr_0605.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![YARN的资源管理器运行一个sparklyr应用程序](assets/mswr_0605.png)'
- en: Figure 6-5\. YARN’s Resource Manager running a sparklyr application
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-5. YARN的资源管理器运行一个sparklyr应用程序
- en: Apache Mesos
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Apache Mesos
- en: Apache Mesos is an open source project to manage computer clusters. Mesos began
    as a research project in the UC Berkeley RAD Lab. It makes use of Linux [Cgroups](http://bit.ly/2Z9KEeW)
    to provide isolation for CPU, memory, I/O, and file system access.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Mesos是一个管理计算机集群的开源项目。Mesos最初是UC Berkeley RAD实验室的一个研究项目。它利用Linux的[Cgroups](http://bit.ly/2Z9KEeW)来提供CPU、内存、I/O和文件系统访问的隔离。
- en: Mesos, like YARN, supports executing many cluster frameworks, including Spark.
    However, one advantage particular to Mesos is that it allows cluster frameworks
    like Spark to implement custom task schedulers. A scheduler is the component that
    coordinates in a cluster which applications are allocated execution time and which
    resources are assigned to them. Spark uses a [coarse-grained scheduler](https://oreil.ly/9WQvg),
    which schedules resources for the duration of the application; however, other
    frameworks might use Mesos’ fine-grained scheduler, which can increase the overall
    efficiency in the cluster by scheduling tasks in shorter intervals, allowing them
    to share resources between them.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos和YARN一样，支持执行许多集群框架，包括Spark。然而，Mesos的一个特定优势在于它允许像Spark这样的集群框架实现自定义的任务调度器。调度器是集群中协调应用程序分配执行时间和分配资源的组件。Spark使用[粗粒度调度器](https://oreil.ly/9WQvg)，为应用程序的整个执行周期安排资源；然而，其他框架可能使用Mesos的细粒度调度器，通过在更短的间隔内调度任务来增加集群的整体效率，使它们能够共享资源。
- en: Mesos provides a web interface to manage your running applications, resources,
    and so on. After connecting to Spark from R, your application will be registered
    like any other application running in Mesos. [Figure 6-6](#clusters-mesos-webui)
    shows a successful connection to Spark from R.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos提供了一个Web界面来管理正在运行的应用程序、资源等。在从R连接到Spark后，您的应用程序将像在Mesos中运行的任何其他应用程序一样注册。[图
    6-6](#clusters-mesos-webui)展示了成功从R连接到Spark的情况。
- en: Mesos is an Apache project with its documentation available at [mesos.apache.org](https://mesos.apache.org/).
    The [*Running Spark on Mesos*](http://bit.ly/31H4LCT) guide is also a great resource
    if you choose to use Mesos as your cluster manager.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos是一个Apache项目，其文档可以在[mesos.apache.org](https://mesos.apache.org/)找到。如果选择将Mesos作为您的集群管理器，[*在Mesos上运行Spark*](http://bit.ly/31H4LCT)指南也是一个很好的资源。
- en: '![Mesos web interface running Spark from R](assets/mswr_0606.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![Mesos web界面运行Spark从R](assets/mswr_0606.png)'
- en: Figure 6-6\. Mesos web interface running Spark and R
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-6. Mesos web界面运行Spark和R
- en: Distributions
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发行版
- en: You can use a cluster manager in on-premises clusters, as described in the previous
    section; however, many organizations—including, but not limited to, Apache Spark—choose
    to partner with companies providing additional management software, services,
    and resources to help manage applications in their cluster. Some of the on-premises
    cluster providers include *Cloudera*, *Hortonworks*, and *MapR*, which we briefly
    introduce next.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本地集群中使用集群管理器，如前一节所述；然而，许多组织，包括但不限于Apache Spark，选择与提供额外管理软件、服务和资源的公司合作来管理其集群中的应用程序。一些本地集群提供商包括*Cloudera*、*Hortonworks*和*MapR*，我们将在下文简要介绍。
- en: '*Cloudera*, Inc., is a US-based software company that provides Apache Hadoop
    and Apache Spark–based software, support and services, and training to business
    customers. Cloudera’s hybrid open source Apache Hadoop distribution, Cloudera
    Distribution Including Apache Hadoop (CDH), targets enterprise-class deployments
    of that technology. Cloudera donates more than 50% of its engineering output to
    the various Apache-licensed open source projects (Apache Hive, Apache Avro, Apache
    HBase, and so on) that combine to form the Apache Hadoop platform. [Cloudera](http://bit.ly/2KJmcfe)
    is also a sponsor of the Apache Software Foundation.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*Cloudera*，Inc.，是一家总部位于美国的软件公司，提供基于Apache Hadoop和Apache Spark的软件、支持和服务以及培训给商业客户。Cloudera的混合开源Apache
    Hadoop发行版，Cloudera分布包括Apache Hadoop（CDH），针对企业级部署该技术。Cloudera向组成Apache Hadoop平台的各种Apache许可的开源项目（如Apache
    Hive、Apache Avro、Apache HBase等）捐赠超过50%的工程输出。[Cloudera](http://bit.ly/2KJmcfe)也是Apache软件基金会的赞助商。'
- en: Cloudera clusters make use of [*parcels*](http://bit.ly/33LHpxU), which are
    binary distributions containing program files and metadata. Spark happens to be
    installed as a parcel in Cloudera. It’s beyond the scope of this book to present
    how to configure Cloudera clusters, but resources and documentation can be found
    under [cloudera.com](http://bit.ly/33yUUkp), and [“Introducing sparklyr, an R
    Interface for Apache Spark”](http://bit.ly/2HbAtjY) on the Cloudera blog.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Cloudera 集群使用 [*parcels*](http://bit.ly/33LHpxU)，这些是包含程序文件和元数据的二进制分发物。在 Cloudera
    中，Spark 安装为一个 parcel。本书不涵盖如何配置 Cloudera 集群，但资源和文档可以在 [cloudera.com](http://bit.ly/33yUUkp)
    和 Cloudera 博客上的 [“Introducing sparklyr, an R Interface for Apache Spark”](http://bit.ly/2HbAtjY)
    找到。
- en: Cloudera provides the Cloudera Manager web interface to manage resources, services,
    parcels, diagnostics, and more. [Figure 6-7](#clusters-cloudera-manager-spark)
    shows a Spark parcel running in Cloudera Manager, which you can later use to connect
    from R.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Cloudera 提供 Cloudera Manager 网页界面，用于管理资源、服务、parcels、诊断等等。[图 6-7](#clusters-cloudera-manager-spark)
    展示了在 Cloudera Manager 中运行的一个 Spark parcel，稍后可以用来从 R 进行连接。
- en: '![Cloudera Manager running Spark parcel](assets/mswr_0607.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![Cloudera Manager 运行 Spark parcel](assets/mswr_0607.png)'
- en: Figure 6-7\. Cloudera Manager running Spark parcel
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-7\. Cloudera Manager 运行 Spark parcel
- en: '[`sparklyr` is certified with Cloudera](http://bit.ly/2z1yydc), meaning that
    Cloudera’s support is aware of `sparklyr` and can be effective helping organizations
    that are using Spark and R. [Table 6-1](#table0601) summarizes the versions currently
    certified.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[`sparklyr` 已与 Cloudera 认证](http://bit.ly/2z1yydc)，这意味着 Cloudera 的支持团队已了解 `sparklyr`，并能够有效地帮助使用
    Spark 和 R 的组织。[表 6-1](#table0601) 总结了目前认证的版本。'
- en: Table 6-1\. Versions of sparklyr certified with Cloudera
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-1\. 与 Cloudera 认证的 sparklyr 版本
- en: '| Cloudera version | Product | Version | Components | Kerberos |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| Cloudera 版本 | 产品 | 版本 | 组件 | Kerberos |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| CDH5.9 | sparklyr | 0.5 | HDFS, Spark | Yes |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| CDH5.9 | sparklyr | 0.5 | HDFS, Spark | Yes |'
- en: '| CDH5.9 | sparklyr | 0.6 | HDFS, Spark | Yes |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| CDH5.9 | sparklyr | 0.6 | HDFS, Spark | Yes |'
- en: '| CDH5.9 | sparklyr | 0.7 | HDFS, Spark | Yes |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| CDH5.9 | sparklyr | 0.7 | HDFS, Spark | Yes |'
- en: '*Hortonworks* is a big data software company based in Santa Clara, California.
    The company develops, supports, and provides expertise on an expansive set of
    entirely open source software designed to manage data and processing for everything
    from Internet of Things (IoT) to advanced analytics and machine learning. [Hortonworks](http://bit.ly/2KTufpV)
    believes that it is a data management company bridging the cloud and the datacenter.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*Hortonworks* 是一家总部位于加利福尼亚州圣克拉拉的大数据软件公司。该公司开发、支持并提供广泛的完全开源软件，旨在管理从物联网（IoT）到高级分析和机器学习的数据和处理。[Hortonworks](http://bit.ly/2KTufpV)
    认为自己是一家数据管理公司，架设云端与数据中心之间的桥梁。'
- en: '[Hortonworks partnered with Microsoft](http://bit.ly/2NbfuBH) to improve support
    in Microsoft Windows for Hadoop and Spark, which used to be a differentiation
    point from Cloudera; however, comparing Hortonworks and Cloudera is less relevant
    today since the [companies merged in January 2019](http://bit.ly/2Mk1UMt). Despite
    the merger, support for the Cloudera and Hortonworks Spark distributions are still
    available. Additional resources to configure Spark under Hortonworks are available
    at [hortonworks.com](http://bit.ly/2Z8M8Kh).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hortonworks 与 Microsoft 合作](http://bit.ly/2NbfuBH) 提升了在 Microsoft Windows
    上对 Hadoop 和 Spark 的支持，这曾是与 Cloudera 的区别点；然而，比较 Hortonworks 和 Cloudera 在今天已不那么相关，因为这两家公司于
    2019 年 1 月 [合并](http://bit.ly/2Mk1UMt)。尽管合并，Cloudera 和 Hortonworks 的 Spark 发行版仍可获得支持。有关在
    Hortonworks 下配置 Spark 的额外资源，请访问 [hortonworks.com](http://bit.ly/2Z8M8Kh)。'
- en: '*MapR* is a business software company headquartered in Santa Clara, California.
    [MapR](http://bit.ly/33DU8Cs) provides access to a variety of data sources from
    a single computer cluster, including big data workloads such as Apache Hadoop
    and Apache Spark, a distributed file system, a multimodel database management
    system, and event stream processing, combining analytics in real time with operational
    applications. Its technology runs on both commodity hardware and public cloud
    computing services.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*MapR* 是一家总部位于加利福尼亚州圣克拉拉的商业软件公司。[MapR](http://bit.ly/33DU8Cs)提供从单个计算机集群访问各种数据源的服务，包括
    Apache Hadoop 和 Apache Spark 等大数据工作负载，分布式文件系统，多模型数据库管理系统以及事件流处理，将实时分析与操作应用程序结合在一起。其技术可在商品硬件和公共云计算服务上运行。'
- en: Cloud
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云
- en: If you have neither an on-premises cluster nor spare machines to reuse, starting
    with a cloud cluster can be quite convenient since it will allow you to access
    a proper cluster in a matter of minutes. This section briefly mentions some of
    the major cloud infrastructure providers and gives you resources to help you get
    started if you choose to use a cloud provider.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你既没有本地集群也没有多余的机器可供重复使用，从云集群开始会非常方便，因为它将允许你在几分钟内访问一个合适的集群。本节简要提到了一些主要的云基础设施提供商，并为你提供了资源，以帮助你开始使用云服务提供商。
- en: In cloud services, the compute instances are billed for as long the Spark cluster
    runs; your billing starts when the cluster launches, and it stops when the cluster
    stops. This cost needs to be multiplied by the number of instances reserved for
    your cluster. So, for instance, if a cloud provider charges $1.00 per compute
    instance per hour, and you start a three-node cluster that you use for one hour
    and 10 minutes, it is likely that you’ll receive a bill for $1.00 x 2 hours x
    3 nodes = $6.00\. Some cloud providers charge per minute, but at least you can
    rely on all of them charging per compute hour.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在云服务中，计算实例的计费时间与 Spark 集群运行时间一致；你的计费从集群启动开始算起，集群停止时结束。这项费用需要按照为你的集群预留的实例数量进行乘算。例如，如果一个云服务提供商每小时每个计算实例收费
    $1.00，你启动了一个三节点的集群并使用了一小时零十分钟，那么你可能会收到一张 $1.00 x 2 小时 x 3 节点 = $6.00 的账单。有些云服务提供商按分钟计费，但至少你可以依赖它们都是按计算小时计费。
- en: Be aware that, while computing costs can be quite low for small clusters, accidentally
    leaving a cluster running can cause significant billing expenses. Therefore, it’s
    worth taking the extra time to check twice that your cluster is terminated when
    you no longer need it. It’s also a good practice to monitor costs daily while
    using clusters to make sure your expectations match the daily bill.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管小规模集群的计算成本可能非常低，但意外地让集群保持运行可能导致显著的计费费用。因此，在你不再需要集群时，花额外的时间检查两次确保集群已经终止是值得的。在使用集群时，每天监控成本以确保你的预期与每日账单相匹配也是一个好习惯。
- en: From past experience, you should also plan to request compute resources in advance
    while dealing with large-scale projects; various cloud providers will not allow
    you to start a cluster with hundreds of machines before requesting them explicitly
    through a support request. While this can be cumbersome, it’s also a way to help
    you control costs in your organization.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 根据过去的经验，在处理大规模项目时，你还应提前请求计算资源；各种云服务提供商通常不允许你在通过支持请求明确要求之前启动数百台机器的集群。虽然这可能有些繁琐，但这也是帮助你控制组织成本的一种方式。
- en: Since the cluster size is flexible, it is a good practice to start with small
    clusters and scale compute resources as needed. Even if you know in advance that
    a cluster of significant size will be required, starting small provides an opportunity
    to troubleshoot issues at a lower cost since it’s unlikely that your data analysis
    will run at scale flawlessly on the first try. As a rule of thumb, grow the instances
    exponentially; if you need to run a computation over an eight-node cluster, start
    with one node and an eighth of the entire dataset, then two nodes with a fourth,
    then four nodes with half of the dataset, and then, finally, eight nodes and the
    entire dataset. As you become more experienced, you’ll develop a good sense of
    how to troubleshoot issues, and of the size of the required cluster, and you’ll
    be able to skip intermediate steps, but for starters, this is a good practice
    to follow.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 由于集群大小是灵活的，最佳实践是从小集群开始，根据需要扩展计算资源。即使你事先知道需要一个大型集群，从小开始也提供了以较低成本解决问题的机会，因为第一次尝试时你的数据分析不太可能无缺陷地在大规模上运行。作为经验法则，指数级增加实例；如果你需要在八节点集群上运行计算，从一个节点和八分之一的整个数据集开始，然后两个节点和四分之一，然后四个节点和半个数据集，最后八个节点和整个数据集。随着经验的积累，你会培养出良好的问题解决感觉，了解所需集群的大小，并能跳过中间步骤，但作为初学者，这是一个很好的实践方法。
- en: You can also use a cloud provider to acquire bare computing resources and then
    install the on-premises distributions presented in the previous section yourself;
    for instance, you can run the Cloudera distribution on Amazon Elastic Compute
    Cloud (Amazon EC2). This model would avoid procuring colocated hardware, but it
    still allows you to closely manage and customize your cluster. This book presents
    an overview of only the fully managed Spark services available by cloud providers;
    however, you can usually find with ease instructions online on how to install
    on-premises distributions in the cloud.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用云提供商获取裸计算资源，然后自行安装前一节介绍的本地分布；例如，您可以在Amazon Elastic Compute Cloud（Amazon
    EC2）上运行Cloudera分布。这种模型避免了采购共同托管的硬件，但仍允许您紧密管理和自定义集群。本书仅介绍云提供商提供的完全托管的Spark服务概述；不过，您通常可以轻松找到在线有关如何在云中安装本地分布的说明。
- en: Some of the major providers of cloud computing infrastructure are Amazon, Databricks,
    Google, IBM, and Microsoft and Qubole. The subsections that follow briefly introduce
    each one.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一些主要的云计算基础设施提供商包括Amazon、Databricks、Google、IBM、Microsoft和Qubole。接下来的小节简要介绍了每个提供商。
- en: Amazon
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon
- en: Amazon provides cloud services through [AWS](https://aws.amazon.com/); more
    specifically, it provides an on-demand Spark cluster through [Amazon EMR](https://aws.amazon.com/emr/).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon通过[AWS](https://aws.amazon.com/)提供云服务；具体来说，它通过[Amazon EMR](https://aws.amazon.com/emr/)提供按需Spark集群。
- en: 'Detailed instructions on using R with Amazon EMR were published under Amazon’s
    Big Data blog in a post called [“Running sparklyr on Amazon EMR”](https://amzn.to/2OYWMQ5).
    This post introduced the launch of `sparklyr` and instructions to configure Amazon
    EMR clusters with `sparklyr`. For instance, it suggests you can use the [Amazon
    Command Line Interface](https://aws.amazon.com/cli/) to launch a cluster with
    three nodes, as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Amazon EMR与R的详细说明已在Amazon的大数据博客中发布，名为[“在Amazon EMR上运行sparklyr”](https://amzn.to/2OYWMQ5)。该文章介绍了`sparklyr`的启动和配置Amazon
    EMR集群的说明。例如，它建议您可以使用[Amazon命令行界面](https://aws.amazon.com/cli/)启动一个包含三个节点的集群：
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can then see the cluster launching and then eventually running under the
    AWS portal, as illustrated in [Figure 6-8](#clusters-amazon-emr-launching).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 您随后可以在AWS门户下看到集群的启动和运行情况，如[图 6-8](#clusters-amazon-emr-launching)所示。
- en: You then can navigate to the Master Public DNS and find RStudio under port 8787—for
    example, `ec2-12-34-567-890.us-west-1.compute.amazonaws.com:8787`—and then log
    in with user `hadoop` and password `password`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以导航到主公共DNS并在端口8787下找到RStudio，例如`ec2-12-34-567-890.us-west-1.compute.amazonaws.com:8787`，然后使用用户名`hadoop`和密码`password`登录。
- en: '![Launching an Amazon EMR cluster](assets/mswr_0608.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![启动Amazon EMR集群](assets/mswr_0608.png)'
- en: Figure 6-8\. Launching an Amazon EMR cluster
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-8\. 启动Amazon EMR集群
- en: It is also possible to launch the Amazon EMR cluster using the web interface;
    the same introductory post contains additional details and walkthroughs specifically
    designed for Amazon EMR.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过Web界面启动Amazon EMR集群；同一篇介绍性文章包含了专门为Amazon EMR设计的额外细节和操作说明。
- en: Remember to turn off your cluster to avoid unnecessary charges and use appropriate
    security restrictions when starting Amazon EMR clusters for sensitive data analysis.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 记得关闭您的集群，以避免不必要的费用，并在启动Amazon EMR集群进行敏感数据分析时使用适当的安全限制。
- en: Regarding cost, you can find the most up-to-date information at [Amazon EMR
    Pricing](https://amzn.to/2YRGb5r). [Table 6-2](#table0602) presents some of the
    instance types available in the `us-west-1` region (as of this writing); this
    is meant to provide a glimpse of the resources and costs associated with cloud
    processing. Notice that the “EMR price is in addition to the Amazon EC2 price
    (the price for the underlying servers).”
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 关于成本，您可以在[Amazon EMR定价](https://amzn.to/2YRGb5r)处找到最新信息。[表 6-2](#table0602)
    展示了在`us-west-1`地区（截至本文撰写时）可用的一些实例类型；这旨在提供云处理资源和成本的一瞥。请注意，“EMR价格另外加上Amazon EC2价格（即底层服务器的价格）。”
- en: Table 6-2\. Amazon EMR pricing information
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-2\. Amazon EMR定价信息
- en: '| Instance | CPUs | Memory | Storage | EC2 cost | EMR cost |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 实例 | CPU | 内存 | 存储 | EC2成本 | EMR成本 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| c1.medium | 2 | 1.7 GB | 350 GB | $0.148/hour | $0.030/hour |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| c1.medium | 2 | 1.7 GB | 350 GB | 每小时$0.148 | 每小时$0.030 |'
- en: '| m3.2xlarge | 8 | 30 GB | 160 GB | $0.616/hour | $0.140/hour |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| m3.2xlarge | 8 | 30 GB | 160 GB | 每小时$0.616 | 每小时$0.140 |'
- en: '| i2.8xlarge | 32 | 244 GB | 6400 GB | $7.502/hour | $0.270/hour |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| i2.8xlarge | 32 | 244 GB | 6400 GB | 每小时$7.502 | 每小时$0.270 |'
- en: Note
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: We are presenting only a subset of the available compute instances for Amazon
    and subsequent cloud providers as of 2019; however, note that hardware (CPU speed,
    hard drive speed, etc.) varies between vendors and locations; therefore, you can’t
    use these hardware tables as an accurate price comparison. Accurate comparison
    would require running your particular workloads and considering other aspects
    beyond compute instance cost.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅展示了截至 2019 年 Amazon 和其他云服务提供商提供的计算实例的部分列表；然而，请注意硬件（CPU 速度、硬盘速度等）在供应商和地点之间会有所不同；因此，您不能将这些硬件表格用作准确的价格比较依据。准确的比较需要运行特定的工作负载并考虑计算实例成本之外的其他因素。
- en: Databricks
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Databricks
- en: '[Databricks](https://databricks.com) is a company founded by the creators of
    Apache Spark, whose aim is to help clients with cloud-based big data processing
    using Spark. Databricks grew out of the [AMPLab](https://oreil.ly/W2Eoe) project
    at the University of California, Berkeley.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[Databricks](https://databricks.com) 是由 Apache Spark 的创始人创建的公司，旨在帮助客户通过 Spark
    进行基于云的大数据处理。Databricks 起源于加州大学伯克利分校的 [AMPLab](https://oreil.ly/W2Eoe) 项目。'
- en: Databricks provides enterprise-level cluster computing plans as well as a free/community
    tier to explore functionality and become familiar with their environment.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 提供企业级集群计算方案以及用于探索功能并熟悉其环境的免费/社区层级。
- en: After a cluster is launched, you can use R and `sparklyr` from Databricks notebooks
    following the steps provided in [Chapter 2](ch02.html#starting) or by installing
    [RStudio on Databricks](http://bit.ly/2KCDax6). [Figure 6-9](#clusters-databricks-notebook)
    shows a Databricks notebook using Spark through `sparkylyr`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动集群后，您可以按照 [第二章](ch02.html#starting) 中提供的步骤，在 Databricks 笔记本中使用 R 和 `sparklyr`，或者通过在
    [Databricks 上安装 RStudio](http://bit.ly/2KCDax6) 来进行操作。[图 6-9](#clusters-databricks-notebook)
    展示了使用 `sparkylyr` 在 Databricks 笔记本上运行 Spark 的情况。
- en: '![Databricks community notebook running sparklyr](assets/mswr_0609.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![Databricks 社区笔记本运行 sparklyr](assets/mswr_0609.png)'
- en: Figure 6-9\. Databricks community notebook running sparklyr
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-9\. Databricks 社区笔记本运行 sparklyr
- en: Additional resources are available under the Databricks Engineering Blog post
    [“Using sparklyr in Databricks”](http://bit.ly/2N59jyR) and the [Databricks documentation
    for `sparklyr`](http://bit.ly/2MkOYWC).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 额外资源可在 Databricks 工程博客文章 [“在 Databricks 中使用 sparklyr”](http://bit.ly/2N59jyR)
    和 [Databricks `sparklyr` 文档](http://bit.ly/2MkOYWC) 中找到。
- en: You can find the latest pricing information at [*databricks.com/product/pricing*](http://bit.ly/305Rnrt).
    [Table 6-3](#Table0603) lists the available plans as of this writing.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [*databricks.com/product/pricing*](http://bit.ly/305Rnrt) 查找最新的定价信息。[表
    6-3](#Table0603) 列出了撰写本文时提供的计划。
- en: Table 6-3\. Databricks procong information
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-3\. Databricks 产品信息
- en: '| Plan | Basic | Data engineering | Data analytics |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 方案 | 基础 | 数据工程 | 数据分析 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| AWS Standard | $0.07/DBU | $0.20/DBU | $0.40/DBU |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| AWS 标准 | $0.07/DBU | $0.20/DBU | $0.40/DBU |'
- en: '| Azure Standard |  | $0.20/DBU | $0.40/DBU |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| Azure 标准 |  | $0.20/DBU | $0.40/DBU |'
- en: '| Azure Premium |  | $0.35/DBU | $0.55/DBU |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| Azure 高级 |  | $0.35/DBU | $0.55/DBU |'
- en: Notice that pricing is based on cost of DBU per hour. From Databricks, “a [Databricks
    Unit](https://oreil.ly/3muQq) (DBU) is a unit of Apache Spark processing capability
    per hour. For a varied set of instances, DBUs are a more transparent way to view
    usage instead of the node-hour.”
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，定价是基于每小时的 DBU 成本。根据 Databricks 的说法，“[Databricks Unit](https://oreil.ly/3muQq)（DBU）是每小时的
    Apache Spark 处理能力单位。对于多种实例，DBU 是一种更透明的使用方式，而不是节点小时。”
- en: Google
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google
- en: Google provides Google Cloud Dataproc as a cloud-based managed Spark and Hadoop
    service offered on Google Cloud Platform (GCP). Dataproc utilizes many GCP technologies,
    such as Google Compute Engine and Google Cloud Storage, to offer fully managed
    clusters running popular data processing frameworks such as Apache Hadoop and
    Apache Spark.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Google 提供 Google Cloud Dataproc 作为一种基于云的托管 Spark 和 Hadoop 服务，提供在 Google Cloud
    Platform（GCP）上运行的服务。Dataproc 利用许多 GCP 技术，如 Google Compute Engine 和 Google Cloud
    Storage，为运行流行的数据处理框架（如 Apache Hadoop 和 Apache Spark）的完全托管集群提供支持。
- en: You can easily create a cluster from the Google Cloud console or the Google
    Cloud command-line interface (CLI) as illustrated in [Figure 6-10](#clusters-google-dataproc-launch).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过 Google Cloud 控制台或 Google Cloud 命令行界面（CLI）轻松创建集群，如 [图 6-10](#clusters-google-dataproc-launch)
    所示。
- en: '![Launching a Dataproc cluster](assets/mswr_0610.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![启动 Dataproc 集群](assets/mswr_0610.png)'
- en: Figure 6-10\. Launching a Dataproc cluster
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-10\. 启动 Dataproc 集群
- en: 'After you’ve created your cluster, ports can be forwarded to allow you to access
    this cluster from your machine—for instance, by launching Chrome to make use of
    this proxy and securely connect to the Dataproc cluster. Configuring this connection
    looks as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 创建集群后，可以将端口转发，以便从您的机器访问此集群，例如，通过启动Chrome来使用此代理并安全连接到Dataproc集群。配置此连接如下所示：
- en: '[PRE5]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: There are various [tutorials available](http://bit.ly/2OYyo18) (cloud.google.com/dataproc/docs/tutorials),
    including a comprehensive [tutorial to configure RStudio and `sparklyr`](http://bit.ly/2MhSgKg).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种[可用的教程](http://bit.ly/2OYyo18)（cloud.google.com/dataproc/docs/tutorials），包括一个详细的[tutorial配置RStudio和`sparklyr`](http://bit.ly/2MhSgKg)。
- en: You can find the latest pricing information at [*cloud.google.com/dataproc/pricing*](http://bit.ly/31J0uyC).
    In [Table 6-4](#Table0604) notice that the cost is split between compute engine
    and a dataproc premium.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[*cloud.google.com/dataproc/pricing*](http://bit.ly/31J0uyC)找到最新的定价信息。在[表6-4](#Table0604)中请注意，成本分为计算引擎和Dataproc高级部分。
- en: Table 6-4\. Google Cloud Dataproc pricing information
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-4\. Google Cloud Dataproc定价信息
- en: '| Instance | CPUs | Memory | Compute engine | Dataproc premium |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 实例 | CPU | 内存 | 计算引擎 | Dataproc高级部分 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| n1-standard-1 | 1 | 3.75 GB | $0.0475/hour | $0.010/hour |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| n1-standard-1 | 1 | 3.75 GB | $0.0475/小时 | $0.010/小时 |'
- en: '| n1-standard-8 | 8 | 30 GB | $0.3800/hour | $0.080/hour |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| n1-standard-8 | 8 | 30 GB | $0.3800/小时 | $0.080/小时 |'
- en: '| n1-standard-64 | 64 | 244 GB | $3.0400/hour | $0.640/hour |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| n1-standard-64 | 64 | 244 GB | $3.0400/小时 | $0.640/小时 |'
- en: IBM
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IBM
- en: IBM cloud computing is a set of cloud computing services for business. IBM cloud
    includes Infrastructure as a Service (IaaS), Software as a Service (SaaS), and
    Platform as a Service (PaaS) offered through public, private, and hybrid cloud
    delivery models, in addition to the components that make up those clouds.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: IBM云计算是一套面向企业的云计算服务。IBM云包括基础设施即服务（IaaS）、软件即服务（SaaS）和平台即服务（PaaS），通过公共、私有和混合云交付模型提供，除此之外还包括组成这些云的各个组件。
- en: From within IBM Cloud, open Watson Studio and create a Data Science project,
    add a Spark cluster under the project settings, and then, on the Launch IDE menu,
    start RStudio. Please note that, as of this writing, the provided version of `sparklyr`
    was not the latest version available in CRAN, since `sparklyr` was modified to
    run under the IBM Cloud. In any case, follow IBM’s documentation as an authoritative
    reference to run R and Spark on the IBM Cloud and particularly on how to upgrade
    `sparklyr` appropriately. [Figure 6-11](#clusters-ibm-portal) captures IBM’s Cloud
    portal launching a Spark cluster.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在IBM Cloud内部，打开Watson Studio并创建一个数据科学项目，在项目设置下添加一个Spark集群，然后在启动IDE菜单上启动RStudio。请注意，截至撰写本文时，提供的`sparklyr`版本并非CRAN中最新版本，因为`sparklyr`已经修改以在IBM
    Cloud上运行。无论如何，请遵循IBM的文档作为运行R和Spark在IBM Cloud上以及如何适当升级`sparklyr`的权威参考。[图6-11](#clusters-ibm-portal)捕捉了IBM云门户启动Spark集群的场景。
- en: '![IBM Watson Studio launching Spark with R support](assets/mswr_0611.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![IBM Watson Studio启动支持R的Spark](assets/mswr_0611.png)'
- en: Figure 6-11\. IBM Watson Studio launching Spark with R support
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-11\. IBM Watson Studio启动支持R的Spark
- en: The most up-to-date pricing information is available at [*ibm.com/cloud/pricing*](https://www.ibm.com/cloud/pricing).
    In [Table 6-5](#Table0605), compute cost was normalized using 31 days from the
    per-month costs.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最新的定价信息请访问[*ibm.com/cloud/pricing*](https://www.ibm.com/cloud/pricing)。在[表6-5](#Table0605)中，计算成本使用每月成本的31天进行了标准化。
- en: Table 6-5\. IBM Cloud pricing information
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-5\. IBM云定价信息
- en: '| Instance | CPUs | Memory | Storage | Cost |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 实例 | CPU | 内存 | 存储 | 成本 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| C1.1x1x25 | 1 | 1 GB | 25 GB | $0.033/hour |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| C1.1x1x25 | 1 | 1 GB | 25 GB | $0.033/小时 |'
- en: '| C1.4x4x25 | 4 | 4 GB | 25 GB | $0.133/hour |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| C1.4x4x25 | 4 | 4 GB | 25 GB | $0.133/小时 |'
- en: '| C1.32x32x25 | 32 | 25 GB | 25 GB | $0.962/hour |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| C1.32x32x25 | 32 | 25 GB | 25 GB | $0.962/小时 |'
- en: Microsoft
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微软
- en: Microsoft Azure is a cloud computing service created by Microsoft for building,
    testing, deploying, and managing applications and services through a global network
    of Microsoft-managed datacenters. It provides SaaS, PaaS, and IaaS and supports
    many different programming languages, tools, and frameworks, including both Microsoft-specific
    and third-party software and systems.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft Azure是由微软创建的用于构建、测试、部署和管理应用程序和服务的云计算服务，通过全球网络的Microsoft托管数据中心提供。它支持SaaS、PaaS和IaaS，并支持许多不同的编程语言、工具和框架，包括Microsoft特定和第三方软件和系统。
- en: From the Azure portal, the Azure HDInsight service provides support for on-demand
    Spark clusters. You can easily create HDInsight cluster with support for Spark
    and RStudio by selecting the ML Services cluster type. Note that the provided
    version of `sparklyr` might not be the latest version available in CRAN since
    the default package repository seems to be initialized using a Microsoft R Application
    Network (MRAN) snapshot, not directly from CRAN. [Figure 6-12](#clusters-azure-hdinsight-mlservices)
    shows the Azure portal launching a Spark cluster with support for R.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Azure 门户，Azure HDInsight 服务支持按需创建 Spark 集群。你可以通过选择 ML Services 集群类型轻松创建支持
    Spark 和 RStudio 的 HDInsight 集群。请注意，提供的 `sparklyr` 版本可能不是 CRAN 中最新的版本，因为默认的软件包存储库似乎是使用
    Microsoft R 应用程序网络（MRAN）的快照初始化的，而不是直接从 CRAN 获取的。[图 6-12](#clusters-azure-hdinsight-mlservices)
    展示了 Azure 门户启动支持 R 的 Spark 集群。
- en: '![Creating an Azure HDInsight Spark cluster](assets/mswr_0612.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![创建 Azure HDInsight Spark 集群](assets/mswr_0612.png)'
- en: Figure 6-12\. Creating an Azure HDInsight Spark cluster
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-12\. 创建 Azure HDInsight Spark 集群
- en: Up-to-date pricing for HDInsight is available at [*azure.microsoft.com/en-us/pricing/details/hdinsight*](http://bit.ly/2H9Ce0X);
    [Table 6-6](#Table0606) lists the pricing as of this writing.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: HDInsight 的最新定价信息可在 [*azure.microsoft.com/en-us/pricing/details/hdinsight*](http://bit.ly/2H9Ce0X)
    上找到；[表 6-6](#Table0606) 列出了本文撰写时的定价。
- en: Table 6-6\. Azure HDInsight pricing information
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-6\. Azure HDInsight 定价信息
- en: '| Instance | CPUs | Memory | Total cost |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 实例 | CPUs | 内存 | 总成本 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| D1 v2 | 1 | 3.5 GB | $0.074/hour |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| D1 v2 | 1 | 3.5 GB | $0.074/小时 |'
- en: '| D4 v2 | 8 | 28 GB | $0.59/hour |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| D4 v2 | 8 | 28 GB | $0.59/小时 |'
- en: '| G5 | 64 | 448 GB | $9.298/hour |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| G5 | 64 | 448 GB | $9.298/小时 |'
- en: Qubole
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Qubole
- en: '[Qubole](https://www.qubole.com) was founded in 2013 with a mission to close
    the data accessibility gap. Qubole delivers a self-service platform for big data
    analytics built on Amazon, Microsoft, Google, and Oracle Clouds. In Qubole, you
    can launch Spark clusters, which you can then use from [Qubole notebooks](http://bit.ly/33ChKYk)
    or RStudio Server. [Figure 6-13](#clusters-qubole-notebook) shows a Qubole cluster
    initialized with RStudio and `sparklyr`.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[Qubole](https://www.qubole.com) 成立于2013年，旨在缩小数据可访问性差距。Qubole 提供一个建立在亚马逊、微软、谷歌和甲骨文云上的自助式大数据分析平台。在
    Qubole 中，你可以启动 Spark 集群，并可以从 [Qubole notebooks](http://bit.ly/33ChKYk) 或 RStudio
    Server 使用。[图 6-13](#clusters-qubole-notebook) 展示了一个使用 RStudio 和 `sparklyr` 初始化的
    Qubole 集群。'
- en: '![A Qubole notebook running sparklyr](assets/mswr_0613.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![运行 sparklyr 的 Qubole 笔记本](assets/mswr_0613.png)'
- en: Figure 6-13\. A Qubole cluster initialized with RStudio and sparklyr
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-13\. 使用 RStudio 和 sparklyr 初始化的 Qubole 集群
- en: You can find the latest pricing information at [Qubole’s pricing page](http://bit.ly/33AuKh8).
    [Table 6-7](#Table0607) lists the price for Qubole’s current plan, as of this
    writing. Notice that pricing is based on cost of QCU/hr, which stands for “Qubole
    Compute Unit per hour,” and the Enterprise Edition requires an annual contract.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [Qubole 的定价页面](http://bit.ly/33AuKh8) 找到最新的定价信息。[表 6-7](#Table0607) 列出了
    Qubole 当前计划的价格，截至本文撰写时。请注意，定价是基于每小时 QCU（Qubole 计算单元）的成本计算，企业版需要签订年度合同。
- en: Table 6-7\. Qubole pricing information
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-7\. Qubole 定价信息
- en: '| Test Drive | Full-featured trial | Enterprise Edition |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 试用 | 完整试用 | 企业版 |'
- en: '| --- | --- | --- |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| $0 | $0 | $0.14/QCU |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| $0 | $0 | $0.14/QCU |'
- en: Kubernetes
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes
- en: Kubernetes is an open source container orchestration system for automating deployment,
    scaling, and management of containerized applications that was originally designed
    by Google and is now maintained by the [Cloud Native Computing Foundation](https://www.cncf.io/)
    (CNCF). Kubernetes was originally based on [Docker](https://www.docker.com/),
    while, like Mesos, it’s also based on Linux Cgroups.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个由 Google 最初设计并现由 [Cloud Native Computing Foundation](https://www.cncf.io/)（CNCF）维护的开源容器编排系统，用于自动化部署、扩展和管理容器化应用程序。Kubernetes
    最初基于 [Docker](https://www.docker.com/) 开发，与 Mesos 类似，也基于 Linux Cgroups。
- en: Kubernetes can execute many cluster applications and frameworks that you can
    highly customize by using container images with specific resources and libraries.
    This allows a single Kubernetes cluster to be used for many different purposes
    beyond data analysis, which in turn helps organizations manage their compute resources
    with ease. One trade-off from using custom images is that they add further configuration
    overhead but make Kubernetes clusters extremely flexible. Nevertheless, this flexibility
    has proven to be instrumental to easily administer cluster resources in many organizations
    and, as pointed out in [“Overview”](#clusters-overview), Kubernetes is becoming
    a very popular cluster framework.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes可以执行许多集群应用程序和框架，通过使用具有特定资源和库的容器映像进行高度定制。这使得单个Kubernetes集群可以用于超出数据分析之外的许多不同目的，从而帮助组织轻松管理其计算资源。使用自定义映像的一个权衡是它们增加了进一步的配置开销，但使Kubernetes集群极其灵活。尽管如此，这种灵活性已被证明对于许多组织轻松管理集群资源至关重要，正如在[“概述”](#clusters-overview)中指出的那样，Kubernetes正在成为一个非常受欢迎的集群框架。
- en: Kubernetes is supported across all major cloud providers. They all provide extensive
    documentation as to how to launch, manage, and tear down Kubernetes clusters;
    [Figure 6-14](#clusters-kubernetes-google-console) shows the GCP console while
    creating a Kubernetes cluster. You can deploy Spark over any Kubernetes cluster,
    and you can use R to connect, analyze, model, and more.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes被所有主要的云服务提供商支持。它们都提供了关于如何启动、管理和撤销Kubernetes集群的广泛文档；[图6-14](#clusters-kubernetes-google-console)展示了在创建Kubernetes集群时的GCP控制台。你可以在任何Kubernetes集群上部署Spark，并且可以使用R来连接、分析、建模等。
- en: '![Creating a Kubernetes cluster for Spark and R using Google Cloud](assets/mswr_0614.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![在Google Cloud上创建用于Spark和R的Kubernetes集群](assets/mswr_0614.png)'
- en: Figure 6-14\. Creating a Kubernetes cluster for Spark and R using Google Cloud
  id: totrans-175
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-14\. 在Google Cloud上创建用于Spark和R的Kubernetes集群
- en: You can learn more at [kubernetes.io](https://kubernetes.io/), and read the
    *Running Spark on Kubernetes* guide from [spark.apache.org](http://bit.ly/2KAZze7).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[kubernetes.io](https://kubernetes.io/)上了解更多信息，并阅读来自[spark.apache.org](http://bit.ly/2KAZze7)的*在Kubernetes上运行Spark*指南。
- en: Strictly speaking, Kubernetes is a cluster technology, not a specific cluster
    architecture. However, Kubernetes represents a larger trend often referred to
    as a *hybrid cloud*. A hybrid cloud is a computing environment that makes use
    of on-premises and public cloud services with orchestration between the various
    platforms. It’s still too early to precisely categorize the leading technologies
    that will form a hybrid approach to cluster computing; although, as previously
    mentioned, Kubernetes is the leading one, many more are likely to form to complement
    or even replace existing technologies.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 严格来说，Kubernetes是一种集群技术，而不是一种特定的集群架构。然而，Kubernetes代表了一个更大的趋势，通常被称为*混合云*。混合云是利用本地和公共云服务，并在各个平台之间进行编排的计算环境。现在精确分类将形成混合集群计算的主导技术尚为时过早；尽管如此，如前所述，Kubernetes是其中领先的技术之一，还可能会有更多技术来补充或甚至替代现有技术。
- en: Tools
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工具
- en: While using only R and Spark can be sufficient for some clusters, it is common
    to install complementary tools in your cluster to improve monitoring, SQL analysis,
    workflow coordination, and more, with applications like [Ganglia](http://ganglia.info/),
    [Hue](http://gethue.com/), and [Oozie](https://oozie.apache.org), respectively.
    This section is not meant to cover all tools; rather, it mentions the ones that
    are commonly used.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然只使用R和Spark对一些集群来说可能已足够，但通常在集群中安装一些辅助工具是常见的，以改善监控、SQL分析、工作流协调等，例如[Ganglia](http://ganglia.info/)、[Hue](http://gethue.com/)和[Oozie](https://oozie.apache.org/)。本节并不意味着涵盖所有工具，而是提到了常用的工具。
- en: RStudio
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RStudio
- en: From reading [Chapter 1](ch01.html#intro), you are aware that RStudio is a well-known
    and free desktop development environment for R; therefore, it is likely that you
    are following the examples in this book using RStudio Desktop. However, you might
    not be aware that you can run RStudio as a web service within a Spark cluster.
    This version of RStudio is known as *RStudio Server*. You can see RStudio Server
    running in [Figure 6-15](#clusters-rstudio-server). In the same way that the Spark
    UI runs in the cluster, you can install RStudio Server within the cluster. Then
    you can connect to RStudio Server and use RStudio in exactly the same way you
    use RStudio Desktop but with the ability to run code against the Spark cluster.
    As you can see in [Figure 6-15](#clusters-rstudio-server), RStudio Server looks
    and feels just like RStudio Desktop, but adds support to run commands efficiently
    by being located within the cluster.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 从阅读[第一章](ch01.html#intro)可以知道，RStudio是一个著名且免费的R桌面开发环境；因此，你很可能正在使用RStudio Desktop来跟随本书中的示例。然而，你可能不知道你可以在Spark集群内作为Web服务运行RStudio。这个版本的RStudio称为*RStudio
    Server*。你可以在[图 6-15](#clusters-rstudio-server)中看到RStudio Server正在运行。与Spark UI在集群中运行类似，你可以在集群中安装RStudio
    Server。然后你可以连接到RStudio Server，并且以与使用RStudio Desktop相同的方式使用RStudio，但具有对Spark集群运行代码的能力。正如你在[图 6-15](#clusters-rstudio-server)中看到的那样，RStudio
    Server看起来和感觉都像RStudio Desktop，但通过位于集群中来运行命令可以高效运行。
- en: '![RStudio Server](assets/mswr_0615.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![RStudio Server](assets/mswr_0615.png)'
- en: Figure 6-15\. RStudio Server Pro running in AWS
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-15\. 在AWS中运行的RStudio Server Pro
- en: If you’re familiar with R, Shiny Server is a very popular tool for building
    interactive web applications from R. We recommended that you install Shiny directly
    in your Spark cluster.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉R，Shiny Server是一个非常流行的工具，用于从R构建交互式Web应用程序。我们建议你直接在你的Spark集群中安装Shiny。
- en: RStudio Server and Shiny Server are a free and open source; however, RStudio
    also provides professional products like RStudio Server, [RStudio Server Pro](http://bit.ly/2KCaxQn),
    [Shiny Server Pro](http://bit.ly/30aV0fK), and [RStudio Connect](http://bit.ly/306fHcY),
    which you can install within the cluster to support additional R workflows. While
    `sparklyr` does not require any additional tools, they provide significant productivity
    gains worth considering. You can learn more about them at [*rstudio.com/products/*](http://bit.ly/2MihHLP).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: RStudio Server和Shiny Server是免费开源的；然而，RStudio还提供专业产品如RStudio Server、[RStudio
    Server Pro](http://bit.ly/2KCaxQn)、[Shiny Server Pro](http://bit.ly/30aV0fK)和[RStudio
    Connect](http://bit.ly/306fHcY)，你可以在集群内安装以支持额外的R工作流。虽然`sparklyr`不需要任何额外的工具，但它们提供了显著的生产力提升，值得考虑。你可以在[*rstudio.com/products/*](http://bit.ly/2MihHLP)了解更多信息。
- en: Jupyter
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Jupyter
- en: Project [Jupyter](http://jupyter.org/) exists to develop open source software,
    open standards, and services for interactive computing across dozens of programming
    languages. A Jupyter notebook provides support for various programming languages,
    including R. You can use `sparklyr` with Jupyter notebooks using the R Kernel.
    [Figure 6-16](#clusters-jupyter-sparklyr) shows `sparklyr` running within a local
    Jupyter notebook.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '[Jupyter](http://jupyter.org/)项目旨在开发跨多种编程语言的交互式计算的开源软件、开放标准和服务。Jupyter笔记本支持包括R在内的各种编程语言。你可以使用`sparklyr`与Jupyter笔记本一起使用R内核。[图 6-16](#clusters-jupyter-sparklyr)展示了`sparklyr`在本地Jupyter笔记本中的运行。'
- en: '![Jupyter notebook running sparklyr](assets/mswr_0616.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![Jupyter笔记本运行sparklyr](assets/mswr_0616.png)'
- en: Figure 6-16\. Jupyter notebook running sparklyr
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-16\. Jupyter笔记本运行sparklyr
- en: Livy
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Livy
- en: '[Apache Livy](http://bit.ly/2L2TZAn) is an incubation project in Apache providing
    support to use Spark clusters remotely through a web interface. It is ideal to
    connect directly into the Spark cluster; however, there are times where connecting
    directly to the cluster is not feasible. When facing those constraints, you can
    consider installing Livy in the cluster and secure it properly to enable remote
    use over web protocols. Be aware, though, that there is a significant performance
    overhead from using Livy in `sparklyr`.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[Apache Livy](http://bit.ly/2L2TZAn)是Apache的孵化项目，通过Web界面提供支持，使得可以远程使用Spark集群。它非常适合直接连接到Spark集群；然而，在无法直接连接到集群的情况下，你可以考虑在集群中安装Livy，并适当地进行安全设置，以便通过Web协议进行远程使用。但要注意，使用Livy会带来显著的性能开销。'
- en: 'To help test Livy locally, `sparklyr` provides support to list, install, start,
    and stop a local Livy instance by executing `livy_available_versions()`:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助在本地测试Livy，`sparklyr`提供了支持通过执行`livy_available_versions()`列出、安装、启动和停止本地Livy实例的功能。
- en: '[PRE6]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This lists the versions that you can install; we recommend installing the latest
    version and verifying it as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了您可以安装的版本；我们建议安装最新版本，并按以下方式进行验证：
- en: '[PRE7]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You then can navigate to the local Livy session at [*http://localhost:8998*](http://localhost:8998).
    [Chapter 7](ch07.html#connections) will detail how to connect through Livy. After
    you’re connected, you can navigate to the Livy web application, as shown in [Figure 6-17](#clusters-livy-local).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以访问本地的 Livy 会话 [*http://localhost:8998*](http://localhost:8998)。[第 7 章](ch07.html#connections)
    将详细介绍如何通过 Livy 进行连接。连接成功后，您可以访问 Livy Web 应用程序，如 [图 6-17](#clusters-livy-local)
    所示。
- en: '![Apache Livy running as a local service](assets/mswr_0617.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![作为本地服务运行的Apache Livy](assets/mswr_0617.png)'
- en: Figure 6-17\. Apache Livy running as a local service
  id: totrans-198
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-17\. Apache Livy 作为本地服务运行
- en: 'Make sure you also stop the Livy service when working with local Livy instances
    (for proper Livy services running in a cluster, you won’t have to):'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用本地 Livy 实例时，请确保也停止 Livy 服务（对于在集群中正常运行的 Livy 服务，则无需停止）：
- en: '[PRE8]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Recap
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This chapter explained the history and trade-offs of on-premises and cloud
    computing and presented Kubernetes as a promising framework to provide flexibility
    across on-premises or multiple cloud providers. It also introduced cluster managers
    (Spark Standalone, YARN, Mesos, and Kubernetes) as the software needed to run
    Spark as a cluster application. This chapter briefly mentioned on-premises cluster
    providers like Cloudera, Hortonworks, and MapR, as well as the major Spark cloud
    providers: Amazon, Databricks, IBM, Google, Microsoft, and Qubole.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讲解了本地部署和云计算的历史和权衡，并介绍了 Kubernetes 作为一个有前途的框架，可以在本地或多个云服务提供商之间提供灵活性。它还介绍了集群管理器（Spark
    Standalone、YARN、Mesos 和 Kubernetes）作为运行 Spark 作为集群应用所需的软件。本章简要提到了像 Cloudera、Hortonworks
    和 MapR 这样的本地集群提供商，以及主要的 Spark 云提供商：亚马逊、Databricks、IBM、谷歌、微软和 Qubole。
- en: While this chapter provided a solid foundation to understand current cluster
    computing trends, tools, and service providers useful to perform data science
    at scale, it did not provide a comprehensive framework to help you decide which
    cluster technologies to choose. Instead, use this chapter as an overview and a
    starting point to seek out additional resources to help you find the cluster stack
    that best fits your organization needs.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本章为理解当前集群计算趋势、工具和服务提供商奠定了坚实的基础，有助于在规模上进行数据科学，但未提供一个全面的框架来帮助您决定选择哪种集群技术。相反，请将本章作为概述和寻找额外资源的起点，帮助您找到最适合组织需求的集群堆栈。
- en: '[Chapter 7](ch07.html#connections) will focus on understanding how to connect
    to existing clusters; therefore, it assumes a Spark cluster like those we presented
    in this chapter is already available to you.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 7 章](ch07.html#connections) 将专注于理解如何连接到现有的集群；因此，它假定您已经可以访问像我们在本章中介绍的 Spark
    集群之一。'
