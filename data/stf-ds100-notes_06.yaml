- en: 5  Data Cleaning and EDA
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 数据清洗和探索性数据分析
- en: 原文：[https://ds100.org/course-notes/eda/eda.html](https://ds100.org/course-notes/eda/eda.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ds100.org/course-notes/eda/eda.html](https://ds100.org/course-notes/eda/eda.html)
- en: <details><summary>Code</summary>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE0]</details> *Learning Outcomes* ***   Recognize common file formats'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE0]</details> *学习成果* ***   识别常见文件格式'
- en: Categorize data by its variable type
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按其变量类型对数据进行分类
- en: Build awareness of issues with data faithfulness and develop targeted solutions**  ****This
    content is covered in lectures 4, 5, and 6.**
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立对数据可信度问题的认识，并制定有针对性的解决方案**  ****此内容在第4、5和6讲中涵盖。**
- en: In the past few lectures, we’ve learned that `pandas` is a toolkit to restructure,
    modify, and explore a dataset. What we haven’t yet touched on is *how* to make
    these data transformation decisions. When we receive a new set of data from the
    “real world,” how do we know what processing we should do to convert this data
    into a usable form?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几堂课上，我们已经学到`pandas`是一个重塑、修改和探索数据集的工具包。我们还没有涉及的是*如何*做出这些数据转换决策。当我们从“现实世界”收到一组新数据时，我们如何知道我们应该做什么处理来将这些数据转换为可用的形式？
- en: '**Data cleaning**, also called **data wrangling**, is the process of transforming
    raw data to facilitate subsequent analysis. It is often used to address issues
    like:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据清洗**，也称为**数据整理**，是将原始数据转换为便于后续分析的过程。它通常用于解决诸如：'
- en: Unclear structure or formatting
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构不清晰或格式不正确
- en: Missing or corrupted values
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失或损坏的值
- en: Unit conversions
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单位转换
- en: …and so on
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '...等等'
- en: '**Exploratory Data Analysis (EDA)** is the process of understanding a new dataset.
    It is an open-ended, informal analysis that involves familiarizing ourselves with
    the variables present in the data, discovering potential hypotheses, and identifying
    possible issues with the data. This last point can often motivate further data
    cleaning to address any problems with the dataset’s format; because of this, EDA
    and data cleaning are often thought of as an “infinite loop,” with each process
    driving the other.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索性数据分析（EDA）**是了解新数据集的过程。这是一种开放式、非正式的分析，涉及熟悉数据中存在的变量，发现潜在的假设，并识别数据可能存在的问题。这最后一点通常会激发进一步的数据清洗，以解决数据集格式的任何问题；因此，EDA和数据清洗通常被认为是一个“无限循环”，每个过程都推动着另一个过程。'
- en: In this lecture, we will consider the key properties of data to consider when
    performing data cleaning and EDA. In doing so, we’ll develop a “checklist” of
    sorts for you to consider when approaching a new dataset. Throughout this process,
    we’ll build a deeper understanding of this early (but very important!) stage of
    the data science lifecycle.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本讲座中，我们将考虑在进行数据清洗和EDA时要考虑的数据的关键属性。在这个过程中，我们将为您制定一个“清单”，以便在处理新数据集时考虑。通过这个过程，我们将更深入地了解数据科学生命周期的这个早期阶段（但非常重要！）。
- en: 5.1 Structure
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 结构
- en: 5.1.1 File Formats
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 文件格式
- en: 'There are many file types for storing structured data: TSV, JSON, XML, ASCII,
    SAS, etc. We’ll only cover CSV, TSV, and JSON in lecture, but you’ll likely encounter
    other formats as you work with different datasets. Reading documentation is your
    best bet for understanding how to process the multitude of different file types.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多用于存储结构化数据的文件类型：TSV、JSON、XML、ASCII、SAS等。在讲座中，我们只会涵盖CSV、TSV和JSON，但在处理不同数据集时，您可能会遇到其他格式。阅读文档是了解如何处理多种不同文件类型的最佳方法。
- en: 5.1.1.1 CSV
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1.1 CSV
- en: 'CSVs, which stand for **Comma-Separated Values**, are a common tabular data
    format. In the past two `pandas` lectures, we briefly touched on the idea of file
    format: the way data is encoded in a file for storage. Specifically, our `elections`
    and `babynames` datasets were stored and loaded as CSVs:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: CSV，代表**逗号分隔值**，是一种常见的表格数据格式。在过去的两堂`pandas`讲座中，我们简要涉及了文件格式的概念：数据在文件中的编码方式。具体来说，我们的`elections`和`babynames`数据集是以CSV格式存储和加载的：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|  | Year | Candidate | Party | Popular vote | Result | % |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '|  | 年份 | 候选人 | 党派 | 普选票 | 结果 | % |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 1824 | Andrew Jackson | Democratic-Republican | 151271 | loss | 57.21
    |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1824 | Andrew Jackson | Democratic-Republican | 151271 | loss | 57.21
    |'
- en: '| 1 | 1824 | John Quincy Adams | Democratic-Republican | 113142 | win | 42.79
    |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1824 | John Quincy Adams | Democratic-Republican | 113142 | win | 42.79
    |'
- en: '| 2 | 1828 | Andrew Jackson | Democratic | 642806 | win | 56.20 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1828 | Andrew Jackson | Democratic | 642806 | win | 56.20 |'
- en: '| 3 | 1828 | John Quincy Adams | National Republican | 500897 | loss | 43.80
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1828 | John Quincy Adams | National Republican | 500897 | loss | 43.80
    |'
- en: '| 4 | 1832 | Andrew Jackson | Democratic | 702735 | win | 54.57 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1832 | Andrew Jackson | Democratic | 702735 | win | 54.57 |'
- en: 'To better understand the properties of a CSV, let’s take a look at the first
    few rows of the raw data file to see what it looks like before being loaded into
    a `DataFrame`. We’ll use the `repr()` function to return the raw string with its
    special characters:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解CSV的属性，让我们来看看原始数据文件的前几行，看看在加载到`DataFrame`之前它是什么样子的。我们将使用`repr()`函数返回带有特殊字符的原始字符串：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Each row, or **record**, in the data is delimited by a newline `\n`. Each column,
    or **field**, in the data is delimited by a comma `,` (hence, comma-separated!).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中的每一行，或**记录**，由换行符`\n`分隔。数据中的每一列，或**字段**，由逗号`,`分隔（因此是逗号分隔的！）。
- en: 5.1.1.2 TSV
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1.2 TSV
- en: Another common file type is **TSV (Tab-Separated Values)**. In a TSV, records
    are still delimited by a newline `\n`, while fields are delimited by `\t` tab
    character.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的文件类型是**TSV（制表符分隔值）**。在TSV中，记录仍然由换行符`\n`分隔，而字段由制表符`\t`分隔。
- en: Let’s check out the first few rows of the raw TSV file. Again, we’ll use the
    `repr()` function so that `print` shows the special characters.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看原始TSV文件的前几行。同样，我们将使用`repr()`函数，以便`print`显示特殊字符。
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: TSVs can be loaded into `pandas` using `pd.read_csv`. We’ll need to specify
    the **delimiter** with parameter`sep='\t'` [(documentation)](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: TSV可以使用`pd.read_csv`加载到`pandas`中。我们需要使用参数`sep='\t'`来指定**分隔符**[(文档)](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)。
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '|  | Year | Candidate | Party | Popular vote | Result | % |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | 年份 | 候选人 | 党派 | 普选票 | 结果 | % |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 1824 | Andrew Jackson | Democratic-Republican | 151271 | loss | 57.21
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1824 | Andrew Jackson | Democratic-Republican | 151271 | loss | 57.21
    |'
- en: '| 1 | 1824 | John Quincy Adams | Democratic-Republican | 113142 | win | 42.79
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1824 | John Quincy Adams | Democratic-Republican | 113142 | win | 42.79
    |'
- en: '| 2 | 1828 | Andrew Jackson | Democratic | 642806 | win | 56.20 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1828 | Andrew Jackson | Democratic | 642806 | win | 56.20 |'
- en: An issue with CSVs and TSVs comes up whenever there are commas or tabs within
    the records. How does `pandas` differentiate between a comma delimiter vs. a comma
    within the field itself, for example `8,900`? To remedy this, check out the [`quotechar`
    parameter](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: CSV和TSV的问题出现在记录中有逗号或制表符的情况下。`pandas`如何区分逗号分隔符与字段本身中的逗号，例如`8,900`？为了解决这个问题，可以查看[`quotechar`参数](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)。
- en: 5.1.1.3 JSON
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1.3 JSON
- en: '**JSON (JavaScript Object Notation)** files behave similarly to Python dictionaries.
    A raw JSON is shown below.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**JSON（JavaScript对象表示）**文件的行为类似于Python字典。下面显示了原始JSON。'
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: JSON files can be loaded into `pandas` using `pd.read_json`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`pd.read_json`将JSON文件加载到`pandas`中。
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '|  | Year | Candidate | Party | Popular vote | Result | % |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | 年份 | 候选人 | 党派 | 普选票 | 结果 | % |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 1824 | Andrew Jackson | Democratic-Republican | 151271 | loss | 57.21
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1824 | Andrew Jackson | Democratic-Republican | 151271 | loss | 57.21
    |'
- en: '| 1 | 1824 | John Quincy Adams | Democratic-Republican | 113142 | win | 42.79
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1824 | John Quincy Adams | Democratic-Republican | 113142 | win | 42.79
    |'
- en: '| 2 | 1828 | Andrew Jackson | Democratic | 642806 | win | 56.20 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1828 | Andrew Jackson | Democratic | 642806 | win | 56.20 |'
- en: '5.1.1.3.1 EDA with JSON: Berkeley COVID-19 Data'
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 5.1.1.3.1 使用JSON进行EDA：伯克利COVID-19数据
- en: The City of Berkeley Open Data [website](https://data.cityofberkeley.info/Health/COVID-19-Confirmed-Cases/xn6j-b766)
    has a dataset with COVID-19 Confirmed Cases among Berkeley residents by date.
    Let’s download the file and save it as a JSON (note the source URL file type is
    also a JSON). In the interest of reproducible data science, we will download the
    data programatically. We have defined some helper functions in the [`ds100_utils.py`](https://ds100.org/fa23/resources/assets/lectures/lec05/lec05-eda.html)
    file that we can reuse these helper functions in many different notebooks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 伯克利市政府开放数据[网站](https://data.cityofberkeley.info/Health/COVID-19-Confirmed-Cases/xn6j-b766)有一个关于伯克利居民COVID-19确诊病例的数据集。让我们下载文件并将其保存为JSON（请注意，源URL文件类型也是JSON）。为了可重复的数据科学，我们将以程序方式下载数据。我们在[`ds100_utils.py`](https://ds100.org/fa23/resources/assets/lectures/lec05/lec05-eda.html)文件中定义了一些辅助函数，我们可以在许多不同的笔记本中重用这些辅助函数。
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 5.1.1.3.1.1 File Size
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 5.1.1.3.1.1 文件大小
- en: Let’s start our analysis by getting a rough estimate of the size of the dataset
    to inform the tools we use to view the data. For relatively small datasets, we
    can use a text editor or spreadsheet. For larger datasets, more programmatic exploration
    or distributed computing tools may be more fitting. Here we will use `Python`
    tools to probe the file.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过对数据集的大小进行粗略估计来确定我们用于查看数据的工具。对于相对较小的数据集，我们可以使用文本编辑器或电子表格。对于较大的数据集，更多的编程探索或分布式计算工具可能更合适。在这里，我们将使用`Python`工具来探查文件。
- en: Since there seem to be text files, let’s investigate the number of lines, which
    often corresponds to the number of records
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于似乎存在文本文件，让我们调查一下行数，这通常对应于记录的数量。
- en: '[PRE13]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 5.1.1.3.1.2 Unix Commands
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 5.1.1.3.1.2 Unix Commands
- en: As part of the EDA workflow, Unix commands can come in very handy. In fact,
    there’s an entire book called [“Data Science at the Command Line”](https://datascienceatthecommandline.com/)
    that explores this idea in depth! In Jupyter/IPython, you can prefix lines with
    `!` to execute arbitrary Unix commands, and within those lines, you can refer
    to `Python` variables and expressions with the syntax `{expr}`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 作为EDA工作流的一部分，Unix命令非常有用。事实上，有一本名为[“Data Science at the Command Line”](https://datascienceatthecommandline.com/)的整本书深入探讨了这个想法！在Jupyter/IPython中，您可以使用`!`前缀执行任意的Unix命令，并且在这些行内，您可以使用`{expr}`语法引用`Python`变量和表达式。
- en: Here, we use the `ls` command to list files, using the `-lh` flags, which request
    “long format with information in human-readable form.” We also use the `wc` command
    for “word count,” but with the `-l` flag, which asks for line counts instead of
    words.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`ls`命令列出文件，使用`-lh`标志，请求“以人类可读的形式显示详细信息”。我们还使用`wc`命令进行“字数统计”，但使用`-l`标志，该标志请求行数而不是单词数。
- en: 'These two give us the same information as the code above, albeit in a slightly
    different form:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个代码给出了与上面的代码相同的信息，尽管形式略有不同：
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 5.1.1.3.1.3 File Contents
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 5.1.1.3.1.3 文件内容
- en: Let’s explore the data format using `Python`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`Python`来探索数据格式。
- en: '[PRE18]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can use the `head` Unix command (which is where `pandas`’ `head` method
    comes from!) to see the first few lines of the file:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`head` Unix命令（这也是`pandas`的`head`方法的来源！）来查看文件的前几行：
- en: '[PRE20]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In order to load the JSON file into `pandas`, Let’s first do some EDA with `Python`’s
    `json` package to understand the particular structure of this JSON file so that
    we can decide what (if anything) to load into `pandas`. `Python` has relatively
    good support for JSON data since it closely matches the internal python object
    model. In the following cell we import the entire JSON datafile into a python
    dictionary using the `json` package.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将JSON文件加载到`pandas`中，让我们首先使用`Python`的`json`包进行一些EDA，以了解JSON文件的特定结构，以便决定是否（以及如何）将其加载到`pandas`中。由于JSON数据与内部Python对象模型非常匹配，`Python`对JSON数据有相对良好的支持。在下面的单元格中，我们使用`json`包将整个JSON数据文件导入Python字典。
- en: '[PRE22]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `covid_json` variable is now a dictionary encoding the data in the file:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`covid_json`变量现在是一个编码文件中数据的字典：'
- en: '[PRE23]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We can examine what keys are in the top level json object by listing out the
    keys.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过列出键来检查顶级JSON对象中有哪些键。
- en: '[PRE25]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '**Observation**: The JSON dictionary contains a `meta` key which likely refers
    to meta data (data about the data). Meta data often maintained with the data and
    can be a good source of additional information.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**观察**：JSON字典包含一个`meta`键，这可能是指元数据（关于数据的数据）。元数据通常与数据一起维护，并且可以成为额外信息的良好来源。'
- en: We can investigate the meta data further by examining the keys associated with
    the metadata.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过检查与元数据相关联的键来进一步调查元数据。
- en: '[PRE27]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `meta` key contains another dictionary called `view`. This likely refers
    to meta-data about a particular “view” of some underlying database. We will learn
    more about views when we study SQL later in the class.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`meta`键包含另一个名为`view`的字典。这可能是关于某个基础数据库的特定“视图”的元数据。我们将在后面的课程中学习更多关于视图的知识。'
- en: '[PRE29]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Notice that this a nested/recursive data structure. As we dig deeper we reveal
    more and more keys and the corresponding data:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是一个嵌套/递归数据结构。随着我们深入挖掘，我们会揭示更多的键和相应的数据：
- en: '[PRE31]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'There is a key called description in the view sub dictionary. This likely contains
    a description of the data:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在视图子字典中有一个名为描述的键。这可能包含了数据的描述：
- en: '[PRE32]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 5.1.1.3.1.4 Examining the Data Field for Records
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 5.1.1.3.1.4 检查记录的数据字段
- en: We can look at a few entries in the `data` field. This is what we’ll load into
    `pandas`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看`data`字段中的一些条目。这是我们将加载到`pandas`中的数据。
- en: '[PRE34]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Observations: * These look like equal-length records, so maybe `data` is a
    table! * But what do each of values in the record mean? Where can we find column
    headers?'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：* 这些看起来像等长的记录，所以也许`data`是一个表格！* 但记录中的每个值代表什么？我们在哪里可以找到列标题？
- en: 'For that, we’ll need the `columns` key in the metadata dictionary. This returns
    a list:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要元数据字典中的`columns`键。这将返回一个列表：
- en: '[PRE36]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 5.1.1.3.1.5 Summary of exploring the JSON file
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 5.1.1.3.1.5 探索JSON文件的总结
- en: The above **metadata** tells us a lot about the columns in the data including
    column names, potential data anomalies, and a basic statistic.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述**元数据**告诉我们很多关于数据中的列，包括列名、潜在的数据异常和基本统计信息。
- en: Because of its non-tabular structure, JSON makes it easier (than CSV) to create
    **self-documenting data**, meaning that information about the data is stored in
    the same file as the data.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于其非表格结构，JSON比CSV更容易创建**自描述数据**，这意味着数据的信息存储在与数据相同的文件中。
- en: Self-documenting data can be helpful since it maintains its own description
    and these descriptions are more likely to be updated as data changes.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自描述数据可能会有所帮助，因为它保留了自己的描述，并且这些描述更有可能随着数据的变化而更新。
- en: 5.1.1.3.1.6 Loading COVID Data into `pandas`
  id: totrans-111
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 5.1.1.3.1.6 将COVID数据加载到`pandas`中
- en: 'Finally, let’s load the data (not the metadata) into a `pandas` `DataFrame`.
    In the following block of code we:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们将数据（而不是元数据）加载到`pandas`的`DataFrame`中。在下面的代码块中，我们：
- en: 'Translate the JSON records into a `DataFrame`:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将JSON记录翻译成`DataFrame`：
- en: 'fields: `covid_json[''meta''][''view''][''columns'']`'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字段：`covid_json['meta']['view']['columns']`
- en: 'records: `covid_json[''data'']`'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录：`covid_json['data']`
- en: Remove columns that have no metadata description. This would be a bad idea in
    general, but here we remove these columns since the above analysis suggests they
    are unlikely to contain useful information.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除没有元数据描述的列。一般来说，这是一个坏主意，但在这里我们删除这些列，因为上面的分析表明它们不太可能包含有用的信息。
- en: Examine the `tail` of the table.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查表的`tail`。
- en: '[PRE38]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '|  | sid | id | position | created_at | created_meta | updated_at | updated_meta
    | meta | Date | New Cases | Cumulative Cases |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | sid | id | position | created_at | created_meta | updated_at | updated_meta
    | meta | Date | New Cases | Cumulative Cases |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 699 | row-49b6_x8zv.gyum | 00000000-0000-0000-A18C-9174A6D05774 | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-27T00:00:00 | 106 | 10694 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 699 | row-49b6_x8zv.gyum | 00000000-0000-0000-A18C-9174A6D05774 | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-27T00:00:00 | 106 | 10694 |'
- en: '| 700 | row-gs55-p5em.y4v9 | 00000000-0000-0000-F41D-5724AEABB4D6 | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-28T00:00:00 | 223 | 10917 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 700 | row-gs55-p5em.y4v9 | 00000000-0000-0000-F41D-5724AEABB4D6 | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-28T00:00:00 | 223 | 10917 |'
- en: '| 701 | row-3pyj.tf95-qu67 | 00000000-0000-0000-BEE3-B0188D2518BD | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-29T00:00:00 | 139 | 11056 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 701 | row-3pyj.tf95-qu67 | 00000000-0000-0000-BEE3-B0188D2518BD | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-29T00:00:00 | 139 | 11056 |'
- en: '| 702 | row-cgnd.8syv.jvjn | 00000000-0000-0000-C318-63CF75F7F740 | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-30T00:00:00 | 33 | 11089 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 702 | row-cgnd.8syv.jvjn | 00000000-0000-0000-C318-63CF75F7F740 | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-30T00:00:00 | 33 | 11089 |'
- en: '| 703 | row-qywv_24x6-237y | 00000000-0000-0000-FE92-9789FED3AA20 | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-31T00:00:00 | 42 | 11131 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 703 | row-qywv_24x6-237y | 00000000-0000-0000-FE92-9789FED3AA20 | 0 | 1643733903
    | None | 1643733903 | None | { } | 2022-01-31T00:00:00 | 42 | 11131 |'
- en: 5.1.2 Variable Types
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 变量类型
- en: After loading data into a file, it’s a good idea to take the time to understand
    what pieces of information are encoded in the dataset. In particular, we want
    to identify what variable types are present in our data. Broadly speaking, we
    can categorize variables into one of two overarching types.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据加载到文件后，花时间了解数据集中编码的信息是一个好主意。特别是，我们想要确定我们的数据中存在哪些变量类型。广义上说，我们可以将变量分类为两种主要类型之一。
- en: '**Quantitative variables** describe some numeric quantity or amount. We can
    divide quantitative data further into:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**定量变量**描述一些数值数量或量。我们可以进一步将定量数据分为：'
- en: '**Continuous quantitative variables**: numeric data that can be measured on
    a continuous scale to arbitrary precision. Continuous variables do not have a
    strict set of possible values – they can be recorded to any number of decimal
    places. For example, weights, GPA, or CO[2] concentrations.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**连续定量变量**：可以在连续尺度上以任意精度测量的数值数据。连续变量没有严格的可能值集 - 它们可以记录到任意数量的小数位。例如，重量、GPA或CO[2]浓度。'
- en: '**Discrete quantitative variables**: numeric data that can only take on a finite
    set of possible values. For example, someone’s age or the number of siblings they
    have.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离散定量变量**：只能取有限可能值的数值数据。例如，某人的年龄或他们的兄弟姐妹数量。'
- en: '**Qualitative variables**, also known as **categorical variables**, describe
    data that isn’t measuring some quantity or amount. The sub-categories of categorical
    data are:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**定性变量**，也称为**分类变量**，描述的是不测量某种数量或量的数据。分类数据的子类别包括：'
- en: '**Ordinal qualitative variables**: categories with ordered levels. Specifically,
    ordinal variables are those where the difference between levels has no consistent,
    quantifiable meaning. Some examples include levels of education (high school,
    undergrad, grad, etc.), income bracket (low, medium, high), or Yelp rating.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有序定性变量**：具有有序级别的类别。具体来说，有序变量是指级别之间的差异没有一致的、可量化的含义。一些例子包括教育水平（高中、本科、研究生等）、收入档次（低、中、高）或Yelp评分。'
- en: '**Nominal qualitative variables**: categories with no specific order. For example,
    someone’s political affiliation or Cal ID number.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无序定性变量**：没有特定顺序的类别。例如，某人的政治立场或Cal ID号码。'
- en: '![](../Images/0c2f62ee89a94219c8c90e27d97eb295.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c2f62ee89a94219c8c90e27d97eb295.png)'
- en: Classification of variable types
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 变量类型的分类
- en: Note that many variables don’t sit neatly in just one of these categories. Qualitative
    variables could have numeric levels, and conversely, quantitative variables could
    be stored as strings.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，许多变量不会完全属于这些类别中的一个。定性变量可能具有数值级别，反之亦然，定量变量可以存储为字符串。
- en: 5.1.3 Primary and Foreign Keys
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.3 主键和外键
- en: Last time, we introduced `.merge` as the `pandas` method for joining multiple
    `DataFrame`s together. In our discussion of joins, we touched on the idea of using
    a “key” to determine what rows should be merged from each table. Let’s take a
    moment to examine this idea more closely.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 上次，我们介绍了`.merge`作为`pandas`方法，用于将多个`DataFrame`连接在一起。在我们讨论连接时，我们提到了使用“键”来确定应该从每个表中合并哪些行的想法。让我们花点时间更仔细地研究这个想法。
- en: The **primary key** is the column or set of columns in a table that *uniquely*
    determine the values of the remaining columns. It can be thought of as the unique
    identifier for each individual row in the table. For example, a table of Data
    100 students might use each student’s Cal ID as the primary key.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**主键**是表中*唯一*确定其余列值的列或列集。它可以被认为是表中每一行的唯一标识符。例如，Data 100学生表可能使用每个学生的Cal ID作为主键。'
- en: '|  | Cal ID | Name | Major |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|  | Cal ID | 名字 | 专业 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 3034619471 | Oski | Data Science |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 3034619471 | Oski | 数据科学 |'
- en: '| 1 | 3035619472 | Ollie | Computer Science |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3035619472 | 奥利 | 计算机科学 |'
- en: '| 2 | 3025619473 | Orrie | Data Science |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3025619473 | 奥里 | 数据科学 |'
- en: '| 3 | 3046789372 | Ollie | Economics |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 3046789372 | 奥利 | 经济学 |'
- en: The **foreign key** is the column or set of columns in a table that reference
    primary keys in other tables. Knowing a dataset’s foreign keys can be useful when
    assigning the `left_on` and `right_on` parameters of `.merge`. In the table of
    office hour tickets below, `"Cal ID"` is a foreign key referencing the previous
    table.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**外键**是表中引用其他表主键的列或列集。在分配`.merge`的`left_on`和`right_on`参数时，了解数据集的外键可以很有用。在下面的办公时间票表中，“Cal
    ID”是引用前表的外键。'
- en: '|  | OH Request | Cal ID | Question |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|  | OH请求 | Cal ID | 问题 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 1 | 3034619471 | HW 2 Q1 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1 | 3034619471 | 作业2问题1 |'
- en: '| 1 | 2 | 3035619472 | HW 2 Q3 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | 3035619472 | 作业2问题3 |'
- en: '| 2 | 3 | 3025619473 | Lab 3 Q4 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 3 | 3025619473 | 实验3问题4 |'
- en: '| 3 | 4 | 3035619472 | HW 2 Q7 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4 | 3035619472 | 作业2问题7 |'
- en: 5.2 Granularity, Scope, and Temporality
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 粒度、范围和时间性
- en: After understanding the structure of the dataset, the next task is to determine
    what exactly the data represents. We’ll do so by considering the data’s granularity,
    scope, and temporality.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解数据集的结构之后，下一个任务是确定数据究竟代表什么。我们将通过考虑数据的粒度、范围和时间性来做到这一点。
- en: 5.2.1 Granularity
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 粒度
- en: 'The **granularity** of a dataset is what a single row represents. You can also
    think of it as the level of detail included in the data. To determine the data’s
    granularity, ask: what does each row in the dataset represent? Fine-grained data
    contains a high level of detail, with a single row representing a small individual
    unit. For example, each record may represent one person. Coarse-grained data is
    encoded such that a single row represents a large individual unit – for example,
    each record may represent a group of people.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的**粒度**是单行代表的内容。您也可以将其视为数据中包含的细节级别。要确定数据的粒度，可以问：数据集中的每一行代表什么？细粒度数据包含大量细节，单行代表一个小的个体单位。例如，每条记录可能代表一个人。粗粒度数据被编码，以便单行代表一个大的个体单位-例如，每条记录可能代表一组人。
- en: 5.2.2 Scope
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 范围
- en: The **scope** of a dataset is the subset of the population covered by the data.
    If we were investigating student performance in Data Science courses, a dataset
    with a narrow scope might encompass all students enrolled in Data 100 whereas
    a dataset with an expansive scope might encompass all students in California.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的**范围**是数据所涵盖的人口子集。如果我们调查数据科学课程中学生的表现，一个范围较窄的数据集可能包括所有注册Data 100课程的学生，而一个范围较广的数据集可能包括加利福尼亚州的所有学生。
- en: 5.2.3 Temporality
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 时间性
- en: The **temporality** of a dataset describes the periodicity over which the data
    was collected as well as when the data was most recently collected or updated.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的**时间性**描述了数据收集的周期性，以及数据最近收集或更新的时间。
- en: 'Time and date fields of a dataset could represent a few things:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的时间和日期字段可能代表一些内容：
- en: when the “event” happened
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “事件”发生的时间
- en: when the data was collected, or when it was entered into the system
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据收集的时间，或者数据输入系统的时间
- en: when the data was copied into the database
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据复制到数据库中的时间
- en: To fully understand the temporality of the data, it also may be necessary to
    standardize time zones or inspect recurring time-based trends in the data (do
    patterns recur in 24-hour periods? Over the course of a month? Seasonally?). The
    convention for standardizing time is the Coordinated Universal Time (UTC), an
    international time standard measured at 0 degrees latitude that stays consistent
    throughout the year (no daylight savings). We can represent Berkeley’s time zone,
    Pacific Standard Time (PST), as UTC-7 (with daylight savings).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分了解数据的时间性，还可能需要标准化时区或检查数据中的重复时间趋势（模式是否在24小时内重复？一个月内？季节性？）。标准化时间的惯例是协调世界时（UTC），这是一个国际时间标准，在0度纬度上测量，整年保持一致（没有夏令时）。我们可以表示伯克利的时区，太平洋标准时间（PST），为UTC-7（夏令时）。
- en: 5.2.3.1 Temporality with `pandas`’ `dt` accessors
  id: totrans-166
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3.1 使用`pandas`的`dt`访问器进行时间处理
- en: 'Let’s briefly look at how we can use `pandas`’ `dt` accessors to work with
    dates/times in a dataset using the dataset you’ll see in Lab 3: the Berkeley PD
    Calls for Service dataset.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要地看一下如何使用`pandas`的`dt`访问器来处理数据集中的日期/时间，使用你在实验3中看到的数据集：伯克利警察服务呼叫数据集。
- en: <details><summary>Code</summary>
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>Code</summary>
- en: '[PRE39]</details>'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE39]</details>'
- en: '|  | CASENO | OFFENSE | EVENTDT | EVENTTM | CVLEGEND | CVDOW | InDbDate | Block_Location
    | BLKADDR | City | State |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | CASENO | OFFENSE | EVENTDT | EVENTTM | CVLEGEND | CVDOW | InDbDate | Block_Location
    | BLKADDR | City | State |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 21014296 | THEFT MISD. (UNDER $950) | 04/01/2021 12:00:00 AM | 10:58
    | LARCENY | 4 | 06/15/2021 12:00:00 AM | Berkeley, CA\n(37.869058, -122.270455)
    | NaN | Berkeley | CA |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 21014296 | THEFT MISD. (UNDER $950) | 04/01/2021 12:00:00 AM | 10:58
    | LARCENY | 4 | 06/15/2021 12:00:00 AM | Berkeley, CA\n(37.869058, -122.270455)
    | NaN | Berkeley | CA |'
- en: '| 1 | 21014391 | THEFT MISD. (UNDER $950) | 04/01/2021 12:00:00 AM | 10:38
    | LARCENY | 4 | 06/15/2021 12:00:00 AM | Berkeley, CA\n(37.869058, -122.270455)
    | NaN | Berkeley | CA |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 21014391 | THEFT MISD. (UNDER $950) | 04/01/2021 12:00:00 AM | 10:38
    | LARCENY | 4 | 06/15/2021 12:00:00 AM | Berkeley, CA\n(37.869058, -122.270455)
    | NaN | Berkeley | CA |'
- en: '| 2 | 21090494 | THEFT MISD. (UNDER $950) | 04/19/2021 12:00:00 AM | 12:15
    | LARCENY | 1 | 06/15/2021 12:00:00 AM | 2100 BLOCK HASTE ST\nBerkeley, CA\n(37.864908,...
    | 2100 BLOCK HASTE ST | Berkeley | CA |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 21090494 | THEFT MISD. (UNDER $950) | 04/19/2021 12:00:00 AM | 12:15
    | LARCENY | 1 | 06/15/2021 12:00:00 AM | 2100 BLOCK HASTE ST\nBerkeley, CA\n(37.864908,...
    | 2100 BLOCK HASTE ST | Berkeley | CA |'
- en: '| 3 | 21090204 | THEFT FELONY (OVER $950) | 02/13/2021 12:00:00 AM | 17:00
    | LARCENY | 6 | 06/15/2021 12:00:00 AM | 2600 BLOCK WARRING ST\nBerkeley, CA\n(37.86393...
    | 2600 BLOCK WARRING ST | Berkeley | CA |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 21090204 | THEFT FELONY (OVER $950) | 02/13/2021 12:00:00 AM | 17:00
    | LARCENY | 6 | 06/15/2021 12:00:00 AM | 2600 BLOCK WARRING ST\nBerkeley, CA\n(37.86393...
    | 2600 BLOCK WARRING ST | Berkeley | CA |'
- en: '| 4 | 21090179 | BURGLARY AUTO | 02/08/2021 12:00:00 AM | 6:20 | BURGLARY -
    VEHICLE | 1 | 06/15/2021 12:00:00 AM | 2700 BLOCK GARBER ST\nBerkeley, CA\n(37.86066,...
    | 2700 BLOCK GARBER ST | Berkeley | CA |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 21090179 | BURGLARY AUTO | 02/08/2021 12:00:00 AM | 6:20 | BURGLARY -
    VEHICLE | 1 | 06/15/2021 12:00:00 AM | 2700 BLOCK GARBER ST\nBerkeley, CA\n(37.86066,...
    | 2700 BLOCK GARBER ST | Berkeley | CA |'
- en: 'Looks like there are three columns with dates/times: `EVENTDT`, `EVENTTM`,
    and `InDbDate`.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来有三列带有日期/时间：`EVENTDT`，`EVENTTM`和`InDbDate`。
- en: Most likely, `EVENTDT` stands for the date when the event took place, `EVENTTM`
    stands for the time of day the event took place (in 24-hr format), and `InDbDate`
    is the date this call is recorded onto the database.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，`EVENTDT`代表事件发生的日期，`EVENTTM`代表事件发生的时间（24小时制），`InDbDate`是这个呼叫被记录到数据库的日期。
- en: If we check the data type of these columns, we will see they are stored as strings.
    We can convert them to `datetime` objects using pandas `to_datetime` function.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查这些列的数据类型，我们会发现它们被存储为字符串。我们可以使用pandas的`to_datetime`函数将它们转换为`datetime`对象。
- en: '[PRE40]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '|  | CASENO | OFFENSE | EVENTDT | EVENTTM | CVLEGEND | CVDOW | InDbDate | Block_Location
    | BLKADDR | City | State |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '|  | CASENO | OFFENSE | EVENTDT | EVENTTM | CVLEGEND | CVDOW | InDbDate | Block_Location
    | BLKADDR | City | State |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 21014296 | THEFT MISD. (UNDER $950) | 2021-04-01 | 10:58 | LARCENY |
    4 | 06/15/2021 12:00:00 AM | Berkeley, CA\n(37.869058, -122.270455) | NaN | Berkeley
    | CA |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 21014296 | THEFT MISD. (UNDER $950) | 2021-04-01 | 10:58 | LARCENY |
    4 | 06/15/2021 12:00:00 AM | Berkeley, CA\n(37.869058, -122.270455) | NaN | Berkeley
    | CA |'
- en: '| 1 | 21014391 | THEFT MISD. (UNDER $950) | 2021-04-01 | 10:38 | LARCENY |
    4 | 06/15/2021 12:00:00 AM | Berkeley, CA\n(37.869058, -122.270455) | NaN | Berkeley
    | CA |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 21014391 | THEFT MISD. (UNDER $950) | 2021-04-01 | 10:38 | LARCENY |
    4 | 06/15/2021 12:00:00 AM | Berkeley, CA\n(37.869058, -122.270455) | NaN | Berkeley
    | CA |'
- en: '| 2 | 21090494 | THEFT MISD. (UNDER $950) | 2021-04-19 | 12:15 | LARCENY |
    1 | 06/15/2021 12:00:00 AM | 2100 BLOCK HASTE ST\nBerkeley, CA\n(37.864908,...
    | 2100 BLOCK HASTE ST | Berkeley | CA |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 21090494 | THEFT MISD. (UNDER $950) | 2021-04-19 | 12:15 | LARCENY |
    1 | 06/15/2021 12:00:00 AM | 2100 BLOCK HASTE ST\nBerkeley, CA\n(37.864908,...
    | 2100 BLOCK HASTE ST | Berkeley | CA |'
- en: '| 3 | 21090204 | THEFT FELONY (OVER $950) | 2021-02-13 | 17:00 | LARCENY |
    6 | 06/15/2021 12:00:00 AM | 2600 BLOCK WARRING ST\nBerkeley, CA\n(37.86393...
    | 2600 BLOCK WARRING ST | Berkeley | CA |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 21090204 | THEFT FELONY (OVER $950) | 2021-02-13 | 17:00 | LARCENY |
    6 | 06/15/2021 12:00:00 AM | 2600 BLOCK WARRING ST\nBerkeley, CA\n(37.86393...
    | 2600 BLOCK WARRING ST | Berkeley | CA |'
- en: '| 4 | 21090179 | BURGLARY AUTO | 2021-02-08 | 6:20 | BURGLARY - VEHICLE | 1
    | 06/15/2021 12:00:00 AM | 2700 BLOCK GARBER ST\nBerkeley, CA\n(37.86066,... |
    2700 BLOCK GARBER ST | Berkeley | CA |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 21090179 | BURGLARY AUTO | 2021-02-08 | 6:20 | BURGLARY - VEHICLE | 1
    | 06/15/2021 12:00:00 AM | 2700 BLOCK GARBER ST\nBerkeley, CA\n(37.86066,... |
    2700 BLOCK GARBER ST | Berkeley | CA |'
- en: Now, we can use the `dt` accessor on this column.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在这一列上使用`dt`访问器。
- en: 'We can get the month:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得到月份：
- en: '[PRE41]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Which day of the week the date is on:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 日期是一周中的哪一天：
- en: '[PRE43]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Check the mimimum values to see if there are any suspicious-looking, 70s dates:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 检查最小值，看看是否有任何看起来可疑的70年代日期：
- en: '[PRE45]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '|  | CASENO | OFFENSE | EVENTDT | EVENTTM | CVLEGEND | CVDOW | InDbDate | Block_Location
    | BLKADDR | City | State |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | CASENO | OFFENSE | EVENTDT | EVENTTM | CVLEGEND | CVDOW | InDbDate | Block_Location
    | BLKADDR | City | State |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 2513 | 20057398 | BURGLARY COMMERCIAL | 2020-12-17 | 16:05 | BURGLARY - COMMERCIAL
    | 4 | 06/15/2021 12:00:00 AM | 600 BLOCK GILMAN ST\nBerkeley, CA\n(37.878405,...
    | 600 BLOCK GILMAN ST | Berkeley | CA |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 2513 | 20057398 | BURGLARY COMMERCIAL | 2020-12-17 | 16:05 | BURGLARY - COMMERCIAL
    | 4 | 06/15/2021 12:00:00 AM | 600 BLOCK GILMAN ST\nBerkeley, CA\n(37.878405,...
    | 600 BLOCK GILMAN ST | Berkeley | CA |'
- en: '| 624 | 20057207 | ASSAULT/BATTERY MISD. | 2020-12-17 | 16:50 | ASSAULT | 4
    | 06/15/2021 12:00:00 AM | 2100 BLOCK SHATTUCK AVE\nBerkeley, CA\n(37.871... |
    2100 BLOCK SHATTUCK AVE | Berkeley | CA |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 624 | 20057207 | ASSAULT/BATTERY MISD. | 2020-12-17 | 16:50 | ASSAULT | 4
    | 06/15/2021 12:00:00 AM | 2100 BLOCK SHATTUCK AVE\nBerkeley, CA\n(37.871... |
    2100 BLOCK SHATTUCK AVE | Berkeley | CA |'
- en: '| 154 | 20092214 | THEFT FROM AUTO | 2020-12-17 | 18:30 | LARCENY - FROM VEHICLE
    | 4 | 06/15/2021 12:00:00 AM | 800 BLOCK SHATTUCK AVE\nBerkeley, CA\n(37.8918...
    | 800 BLOCK SHATTUCK AVE | Berkeley | CA |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 154 | 20092214 | THEFT FROM AUTO | 2020-12-17 | 18:30 | LARCENY - FROM VEHICLE
    | 4 | 06/15/2021 12:00:00 AM | 800 BLOCK SHATTUCK AVE\nBerkeley, CA\n(37.8918...
    | 800 BLOCK SHATTUCK AVE | Berkeley | CA |'
- en: '| 659 | 20057324 | THEFT MISD. (UNDER $950) | 2020-12-17 | 15:44 | LARCENY
    | 4 | 06/15/2021 12:00:00 AM | 1800 BLOCK 4TH ST\nBerkeley, CA\n(37.869888, -...
    | 1800 BLOCK 4TH ST | Berkeley | CA |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 659 | 20057324 | THEFT MISD. (UNDER $950) | 2020-12-17 | 15:44 | LARCENY
    | 4 | 06/15/2021 12:00:00 AM | 1800 BLOCK 4TH ST\nBerkeley, CA\n(37.869888, -...
    | 1800 BLOCK 4TH ST | Berkeley | CA |'
- en: '| 993 | 20057573 | BURGLARY RESIDENTIAL | 2020-12-17 | 22:15 | BURGLARY - RESIDENTIAL
    | 4 | 06/15/2021 12:00:00 AM | 1700 BLOCK STUART ST\nBerkeley, CA\n(37.857495...
    | 1700 BLOCK STUART ST | Berkeley | CA |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 993 | 20057573 | BURGLARY RESIDENTIAL | 2020-12-17 | 22:15 | BURGLARY - RESIDENTIAL
    | 4 | 06/15/2021 12:00:00 AM | 1700 BLOCK STUART ST\nBerkeley, CA\n(37.857495...
    | 1700 BLOCK STUART ST | Berkeley | CA |'
- en: Doesn’t look like it! We are good!
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不像！我们做得很好！
- en: We can also do many things with the `dt` accessor like switching time zones
    and converting time back to UNIX/POSIX time. Check out the documentation on [`.dt`
    accessor](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors)
    and [time series/date functionality](https://pandas.pydata.org/docs/user_guide/timeseries.html#).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`dt`访问器执行许多操作，例如切换时区和将时间转换回UNIX/POSIX时间。查看[`.dt`访问器](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors)和[时间序列/日期功能](https://pandas.pydata.org/docs/user_guide/timeseries.html#)的文档。
- en: 5.3 Faithfulness
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 忠实度
- en: 'At this stage in our data cleaning and EDA workflow, we’ve achieved quite a
    lot: we’ve identified how our data is structured, come to terms with what information
    it encodes, and gained insight as to how it was generated. Throughout this process,
    we should always recall the original intent of our work in Data Science – to use
    data to better understand and model the real world. To achieve this goal, we need
    to ensure that the data we use is faithful to reality; that is, that our data
    accurately captures the “real world.”'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据清理和EDA工作流的这个阶段，我们已经取得了相当大的成就：我们已经确定了数据的结构，了解了它所编码的信息，并获得了有关它是如何生成的见解。在整个过程中，我们应该始终记住数据科学工作的最初目的
    - 使用数据更好地理解和建模现实世界。为了实现这一目标，我们需要确保我们使用的数据忠实于现实；也就是说，我们的数据准确地捕捉了“真实世界”。
- en: 'Data used in research or industry is often “messy” – there may be errors or
    inaccuracies that impact the faithfulness of the dataset. Signs that data may
    not be faithful include:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 用于研究或工业的数据通常是“混乱的” - 可能存在影响数据集忠实度的错误或不准确性。数据可能不忠实的迹象包括：
- en: Unrealistic or “incorrect” values, such as negative counts, locations that don’t
    exist, or dates set in the future
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不切实际或“错误”的值，例如负计数、不存在的位置或设置在未来的日期
- en: Violations of obvious dependencies, like an age that does not match a birthday
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 违反明显依赖关系的迹象，例如年龄与生日不匹配
- en: Clear signs that data was entered by hand, which can lead to spelling errors
    or fields that are incorrectly shifted
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明显表明数据是手工输入的迹象，这可能导致拼写错误或字段错误移位
- en: Signs of data falsification, such as fake email addresses or repeated use of
    the same names
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据伪造的迹象，例如虚假的电子邮件地址或重复使用相同的名称
- en: Duplicated records or fields containing the same information
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含相同信息的重复记录或字段
- en: Truncated data, e.g. Microsoft Excel would limit the number of rows to 655536
    and the number of columns to 255
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 截断数据，例如Microsoft Excel将行数限制为655536，列数限制为255
- en: 'We often solve some of these more common issues in the following ways:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常通过以下方式解决一些更常见的问题：
- en: 'Spelling errors: apply corrections or drop records that aren’t in a dictionary'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拼写错误：应用更正或删除不在字典中的记录
- en: 'Time zone inconsistencies: convert to a common time zone (e.g. UTC)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时区不一致：转换为通用时区（例如UTC）
- en: 'Duplicated records or fields: identify and eliminate duplicates (using primary
    keys)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复的记录或字段：识别和消除重复项（使用主键）
- en: 'Unspecified or inconsistent units: infer the units and check that values are
    in reasonable ranges in the data'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未指定或不一致的单位：推断单位并检查数据中的值是否在合理范围内
- en: 5.3.1 Missing Values
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 缺失值
- en: Another common issue encountered with real-world datasets is that of missing
    data. One strategy to resolve this is to simply drop any records with missing
    values from the dataset. This does, however, introduce the risk of inducing biases
    – it is possible that the missing or corrupt records may be systemically related
    to some feature of interest in the data. Another solution is to keep the data
    as `NaN` values.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界数据集经常遇到的另一个常见问题是缺失数据。解决这个问题的一种策略是从数据集中简单地删除任何具有缺失值的记录。然而，这会引入引入偏见的风险 - 缺失或损坏的记录可能与数据中感兴趣的某些特征有系统关联。另一个解决方案是将数据保留为`NaN`值。
- en: 'A third method to address missing data is to perform **imputation**: infer
    the missing values using other data available in the dataset. There is a wide
    variety of imputation techniques that can be implemented; some of the most common
    are listed below.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 解决缺失数据的第三种方法是执行**插补**：使用数据集中的其他数据推断缺失值。可以实施各种插补技术；以下是一些最常见的插补技术。
- en: 'Average imputation: replace missing values with the average value for that
    field'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均插补：用该字段的平均值替换缺失值
- en: 'Hot deck imputation: replace missing values with some random value'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 热卡插补：用某个随机值替换缺失值
- en: 'Regression imputation: develop a model to predict missing values'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归插补：开发模型以预测缺失值
- en: 'Multiple imputation: replace missing values with multiple random values'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多重插补：用多个随机值替换缺失值
- en: Regardless of the strategy used to deal with missing data, we should think carefully
    about *why* particular records or fields may be missing – this can help inform
    whether or not the absence of these values is significant or meaningful.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 无论使用何种策略来处理缺失数据，我们都应该仔细考虑*为什么*特定记录或字段可能丢失 - 这可以帮助确定这些值的缺失是否重要或有意义。
- en: '6 EDA Demo 1: Tuberculosis in the United States'
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 EDA演示1：美国的结核病
- en: Now, let’s walk through the data-cleaning and EDA workflow to see what can we
    learn about the presence of Tuberculosis in the United States!
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们走一遍数据清理和EDA工作流程，看看我们能从美国的结核病情况中学到什么！
- en: We will examine the data included in the [original CDC article](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w#T1_down)
    published in 2021.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将检查[2021年发表的原始CDC文章](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w#T1_down)中包含的数据。
- en: 6.1 CSVs and Field Names
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 CSV和字段名称
- en: Suppose Table 1 was saved as a CSV file located in `data/cdc_tuberculosis.csv`.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 假设表1被保存为位于`data/cdc_tuberculosis.csv`的CSV文件。
- en: 'We can then explore the CSV (which is a text file, and does not contain binary-encoded
    data) in many ways: 1\. Using a text editor like emacs, vim, VSCode, etc. 2\.
    Opening the CSV directly in DataHub (read-only), Excel, Google Sheets, etc. 3\.
    The `Python` file object 4\. `pandas`, using `pd.read_csv()`'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以以多种方式探索CSV（这是一个文本文件，不包含二进制编码数据）：1. 使用文本编辑器如emacs，vim，VSCode等。2. 直接在DataHub（只读），Excel，Google
    Sheets等中打开CSV。3. `Python`文件对象4. `pandas`，使用`pd.read_csv()`
- en: To try out options 1 and 2, you can view or download the Tuberculosis from the
    [lecture demo notebook](https://data100.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FDS-100%2Ffa23-student&urlpath=lab%2Ftree%2Ffa23-student%2Flecture%2Flec05%2Flec04-eda.ipynb&branch=main)
    under the `data` folder in the left hand menu. Notice how the CSV file is a type
    of **rectangular data (i.e., tabular data) stored as comma-separated values**.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 要尝试选项1和2，您可以在左侧菜单中的`data`文件夹下查看或下载来自[演示笔记本](https://data100.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FDS-100%2Ffa23-student&urlpath=lab%2Ftree%2Ffa23-student%2Flecture%2Flec05%2Flec04-eda.ipynb&branch=main)的结核病数据。请注意，CSV文件是一种**矩形数据（即表格数据），存储为逗号分隔的值**。
- en: 'Next, let’s try out option 3 using the `Python` file object. We’ll look at
    the first four lines:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们尝试使用`Python`文件对象的选项3。我们将查看前四行：
- en: <details><summary>Code</summary>
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE46]</details>'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE46]</details>'
- en: '[PRE47]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Whoa, why are there blank lines interspaced between the lines of the CSV?
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，为什么在CSV的行之间有空行？
- en: You may recall that all line breaks in text files are encoded as the special
    newline character `\n`. Python’s `print()` prints each string (including the newline),
    and an additional newline on top of that.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得文本文件中的所有换行符都被编码为特殊的换行符`\n`。 Python的`print()`打印每个字符串（包括换行符），并在此基础上再添加一个换行符。
- en: 'If you’re curious, we can use the `repr()` function to return the raw string
    with all special characters:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您感兴趣，我们可以使用`repr()`函数返回带有所有特殊字符的原始字符串：
- en: <details><summary>Code</summary>
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE48]</details>'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE48]</details>'
- en: '[PRE49]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Finally, let’s try option 4 and use the tried-and-true Data 100 approach: `pandas`.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们尝试选项4，并使用经过验证的Data 100方法：`pandas`。
- en: '[PRE50]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '|  | Unnamed: 0 | No. of TB cases | Unnamed: 2 | Unnamed: 3 | TB incidence
    | Unnamed: 5 | Unnamed: 6 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  | 未命名: 0 | 结核病病例数 | 未命名: 2 | 未命名: 3 | 结核病发生率 | 未命名: 5 | 未命名: 6 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | U.S. jurisdiction | 2019 | 2020 | 2021 | 2019.00 | 2020.00 | 2021.00
    |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 美国司法管辖区 | 2019 | 2020 | 2021 | 2019.00 | 2020.00 | 2021.00 |'
- en: '| 1 | Total | 8,900 | 7,173 | 7,860 | 2.71 | 2.16 | 2.37 |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 总计 | 8,900 | 7,173 | 7,860 | 2.71 | 2.16 | 2.37 |'
- en: '| 2 | Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 阿拉巴马 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
- en: '| 3 | Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
- en: '| 4 | Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 亚利桑那 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
- en: 'You may notice some strange things about this table: what’s up with the “Unnamed”
    column names and the first row?'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到这个表格有一些奇怪的地方：列名中的“未命名”是怎么回事，以及第一行是什么？
- en: Congratulations — you’re ready to wrangle your data! Because of how things are
    stored, we’ll need to clean the data a bit to name our columns better.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜 - 您已经准备好整理您的数据了！由于数据的存储方式，我们需要稍微清理一下数据，以更好地命名我们的列。
- en: 'A reasonable first step is to identify the row with the right header. The `pd.read_csv()`
    function ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html))
    has the convenient `header` parameter that we can set to use the elements in row
    1 as the appropriate columns:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 一个合理的第一步是识别正确标题的行。`pd.read_csv()`函数（[文档](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)）具有方便的`header`参数，我们可以将其设置为使用第1行的元素作为适当的列：
- en: '[PRE51]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '|  | U.S. jurisdiction | 2019 | 2020 | 2021 | 2019.1 | 2020.1 | 2021.1 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '|  | 美国司法管辖区 | 2019 | 2020 | 2021 | 2019.1 | 2020.1 | 2021.1 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | Total | 8,900 | 7,173 | 7,860 | 2.71 | 2.16 | 2.37 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 总计 | 8,900 | 7,173 | 7,860 | 2.71 | 2.16 | 2.37 |'
- en: '| 1 | Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 阿拉巴马 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
- en: '| 2 | Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
- en: '| 3 | Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 亚利桑那 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
- en: '| 4 | Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 阿肯色州 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
- en: Wait…but now we can’t differentiate betwen the “Number of TB cases” and “TB
    incidence” year columns. `pandas` has tried to make our lives easier by automatically
    adding “.1” to the latter columns, but this doesn’t help us, as humans, understand
    the data.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 等等...现在我们无法区分“结核病病例数”和“结核病发生率”年列。 `pandas`已经尝试通过自动向后面的列添加“.1”来简化我们的生活，但这并不能帮助我们，作为人类，理解数据。
- en: 'We can do this manually with `df.rename()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html?highlight=rename#pandas.DataFrame.rename)):'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`df.rename()`（[文档](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html?highlight=rename#pandas.DataFrame.rename)）手动执行此操作：
- en: '[PRE52]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '|  | U.S. jurisdiction | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB
    incidence 2019 | TB incidence 2020 | TB incidence 2021 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '|  | 美国司法管辖区 | 2019年结核病病例 | 2020年结核病病例 | 2021年结核病病例 | 2019年结核病发病率 | 2020年结核病发病率
    | 2021年结核病发病率 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | Total | 8,900 | 7,173 | 7,860 | 2.71 | 2.16 | 2.37 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 总计 | 8,900 | 7,173 | 7,860 | 2.71 | 2.16 | 2.37 |'
- en: '| 1 | Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 阿拉巴马 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
- en: '| 2 | Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
- en: '| 3 | Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 亚利桑那 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
- en: '| 4 | Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 阿肯色 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
- en: 6.2 Record Granularity
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 记录粒度
- en: 'You might already be wondering: what’s up with that first record?'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经在想：第一条记录怎么了？
- en: Row 0 is what we call a **rollup record**, or summary record. It’s often useful
    when displaying tables to humans. The **granularity** of record 0 (Totals) vs
    the rest of the records (States) is different.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 第0行是我们所谓的**汇总记录**，或摘要记录。在向人类显示表格时，它通常很有用。记录0（总计）的**粒度**与其他记录（州）的粒度不同。
- en: Okay, EDA step two. How was the rollup record aggregated?
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，探索性数据分析第二步。汇总记录是如何聚合的？
- en: Let’s check if Total TB cases is the sum of all state TB cases. If we sum over
    all rows, we should get **2x** the total cases in each of our TB cases by year
    (why do you think this is?).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查总结核病例是否是所有州结核病例的总和。如果我们对所有行求和，我们应该得到每年结核病病例的总数的**2倍**（你认为这是为什么？）。
- en: <details><summary>Code</summary>
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: <详情><总结>代码</总结>
- en: '[PRE53]</details>'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE53]</details>'
- en: '[PRE54]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Whoa, what’s going on with the TB cases in 2019, 2020, and 2021? Check out
    the column types:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，2019年、2020年和2021年的结核病病例怎么了？查看列类型：
- en: <details><summary>Code</summary>
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: <详情><总结>代码</总结>
- en: '[PRE55]</details>'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE55]</details>'
- en: '[PRE56]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Since there are commas in the values for TB cases, the numbers are read as
    the `object` datatype, or **storage type** (close to the `Python` string datatype),
    so `pandas` is concatenating strings instead of adding integers (recall that `Python`
    can “sum”, or concatenate, strings together: `"data" + "100"` evaluates to `"data100"`).'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 由于结核病病例的值中有逗号，数字被读取为`object`数据类型，或**存储类型**（接近`Python`字符串数据类型），因此`pandas`正在连接字符串而不是添加整数（回想一下`Python`可以“求和”或连接字符串在一起：`"data"
    + "100"`的结果是`"data100"`）。
- en: 'Fortunately `read_csv` also has a `thousands` parameter ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)):'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，`read_csv`还有一个`thousands`参数（[文档](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)）：
- en: '[PRE57]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '|  | U.S. jurisdiction | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB
    incidence 2019 | TB incidence 2020 | TB incidence 2021 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '|  | 美国司法管辖区 | 2019年结核病病例 | 2020年结核病病例 | 2021年结核病病例 | 2019年结核病发病率 | 2020年结核病发病率
    | 2021年结核病发病率 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | Total | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 总计 | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 |'
- en: '| 1 | Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 阿拉巴马 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
- en: '| 2 | Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
- en: '| 3 | Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 亚利桑那 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
- en: '| 4 | Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 阿肯色 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
- en: '[PRE58]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The Total TB cases look right. Phew!
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 总结核病例看起来没问题。哦！
- en: 'Let’s just look at the records with **state-level granularity**:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们只看具有**州级粒度**的记录：
- en: <details><summary>Code</summary>
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: <详情><总结>代码</总结>
- en: '[PRE60]</details>'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE60]</details>'
- en: '|  | U.S. jurisdiction | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB
    incidence 2019 | TB incidence 2020 | TB incidence 2021 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '|  | 美国司法管辖区 | 2019年结核病病例 | 2020年结核病病例 | 2021年结核病病例 | 2019年结核病发病率 | 2020年结核病发病率
    | 2021年结核病发病率 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 阿拉巴马 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
- en: '| 2 | Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
- en: '| 3 | Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 亚利桑那 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
- en: '| 4 | Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 阿肯色 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
- en: '| 5 | California | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 加利福尼亚 | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 |'
- en: 6.3 Gather Census Data
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 收集人口普查数据
- en: U.S. Census population estimates [source](https://www.census.gov/data/tables/time-series/demo/popest/2010s-state-total.html)
    (2019), [source](https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html)
    (2020-2021).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 美国人口普查人口估计[来源](https://www.census.gov/data/tables/time-series/demo/popest/2010s-state-total.html)（2019年），[来源](https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html)（2020-2021年）。
- en: 'Running the below cells cleans the data. There are a few new methods here:
    * `df.convert_dtypes()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html))
    conveniently converts all float dtypes into ints and is out of scope for the class.
    * `df.drop_na()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html))
    will be explained in more detail next time.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 运行下面的单元格清理数据。这里有一些新的方法：* `df.convert_dtypes()` ([文档](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html))方便地将所有浮点数类型转换为整数，超出了课程范围。*
    `df.drop_na()` ([文档](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html))将在下次详细解释。
- en: <details><summary>Code</summary>
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: <详情><总结>代码</总结>
- en: '[PRE61]</details>'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE61]</details>'
- en: '|  | Geographic Area | 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017
    | 2018 | 2019 |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '|  | 地理区域 | 2010年 | 2011年 | 2012年 | 2013年 | 2014年 | 2015年 | 2016年 | 2017年 |
    2018年 | 2019年 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | United States | 309321666 | 311556874 | 313830990 | 315993715 | 318301008
    | 320635163 | 322941311 | 324985539 | 326687501 | 328239523 |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 美国 | 309,321,666 | 311,556,874 | 313,830,990 | 315,993,715 | 318,301,008
    | 320,635,163 | 322,941,311 | 324,985,539 | 326,687,501 | 328,239,523 |'
- en: '| 1 | Northeast | 55380134 | 55604223 | 55775216 | 55901806 | 56006011 | 56034684
    | 56042330 | 56059240 | 56046620 | 55982803 |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 东北部 | 55380134 | 55604223 | 55775216 | 55901806 | 56006011 | 56034684
    | 56042330 | 56059240 | 56046620 | 55982803 |'
- en: '| 2 | Midwest | 66974416 | 67157800 | 67336743 | 67560379 | 67745167 | 67860583
    | 67987540 | 68126781 | 68236628 | 68329004 |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 中西部 | 66974416 | 67157800 | 67336743 | 67560379 | 67745167 | 67860583
    | 67987540 | 68126781 | 68236628 | 68329004 |'
- en: '| 3 | South | 114866680 | 116006522 | 117241208 | 118364400 | 119624037 | 120997341
    | 122351760 | 123542189 | 124569433 | 125580448 |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 南部 | 114866680 | 116006522 | 117241208 | 118364400 | 119624037 | 120997341
    | 122351760 | 123542189 | 124569433 | 125580448 |'
- en: '| 4 | West | 72100436 | 72788329 | 73477823 | 74167130 | 74925793 | 75742555
    | 76559681 | 77257329 | 77834820 | 78347268 |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 西部 | 72100436 | 72788329 | 73477823 | 74167130 | 74925793 | 75742555
    | 76559681 | 77257329 | 77834820 | 78347268 |'
- en: 'Occasionally, you will want to modify code that you have imported. To reimport
    those modifications you can either use `python`’s `importlib` library:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，您会想要修改导入的代码。要重新导入这些修改，您可以使用`python`的`importlib`库：
- en: '[PRE62]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'or use `iPython` magic which will intelligently import code when files change:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 或者使用`iPython`魔术，它将在文件更改时智能地导入代码：
- en: '[PRE63]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: <details><summary>Code</summary>
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE64]</details>'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE64]</details>'
- en: '|  | Geographic Area | 2020 | 2021 | 2022 |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '|  | 地理区域 | 2020 | 2021 | 2022 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | United States | 331511512 | 332031554 | 333287557 |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 美国 | 331511512 | 332031554 | 333287557 |'
- en: '| 1 | Northeast | 57448898 | 57259257 | 57040406 |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 东北部 | 57448898 | 57259257 | 57040406 |'
- en: '| 2 | Midwest | 68961043 | 68836505 | 68787595 |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 中西部 | 68961043 | 68836505 | 68787595 |'
- en: '| 3 | South | 126450613 | 127346029 | 128716192 |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 南部 | 126450613 | 127346029 | 128716192 |'
- en: '| 4 | West | 78650958 | 78589763 | 78743364 |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 西部 | 78650958 | 78589763 | 78743364 |'
- en: 6.4 Joining Data (Merging `DataFrame`s)
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 合并数据（合并“DataFrame”）
- en: Time to `merge`! Here we use the `DataFrame` method `df1.merge(right=df2, ...)`
    on `DataFrame` `df1` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)).
    Contrast this with the function `pd.merge(left=df1, right=df2, ...)` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.merge.html?highlight=pandas%20merge#pandas.merge)).
    Feel free to use either.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 时间`merge`！这里我们使用`DataFrame`方法`df1.merge(right=df2, ...)`在`DataFrame` `df1`上（[文档](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)）。与函数`pd.merge(left=df1,
    right=df2, ...)`（[文档](https://pandas.pydata.org/docs/reference/api/pandas.merge.html?highlight=pandas%20merge#pandas.merge)）进行对比。可以随意使用任何一个。
- en: '[PRE65]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '|  | U.S. jurisdiction | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB
    incidence 2019 | TB incidence 2020 | TB incidence 2021 | Geographic Area_x | 2010
    | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 | Geographic Area_y
    | 2020 | 2021 | 2022 |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '|  | 美国司法管辖区 | 2019年结核病病例 | 2020年结核病病例 | 2021年结核病病例 | 2019年结核病发病率 | 2020年结核病发病率
    | 2021年结核病发病率 | 地理区域_x | 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017
    | 2018 | 2019 | 地理区域_y | 2020 | 2021 | 2022 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | Alabama | 4785437 | 4799069
    | 4815588 | 4830081 | 4841799 | 4852347 | 4863525 | 4874486 | 4887681 | 4903185
    | Alabama | 5031362 | 5049846 | 5074296 |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 阿拉巴马 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 阿拉巴马 | 4785437 | 4799069 |
    4815588 | 4830081 | 4841799 | 4852347 | 4863525 | 4874486 | 4887681 | 4903185
    | 阿拉巴马 | 5031362 | 5049846 | 5074296 |'
- en: '| 1 | Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | Alaska | 713910 | 722128
    | 730443 | 737068 | 736283 | 737498 | 741456 | 739700 | 735139 | 731545 | Alaska
    | 732923 | 734182 | 733583 |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 阿拉斯加 | 713910 | 722128 | 730443
    | 737068 | 736283 | 737498 | 741456 | 739700 | 735139 | 731545 | 阿拉斯加 | 732923
    | 734182 | 733583 |'
- en: '| 2 | Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | Arizona | 6407172 |
    6472643 | 6554978 | 6632764 | 6730413 | 6829676 | 6941072 | 7044008 | 7158024
    | 7278717 | Arizona | 7179943 | 7264877 | 7359197 |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 亚利桑那 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 亚利桑那 | 6407172 | 6472643
    | 6554978 | 6632764 | 6730413 | 6829676 | 6941072 | 7044008 | 7158024 | 7278717
    | 亚利桑那 | 7179943 | 7264877 | 7359197 |'
- en: '| 3 | Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | Arkansas | 2921964 | 2940667
    | 2952164 | 2959400 | 2967392 | 2978048 | 2989918 | 3001345 | 3009733 | 3017804
    | Arkansas | 3014195 | 3028122 | 3045637 |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 阿肯色 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 阿肯色 | 2921964 | 2940667 | 2952164
    | 2959400 | 2967392 | 2978048 | 2989918 | 3001345 | 3009733 | 3017804 | 阿肯色 |
    3014195 | 3028122 | 3045637 |'
- en: '| 4 | California | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 | California | 37319502
    | 37638369 | 37948800 | 38260787 | 38596972 | 38918045 | 39167117 | 39358497 |
    39461588 | 39512223 | California | 39501653 | 39142991 | 39029342 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 加利福尼亚 | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 | 加利福尼亚 | 37319502 |
    37638369 | 37948800 | 38260787 | 38596972 | 38918045 | 39167117 | 39358497 | 39461588
    | 39512223 | 加利福尼亚 | 39501653 | 39142991 | 39029342 |'
- en: Having all of these columns is a little unwieldy. We could either drop the unneeded
    columns now, or just merge on smaller census `DataFrame`s. Let’s do the latter.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有所有这些列有点不方便。我们现在可以删除不需要的列，或者只是合并较小的人口普查“DataFrame”。让我们选择后者。
- en: '[PRE66]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '|  | U.S. jurisdiction | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB
    incidence 2019 | TB incidence 2020 | TB incidence 2021 | 2019 | 2020 | 2021 |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '|  | 美国司法管辖区 | 2019年结核病病例 | 2020年结核病病例 | 2021年结核病病例 | 2019年结核病发病率 | 2020年结核病发病率
    | 2021年结核病发病率 | 2019 | 2020 | 2021 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846
    |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 阿拉巴马 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846
    |'
- en: '| 1 | Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182
    |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182 |'
- en: '| 2 | Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 |
    7264877 |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 亚利桑那 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 | 7264877
    |'
- en: '| 3 | Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122
    |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 阿肯色 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122
    |'
- en: '| 4 | California | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 | 39512223 | 39501653
    | 39142991 |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 加利福尼亚 | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 | 39512223 | 39501653
    | 39142991 |'
- en: '6.5 Reproducing Data: Compute Incidence'
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 再现数据：计算发病率
- en: Let’s recompute incidence to make sure we know where the original CDC numbers
    came from.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新计算发病率，以确保我们知道原始CDC数字来自何处。
- en: 'From the [CDC report](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w#T1_down):
    TB incidence is computed as “Cases per 100,000 persons using mid-year population
    estimates from the U.S. Census Bureau.”'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[疾病控制和预防中心的报告](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w#T1_down)：TB发病率计算为“使用美国人口普查局的中期人口估计，每10万人的病例数”。
- en: If we define a group as 100,000 people, then we can compute the TB incidence
    for a given state population as
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将一个群体定义为10万人，那么我们可以计算给定州人口的TB发病率为
- en: \[\text{TB incidence} = \frac{\text{TB cases in population}}{\text{groups in
    population}} = \frac{\text{TB cases in population}}{\text{population}/100000}
    \]
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: \[\text{TB发病率} = \frac{\text{人口中的TB病例}}{\text{人口中的群体}} = \frac{\text{人口中的TB病例}}{\text{人口}/100000}
    \]
- en: \[= \frac{\text{TB cases in population}}{\text{population}} \times 100000\]
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: \[= \frac{\text{人口中的TB病例}}{\text{人口}} \times 100000\]
- en: 'Let’s try this for 2019:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试2019年的情况：
- en: '[PRE67]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '|  | U.S. jurisdiction | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB
    incidence 2019 | TB incidence 2020 | TB incidence 2021 | 2019 | 2020 | 2021 |
    recompute incidence 2019 |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '|  | 美国司法管辖区 | TB病例2019 | TB病例2020 | TB病例2021 | TB发病率2019 | TB发病率2020 | TB发病率2021
    | 2019 | 2020 | 2021 | 重新计算发病率2019 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846
    | 1.77 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 阿拉巴马州 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846
    | 1.77 |'
- en: '| 1 | Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182
    | 7.93 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 阿拉斯加州 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182
    | 7.93 |'
- en: '| 2 | Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 |
    7264877 | 2.51 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 亚利桑那州 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 | 7264877
    | 2.51 |'
- en: '| 3 | Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122
    | 2.12 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 阿肯色州 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122
    | 2.12 |'
- en: '| 4 | California | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 | 39512223 | 39501653
    | 39142991 | 5.34 |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 加利福尼亚州 | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 | 39512223 | 39501653
    | 39142991 | 5.34 |'
- en: Awesome!!!
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！！！
- en: Let’s use a for-loop and `Python` format strings to compute TB incidence for
    all years. `Python` f-strings are just used for the purposes of this demo, but
    they’re handy to know when you explore data beyond this course ([documentation](https://docs.python.org/3/tutorial/inputoutput.html)).
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用for循环和`Python`格式字符串来计算所有年份的TB发病率。`Python` f-strings仅用于此演示目的，但在探索本课程之外的数据时，它们很方便（[文档](https://docs.python.org/3/tutorial/inputoutput.html)）。
- en: '[PRE68]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '|  | U.S. jurisdiction | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB
    incidence 2019 | TB incidence 2020 | TB incidence 2021 | 2019 | 2020 | 2021 |
    recompute incidence 2019 | recompute incidence 2020 | recompute incidence 2021
    |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '|  | 美国司法管辖区 | TB病例2019 | TB病例2020 | TB病例2021 | TB发病率2019 | TB发病率2020 | TB发病率2021
    | 2019 | 2020 | 2021 | 重新计算发病率2019 | 重新计算发病率2020 | 重新计算发病率2021 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
- en: '| 0 | Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846
    | 1.77 | 1.43 | 1.82 |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 阿拉巴马州 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846
    | 1.77 | 1.43 | 1.82 |'
- en: '| 1 | Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182
    | 7.93 | 7.91 | 7.90 |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 阿拉斯加州 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182
    | 7.93 | 7.91 | 7.90 |'
- en: '| 2 | Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 |
    7264877 | 2.51 | 1.89 | 1.78 |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 亚利桑那州 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 | 7264877
    | 2.51 | 1.89 | 1.78 |'
- en: '| 3 | Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122
    | 2.12 | 1.96 | 2.28 |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 阿肯色州 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122
    | 2.12 | 1.96 | 2.28 |'
- en: '| 4 | California | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 | 39512223 | 39501653
    | 39142991 | 5.34 | 4.32 | 4.47 |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 加利福尼亚州 | 2111 | 1706 | 1750 | 5.35 | 4.32 | 4.46 | 39512223 | 39501653
    | 39142991 | 5.34 | 4.32 | 4.47 |'
- en: These numbers look pretty close!!! There are a few errors in the hundredths
    place, particularly in 2021\. It may be useful to further explore reasons behind
    this discrepancy.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数字看起来非常接近！！！特别是在2021年，百分位数的小数位上有一些错误。进一步探讨这种差异背后的原因可能是有用的。
- en: '[PRE69]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '|  | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB incidence 2019 | TB
    incidence 2020 | TB incidence 2021 | 2019 | 2020 | 2021 | recompute incidence
    2019 | recompute incidence 2020 | recompute incidence 2021 |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '|  | TB病例2019 | TB病例2020 | TB病例2021 | TB发病率2019 | TB发病率2020 | TB发病率2021 | 2019
    | 2020 | 2021 | 重新计算发病率2019 | 重新计算发病率2020 | 重新计算发病率2021 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
- en: '| count | 51.00 | 51.00 | 51.00 | 51.00 | 51.00 | 51.00 | 51.00 | 51.00 | 51.00
    | 51.00 | 51.00 | 51.00 |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 计数 | 51.00 | 51.00 | 51.00 | 51.00 | 51.00 | 51.00 | 51.00 | 51.00 | 51.00
    | 51.00 | 51.00 | 51.00 |'
- en: '| mean | 174.51 | 140.65 | 154.12 | 2.10 | 1.78 | 1.97 | 6436069.08 | 6500225.73
    | 6510422.63 | 2.10 | 1.78 | 1.97 |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 174.51 | 140.65 | 154.12 | 2.10 | 1.78 | 1.97 | 6436069.08 | 6500225.73
    | 6510422.63 | 2.10 | 1.78 | 1.97 |'
- en: '| std | 341.74 | 271.06 | 286.78 | 1.50 | 1.34 | 1.48 | 7360660.47 | 7408168.46
    | 7394300.08 | 1.50 | 1.34 | 1.47 |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 标准差 | 341.74 | 271.06 | 286.78 | 1.50 | 1.34 | 1.48 | 7360660.47 | 7408168.46
    | 7394300.08 | 1.50 | 1.34 | 1.47 |'
- en: '| min | 1.00 | 0.00 | 2.00 | 0.17 | 0.00 | 0.21 | 578759.00 | 577605.00 | 579483.00
    | 0.17 | 0.00 | 0.21 |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| 最小值 | 1.00 | 0.00 | 2.00 | 0.17 | 0.00 | 0.21 | 578759.00 | 577605.00 | 579483.00
    | 0.17 | 0.00 | 0.21 |'
- en: '| 25% | 25.50 | 29.00 | 23.00 | 1.29 | 1.21 | 1.23 | 1789606.00 | 1820311.00
    | 1844920.00 | 1.30 | 1.21 | 1.23 |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 25% | 25.50 | 29.00 | 23.00 | 1.29 | 1.21 | 1.23 | 1789606.00 | 1820311.00
    | 1844920.00 | 1.30 | 1.21 | 1.23 |'
- en: '| 50% | 70.00 | 67.00 | 69.00 | 1.80 | 1.52 | 1.70 | 4467673.00 | 4507445.00
    | 4506589.00 | 1.81 | 1.52 | 1.69 |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| 50% | 70.00 | 67.00 | 69.00 | 1.80 | 1.52 | 1.70 | 4467673.00 | 4507445.00
    | 4506589.00 | 1.81 | 1.52 | 1.69 |'
- en: '| 75% | 180.50 | 139.00 | 150.00 | 2.58 | 1.99 | 2.22 | 7446805.00 | 7451987.00
    | 7502811.00 | 2.58 | 1.99 | 2.22 |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| 75% | 180.50 | 139.00 | 150.00 | 2.58 | 1.99 | 2.22 | 7446805.00 | 7451987.00
    | 7502811.00 | 2.58 | 1.99 | 2.22 |'
- en: '| max | 2111.00 | 1706.00 | 1750.00 | 7.91 | 7.92 | 7.92 | 39512223.00 | 39501653.00
    | 39142991.00 | 7.93 | 7.91 | 7.90 |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 最大值 | 2111.00 | 1706.00 | 1750.00 | 7.91 | 7.92 | 7.92 | 39512223.00 | 39501653.00
    | 39142991.00 | 7.93 | 7.91 | 7.90 |'
- en: '6.6 Bonus EDA: Reproducing the Reported Statistic'
  id: totrans-391
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.6奖励EDA：重现报告的统计数据
- en: '**How do we reproduce that reported statistic in the original [CDC report](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w)?**'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们如何重现原始[CDC报告](https://www.cdc.gov/mmwr/volumes/71/wr/mm7112a1.htm?s_cid=mm7112a1_w)中报告的统计数据？**'
- en: Reported TB incidence (cases per 100,000 persons) increased **9.4%**, from **2.2**
    during 2020 to **2.4** during 2021 but was lower than incidence during 2019 (2.7).
    Increases occurred among both U.S.-born and non–U.S.-born persons.
  id: totrans-393
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 报告的结核病发病率（每10万人口的病例数）增加了**9.4%**，从2020年的**2.2**增加到2021年的**2.4**，但低于2019年的发病率（2.7）。美国出生和非美国出生人群的发病率均有所增加。
- en: This is TB incidence computed across the entire U.S. population! How do we reproduce
    this? * We need to reproduce the “Total” TB incidences in our rolled record. *
    But our current `tb_census_df` only has 51 entries (50 states plus Washington,
    D.C.). There is no rolled record. * What happened…?
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在整个美国人口中计算的结核病发病率！我们如何重现这一点？*我们需要重现我们滚动记录中的“总”结核病发病率。*但是我们当前的`tb_census_df`只有51个条目（50个州加上华盛顿特区）。没有滚动记录。*发生了什么…？
- en: Let’s get exploring!
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始探索吧！
- en: Before we keep exploring, we’ll set all indexes to more meaningful values, instead
    of just numbers that pertain to some row at some point. This will make our cleaning
    slightly easier.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续探索之前，我们将所有索引设置为更有意义的值，而不仅仅是与某一行相关的数字。这将使我们的清理稍微容易一些。
- en: <details><summary>Code</summary>
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE70]</details>'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE70]</details>'
- en: '|  | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB incidence 2019 | TB
    incidence 2020 | TB incidence 2021 |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '|  | TB病例2019 | TB病例2020 | TB病例2021 | TB发病率2019 | TB发病率2020 | TB发病率2021 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| U.S. jurisdiction |  |  |  |  |  |  |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 美国司法管辖区 |  |  |  |  |  |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Total | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 |'
- en: '| Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 阿拉巴马 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
- en: '| Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
- en: '| Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 亚利桑那 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
- en: '| Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 阿肯色 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
- en: '[PRE71]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '|  | 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '|  | 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Geographic Area |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 地理区域 |  |  |  |  |  |  |  |  |  |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| United States | 309321666 | 311556874 | 313830990 | 315993715 | 318301008
    | 320635163 | 322941311 | 324985539 | 326687501 | 328239523 |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| 美国 | 309321666 | 311556874 | 313830990 | 315993715 | 318301008 | 320635163
    | 322941311 | 324985539 | 326687501 | 328239523 |'
- en: '| Northeast | 55380134 | 55604223 | 55775216 | 55901806 | 56006011 | 56034684
    | 56042330 | 56059240 | 56046620 | 55982803 |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| 东北部 | 55380134 | 55604223 | 55775216 | 55901806 | 56006011 | 56034684 | 56042330
    | 56059240 | 56046620 | 55982803 |'
- en: '| Midwest | 66974416 | 67157800 | 67336743 | 67560379 | 67745167 | 67860583
    | 67987540 | 68126781 | 68236628 | 68329004 |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| 中西部 | 66974416 | 67157800 | 67336743 | 67560379 | 67745167 | 67860583 | 67987540
    | 68126781 | 68236628 | 68329004 |'
- en: '| South | 114866680 | 116006522 | 117241208 | 118364400 | 119624037 | 120997341
    | 122351760 | 123542189 | 124569433 | 125580448 |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| 南部 | 114866680 | 116006522 | 117241208 | 118364400 | 119624037 | 120997341
    | 122351760 | 123542189 | 124569433 | 125580448 |'
- en: '| West | 72100436 | 72788329 | 73477823 | 74167130 | 74925793 | 75742555 |
    76559681 | 77257329 | 77834820 | 78347268 |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| 西部 | 72100436 | 72788329 | 73477823 | 74167130 | 74925793 | 75742555 | 76559681
    | 77257329 | 77834820 | 78347268 |'
- en: '[PRE72]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '|  | 2020 | 2021 | 2022 |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '|  | 2020 | 2021 | 2022 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Geographic Area |  |  |  |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| 地理区域 |  |  |  |'
- en: '| --- | --- | --- | --- |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| United States | 331511512 | 332031554 | 333287557 |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| 美国 | 331511512 | 332031554 | 333287557 |'
- en: '| Northeast | 57448898 | 57259257 | 57040406 |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| 东北部 | 57448898 | 57259257 | 57040406 |'
- en: '| Midwest | 68961043 | 68836505 | 68787595 |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| 中西部 | 68961043 | 68836505 | 68787595 |'
- en: '| South | 126450613 | 127346029 | 128716192 |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| 南部 | 126450613 | 127346029 | 128716192 |'
- en: '| West | 78650958 | 78589763 | 78743364 |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 西部 | 78650958 | 78589763 | 78743364 |'
- en: 'It turns out that our merge above only kept state records, even though our
    original `tb_df` had the “Total” rolled record:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，我们上面的合并只保留了州记录，即使我们原始的`tb_df`中有“总计”滚动记录：
- en: '[PRE73]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '|  | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB incidence 2019 | TB
    incidence 2020 | TB incidence 2021 |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '|  | TB病例2019 | TB病例2020 | TB病例2021 | TB发病率2019 | TB发病率2020 | TB发病率2021 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| U.S. jurisdiction |  |  |  |  |  |  |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 美国司法管辖区 |  |  |  |  |  |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Total | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 |'
- en: '| Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 阿拉巴马 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 |'
- en: '| Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 |'
- en: '| Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 亚利桑那 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 |'
- en: '| Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 阿肯色 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 |'
- en: Recall that `merge` by default does an **inner** merge by default, meaning that
    it only preserves keys that are present in **both** `DataFrame`s.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，默认情况下，`merge`执行**内部**合并，默认情况下，这意味着它只保留在**两个**`DataFrame`中都存在的键。
- en: 'The rolled records in our census `DataFrame` have different `Geographic Area`
    fields, which was the key we merged on:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 我们人口普查`DataFrame`中的滚动记录具有不同的`地理区域`字段，这是我们合并的关键：
- en: '[PRE74]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '|  | 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '|  | 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Geographic Area |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| 地理区域 |  |  |  |  |  |  |  |  |  |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| United States | 309321666 | 311556874 | 313830990 | 315993715 | 318301008
    | 320635163 | 322941311 | 324985539 | 326687501 | 328239523 |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| 美国 | 309321666 | 311556874 | 313830990 | 315993715 | 318301008 | 320635163
    | 322941311 | 324985539 | 326687501 | 328239523 |'
- en: '| Northeast | 55380134 | 55604223 | 55775216 | 55901806 | 56006011 | 56034684
    | 56042330 | 56059240 | 56046620 | 55982803 |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| 东北部 | 55380134 | 55604223 | 55775216 | 55901806 | 56006011 | 56034684 | 56042330
    | 56059240 | 56046620 | 55982803 |'
- en: '| Midwest | 66974416 | 67157800 | 67336743 | 67560379 | 67745167 | 67860583
    | 67987540 | 68126781 | 68236628 | 68329004 |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| 中西部 | 66974416 | 67157800 | 67336743 | 67560379 | 67745167 | 67860583 | 67987540
    | 68126781 | 68236628 | 68329004 |'
- en: '| South | 114866680 | 116006522 | 117241208 | 118364400 | 119624037 | 120997341
    | 122351760 | 123542189 | 124569433 | 125580448 |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| 南部 | 114866680 | 116006522 | 117241208 | 118364400 | 119624037 | 120997341
    | 122351760 | 123542189 | 124569433 | 125580448 |'
- en: '| West | 72100436 | 72788329 | 73477823 | 74167130 | 74925793 | 75742555 |
    76559681 | 77257329 | 77834820 | 78347268 |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| 西部 | 72100436 | 72788329 | 73477823 | 74167130 | 74925793 | 75742555 | 76559681
    | 77257329 | 77834820 | 78347268 |'
- en: The Census `DataFrame` has several rolled records. The aggregate record we are
    looking for actually has the Geographic Area named “United States”.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 人口普查`DataFrame`有几个已经合并的记录。我们正在寻找的聚合记录实际上将地理区域命名为“美国”。
- en: 'One straightforward way to get the right merge is to rename the value itself.
    Because we now have the Geographic Area index, we’ll use `df.rename()` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)):'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个直接的方法来获得正确的合并，那就是重命名值本身。因为我们现在有地理区域索引，我们将使用`df.rename()` ([文档](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html))：
- en: '[PRE75]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '|  | 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
  zh: '|  | 2010 | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 | 2017 | 2018 | 2019 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-455
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Geographic Area |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '| 地理区域 |  |  |  |  |  |  |  |  |  |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Total | 309321666 | 311556874 | 313830990 | 315993715 | 318301008 | 320635163
    | 322941311 | 324985539 | 326687501 | 328239523 |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| 总数 | 309321666 | 311556874 | 313830990 | 315993715 | 318301008 | 320635163
    | 322941311 | 324985539 | 326687501 | 328239523 |'
- en: '| Northeast | 55380134 | 55604223 | 55775216 | 55901806 | 56006011 | 56034684
    | 56042330 | 56059240 | 56046620 | 55982803 |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| 东北部 | 55380134 | 55604223 | 55775216 | 55901806 | 56006011 | 56034684 | 56042330
    | 56059240 | 56046620 | 55982803 |'
- en: '| Midwest | 66974416 | 67157800 | 67336743 | 67560379 | 67745167 | 67860583
    | 67987540 | 68126781 | 68236628 | 68329004 |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| 中西部 | 66974416 | 67157800 | 67336743 | 67560379 | 67745167 | 67860583 | 67987540
    | 68126781 | 68236628 | 68329004 |'
- en: '| South | 114866680 | 116006522 | 117241208 | 118364400 | 119624037 | 120997341
    | 122351760 | 123542189 | 124569433 | 125580448 |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| 南部 | 114866680 | 116006522 | 117241208 | 118364400 | 119624037 | 120997341
    | 122351760 | 123542189 | 124569433 | 125580448 |'
- en: '| West | 72100436 | 72788329 | 73477823 | 74167130 | 74925793 | 75742555 |
    76559681 | 77257329 | 77834820 | 78347268 |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| 西部 | 72100436 | 72788329 | 73477823 | 74167130 | 74925793 | 75742555 | 76559681
    | 77257329 | 77834820 | 78347268 |'
- en: '[PRE76]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '|  | 2020 | 2021 | 2022 |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '|  | 2020 | 2021 | 2022 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Geographic Area |  |  |  |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| 地理区域 |  |  |  |'
- en: '| --- | --- | --- | --- |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Total | 331511512 | 332031554 | 333287557 |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| 总数 | 331511512 | 332031554 | 333287557 |'
- en: '| Northeast | 57448898 | 57259257 | 57040406 |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| 东北部 | 57448898 | 57259257 | 57040406 |'
- en: '| Midwest | 68961043 | 68836505 | 68787595 |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| 中西部 | 68961043 | 68836505 | 68787595 |'
- en: '| South | 126450613 | 127346029 | 128716192 |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| 南部 | 126450613 | 127346029 | 128716192 |'
- en: '| West | 78650958 | 78589763 | 78743364 |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| 西部 | 78650958 | 78589763 | 78743364 |'
- en: Next let’s rerun our merge. Note the different chaining, because we are now
    merging on indexes (`df.merge()` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)).
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来让我们重新运行我们的合并。请注意不同的链接方式，因为我们现在是在索引上进行合并(`df.merge()` [文档](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html))。
- en: '[PRE77]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '|  | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB incidence 2019 | TB
    incidence 2020 | TB incidence 2021 | 2019 | 2020 | 2021 |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '|  | 2019结核病例 | 2020结核病例 | 2021结核病例 | 2019结核发病率 | 2020结核发病率 | 2021结核发病率 | 2019
    | 2020 | 2021 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Total | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 | 328239523 | 331511512 |
    332031554 |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
  zh: '| 总数 | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 | 328239523 | 331511512 | 332031554
    |'
- en: '| Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846
    |'
  id: totrans-478
  prefs: []
  type: TYPE_TB
  zh: '| 阿拉巴马州 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846 |'
- en: '| Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182 |'
  id: totrans-479
  prefs: []
  type: TYPE_TB
  zh: '| 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182 |'
- en: '| Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 | 7264877
    |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| 亚利桑那州 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 | 7264877
    |'
- en: '| Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122
    |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| 阿肯色州 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122 |'
- en: 'Finally, let’s recompute our incidences:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们重新计算我们的发病率：
- en: '[PRE78]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '|  | TB cases 2019 | TB cases 2020 | TB cases 2021 | TB incidence 2019 | TB
    incidence 2020 | TB incidence 2021 | 2019 | 2020 | 2021 | recompute incidence
    2019 | recompute incidence 2020 | recompute incidence 2021 |'
  id: totrans-484
  prefs: []
  type: TYPE_TB
  zh: '|  | 2019结核病例 | 2020结核病例 | 2021结核病例 | 2019结核发病率 | 2020结核发病率 | 2021结核发病率 | 2019
    | 2020 | 2021 | 重新计算发病率2019 | 重新计算发病率2020 | 重新计算发病率2021 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
- en: '| Total | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 | 328239523 | 331511512 |
    332031554 | 2.71 | 2.16 | 2.37 |'
  id: totrans-486
  prefs: []
  type: TYPE_TB
  zh: '| 总数 | 8900 | 7173 | 7860 | 2.71 | 2.16 | 2.37 | 328239523 | 331511512 | 332031554
    | 2.71 | 2.16 | 2.37 |'
- en: '| Alabama | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846
    | 1.77 | 1.43 | 1.82 |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '| 阿拉巴马州 | 87 | 72 | 92 | 1.77 | 1.43 | 1.83 | 4903185 | 5031362 | 5049846 |
    1.77 | 1.43 | 1.82 |'
- en: '| Alaska | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182 | 7.93
    | 7.91 | 7.90 |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '| 阿拉斯加 | 58 | 58 | 58 | 7.91 | 7.92 | 7.92 | 731545 | 732923 | 734182 | 7.93
    | 7.91 | 7.90 |'
- en: '| Arizona | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 | 7264877
    | 2.51 | 1.89 | 1.78 |'
  id: totrans-489
  prefs: []
  type: TYPE_TB
  zh: '| 亚利桑那州 | 183 | 136 | 129 | 2.51 | 1.89 | 1.77 | 7278717 | 7179943 | 7264877
    | 2.51 | 1.89 | 1.78 |'
- en: '| Arkansas | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122
    | 2.12 | 1.96 | 2.28 |'
  id: totrans-490
  prefs: []
  type: TYPE_TB
  zh: '| 阿肯色州 | 64 | 59 | 69 | 2.12 | 1.96 | 2.28 | 3017804 | 3014195 | 3028122 |
    2.12 | 1.96 | 2.28 |'
- en: We reproduced the total U.S. incidences correctly!
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正确地重现了美国的总发病率！
- en: 'We’re almost there. Let’s revisit the quote:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 我们快要完成了。让我们重新审视这段引用：
- en: Reported TB incidence (cases per 100,000 persons) increased **9.4%**, from **2.2**
    during 2020 to **2.4** during 2021 but was lower than incidence during 2019 (2.7).
    Increases occurred among both U.S.-born and non–U.S.-born persons.
  id: totrans-493
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 报告的结核病发病率（每10万人口的病例）增加了**9.4%**，从2020年的**2.2**增加到2021年的**2.4**，但低于2019年的发病率（2.7）。美国出生和非美国出生人群的发病率均有所增加。
- en: Recall that percent change from \(A\) to \(B\) is computed as \(\text{percent
    change} = \frac{B - A}{A} \times 100\).
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，从\(A\)到\(B\)的百分比变化计算公式为\(\text{percent change} = \frac{B - A}{A} \times
    100\)。
- en: '[PRE79]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-499
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '7 EDA Demo 2: Mauna Loa CO[2] Data – A Lesson in Data Faithfulness'
  id: totrans-501
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 EDA演示2：毛纳罗亚CO[2]数据 - 数据忠实度的一课
- en: '[Mauna Loa Observatory](https://gml.noaa.gov/ccgg/trends/data.html) has been
    monitoring CO[2] concentrations since 1958'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '[毛纳罗亚观测站](https://gml.noaa.gov/ccgg/trends/data.html) 自1958年以来一直在监测二氧化碳浓度'
- en: '[PRE85]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Let’s do some **EDA**!!
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一些**EDA**！
- en: 7.1 Reading this file into Pandas?
  id: totrans-505
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 将此文件读入Pandas？
- en: 'Let’s instead check out this `.txt` file. Some questions to keep in mind: Do
    we trust this file extension? What structure is it?'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这个`.txt`文件。要记住的一些问题：我们信任这个文件扩展名吗？它的结构是什么？
- en: 'Lines 71-78 (inclusive) are shown below:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 第71-78行（包括）如下所示：
- en: '[PRE86]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Notice how:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：
- en: The values are separated by white space, possibly tabs.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些值由空格分隔，可能是制表符。
- en: The data line up down the rows. For example, the month appears in 7th to 8th
    position of each line.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据在行上排列。例如，每行的第7到第8个位置显示了月份。
- en: The 71st and 72nd lines in the file contain column headings split over two lines.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件的第71和72行包含分布在两行上的列标题。
- en: We can use `read_csv` to read the data into a `pandas` `DataFrame`, and we provide
    several arguments to specify that the separators are white space, there is no
    header (**we will set our own column names**), and to skip the first 72 rows of
    the file.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`read_csv`将数据读入`pandas`的`DataFrame`，并提供几个参数来指定分隔符是空格，没有标题（**我们将设置自己的列名**），并跳过文件的前72行。
- en: '[PRE87]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '|  | 0 | 1 | 2 | 3 | 4 | 5 | 6 |'
  id: totrans-515
  prefs: []
  type: TYPE_TB
  zh: "0\t1\t2\t3\t4\t5\t6"
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
  zh: "---\t---\t---\t---\t---\t---\t---"
- en: '| 0 | 1958 | 3 | 1958.21 | 315.71 | 315.71 | 314.62 | -1 |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
  zh: "0\t1958\t3\t1958.21\t315.71\t315.71\t314.62\t-1"
- en: '| 1 | 1958 | 4 | 1958.29 | 317.45 | 317.45 | 315.29 | -1 |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
  zh: "1\t1958\t4\t1958.29\t317.45\t317.45\t315.29\t-1"
- en: '| 2 | 1958 | 5 | 1958.38 | 317.50 | 317.50 | 314.71 | -1 |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
  zh: "2\t1958\t5\t1958.38\t317.50\t317.50\t314.71\t-1"
- en: '| 3 | 1958 | 6 | 1958.46 | -99.99 | 317.10 | 314.85 | -1 |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
  zh: "3\t1958\t6\t1958.46\t-99.99\t317.10\t314.85\t-1"
- en: '| 4 | 1958 | 7 | 1958.54 | 315.86 | 315.86 | 314.98 | -1 |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
  zh: "4\t1958\t7\t1958.54\t315.86\t315.86\t314.98\t-1"
- en: Congratulations! You’ve wrangled the data!
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经整理好了数据！
- en: …But our columns aren’t named. **We need to do more EDA.**
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: …但是我们的列没有命名。**我们需要做更多的EDA。**
- en: 7.2 Exploring Variable Feature Types
  id: totrans-524
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 探索变量特征类型
- en: The NOAA [webpage](https://gml.noaa.gov/ccgg/trends/) might have some useful
    tidbits (in this case it doesn’t).
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: NOAA [网页](https://gml.noaa.gov/ccgg/trends/) 可能有一些有用的信息（在这种情况下没有）。
- en: Using this information, we’ll rerun `pd.read_csv`, but this time with some **custom
    column names.**
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些信息，我们将重新运行`pd.read_csv`，但这次使用一些**自定义列名**。
- en: '[PRE88]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '|  | Yr | Mo | DecDate | Avg | Int | Trend | Days |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: "Yr\tMo\tDecDate\tAvg\tInt\tTrend\tDays"
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-529
  prefs: []
  type: TYPE_TB
  zh: "---\t---\t---\t---\t---\t---\t---"
- en: '| 0 | 1958 | 3 | 1958.21 | 315.71 | 315.71 | 314.62 | -1 |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
  zh: "0\t1958\t3\t1958.21\t315.71\t315.71\t314.62\t-1"
- en: '| 1 | 1958 | 4 | 1958.29 | 317.45 | 317.45 | 315.29 | -1 |'
  id: totrans-531
  prefs: []
  type: TYPE_TB
  zh: "1\t1958\t4\t1958.29\t317.45\t317.45\t315.29\t-1"
- en: '| 2 | 1958 | 5 | 1958.38 | 317.50 | 317.50 | 314.71 | -1 |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
  zh: "2\t1958\t5\t1958.38\t317.50\t317.50\t314.71\t-1"
- en: '| 3 | 1958 | 6 | 1958.46 | -99.99 | 317.10 | 314.85 | -1 |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: "3\t1958\t6\t1958.46\t-99.99\t317.10\t314.85\t-1"
- en: '| 4 | 1958 | 7 | 1958.54 | 315.86 | 315.86 | 314.98 | -1 |'
  id: totrans-534
  prefs: []
  type: TYPE_TB
  zh: "4\t1958\t7\t1958.54\t315.86\t315.86\t314.98\t-1"
- en: 7.3 Visualizing CO[2]
  id: totrans-535
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 可视化CO[2]
- en: Scientific studies tend to have very clean data, right…? Let’s jump right in
    and make a time series plot of CO2 monthly averages.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 科学研究往往具有非常干净的数据，对吧…？让我们立即制作二氧化碳月均值的时间序列图。
- en: <details><summary>Code</summary>
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE89]</details>'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE89]</details>'
- en: '![](../Images/9f08f342e42ba8f2b9a5a5d3edc8f52a.png)'
  id: totrans-539
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f08f342e42ba8f2b9a5a5d3edc8f52a.png)'
- en: The code above uses the `seaborn` plotting library (abbreviated `sns`). We will
    cover this in the Visualization lecture, but now you don’t need to worry about
    how it works!
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码使用了`seaborn`绘图库（缩写为`sns`）。我们将在可视化讲座中介绍这一点，但现在你不需要担心它是如何工作的！
- en: Yikes! Plotting the data uncovered a problem. The sharp vertical lines suggest
    that we have some **missing values**. What happened here?
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 天啊！绘制数据揭示了一个问题。明显的垂直线表明我们有一些**缺失值**。这里发生了什么？
- en: '[PRE90]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '|  | Yr | Mo | DecDate | Avg | Int | Trend | Days |'
  id: totrans-543
  prefs: []
  type: TYPE_TB
  zh: "Yr\tMo\tDecDate\tAvg\tInt\tTrend\tDays"
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-544
  prefs: []
  type: TYPE_TB
  zh: "---\t---\t---\t---\t---\t---\t---"
- en: '| 0 | 1958 | 3 | 1958.21 | 315.71 | 315.71 | 314.62 | -1 |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: "0\t1958\t3\t1958.21\t315.71\t315.71\t314.62\t-1"
- en: '| 1 | 1958 | 4 | 1958.29 | 317.45 | 317.45 | 315.29 | -1 |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
  zh: "1\t1958\t4\t1958.29\t317.45\t317.45\t315.29\t-1"
- en: '| 2 | 1958 | 5 | 1958.38 | 317.50 | 317.50 | 314.71 | -1 |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: "2\t1958\t5\t1958.38\t317.50\t317.50\t314.71\t-1"
- en: '| 3 | 1958 | 6 | 1958.46 | -99.99 | 317.10 | 314.85 | -1 |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
  zh: "3\t1958\t6\t1958.46\t-99.99\t317.10\t314.85\t-1"
- en: '| 4 | 1958 | 7 | 1958.54 | 315.86 | 315.86 | 314.98 | -1 |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
  zh: "4\t1958\t7\t1958.54\t315.86\t315.86\t314.98\t-1"
- en: '[PRE91]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '|  | Yr | Mo | DecDate | Avg | Int | Trend | Days |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: "Yr\tMo\tDecDate\tAvg\tInt\tTrend\tDays"
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
  zh: "---\t---\t---\t---\t---\t---\t---"
- en: '| 733 | 2019 | 4 | 2019.29 | 413.32 | 413.32 | 410.49 | 26 |'
  id: totrans-553
  prefs: []
  type: TYPE_TB
  zh: "733\t2019\t4\t2019.29\t413.32\t413.32\t410.49\t26"
- en: '| 734 | 2019 | 5 | 2019.38 | 414.66 | 414.66 | 411.20 | 28 |'
  id: totrans-554
  prefs: []
  type: TYPE_TB
  zh: "734\t2019\t5\t2019.38\t414.66\t414.66\t411.20\t28"
- en: '| 735 | 2019 | 6 | 2019.46 | 413.92 | 413.92 | 411.58 | 27 |'
  id: totrans-555
  prefs: []
  type: TYPE_TB
  zh: "735\t2019\t6\t2019.46\t413.92\t413.92\t411.58\t27"
- en: '| 736 | 2019 | 7 | 2019.54 | 411.77 | 411.77 | 411.43 | 23 |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
  zh: "736\t2019\t7\t2019.54\t411.77\t411.77\t411.43\t23"
- en: '| 737 | 2019 | 8 | 2019.62 | 409.95 | 409.95 | 411.84 | 29 |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: "737\t2019\t8\t2019.62\t409.95\t409.95\t411.84\t29"
- en: Some data have unusual values like -1 and -99.99.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据有异常值，如-1和-99.99。
- en: Let’s check the description at the top of the file again.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次检查文件顶部的描述。
- en: -1 signifies a missing value for the number of days `Days` the equipment was
    in operation that month.
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -1表示该月设备运行的天数`Days`的缺失值。
- en: -99.99 denotes a missing monthly average `Avg`
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -99.99表示缺失的月度平均`Avg`
- en: How can we fix this? First, let’s explore other aspects of our data. Understanding
    our data will help us decide what to do with the missing values.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 我们该如何解决这个问题？首先，让我们探索数据的其他方面。了解我们的数据将帮助我们决定如何处理缺失值。
- en: '7.4 Sanity Checks: Reasoning about the data'
  id: totrans-563
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 合理性检查：对数据进行推理
- en: First, we consider the shape of the data. How many rows should we have?
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们考虑数据的形状。我们应该有多少行？
- en: If chronological order, we should have one record per month.
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果按时间顺序，我们应该每个月有一条记录。
- en: Data from March 1958 to August 2019.
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据从1958年3月到2019年8月。
- en: We should have $ 12 (2019-1957) - 2 - 4 = 738 $ records.
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该有$ 12 (2019-1957) - 2 - 4 = 738 $条记录。
- en: '[PRE92]'
  id: totrans-568
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-569
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Nice!! The number of rows (i.e. records) match our expectations.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！行数（即记录）与我们的预期相匹配。
- en: Let’s now check the quality of each feature.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查每个特征的质量。
- en: '7.5 Understanding Missing Value 1: `Days`'
  id: totrans-572
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.5 理解缺失值1：`Days`
- en: '`Days` is a time field, so let’s analyze other time fields to see if there
    is an explanation for missing values of days of operation.'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: '`Days`是一个时间字段，所以让我们分析其他时间字段，看看是否有关于操作天数缺失的解释。'
- en: Let’s start with **months**, `Mo`.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从**月份**`Mo`开始。
- en: Are we missing any records? The number of months should have 62 or 61 instances
    (March 1957-August 2019).
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有没有缺失的记录？月份的数量应该有62或61个实例（1957年3月-2019年8月）。
- en: '[PRE94]'
  id: totrans-576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-577
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: As expected Jan, Feb, Sep, Oct, Nov, and Dec have 61 occurrences and the rest
    62.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，1月、2月、9月、10月、11月和12月有61个实例，其余的有62个。
- en: Next let’s explore **days** `Days` itself, which is the number of days that
    the measurement equipment worked.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来让我们探索**天数**`Days`本身，这是测量设备运行的天数。
- en: <details><summary>Code</summary>
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE96]</details>'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE96]</details>'
- en: '[PRE97]'
  id: totrans-582
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '![](../Images/acc554144d7d0a15ea7a6de97dbf9305.png)'
  id: totrans-583
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/acc554144d7d0a15ea7a6de97dbf9305.png)'
- en: In terms of data quality, a handful of months have averages based on measurements
    taken on fewer than half the days. In addition, there are nearly 200 missing values–**that’s
    about 27% of the data**!
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 就数据质量而言，少数月份的平均值是基于少于一半天数的测量得出的。此外，有近200个缺失值-**大约占数据的27%**！
- en: Finally, let’s check the last time feature, **year** `Yr`.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们检查最后一个时间特征，**年份**`Yr`。
- en: Let’s check to see if there is any connection between missing-ness and the year
    of the recording.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下缺失和记录年份之间是否有任何联系。
- en: <details><summary>Code</summary>
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE98]</details>'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE98]</details>'
- en: '![](../Images/97b6dc96c61a6c6e44325b791cbad8dd.png)'
  id: totrans-589
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97b6dc96c61a6c6e44325b791cbad8dd.png)'
- en: '**Observations**:'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: '**观察**：'
- en: All of the missing data are in the early years of operation.
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有缺失的数据都在运营初期。
- en: It appears there may have been problems with equipment in the mid to late 80s.
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 似乎80年代中后期可能出现了设备问题。
- en: '**Potential Next Steps**:'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: '**潜在的下一步**：'
- en: Confirm these explanations through documentation about the historical readings.
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过有关历史读数的文档来确认这些解释。
- en: Maybe drop earliest recordings? However, we would want to delay such action
    until after we have examined the time trends and assess whether there are any
    potential problems.
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 也许删除最早的记录？但是，在我们检查时间趋势并评估是否存在潜在问题之后，我们会推迟这样的行动。
- en: '7.6 Understanding Missing Value 2: `Avg`'
  id: totrans-596
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.6 理解缺失值2：`Avg`
- en: Next, let’s return to the -99.99 values in `Avg` to analyze the overall quality
    of the CO2 measurements. We’ll plot a histogram of the average CO[2] measurements
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们回到`Avg`中的-99.99值，分析二氧化碳测量的整体质量。我们将绘制平均CO[2]测量的直方图
- en: <details><summary>Code</summary>
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE99]</details>'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE99]</details>'
- en: '[PRE100]'
  id: totrans-600
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '![](../Images/66f1985f9d32258a03a96c4d503ce777.png)'
  id: totrans-601
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/66f1985f9d32258a03a96c4d503ce777.png)'
- en: The non-missing values are in the 300-400 range (a regular range of CO2 levels).
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 非缺失值在300-400范围内（二氧化碳水平的常规范围）。
- en: 'We also see that there are only a few missing `Avg` values (**<1% of values**).
    Let’s examine all of them:'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到只有少数缺失的“Avg”值（**<1%的值**）。让我们检查所有这些值：
- en: '[PRE101]'
  id: totrans-604
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '|  | Yr | Mo | DecDate | Avg | Int | Trend | Days |'
  id: totrans-605
  prefs: []
  type: TYPE_TB
  zh: '|  | Yr | Mo | DecDate | Avg | Int | Trend | Days |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-606
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 3 | 1958 | 6 | 1958.46 | -99.99 | 317.10 | 314.85 | -1 |'
  id: totrans-607
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1958 | 6 | 1958.46 | -99.99 | 317.10 | 314.85 | -1 |'
- en: '| 7 | 1958 | 10 | 1958.79 | -99.99 | 312.66 | 315.61 | -1 |'
  id: totrans-608
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 1958 | 10 | 1958.79 | -99.99 | 312.66 | 315.61 | -1 |'
- en: '| 71 | 1964 | 2 | 1964.12 | -99.99 | 320.07 | 319.61 | -1 |'
  id: totrans-609
  prefs: []
  type: TYPE_TB
  zh: '| 71 | 1964 | 2 | 1964.12 | -99.99 | 320.07 | 319.61 | -1 |'
- en: '| 72 | 1964 | 3 | 1964.21 | -99.99 | 320.73 | 319.55 | -1 |'
  id: totrans-610
  prefs: []
  type: TYPE_TB
  zh: '| 72 | 1964 | 3 | 1964.21 | -99.99 | 320.73 | 319.55 | -1 |'
- en: '| 73 | 1964 | 4 | 1964.29 | -99.99 | 321.77 | 319.48 | -1 |'
  id: totrans-611
  prefs: []
  type: TYPE_TB
  zh: '| 73 | 1964 | 4 | 1964.29 | -99.99 | 321.77 | 319.48 | -1 |'
- en: '| 213 | 1975 | 12 | 1975.96 | -99.99 | 330.59 | 331.60 | 0 |'
  id: totrans-612
  prefs: []
  type: TYPE_TB
  zh: '| 213 | 1975 | 12 | 1975.96 | -99.99 | 330.59 | 331.60 | 0 |'
- en: '| 313 | 1984 | 4 | 1984.29 | -99.99 | 346.84 | 344.27 | 2 |'
  id: totrans-613
  prefs: []
  type: TYPE_TB
  zh: '| 313 | 1984 | 4 | 1984.29 | -99.99 | 346.84 | 344.27 | 2 |'
- en: There doesn’t seem to be a pattern to these values, other than that most records
    also were missing `Days` data.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值似乎没有任何模式，除了大多数记录也缺少了`Days`数据。
- en: 7.7 Drop, `NaN`, or Impute Missing `Avg` Data?
  id: totrans-615
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.7 删除、`NaN`或填补缺失的`Avg`数据？
- en: How should we address the invalid `Avg` data?
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该如何处理无效的`Avg`数据？
- en: Drop records
  id: totrans-617
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除记录
- en: Set to NaN
  id: totrans-618
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置为NaN
- en: Impute using some strategy
  id: totrans-619
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用某种策略填补
- en: 'Remember we want to fix the following plot:'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 记住我们想要修复以下的图表：
- en: <details><summary>Code</summary>
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE102]</details>'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE102]</details>'
- en: '![](../Images/42b2f337cf3ca3bf99cd58c1f81b7ced.png)'
  id: totrans-623
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/42b2f337cf3ca3bf99cd58c1f81b7ced.png)'
- en: Since we are plotting `Avg` vs `DecDate`, we should just focus on dealing with
    missing values for `Avg`.
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在绘制`Avg` vs `DecDate`，我们应该专注于处理`Avg`的缺失值。
- en: 'Let’s consider a few options: 1\. Drop those records 2\. Replace -99.99 with
    NaN 3\. Substitute it with a likely value for the average CO2?'
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑几个选项：1. 删除这些记录 2. 用NaN替换-99.99 3. 用平均CO2的可能值替换它？
- en: What do you think are the pros and cons of each possible action?
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为每种可能行动的利弊是什么？
- en: Let’s examine each of these three options.
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查这三个选项。
- en: '[PRE103]'
  id: totrans-628
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '|  | Yr | Mo | DecDate | Avg | Int | Trend | Days |'
  id: totrans-629
  prefs: []
  type: TYPE_TB
  zh: '|  | Yr | Mo | DecDate | Avg | Int | Trend | Days |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-630
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 1958 | 3 | 1958.21 | 315.71 | 315.71 | 314.62 | -1 |'
  id: totrans-631
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1958 | 3 | 1958.21 | 315.71 | 315.71 | 314.62 | -1 |'
- en: '| 1 | 1958 | 4 | 1958.29 | 317.45 | 317.45 | 315.29 | -1 |'
  id: totrans-632
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1958 | 4 | 1958.29 | 317.45 | 317.45 | 315.29 | -1 |'
- en: '| 2 | 1958 | 5 | 1958.38 | 317.50 | 317.50 | 314.71 | -1 |'
  id: totrans-633
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1958 | 5 | 1958.38 | 317.50 | 317.50 | 314.71 | -1 |'
- en: '| 4 | 1958 | 7 | 1958.54 | 315.86 | 315.86 | 314.98 | -1 |'
  id: totrans-634
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1958 | 7 | 1958.54 | 315.86 | 315.86 | 314.98 | -1 |'
- en: '| 5 | 1958 | 8 | 1958.62 | 314.93 | 314.93 | 315.94 | -1 |'
  id: totrans-635
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 1958 | 8 | 1958.62 | 314.93 | 314.93 | 315.94 | -1 |'
- en: '[PRE104]'
  id: totrans-636
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '|  | Yr | Mo | DecDate | Avg | Int | Trend | Days |'
  id: totrans-637
  prefs: []
  type: TYPE_TB
  zh: '|  | 年 | 月 | 日期 | 平均值 | 插值 | 趋势 | 天 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-638
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 1958 | 3 | 1958.21 | 315.71 | 315.71 | 314.62 | -1 |'
  id: totrans-639
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1958 | 3 | 1958.21 | 315.71 | 315.71 | 314.62 | -1 |'
- en: '| 1 | 1958 | 4 | 1958.29 | 317.45 | 317.45 | 315.29 | -1 |'
  id: totrans-640
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1958 | 4 | 1958.29 | 317.45 | 317.45 | 315.29 | -1 |'
- en: '| 2 | 1958 | 5 | 1958.38 | 317.50 | 317.50 | 314.71 | -1 |'
  id: totrans-641
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1958 | 5 | 1958.38 | 317.50 | 317.50 | 314.71 | -1 |'
- en: '| 3 | 1958 | 6 | 1958.46 | NaN | 317.10 | 314.85 | -1 |'
  id: totrans-642
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1958 | 6 | 1958.46 | NaN | 317.10 | 314.85 | -1 |'
- en: '| 4 | 1958 | 7 | 1958.54 | 315.86 | 315.86 | 314.98 | -1 |'
  id: totrans-643
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1958 | 7 | 1958.54 | 315.86 | 315.86 | 314.98 | -1 |'
- en: We’ll also use a third version of the data.
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用数据的第三个版本。
- en: First, we note that the dataset already comes with a **substitute value** for
    the -99.99.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们注意到数据集已经为-99.99提供了一个**替代值**。
- en: 'From the file description:'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 从文件描述：
- en: The `interpolated` column includes average values from the preceding column
    (`average`) and **interpolated values** where data are missing. Interpolated values
    are computed in two steps…
  id: totrans-647
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “插值”列包括前一列（“平均值”）的平均值和数据缺失时的**插值值**。插值值是通过两个步骤计算出来的…
- en: The `Int` feature has values that exactly match those in `Avg`, except when
    `Avg` is -99.99, and then a **reasonable** estimate is used instead.
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: '`Int`特征的值与`Avg`完全匹配，只有当`Avg`为-99.99时，才会使用一个**合理的**估计。'
- en: So, the third version of our data will use the `Int` feature instead of `Avg`.
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的数据的第三个版本将使用`Int`特征而不是`Avg`。
- en: '[PRE105]'
  id: totrans-650
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '|  | Yr | Mo | DecDate | Avg | Int | Trend | Days |'
  id: totrans-651
  prefs: []
  type: TYPE_TB
  zh: '|  | 年 | 月 | 日期 | 平均值 | 插值 | 趋势 | 天 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-652
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 0 | 1958 | 3 | 1958.21 | 315.71 | 315.71 | 314.62 | -1 |'
  id: totrans-653
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1958 | 3 | 1958.21 | 315.71 | 315.71 | 314.62 | -1 |'
- en: '| 1 | 1958 | 4 | 1958.29 | 317.45 | 317.45 | 315.29 | -1 |'
  id: totrans-654
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1958 | 4 | 1958.29 | 317.45 | 317.45 | 315.29 | -1 |'
- en: '| 2 | 1958 | 5 | 1958.38 | 317.50 | 317.50 | 314.71 | -1 |'
  id: totrans-655
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1958 | 5 | 1958.38 | 317.50 | 317.50 | 314.71 | -1 |'
- en: '| 3 | 1958 | 6 | 1958.46 | 317.10 | 317.10 | 314.85 | -1 |'
  id: totrans-656
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1958 | 6 | 1958.46 | 317.10 | 317.10 | 314.85 | -1 |'
- en: '| 4 | 1958 | 7 | 1958.54 | 315.86 | 315.86 | 314.98 | -1 |'
  id: totrans-657
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1958 | 7 | 1958.54 | 315.86 | 315.86 | 314.98 | -1 |'
- en: What’s a **reasonable** estimate?
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**合理的**估计是什么？
- en: To answer this question, let’s zoom in on a short time period, say the measurements
    in 1958 (where we know we have two missing values).
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，让我们放大到一个短时间段，比如1958年的测量数据（我们知道有两个缺失值）。
- en: <details><summary>Code</summary>
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE106]</details>'
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE106]</details>'
- en: '![](../Images/53b4112987d12ce1f74df49351cd202f.png)'
  id: totrans-662
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53b4112987d12ce1f74df49351cd202f.png)'
- en: In the big picture since there are only 7 `Avg` values missing (**<1%** of 738
    months), any of these approaches would work.
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 从大局来看，由于只有7个`Avg`值缺失（占738个月的**<1%**），任何这些方法都可以使用。
- en: 'However there is some appeal to **option C: Imputing**:'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，**选项C：插补**也有一定吸引力：
- en: Shows seasonal trends for CO2
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示二氧化碳的季节性趋势
- en: We are plotting all months in our data as a line plot
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在绘制数据中所有月份的线图
- en: 'Let’s replot our original figure with option 3:'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用选项3重新绘制我们的原始图表：
- en: <details><summary>Code</summary>
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE107]</details>'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE107]</details>'
- en: '![](../Images/09e6fbfb5116ca96a02f583d18cd4d0d.png)'
  id: totrans-670
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09e6fbfb5116ca96a02f583d18cd4d0d.png)'
- en: Looks pretty close to what we see on the NOAA [website](https://gml.noaa.gov/ccgg/trends/)!
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来与NOAA [网站](https://gml.noaa.gov/ccgg/trends/)上看到的差不多！
- en: '7.8 Presenting the data: A Discussion on Data Granularity'
  id: totrans-672
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.8 展示数据：关于数据粒度的讨论
- en: 'From the description:'
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 从描述：
- en: monthly measurements are averages of average day measurements.
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 月度测量是平均每日测量的平均值。
- en: The NOAA GML website has datasets for daily/hourly measurements too.
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NOAA GML网站也有每日/每小时测量的数据集。
- en: The data you present depends on your research question.
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 您呈现的数据取决于您的研究问题。
- en: '**How do CO2 levels vary by season?**'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: '**二氧化碳水平如何随季节变化？**'
- en: You might want to keep average monthly data.
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可能希望保留每月的平均数据。
- en: '**Are CO2 levels rising over the past 50+ years, consistent with global warming
    predictions?**'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: '**过去50多年来，二氧化碳水平是否上升，与全球变暖的预测一致？**'
- en: You might be happier with a **coarser granularity** of average year data!
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可能更喜欢使用年平均数据的**粗粒度**！
- en: <details><summary>Code</summary>
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE108]</details>'
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE108]</details>'
- en: '![](../Images/3b14232e597ac362bc341cba390e78fc.png)'
  id: totrans-683
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b14232e597ac362bc341cba390e78fc.png)'
- en: Indeed, we see a rise by nearly 100 ppm of CO2 since Mauna Loa began recording
    in 1958.
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，自从毛纳罗亚开始记录以来，二氧化碳上升了近100ppm。
- en: 8 Summary
  id: totrans-685
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 总结
- en: 'We went over a lot of content this lecture; let’s summarize the most important
    points:'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本讲座中涵盖了很多内容；让我们总结一下最重要的要点：
- en: 8.1 Dealing with Missing Values
  id: totrans-687
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 处理缺失值
- en: 'There are a few options we can take to deal with missing data:'
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以采取几种方法来处理缺失数据：
- en: Drop missing records
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除缺失记录
- en: Keep `NaN` missing values
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保留`NaN`缺失值
- en: Impute using an interpolated column
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用插值列进行插补
- en: 8.2 EDA and Data Wrangling
  id: totrans-692
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 探索性数据分析和数据整理
- en: 'There are several ways to approach EDA and Data Wrangling:'
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以处理探索性数据分析和数据整理：
- en: 'Examine the **data and metadata**: what is the date, size, organization, and
    structure of the data?'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析**数据和元数据**：数据的日期、大小、组织和结构是什么？
- en: Examine each **field/attribute/dimension** individually.
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐个检查每个**字段/属性/维度**。
- en: Examine pairs of related dimensions (e.g. breaking down grades by major).
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐对相关维度进行检查（例如，按专业分解等级）。
- en: 'Along the way, we can:'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个过程中，我们可以：
- en: '**Visualize** or summarize the data.'
  id: totrans-698
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可视化**或总结数据。'
- en: '**Validate assumptions** about data and its collection process. Pay particular
    attention to when the data was collected.'
  id: totrans-699
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证**关于数据及其收集过程的假设。特别注意数据收集的时间。'
- en: Identify and **address anomalies**.
  id: totrans-700
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别和**解决异常**。
- en: Apply data transformations and corrections (we’ll cover this in the upcoming
    lecture).
  id: totrans-701
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用数据转换和校正（我们将在即将到来的讲座中介绍）。
- en: '**Record everything you do!** Developing in Jupyter Notebook promotes *reproducibility*
    of your own work!**'
  id: totrans-702
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记录你所做的一切！**在Jupyter Notebook中开发可以促进你自己工作的*可重复性*！'
