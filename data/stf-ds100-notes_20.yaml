- en: 19  Bias, Variance, and Inference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 19 偏差、方差和推断
- en: 原文：[https://ds100.org/course-notes/inference_causality/inference_causality.html](https://ds100.org/course-notes/inference_causality/inference_causality.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ds100.org/course-notes/inference_causality/inference_causality.html](https://ds100.org/course-notes/inference_causality/inference_causality.html)
- en: '*Learning Outcomes* ***   Compute the bias, variance, and MSE of an estimator
    for a parameter'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*学习成果* *** 计算参数的估计器的偏差、方差和均方误差'
- en: Introduction to model risk of fitted models
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍拟合模型的模型风险
- en: Decompose the model risk into bias and variance terms
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型风险分解为偏差和方差项
- en: Construct confidence intervals for hypothesis testing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建假设检验的置信区间
- en: Understand the assumptions we make and its impact on our regression inference
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解我们所做的假设及其对回归推断的影响
- en: Compare regression and causation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较回归和因果关系
- en: Experiment setup, confounding variables, average treatment effect, and covariate
    adjustment**  **Last time, we introduced the idea of random variables and its
    effect on the observed relationship we use to fit models.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验设置、混杂变量、平均处理效应和协变量调整**上次，我们介绍了随机变量的概念及其对我们用来拟合模型的观察关系的影响。
- en: In this lecture, we will explore the decomposition of model risk from a fitted
    model, regression inference via hypothesis testing and considering the assumptions
    we make, and the environment of understanding causality in theory and in practice.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本讲座中，我们将探讨从拟合模型中分解模型风险，通过假设检验进行回归推断，并考虑我们所做的假设以及理论和实践中理解因果关系的环境。
- en: 19.1 Bias-Variance Tradeoff
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 19.1 偏差-方差权衡
- en: 'Recall the model and the data we generated from that model in the last section:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾上一节中建立的模型和我们从该模型中生成的数据：
- en: '\[\text{True relationship: } g(x)\]'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{真实关系：} g(x) \]
- en: '\[\text{Observed relationship: }Y = g(x) + \epsilon\]'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{观察到的关系：}Y = g(x) + \epsilon \]
- en: '\[\text{Prediction: }\hat{Y}(x)\]'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{预测：} \hat{Y}(x) \]
- en: 'With this reformulated modeling goal, we can now revisit the Bias-Variance
    Tradeoff from two lectures ago (shown below):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个重新制定的建模目标，我们现在可以重新审视两次讲座前的偏差-方差权衡（如下所示）：
- en: '![](../Images/023ff42513bdec75f217ea67d3ffe83d.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/023ff42513bdec75f217ea67d3ffe83d.png)'
- en: In today’s lecture, we’ll explore a more mathematical version of the graph you
    see above by introducing the terms model risk, observation variance, model bias,
    and model variance. Eventually, we’ll work our way up to an updated version of
    the Bias-Variance Tradeoff graph that you see below
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的讲座中，我们将通过引入模型风险、观测方差、模型偏差和模型方差这些术语，探讨上面所见图表的更数学化版本。最终，我们将更新偏差-方差权衡图表，如下所示
- en: '![](../Images/f7ab128e90f4b79d3ff57f80aafa1cf3.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7ab128e90f4b79d3ff57f80aafa1cf3.png)'
- en: 19.1.1 Performance of an Estimator
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.1.1 估计器的性能
- en: 'Suppose we want to estimate a target \(Y\) using an estimator \(\hat{Y}(x)\).
    For every estimator that we train, we can determine how good a model is by asking
    the following questions:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要使用估计器 \(\hat{Y}(x)\) 估计目标 \(Y\)。对于我们训练的每个估计器，我们可以通过以下问题来确定模型的好坏：
- en: Do we get the right answer on average? **(Bias)**
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们平均得到正确答案吗？**(偏差)**
- en: How variable is the answer? **(Variance)**
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案有多大的变化？**(方差)**
- en: How close do we get to \(Y\)? **(Risk / MSE)**
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们离 \(Y\) 有多近？**(风险/MSE)**
- en: '![](../Images/a2fd8f67522b5e85029b6d9f1d490887.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2fd8f67522b5e85029b6d9f1d490887.png)'
- en: Ideally, we want our estimator to have low bias and low variance, but how can
    we mathematically quantify that? To do so, let’s introduce a few terms.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望我们的估计器偏差和方差都很低，但我们如何在数学上量化呢？为此，让我们引入一些术语。
- en: 19.1.2 Model Risk
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.1.2 模型风险
- en: '**Model risk** is defined as the mean square prediction error of the random
    variable \(\hat{Y}\). It is an expectation across *all* samples we could have
    possibly gotten when fitting the model, which we can denote as random variables
    \(X_1, X_2, \ldots, X_n, Y\). Model risk considers the model’s performance on
    any sample that is theoretically possible, rather than the specific data that
    we have collected.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型风险** 被定义为随机变量 \(\hat{Y}\) 的均方预测误差。它是对我们拟合模型时可能得到的 *所有* 样本的期望，我们可以将其表示为随机变量
    \(X_1, X_2, \ldots, X_n, Y\)。模型风险考虑了模型在理论上可能的任何样本上的表现，而不是我们收集到的具体数据。'
- en: \[\text{model risk }=E\left[(Y-\hat{Y(x)})^2\right]\]
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{模型风险} = E\left[(Y-\hat{Y(x)})^2\right] \]
- en: 'What is the origin of the error encoded by model risk? Note that there are
    two types of errors:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 模型风险所编码的错误的起源是什么？请注意，有两种类型的错误：
- en: 'Chance errors: happen due to randomness alone'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偶然误差：仅由随机性引起
- en: 'Source 1 **(Observation Variance)**: randomness in new observations \(Y\) due
    to random noise \(\epsilon\)'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来源1 **(观测方差)**：由于随机噪声 \(\epsilon\) 导致新观测 \(Y\) 的随机性
- en: 'Source 2 **(Model Variance)**: randomness in the sample we used to train the
    models, as samples \(X_1, X_2, \ldots, X_n, Y\) are random'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来源2 **(模型方差)**：在我们用来训练模型的样本中的随机性，因为样本 \(X_1, X_2, \ldots, X_n, Y\) 是随机的
- en: '**(Model Bias)**: non-random error due to our model being different from the
    true underlying function \(g\)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**(模型偏差)**：由于我们的模型与真实的基本函数 \(g\) 不同而产生的非随机误差'
- en: Recall the data-generating process we established earlier. There is a true underlying
    relationship \(g\), observed data (with random noise) \(Y\), and model \(\hat{Y}\).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾我们之前建立的数据生成过程。存在一个真实的基本关系 \(g\)，观察到的数据（带有随机噪声）\(Y\)，以及模型 \(\hat{Y}\)。
- en: '![errors](../Images/53ba887b16ea0dc61cb9179b76fcb804.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![errors](../Images/53ba887b16ea0dc61cb9179b76fcb804.png)'
- en: To better understand model risk, we’ll zoom in on a single data point in the
    plot above.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解模型风险，我们将放大上图中的一个数据点。
- en: '![breakdown](../Images/d5d20c05c5a1aa3076da06b8d8ab1be8.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![breakdown](../Images/d5d20c05c5a1aa3076da06b8d8ab1be8.png)'
- en: Remember that \(\hat{Y}(x)\) is a random variable – it is the prediction made
    for \(x\) after being fit on the specific sample used for training. If we had
    used a different sample for training, a different prediction might have been made
    for this value of \(x\). To capture this, the diagram above considers both the
    prediction \(\hat{Y}(x)\) made for a particular random training sample, and the
    *expected* prediction across all possible training samples, \(E[\hat{Y}(x)]\).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 记住\(\hat{Y}(x)\)是一个随机变量 - 它是在用于训练的特定样本上拟合后对\(x\)的预测。如果我们使用不同的样本进行训练，可能会对这个值的预测进行不同的预测。为了捕捉这一点，上面的图考虑了对特定随机训练样本进行的预测\(\hat{Y}(x)\)，以及在所有可能的训练样本上的*预期*预测\(E[\hat{Y}(x)]\)。
- en: We can use this simplified diagram to break down the prediction error into smaller
    components. First, start by considering the error on a single prediction, \(Y(x)-\hat{Y}(x)\).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个简化的图表来将预测误差分解为更小的组件。首先，从单个预测的误差\(Y(x)-\hat{Y}(x)\)开始。
- en: '![error](../Images/0a5e4a25827ad0f75a731d8404766440.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![error](../Images/0a5e4a25827ad0f75a731d8404766440.png)'
- en: We can identify three components of this error.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确定这个错误的三个组成部分。
- en: '![decomposition](../Images/b350c999eb60473ae5df13b9ee7bc938.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![decomposition](../Images/b350c999eb60473ae5df13b9ee7bc938.png)'
- en: 'That is, the error can be written as:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，错误可以写成：
- en: \[Y(x)-\hat{Y}(x) = \epsilon + \left(g(x)-E\left[\hat{Y}(x)\right]\right) +
    \left(E\left[\hat{Y}(x)\right] - \hat{Y}(x)\right)\] \[\newline \]
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: \[Y(x)-\hat{Y}(x) = \epsilon + \left(g(x)-E\left[\hat{Y}(x)\right]\right) +
    \left(E\left[\hat{Y}(x)\right] - \hat{Y}(x)\right)\] \[\newline \]
- en: 'The model risk is the expected square of the expression above, \(E\left[(Y(x)-\hat{Y}(x))^2\right]\).
    If we square both sides and then take the expectation, we will get the following
    decomposition of model risk:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 模型风险是上述表达式的平方的期望值，\(E\left[(Y(x)-\hat{Y}(x))^2\right]\)。如果我们两边平方，然后取期望值，我们将得到模型风险的以下分解：
- en: \[E\left[(Y(x)-\hat{Y}(x))^2\right] = E[\epsilon^2] + \left(g(x)-E\left[\hat{Y}(x)\right]\right)^2
    + E\left[\left(E\left[\hat{Y}(x)\right] - \hat{Y}(x)\right)^2\right]\]
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: \[E\left[(Y(x)-\hat{Y}(x))^2\right] = E[\epsilon^2] + \left(g(x)-E\left[\hat{Y}(x)\right]\right)^2
    + E\left[\left(E\left[\hat{Y}(x)\right] - \hat{Y}(x)\right)^2\right]\]
- en: It looks like we are missing some cross-product terms when squaring the right-hand
    side, but it turns out that all of those cross-product terms are zero. The detailed
    derivation is out of scope for this class, but a proof is included at the end
    of this note for your reference.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来当我们平方右边时，我们缺少一些交叉乘积项，但事实证明所有这些交叉乘积项都为零。这门课程的详细推导超出了范围，但在本笔记的末尾包括了一个证明供您参考。
- en: This expression may look complicated at first glance, but we’ve actually already
    defined each term earlier in this lecture! Let’s look at them term by term.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表达式乍一看可能很复杂，但实际上我们在本讲座中已经定义了每个术语！让我们逐个术语地来看。
- en: 19.1.2.1 Observation Variance
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 19.1.2.1 观察方差
- en: 'The first term in the above decomposition is \(E[\epsilon^2]\). Remember \(\epsilon\)
    is the random noise when observing \(Y\), with expectation \(\mathbb{E}(\epsilon)=0\)
    and variance \(\text{Var}(\epsilon) = \sigma^2\). We can show that \(E[\epsilon^2]\)
    is the variance of \(\epsilon\): \[ \begin{align*} \text{Var}(\epsilon) &= E[\epsilon^2]
    + \left(E[\epsilon]\right)^2\\ &= E[\epsilon^2] + 0^2\\ &= \sigma^2. \end{align*}
    \]'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 上述分解中的第一项是\(E[\epsilon^2]\)。记住\(\epsilon\)是观察\(Y\)时的随机噪声，期望为\(\mathbb{E}(\epsilon)=0\)，方差为\(\text{Var}(\epsilon)
    = \sigma^2\)。我们可以证明\(E[\epsilon^2]\)是\(\epsilon\)的方差：\[ \begin{align*} \text{Var}(\epsilon)
    &= E[\epsilon^2] + \left(E[\epsilon]\right)^2\\ &= E[\epsilon^2] + 0^2\\ &= \sigma^2.
    \end{align*} \]
- en: This term describes how variable the random error \(\epsilon\) (and \(Y\)) is
    for each observation. This is called the **observation variance**. It exists due
    to the randomness in our observations \(Y\). It is a form of *chance error* we
    talked about in the Sampling lecture.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这个术语描述了每个观察中随机误差\(\epsilon\)（和\(Y\)）的变量。这被称为**观察方差**。它存在于我们的观察\(Y\)的随机性中。这是我们在抽样讲座中谈到的*偶然误差*的一种形式。
- en: \[\text{observation variance} = \text{Var}(\epsilon) = \sigma^2.\]
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: \[\text{观察方差} = \text{Var}(\epsilon) = \sigma^2.\]
- en: The observation variance results from measurement errors when observing data
    or missing information that acts like noise. To reduce this observation variance,
    we could try to get more precise measurements, but it is often beyond the control
    of data scientists. Because of this, the observation variance \(\sigma^2\) is
    sometimes called “irreducible error.”
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 观察方差是由观察数据时的测量误差或行为像噪声一样的缺失信息引起的。要减少这种观察方差，我们可以尝试获得更精确的测量，但这通常超出了数据科学家的控制范围。因此，观察方差\(\sigma^2\)有时被称为“不可减少的误差”。
- en: 19.1.2.2 Model Variance
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 19.1.2.2 模型方差
- en: 'We will then look at the last term: \(E\left[\left(E\left[\hat{Y}(x)\right]
    - \hat{Y}(x)\right)^2\right]\). If you recall the definition of variance from
    the last lecture, this is precisely \(\text{Var}(\hat{Y}(x))\). We call this the
    **model variance**.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们来看最后一项：\(E\left[\left(E\left[\hat{Y}(x)\right] - \hat{Y}(x)\right)^2\right]\)。如果你回忆一下上一讲的方差的定义，这正是\(\text{Var}(\hat{Y}(x))\)。我们称之为**模型方差**。
- en: It describes how much the prediction \(\hat{Y}(x)\) tends to vary when we fit
    the model on different samples. Remember the sample we collect can come out very
    differently, thus the prediction \(\hat{Y}(x)\) will also be different. The model
    variance describes this variability due to the randomness in our sampling process.
    Like observation variance, it is also a form of *chance error*—even though the
    sources of randomness are different.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 它描述了当我们在不同样本上拟合模型时，预测\(\hat{Y}(x)\)往往变化多少。记住我们收集的样本可能会有很大的不同，因此预测\(\hat{Y}(x)\)也会有所不同。模型方差描述了由于我们抽样过程的随机性而产生的这种变异性。与观察方差一样，它也是一种*偶然误差*
    - 即使随机性的来源是不同的。
- en: \[\text{model variance} = \text{Var}(\hat{Y}(x)) = E\left[\left(\hat{Y}(x) -
    E\left[\hat{Y}(x)\right]\right)^2\right]\]
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: \[模型方差 = Var(\hat{Y}(x)) = E\left[\left(\hat{Y}(x) - E\left[\hat{Y}(x)\right]\right)^2\right]\]
- en: 'The main reason for the large model variance is because of **overfitting**:
    we paid too much attention to the details in our sample that small differences
    in our random sample lead to large differences in the fitted model. To remediate
    this, we try to reduce model complexity (e.g. take out some features and limit
    the magnitude of estimated model coefficients) and not fit our model on the noises.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 模型方差较大的主要原因是**过拟合**：我们过于关注样本中的细节，导致随机样本中的微小差异导致拟合模型中的大差异。为了解决这个问题，我们尝试减少模型复杂性（例如去掉一些特征和限制估计模型系数的大小），并且不要在噪声上拟合我们的模型。
- en: 19.1.2.3 Model Bias
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 19.1.2.3 模型偏差
- en: Finally, the second term is \(\left(g(x)-E\left[\hat{Y}(x)\right]\right)^2\).
    What is this? The term \(E\left[\hat{Y}(x)\right] - g(x)\) is called the **model
    bias**.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，第二项是 \(\left(g(x)-E\left[\hat{Y}(x)\right]\right)^2\)。这是什么？术语 \(E\left[\hat{Y}(x)\right]
    - g(x)\) 被称为**模型偏差**。
- en: Remember that \(g(x)\) is the fixed underlying truth and \(\hat{Y}(x)\) is our
    fitted model, which is random. Model bias therefore measures how far off \(g(x)\)
    and \(\hat{Y}(x)\) are on average over all possible samples.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 记住 \(g(x)\) 是固定的基本真相，\(\hat{Y}(x)\) 是我们拟合的模型，是随机的。因此，模型偏差衡量了 \(g(x)\) 和 \(\hat{Y}(x)\)
    在所有可能样本上的平均偏差。
- en: \[\text{model bias} = E\left[\hat{Y}(x) - g(x)\right] = E\left[\hat{Y}(x)\right]
    - g(x)\]
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: \[\text{模型偏差} = E\left[\hat{Y}(x) - g(x)\right] = E\left[\hat{Y}(x)\right] -
    g(x)\]
- en: The model bias is not random; it’s an average measure for a specific individual
    \(x\). If bias is positive, our model tends to overestimate \(g(x)\); if it’s
    negative, our model tends to underestimate \(g(x)\). And if it’s 0, we can say
    that our model is **unbiased**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 模型偏差不是随机的；它是特定个体 \(x\) 的平均度量。如果偏差是正的，我们的模型倾向于高估 \(g(x)\)；如果是负的，我们的模型倾向于低估 \(g(x)\)。如果是
    0，我们可以说我们的模型是**无偏的**。
- en: '*Unbiased Estimators* *An **unbiased model** has a \(\text{model bias } = 0\).
    In other words, our model predicts \(g(x)\) on average.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*无偏估计* *一个**无偏模型**具有 \(\text{模型偏差 } = 0\)。换句话说，我们的模型平均预测 \(g(x)\)。'
- en: 'Similarly, we can define bias for estimators like the mean. The sample mean
    is an **unbiased estimator** of the population mean, as by CLT, \(\mathbb{E}[\bar{X}_n]
    = \mu\). Therefore, the \(\text{estimator bias } = \mathbb{E}[\bar{X}_n] - \mu
    = 0\).*  *There are two main reasons for large model biases:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以为估计量定义偏差，比如均值。样本均值是总体均值的**无偏估计**，因为根据中心极限定理，\(\mathbb{E}[\bar{X}_n]
    = \mu\)。因此，\(\text{估计器偏差 } = \mathbb{E}[\bar{X}_n] - \mu = 0\).*  *模型偏差较大的两个主要原因是：
- en: 'Underfitting: our model is too simple for the data'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拟合不足：我们的模型对数据来说太简单。
- en: 'Lack of domain knowledge: we don’t understand what features are useful for
    the response variable'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏领域知识：我们不了解哪些特征对响应变量有用
- en: 'To fix this, we increase model complexity (but we don’t want to overfit!) or
    consult domain experts to see which models make sense. You can start to see a
    tradeoff here: if we increase model complexity, we decrease the model bias, but
    we also risk increasing the model variance.*  *### 19.1.3 The Decomposition'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们增加模型复杂性（但我们不想过拟合！）或请教领域专家，看看哪些模型是合理的。你可以开始看到这里的权衡：如果我们增加模型复杂性，我们会减少模型偏差，但我们也会增加模型方差。*  *###
    19.1.3 分解
- en: 'To summarize:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下：
- en: The **model risk**, \(\mathbb{E}\left[(Y(x)-\hat{Y}(x))^2\right]\), is the mean
    squared prediction error of the model.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型风险**，\(\mathbb{E}\left[(Y(x)-\hat{Y}(x))^2\right]\)，是模型的平均预测误差的平方。'
- en: The **observation variance**, \(\sigma^2\), is the variance of the random noise
    in the observations. It describes how variable the random error \(\epsilon\) is
    for each observation.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**观测方差**，\(\sigma^2\)，是观测中随机噪声的方差。它描述了每个观测中随机误差 \(\epsilon\) 的变化程度。'
- en: The **model bias**, \(\mathbb{E}\left[\hat{Y}(x)\right]-g(x)\), is how “off”
    the \(\hat{Y}(x)\) is as an estimator of the true underlying relationship \(g(x)\).
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型偏差**，\(\mathbb{E}\left[\hat{Y}(x)\right]-g(x)\)，是 \(\hat{Y}(x)\) 作为真实基本关系
    \(g(x)\) 估计量的“偏离”程度。'
- en: The **model variance**, \(\text{Var}(\hat{Y}(x))\), describes how much the prediction
    \(\hat{Y}(x)\) tends to vary when we fit the model on different samples.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型方差**，\(\text{Var}(\hat{Y}(x))\)，描述了当我们在不同样本上拟合模型时，预测 \(\hat{Y}(x)\) 倾向于变化的程度。'
- en: 'The above definitions enable us to simplify the decomposition of model risk
    before as:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 上述定义使我们能够在之前简化模型风险的分解：
- en: \[ E[(Y(x) - \hat{Y}(x))^2] = \sigma^2 + (E[\hat{Y}(x)] - g(x))^2 + \text{Var}(\hat{Y}(x))
    \] \[\text{model risk } = \text{observation variance} + (\text{model bias})^2
    \text{+ model variance}\]
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: \[ E[(Y(x) - \hat{Y}(x))^2] = \sigma^2 + (E[\hat{Y}(x)] - g(x))^2 + \text{Var}(\hat{Y}(x))
    \] \[\text{模型风险 } = \text{观测方差} + (\text{模型偏差})^2 \text{+ 模型方差}\]
- en: This is known as the **bias-variance tradeoff**. What does it mean? Remember
    that the model risk is a measure of the model’s performance. Our goal in building
    models is to keep model risk low; this means that we will want to ensure that
    each component of model risk is kept at a small value.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为**偏差-方差权衡**。这是什么意思？记住，模型风险是模型性能的一个度量。我们建模的目标是保持模型风险低；这意味着我们希望确保模型风险的每个组成部分都保持在一个小的值。
- en: Observation variance is an inherent, random part of the data collection process.
    We aren’t able to reduce the observation variance, so we’ll focus our attention
    on the model bias and model variance.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 观测方差是数据收集过程中固有的随机部分。我们无法减少观测方差，所以我们将把注意力集中在模型偏差和模型方差上。
- en: In the Feature Engineering lecture, we considered the issue of overfitting.
    We saw that the model’s error or bias tends to decrease as model complexity increases
    — if we design a highly complex model, it will tend to make predictions that are
    closer to the true relationship \(g\). At the same time, model variance tends
    to *increase* as model complexity increases; a complex model may overfit to the
    training data, meaning that small differences in the random samples used for training
    lead to large differences in the fitted model. We have a problem. To decrease
    model bias, we could increase the model’s complexity, which would lead to overfitting
    and an increase in model variance. Alternatively, we could decrease model variance
    by decreasing the model’s complexity at the cost of increased model bias due to
    underfitting.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征工程讲座中，我们考虑了过拟合的问题。我们发现，随着模型复杂度的增加，模型的误差或偏差往往会减少 - 如果我们设计一个非常复杂的模型，它往往会倾向于做出更接近真实关系\(g\)的预测。与此同时，模型方差往往会*增加*随着模型复杂度的增加；复杂模型可能会对训练数据过拟合，这意味着用于训练的随机样本的微小差异会导致拟合模型的巨大差异。我们有一个问题。为了减少模型偏差，我们可以增加模型的复杂度，这将导致过拟合和模型方差的增加。或者，我们可以通过减少模型的复杂度来减少模型方差，但这会增加由于欠拟合而产生的模型偏差。
- en: '![bvt](../Images/f7ab128e90f4b79d3ff57f80aafa1cf3.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![bvt](../Images/f7ab128e90f4b79d3ff57f80aafa1cf3.png)'
- en: We need to strike a balance. Our goal in model creation is to use a complexity
    level that is high enough to keep bias low, but not so high that model variance
    is large.*  *## 19.2 Interpreting Regression Coefficients
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要取得平衡。我们在模型创建中的目标是使用足够高的复杂度水平来保持偏差低，但不要太高以至于模型方差很大。* *## 19.2 解释回归系数
- en: Recall the framework we established earlier in this lecture. If we assume that
    the underlying relationship between our observations and input features is linear,
    we can express this relationship in terms of the unknown, true model parameters
    \(\theta\).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下我们在本讲座中建立的框架。如果我们假设观察值和输入特征之间的潜在关系是线性的，我们可以用未知的真实模型参数\(\theta\)来表达这种关系。
- en: \[f_{\theta}(x) = g(x) + \epsilon = \theta_0 + \theta_1 x_1 + \ldots + \theta_p
    x_p + \epsilon\]
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: \[f_{\theta}(x) = g(x) + \epsilon = \theta_0 + \theta_1 x_1 + \ldots + \theta_p
    x_p + \epsilon\]
- en: Our model attempts to estimate each true parameter \(\theta_i\) using the estimates
    \(\hat{\theta}_i\) calculated from the design matrix \(\Bbb{X}\) and response
    vector \(\Bbb{Y}\).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型试图使用从设计矩阵\(\Bbb{X}\)和响应向量\(\Bbb{Y}\)计算出的估计值\(\hat{\theta}_i\)来估计每个真实参数\(\theta_i\)。
- en: \[f_{\hat{\theta}}(x) = \hat{\theta}_0 + \hat{\theta}_1 x_1 + \ldots + \hat{\theta}_p
    x_p\]
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: \[f_{\hat{\theta}}(x) = \hat{\theta}_0 + \hat{\theta}_1 x_1 + \ldots + \hat{\theta}_p
    x_p\]
- en: Let’s pause for a moment. At this point, we’re very used to working with the
    idea of a model parameter. But what exactly does each coefficient \(\theta_i\)
    actually *mean*? We can think of each \(\theta_i\) as a *slope* of the linear
    model – if all other variables are held constant, a unit change in \(x_i\) will
    result in a \(\theta_i\) change in \(f_{\theta}(x)\). Broadly speaking, a large
    value of \(\theta_i\) means that the feature \(x_i\) has a large effect on the
    response; conversely, a small value of \(\theta_i\) means that \(x_i\) has little
    effect on the response. In the extreme case, if the true parameter \(\theta_i\)
    is 0, then the feature \(x_i\) has **no effect** on \(Y(x)\).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂停一下。在这一点上，我们非常习惯于使用模型参数的概念。但是每个系数\(\theta_i\)实际上*意味着*什么呢？我们可以将每个\(\theta_i\)看作线性模型的*斜率*
    - 如果所有其他变量保持不变，\(x_i\)的单位变化将导致\(f_{\theta}(x)\)中的\(\theta_i\)变化。广义上讲，\(\theta_i\)的值越大，意味着特征\(x_i\)对响应的影响越大；相反，\(\theta_i\)的值越小，意味着\(x_i\)对响应的影响越小。在极端情况下，如果真实参数\(\theta_i\)为0，则特征\(x_i\)对\(Y(x)\)没有**影响**。
- en: 'If the true parameter \(\theta_i\) for a particular feature is 0, this tells
    us something pretty significant about the world: there is no underlying relationship
    between \(x_i\) and \(Y(x)\)! How then, can we test if a parameter is 0? As a
    baseline, we go through our usual process of drawing a sample, using this data
    to fit a model, and computing an estimate \(\hat{\theta}_i\). However, we need
    to also consider the fact that if our random sample had come out differently,
    we may have found a different result for \(\hat{\theta}_i\). To infer if the true
    parameter \(\theta_i\) is 0, we want to draw our conclusion from the distribution
    of \(\hat{\theta}_i\) estimates we could have drawn across all other random samples.
    This is where [hypothesis testing](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html)
    comes in handy!'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果某个特定特征的真实参数\(\theta_i\)为0，这告诉我们一些非常重要的事情：\(x_i\)和\(Y(x)\)之间没有潜在关系！那么，我们如何测试参数是否为0呢？作为基线，我们按照通常的流程抽取样本，使用这些数据拟合模型，并计算估计值\(\hat{\theta}_i\)。然而，我们还需要考虑这样一个事实，即如果我们的随机样本结果不同，我们可能会得到不同的\(\hat{\theta}_i\)结果。为了推断真实参数\(\theta_i\)是否为0，我们希望从我们可能在所有其他随机样本中抽取的\(\hat{\theta}_i\)估计的分布中得出结论。这就是[假设检验](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html)派上用场的地方！
- en: To test if the true parameter \(\theta_i\) is 0, we construct a **hypothesis
    test** where our null hypothesis states that the true parameter \(\theta_i\) is
    0 and the alternative hypothesis states that the true parameter \(\theta_i\) is
    *not* 0\. If our p-value is smaller than our cutoff value (usually p=0.05), we
    reject the null hypothesis.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 测试真实参数\(\theta_i\)是否为0，我们构建一个**假设检验**，其中零假设表明真实参数\(\theta_i\)为0，备择假设表明真实参数\(\theta_i\)
    *不是* 0。如果我们的p值小于我们的截断值（通常p=0.05），我们拒绝零假设。
- en: '19.3 Hypothesis Testing through Bootstrap: PurpleAir Demo'
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 19.3 通过Bootstrap进行假设检验：PurpleAir演示
- en: An equivalent way to execute the hypothesis test described above is through
    **bootstrapping** (this equivalence can be proven through the [duality argument](https://stats.stackexchange.com/questions/179902/confidence-interval-p-value-duality-vs-frequentist-interpretation-of-cis),
    which is out of scope for this class). We use bootstrapping to compute approximate
    95% confidence intervals for each \(\theta_i\). If the interval doesn’t contain
    0, we reject the null hypothesis at the 5% level. Otherwise, the data is consistent
    with the null, as the true parameter *could* be 0.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 执行上述假设检验的一个等价方法是通过**自举**（可以通过[对偶论证](https://stats.stackexchange.com/questions/179902/confidence-interval-p-value-duality-vs-frequentist-interpretation-of-cis)证明这种等价性，这超出了本课程的范围）。我们使用自举来计算每个\(\theta_i\)的近似95%置信区间。如果区间不包含0，我们在5%的水平上拒绝零假设。否则，数据与零假设一致，因为真实参数*可能*为0。
- en: To show an example of this hypothesis testing process, we’ll work with the [snowy
    plover](https://www.audubon.org/field-guide/bird/snowy-plover) dataset throughout
    this section. The data are about the eggs and newly-hatched chicks of the Snowy
    Plover. The data were collected at the Point Reyes National Seashore by a former
    [student at Berkeley](https://openlibrary.org/books/OL2038693M/BLSS_the_Berkeley_interactive_statistical_system).
    Here’s a [parent bird and some eggs](http://cescos.fau.edu/jay/eps/articles/snowyplover.html).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示这个假设检验过程的一个例子，我们将在本节中使用[雪鸻](https://www.audubon.org/field-guide/bird/snowy-plover)数据集。这些数据是关于雪鸻的蛋和新孵出的雏鸟。这些数据是由伯克利的一位前[学生](https://openlibrary.org/books/OL2038693M/BLSS_the_Berkeley_interactive_statistical_system)在雷耶斯角国家海岸收集的。这是一个[父母鸟和一些蛋](http://cescos.fau.edu/jay/eps/articles/snowyplover.html)。
- en: '![bvt](../Images/e6eb6a7c818653afb008d859b14f5a7e.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![bvt](../Images/e6eb6a7c818653afb008d859b14f5a7e.png)'
- en: Note that `Egg Length` and `Egg Breadth` (widest diameter) are measured in millimeters,
    and `Egg Weight` and `Bird Weight` are measured in grams; for comparison, a standard
    paper clip weighs about one gram.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`蛋长`和`蛋宽`（最宽直径）以毫米为单位测量，`蛋重`和`鸟重`以克为单位测量；作为比较，一个标准的回形针重约一克。
- en: <details><summary>Code</summary>
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE0]</details> <details><summary>Code</summary>'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE0]</details> <details><summary>代码</summary>'
- en: '[PRE1]</details>'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE1]</details>'
- en: '|  | egg_weight | egg_length | egg_breadth | bird_weight |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | 蛋重 | 蛋长 | 蛋宽 | 鸟重 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 7.4 | 28.80 | 21.84 | 5.2 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 7.4 | 28.80 | 21.84 | 5.2 |'
- en: '| 1 | 7.7 | 29.04 | 22.45 | 5.4 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 7.7 | 29.04 | 22.45 | 5.4 |'
- en: '| 2 | 7.9 | 29.36 | 22.48 | 5.6 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 7.9 | 29.36 | 22.48 | 5.6 |'
- en: '| 3 | 7.5 | 30.10 | 21.71 | 5.3 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 7.5 | 30.10 | 21.71 | 5.3 |'
- en: '| 4 | 8.3 | 30.17 | 22.75 | 5.9 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 8.3 | 30.17 | 22.75 | 5.9 |'
- en: Our goal will be to predict the weight of a newborn plover chick, which we assume
    follows the true relationship \(Y = f_{\theta}(x)\) below.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是预测新生雪鸻雏鸟的重量，我们假设其遵循下面的真实关系\(Y = f_{\theta}(x)\)。
- en: \[\text{bird\_weight} = \theta_0 + \theta_1 \text{egg\_weight} + \theta_2 \text{egg\_length}
    + \theta_3 \text{egg\_breadth} + \epsilon\]
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: \[\text{bird\_weight} = \theta_0 + \theta_1 \text{egg\_weight} + \theta_2 \text{egg\_length}
    + \theta_3 \text{egg\_breadth} + \epsilon\]
- en: For each \(i\), the parameter \(\theta_i\) is a fixed number but it is unobservable.
    We can only estimate it.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个\(i\)，参数\(\theta_i\)是一个固定的数字，但是不可观测的。我们只能估计它。
- en: The random error \(\epsilon\) is also unobservable, but it is assumed to have
    expectation 0 and be independent and identically distributed across eggs.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机误差\(\epsilon\)也是不可观测的，但假定其期望为0，并且在蛋中是独立且同分布的。
- en: Say we wish to determine if the `egg_weight` impacts the `bird_weight` of a
    chick – we want to infer if \(\theta_1\) is equal to 0.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望确定`蛋重`是否影响雏鸟的`鸟重`-我们想推断\(\theta_1\)是否等于0。
- en: 'First, we define our hypotheses:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义我们的假设：
- en: '**Null hypothesis**: the true parameter \(\theta_1\) is 0; any variation is
    due to random chance.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零假设**：真实参数\(\theta_1\)为0；任何变化都是由随机机会引起的。'
- en: '**Alternative hypothesis**: the true parameter \(\theta_1\) is not 0.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**备择假设**：真实参数\(\theta_1\)不为0。'
- en: Next, we use our data to fit a model \(\hat{Y} = f_{\hat{\theta}}(x)\) that
    approximates the relationship above. This gives us the **observed value** of \(\hat{\theta}_1\)
    found from our data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用我们的数据来拟合一个模型\(\hat{Y} = f_{\hat{\theta}}(x)\)，该模型近似上面的关系。这给我们了\(\hat{\theta}_1\)的**观察值**，从我们的数据中找到。
- en: '[PRE2]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '|  | theta_hat |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  | \hat{\theta} |'
- en: '| --- | --- |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| intercept | -4.605670 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 截距 | -4.605670 |'
- en: '| egg_weight | 0.431229 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 蛋重 | 0.431229 |'
- en: '| egg_length | 0.066570 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 蛋长 | 0.066570 |'
- en: '| egg_breadth | 0.215914 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 蛋宽 | 0.215914 |'
- en: '[PRE3]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We now have the value of \(\hat{\theta}_1\) when considering the single sample
    of data that we have. To get a sense of how this estimate might vary if we were
    to draw different random samples, we will use **[bootstrapping](https://inferentialthinking.com/chapters/13/2/Bootstrap.html?)**.
    To construct a bootstrap sample, we will draw a resample from the collected data
    that:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了\(\hat{\theta}_1\)的值，考虑到我们拥有的单个数据样本。为了了解如果我们抽取不同的随机样本，这个估计可能会如何变化，我们将使用**[自举](https://inferentialthinking.com/chapters/13/2/Bootstrap.html?)**。为了构建一个自举样本，我们将从收集到的数据中抽取一个重采样：
- en: Has the same sample size as the collected data
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有与收集到的数据相同的样本大小
- en: Is drawn with replacement (this ensures that we don’t draw the exact same sample
    every time!)
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用替换的方式抽取（这确保我们不会每次抽取完全相同的样本！）
- en: We draw a bootstrap sample, use this sample to fit a model, and record the result
    for \(\hat{\theta}_1\) on this bootstrapped sample. We then repeat this process
    many times to generate a **bootstrapped empirical distribution** of \(\hat{\theta}_1\).
    This gives us an estimate of what the true distribution of \(\hat{\theta}_1\)
    across all possible samples might look like.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们抽取一个自举样本，使用这个样本来拟合一个模型，并记录在这个自举样本上的\(\hat{\theta}_1\)的结果。然后我们重复这个过程很多次，以生成\(\hat{\theta}_1\)的**自举经验分布**。这给我们一个估计，即真实分布\(\hat{\theta}_1\)在所有可能的样本中可能是什么样子。
- en: '[PRE4]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We find that our bootstrapped approximate 95% confidence interval for \(\theta_1\)
    is \([-0.259, 1.103]\). Immediately, we can see that 0 *is* indeed contained in
    this interval – this means that we *cannot* conclude that \(\theta_1\) is non-zero!
    More formally, we fail to reject the null hypothesis (that \(\theta_1\) is 0)
    under a 5% p-value cutoff.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，我们的自举近似95%置信区间为\([-0.259, 1.103]\)。立即可以看到0确实包含在这个区间内 - 这意味着我们*无法*断定\(\theta_1\)不为零！更正式地说，我们未能拒绝零假设（即\(\theta_1\)为0）在5%的p值截断下。
- en: 19.4 Colinearity
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 19.4 共线性
- en: We can repeat this process to construct 95% confidence intervals for the other
    parameters of the model.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重复这个过程，为模型的其他参数构建95%置信区间。
- en: <details><summary>Code</summary>
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE6]</details>'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE6]</details>'
- en: '|  | lower | upper |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '|  | 下限 | 上限 |'
- en: '| --- | --- | --- |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| theta_0 | -15.278542 | 5.161473 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| theta_0 | -15.278542 | 5.161473 |'
- en: '| theta_1 | -0.258648 | 1.103424 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| theta_1 | -0.258648 | 1.103424 |'
- en: '| theta_2 | -0.099138 | 0.208557 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| theta_2 | -0.099138 | 0.208557 |'
- en: '| theta_3 | -0.257141 | 0.758155 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| theta_3 | -0.257141 | 0.758155 |'
- en: Something’s off here. Notice that 0 is included in the 95% confidence interval
    for *every* parameter of the model. Using the interpretation we outlined above,
    this would suggest that we can’t say for certain that *any* of the input variables
    impact the response variable! This makes it seem like our model can’t make any
    predictions – and yet, each model we fit in our bootstrap experiment above could
    very much make predictions of \(Y\).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有些不对劲。注意到在模型的每个参数的95%置信区间中都包含了0。根据我们上面概述的解释，这意味着我们无法确定*任何*输入变量对响应变量的影响！这似乎表明我们的模型无法进行任何预测
    - 然而，我们在上面的自助法实验中拟合的每个模型都可以非常好地预测\(Y\)。
- en: How can we explain this result? Think back to how we first interpreted the parameters
    of a linear model. We treated each \(\theta_i\) as a slope, where a unit increase
    in \(x_i\) leads to a \(\theta_i\) increase in \(Y\), **if all other variables
    are held constant**. It turns out that this last assumption is very important.
    If variables in our model are somehow related to one another, then it might not
    be possible to have a change in one of them while holding the others constant.
    This means that our interpretation framework is no longer valid! In the models
    we fit above, we incorporated `egg_length`, `egg_breadth`, and `egg_weight` as
    input variables. These variables are very likely related to one another – an egg
    with large `egg_length` and `egg_breadth` will likely be heavy in `egg_weight`.
    This means that the model parameters cannot be meaningfully interpreted as slopes.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何解释这个结果？回想一下我们如何解释线性模型的参数。我们将每个\(\theta_i\)都视为斜率，其中\(x_i\)的单位增加导致\(Y\)的\(\theta_i\)增加，**如果所有其他变量保持不变**。事实证明，最后这个假设非常重要。如果我们模型中的变量某种程度上相关，那么在保持其他变量不变的情况下可能不可能改变其中一个变量。这意味着我们的解释框架不再有效！在我们上面拟合的模型中，我们将`egg_length`、`egg_breadth`和`egg_weight`作为输入变量。这些变量很可能彼此相关
    - 一个具有较大`egg_length`和`egg_breadth`的蛋很可能在`egg_weight`上很重。这意味着模型参数不能被有意义地解释为斜率。
- en: To support this conclusion, we can visualize the relationships between our feature
    variables. Notice the strong positive association between the features.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持这个结论，我们可以可视化我们的特征变量之间的关系。注意特征之间的强正相关。
- en: <details><summary>Code</summary>
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE7]</details>'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE7]</details>'
- en: '[PRE8]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/63bd5c6f7040f9d46aa6995834eebd2b.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63bd5c6f7040f9d46aa6995834eebd2b.png)'
- en: This issue is known as **colinearity**, sometimes also called **multicolinearity**.
    Collinearity occurs when one feature can be predicted fairly accurately by a linear
    combination of the other features, which happens when one feature is highly correlated
    with the others.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题被称为**共线性**，有时也被称为**多重共线性**。当一个特征与其他特征高度相关时，就会发生共线性，这意味着一个特征可以被其他特征的线性组合相当准确地预测。
- en: 'Why is colinearity a problem? Its consequences span several aspects of the
    modeling process:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么共线性是一个问题？它的后果涵盖了建模过程的几个方面：
- en: '**Inference**: Slopes can’t be interpreted for an inference task.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推断**：斜率不能用于推断任务。'
- en: '**Model Variance**: If features strongly influence one another, even small
    changes in the sampled data can lead to large changes in the estimated slopes.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型方差**：如果特征彼此强烈影响，即使在采样数据中进行微小的变化也可能导致估计斜率的大幅变化。'
- en: '**Unique Solution**: If one feature is a linear combination of the other features,
    the design matrix will not be full rank, and \(\mathbb{X}^{\top}\mathbb{X}\) is
    not invertible. This means that least squares does not have a unique solution.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**唯一解**：如果一个特征是其他特征的线性组合，设计矩阵将不是满秩的，\(\mathbb{X}^{\top}\mathbb{X}\)就不可逆。这意味着最小二乘法没有唯一解。'
- en: The take-home point is that we need to be careful with what features we select
    for modeling. If two features likely encode similar information, it is often a
    good idea to choose only one of them as an input variable.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 重点是，我们需要小心选择建模的特征。如果两个特征很可能编码相似的信息，通常最好只选择其中一个作为输入变量。
- en: 19.4.1 A Simpler Model
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.4.1 一个更简单的模型
- en: 'Let us now consider a more interpretable model: we instead assume a true relationship
    using only egg weight:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在考虑一个更易解释的模型：我们假设真实关系只使用蛋重：
- en: \[f_\theta(x) = \theta_0 + \theta_1 \text{egg\_weight} + \epsilon\]
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: \[f_\theta(x) = \theta_0 + \theta_1 \text{egg\_weight} + \epsilon\]
- en: <details><summary>Code</summary>
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE9]</details>'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE9]</details>'
- en: '|  | theta_hat |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|  | theta_hat |'
- en: '| --- | --- |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| theta_0 | -0.058272 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| theta_0 | -0.058272 |'
- en: '| theta_1 | 0.718515 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| theta_1 | 0.718515 |'
- en: '[PRE10]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/00fab88d27d5352e72999f162631af6c.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00fab88d27d5352e72999f162631af6c.png)'
- en: 'Notice how the interpretable model performs almost as well as our other model:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 注意可解释模型的表现几乎与我们的其他模型一样好：
- en: <details><summary>Code</summary>
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE11]</details>'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE11]</details>'
- en: '[PRE12]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Yet, the confidence interval for the true parameter \(\theta_{1}\) does not
    contain zero.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，真实参数\(\theta_{1}\)的置信区间不包含零。
- en: <details><summary>Code</summary>
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE13]</details>'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE13]</details>'
- en: '[PRE14]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In retrospect, it’s no surprise that the weight of an egg best predicts the
    weight of a newly-hatched chick.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾来看，母鸡的重量最能预测新生小鸡的重量，这并不奇怪。
- en: A model with highly correlated variables prevents us from interpreting how the
    variables are related to the prediction.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 高度相关变量的模型会阻止我们解释变量与预测之间的关系。
- en: '19.4.2 Reminder: Assumptions Matter'
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.4.2 提醒：假设很重要
- en: 'Keep the following in mind: All inference assumes that the regression model
    holds.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住：所有推断都假设回归模型成立。
- en: If the model doesn’t hold, the inference might not be valid.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型不成立，推断可能无效。
- en: If the [assumptions of the bootstrap](https://inferentialthinking.com/chapters/13/3/Confidence_Intervals.html?highlight=p%20value%20confidence%20interval#care-in-using-the-bootstrap-percentile-method)
    don’t hold…
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果[自助法的假设](https://inferentialthinking.com/chapters/13/3/Confidence_Intervals.html?highlight=p%20value%20confidence%20interval#care-in-using-the-bootstrap-percentile-method)不成立…
- en: Sample size n is large
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本量n很大
- en: Sample is representative of population distribution (drawn i.i.d., unbiased)…then
    the results of the bootstrap might not be valid.
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本代表人口分布（随机抽取，无偏）…那么自助法的结果可能无效。
- en: 19.5 (Bonus) Correlation and Causation
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 19.5（奖励）相关性与因果
- en: Let us consider some questions in an arbitrary regression problem.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个任意回归问题中的一些问题。
- en: What does \(\theta_{j}\) mean in our regression?
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的回归中，\(\theta_{j}\)代表什么？
- en: Holding other variables fixed, how much should our prediction change with \(X_{j}\)?
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在保持其他变量不变的情况下，我们的预测应该随着\(X_{j}\)的变化而变化多少？
- en: For simple linear regression, this boils down to the correlation coefficient
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 对于简单线性回归，这归结为相关系数
- en: Does having more \(x\) predict more \(y\) (and by how much)?
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有更多的\(x\)是否预测更多的\(y\)（以及预测多少）？
- en: '**Examples**:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**例子：**'
- en: Are homes with granite countertops worth more money?
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有花岗岩台面的房屋是否更值钱？
- en: Is college GPA higher for students who win a certain scholarship?
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得某项奖学金的学生的大学GPA是否更高？
- en: Are breastfed babies less likely to develop asthma?
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 母乳喂养的婴儿更不容易患哮喘吗？
- en: Do cancer patients given some aggressive treatment have a higher 5-year survival
    rate?
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接受某种激进治疗的癌症患者是否有更高的5年生存率？
- en: Are people who smoke more likely to get cancer?
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吸烟的人更容易患癌症吗？
- en: These sound like causal questions, but they are not!
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这些听起来像是因果问题，但实际上并不是！
- en: 19.5.1 Prediction vs Causation
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.5.1 预测与因果
- en: The difference between correlation/prediction vs. causation is best illustrated
    through examples.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性/预测与因果之间的区别最好通过例子来说明。
- en: 'Some questions about **correlation / prediction** include:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 一些关于**相关性/预测**的问题包括：
- en: Are homes with granite countertops worth more money?
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有花岗岩台面的房屋是否更值钱？
- en: Is college GPA higher for students who win a certain scholarship?
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得某项奖学金的学生的大学GPA是否更高？
- en: Are breastfed babies less likely to develop asthma?
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 母乳喂养的婴儿更不容易患哮喘吗？
- en: Do cancer patients given some aggressive treatment have a higher 5-year survival
    rate?
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接受某种激进治疗的癌症患者是否有更高的5年生存率？
- en: Are people who smoke more likely to get cancer?
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吸烟的人更容易患癌症吗？
- en: 'Some questions about **causality** include:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 一些关于**因果关系**的问题包括：
- en: How much do granite countertops **raise** the value of a house?
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花岗岩台面会**提高**房屋的价值多少？
- en: Does getting the scholarship **improve** students’ GPAs?
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得奖学金是否**提高**了学生的GPA？
- en: Does breastfeeding **protect** babies against asthma?
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 母乳喂养是否**保护**婴儿免受哮喘？
- en: Does the treatment **improve** cancer survival?
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 治疗是否**提高**了癌症的生存率？
- en: Does smoking **cause** cancer?
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吸烟是否**导致**癌症？
- en: Causal questions are about the **effects** of **interventions** (not just passive
    observation). Note, however, that regression coefficients are sometimes called
    “effects”, which can be deceptive!
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 因果问题涉及**干预**的**效果**（不仅仅是被动观察）。但需要注意的是，回归系数有时被称为“效果”，这可能是误导性的！
- en: 'When using data alone, **predictive questions** (i.e. are breastfed babies
    healthier?) can be answered, but **causal questions:** (i.e. does breastfeeding
    improve babies’ health?) cannot. The reason for this is that there are many possible
    causes for our predictive question. For example, possible explanations for why
    breastfed babies are healthier on average include:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 仅使用数据时，可以回答**预测性问题**（即母乳喂养的婴儿更健康吗？），但无法回答**因果问题**（即母乳喂养是否改善了婴儿的健康？）。原因在于我们的预测问题有许多可能的原因。例如，母乳喂养的婴儿平均更健康的可能解释包括：
- en: '**Causal effect:** breastfeeding makes babies healthier'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**因果效应：** 母乳喂养使婴儿更健康'
- en: '**Reverse causality:** healthier babies more likely to successfully breastfeed'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**逆因果关系：** 更健康的婴儿更有可能成功母乳喂养'
- en: '**Common cause:** healthier / richer parents have healthier babies and are
    more likely to breastfeed'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**共同原因：** 更健康/更富有的父母有更健康的婴儿，并更有可能母乳喂养'
- en: We cannot tell which explanations are true (or to what extent) just by observing
    (\(x\),\(y\)) pairs.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能仅通过观察（\(x\),\(y\)）对来判断哪些解释是真实的（或在多大程度上是真实的）。
- en: Additionally, causal questions implicitly involve **counterfactuals**, events
    that didn’t happen. For example, we could ask, **would** the **same** breastfed
    babies have been less healthy **if** they hadn’t been breastfed? Explanation 1
    from above implies they would be, but explanations 2 and 3 do not.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，因果问题隐含地涉及**反事实**，即未发生的事件。例如，我们可以问，**如果**母乳喂养的婴儿没有被母乳喂养，他们是否会更健康？上面的解释1意味着他们会更健康，但解释2和3则不是。
- en: 19.5.2 Confounders
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.5.2 混杂因素
- en: Let T represent a treatment (for example, alcohol use), and Y represent an outcome
    (for example, lung cancer).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 让T代表一种治疗（例如，饮酒），Y代表一个结果（例如，肺癌）。
- en: '![confounder](../Images/156ab231f384f7f2571d78da39650724.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![混杂因素](../Images/156ab231f384f7f2571d78da39650724.png)'
- en: A **confounder** is a variable that affects both T and Y, distorting the correlation
    between them. Using the example above. Confounders can be a measured covariate
    or an unmeasured variable we don’t know about, and they generally cause problems,
    as the relationship between T and Y is really affected by data we cannot see.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '**混杂变量**是影响T和Y的变量，扭曲它们之间的相关性。使用上面的例子。混杂因素可以是一个已测量的协变量或者是我们不知道的未测量变量，它们通常会引起问题，因为T和Y之间的关系实际上受到我们看不到的数据的影响。'
- en: '**Common assumption:** all confounders are observed (**ignorability**)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**常见假设：**所有混杂因素都是被观察到的（**可忽略性**）'
- en: 19.5.3 Terminology
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.5.3 术语
- en: Let us define some terms that will help us understand causal effects.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一些术语，这些术语将帮助我们理解因果效应。
- en: 'In prediction, we had two kinds of variables:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测中，我们有两种变量：
- en: '**Response** (\(Y\)): what we are trying to predict'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应** (\(Y\))：我们试图预测的内容'
- en: '**Predictors** (\(X\)): inputs to our prediction'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测变量** (\(X\))：我们预测的输入'
- en: 'Other variables in causal inference include:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 因果推断中的其他变量包括：
- en: '**Response** (\(Y\)): the outcome of interest'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应** (\(Y\))：我们感兴趣的结果'
- en: '**Treatment** (\(T\)): the variable we might intervene on'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理** (\(T\))：我们可能进行干预的变量'
- en: '**Covariate** (\(X\)): other variables we measured that may affect \(T\) and/or
    \(Y\)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协变量** (\(X\))：我们测量的其他可能影响\(T\)和/或\(Y\)的变量'
- en: 'For this lecture, \(T\) is a **binary (0/1)** variable:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本讲座，\(T\)是一个**二元（0/1）**变量：
- en: 19.5.4 Neyman-Rubin Causal Model
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.5.4 Neyman-Rubin因果模型
- en: 'Causal questions are about **counterfactuals**:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 因果问题涉及**反事实**：
- en: What would have happened if T were different?
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果T不同会发生什么？
- en: What will happen if we set T differently in the future?
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们将来设定T会发生什么？
- en: 'We assume every individual has two **potential outcomes**:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设每个个体都有两个**潜在结果**：
- en: '\(Y_{i}(1)\): value of \(y_{i}\) if \(T_{i} = 1\) (**treated outcome**)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(Y_{i}(1)\)：如果\(T_{i} = 1\)的话，\(y_{i}\)的值（**受治疗结果**）
- en: '\(Y_{i}(0)\): value of \(y_{i}\) if \(T_{i} = 0\) (**control outcome**)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(Y_{i}(0)\)：如果\(T_{i} = 0\)的话，\(y_{i}\)的值（**对照结果**）
- en: 'For each individual in the data set, we observe:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据集中的每个个体，我们观察到：
- en: Covariates \(x_{i}\)
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协变量\(x_{i}\)
- en: Treatment \(T_{i}\)
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理\(T_{i}\)
- en: Response \(y_{i} = Y_{i}(T_{i})\)
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应\(y_{i} = Y_{i}(T_{i})\)
- en: We will assume (\(x_{i}\), \(T_{i}\), \(y_{i} = Y_{i}(T_{i})\)) tuples iid for
    \(i = 1,..., n\)
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设对于\(i = 1,..., n\)，(\(x_{i}\), \(T_{i}\), \(y_{i} = Y_{i}(T_{i})\))元组是独立同分布的
- en: 19.5.5 Average Treatment Effect
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.5.5 平均处理效应
- en: For each individual, the **treatment effect** is \(Y_{i}(1)-Y_{i}(0)\)
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个个体，**处理效应**是\(Y_{i}(1)-Y_{i}(0)\)
- en: The most common thing to estimate is the **Average Treatment Effect (ATE)**
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的估计是**平均处理效应（ATE）**
- en: \[ATE = \mathbb{E}[Y(1)-Y(0)] = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]\]
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: \[ATE = \mathbb{E}[Y(1)-Y(0)] = \mathbb{E}[Y(1)] - \mathbb{E}[Y(0)]\]
- en: Can we just take the sample mean?
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能否只取样本均值？
- en: \[\hat{ATE} = \frac{1}{n}\sum_{i=1}^{n}Y_{i}(1) - Y_{i}(0)\]
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: \[\hat{ATE} = \frac{1}{n}\sum_{i=1}^{n}Y_{i}(1) - Y_{i}(0)\]
- en: We cannot. Why? We only observe one of \(Y_{i}(1)\), \(Y_{i}(0)\).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能。为什么？我们只观察到\(Y_{i}(1)\)，\(Y_{i}(0)\)中的一个。
- en: '**Fundamental problem of causal inference:** We only ever observe one potential
    outcome'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '**因果推断的基本问题：**我们只能观察到一个潜在结果'
- en: To draw causal conclusions, we need some causal assumption relating the observed
    to the unobserved units
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 要得出因果结论，我们需要一些关于观察到的和未观察到的单位之间的因果假设
- en: Instead of \(\frac{1}{n}\sum_{i=1}^{n}Y_{i}(1) - Y_{i}(0)\), what if we took
    the difference between the sample mean for each group?
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 与其\(\frac{1}{n}\sum_{i=1}^{n}Y_{i}(1) - Y_{i}(0)\)，不如我们取每组的样本均值之间的差异？
- en: '\[\hat{ATE} = \frac{1}{n_{1}}\sum_{i: T_{i} = 1}{Y_{i}(1)} - \frac{1}{n_{0}}\sum_{i:
    T_{i} = 0}{Y_{i}(0)} = \frac{1}{n_{1}}\sum_{i: T_{i} = 1}{y_{i}} - \frac{1}{n_{0}}\sum_{i:
    T_{i} = 0}{y_{i}}\]'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '\[\hat{ATE} = \frac{1}{n_{1}}\sum_{i: T_{i} = 1}{Y_{i}(1)} - \frac{1}{n_{0}}\sum_{i:
    T_{i} = 0}{Y_{i}(0)} = \frac{1}{n_{1}}\sum_{i: T_{i} = 1}{y_{i}} - \frac{1}{n_{0}}\sum_{i:
    T_{i} = 0}{y_{i}}\]'
- en: Is this estimator of \(ATE\) unbiased? Thus, this proposed \(\hat{ATE}\) is
    not suitable for our purposes.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这个\(ATE\)的估计是否无偏？因此，这个提出的\(\hat{ATE}\)不适合我们的目的。
- en: If treatment assignment comes from random coin flips, then the treated units
    are an iid random sample of size \(n_{1}\) from the population of \(Y_{i}(1)\).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如果处理分配来自随机抛硬币，那么受治疗单位是来自\(Y_{i}(1)\)总体的大小为\(n_{1}\)的独立同分布随机样本。
- en: This means that,
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，
- en: '\[\mathbb{E}[\frac{1}{n_{1}}\sum_{i: T_{i} = 1}{y_{i}}] = \mathbb{E}[Y_{i}(1)]\]'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '\[\mathbb{E}[\frac{1}{n_{1}}\sum_{i: T_{i} = 1}{y_{i}}] = \mathbb{E}[Y_{i}(1)]\]'
- en: Similarly,
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，
- en: '\[\mathbb{E}[\frac{1}{n_{0}}\sum_{i: T_{i} = 0}{y_{i}}] = \mathbb{E}[Y_{i}(0)]\]'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '\[\mathbb{E}[\frac{1}{n_{0}}\sum_{i: T_{i} = 0}{y_{i}}] = \mathbb{E}[Y_{i}(0)]\]'
- en: 'which allows us to conclude that \(\hat{ATE}\) is an unbiased estimator of
    \(ATE\):'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们得出结论，\(\hat{ATE}\)是\(ATE\)的无偏估计：
- en: \[\mathbb{E}[\hat{ATE}] = ATE\]
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: \[\mathbb{E}[\hat{ATE}] = ATE\]
- en: 19.5.6 Randomized Experiments
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.5.6 随机实验
- en: However, often, randomly assigning treatments is impractical or unethical. For
    example, assigning a treatment of cigarettes would likely be impractical and unethical.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通常随机分配处理是不切实际或不道德的。例如，分配香烟治疗可能是不切实际和不道德的。
- en: An alternative to bypass this issue is to utilize **observational studies**.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 绕过这个问题的另一种方法是利用**观测研究**。
- en: 'Experiments:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 实验：
- en: '![experiment](../Images/f902f03edb3f4d81bca7d30a96d84f4f.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![experiment](../Images/f902f03edb3f4d81bca7d30a96d84f4f.png)'
- en: 'Observational Study:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 观测研究：
- en: '![observational](../Images/4629a7164675397a97546a5ba1dd94e0.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![observational](../Images/4629a7164675397a97546a5ba1dd94e0.png)'
- en: 19.5.7 Covariate Adjustment
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.5.7 协变量调整
- en: What to do about confounders?
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 对于混杂因素该怎么办？
- en: '**Ignorability assumption:** all important confounders are in the data set!'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可忽略性假设：**所有重要的混杂因素都在数据集中！'
- en: '**One idea:** come up with a model that includes them, such as:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个想法：**提出一个包括它们的模型，比如：'
- en: \[Y_{i}(t) = \theta_{0} + \theta_{1}x_{1} + ... + \theta_{p}x_{p} + \tau{t}
    + \epsilon\]
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: \[Y_{i}(t) = \theta_{0} + \theta_{1}x_{1} + ... + \theta_{p}x_{p} + \tau{t}
    + \epsilon\]
- en: '**Question:** what is the \(ATE\) in this model? \(\tau\)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题：**在这个模型中\(ATE\)是多少？\(\tau\)'
- en: 'This approach can work but is **fragile**. Breaks if:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可能有效，但是**脆弱**。如果：
- en: Important covariates are missing or true dependence on \(x\) is nonlinear
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重要的协变量缺失或者对\(x\)的真实依赖是非线性的
- en: Sometimes pejoratively called **“causal inference”**
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时被贬低地称为**“因果推断”**
- en: '![ignorability](../Images/85f6d03dd3af75406ed43a7ecc6d34b2.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![ignorability](../Images/85f6d03dd3af75406ed43a7ecc6d34b2.png)'
- en: 19.5.7.1 Covariate adjustment without parametric assumptions
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 19.5.7.1 不需要参数假设的协变量调整
- en: What to do about confounders?
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对混杂因素怎么办？
- en: '**Ignorability assumption:** all possible confounders are in the data set!'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可忽略性假设：**数据集中包含所有可能的混杂因素！'
- en: '**One idea:** come up with a model that includes them, such as:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个想法：**提出一个包括它们的模型，比如：'
- en: \[Y_{i}(t) = f_{\theta}(x, t) + \epsilon\]
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: \[Y_{i}(t) = f_{\theta}(x, t) + \epsilon\]
- en: 'Then:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 然后：
- en: \[ATE = \frac{1}{n}\sum_{i=1}^{n}{f_{\theta}(x_i, 1) - f_{\theta}(x_i, 0)}\]
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: \[ATE = \frac{1}{n}\sum_{i=1}^{n}{f_{\theta}(x_i, 1) - f_{\theta}(x_i, 0)}\]
- en: With enough data, we may be able to learn \(f_{\theta}\) very accurately
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 有了足够的数据，我们可能能够非常准确地学习\(f_{\theta}\)
- en: Very difficult if x is high-dimensional / its functional form is highly nonlinear
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果\(x\)是高维的/其函数形式高度非线性，则非常困难
- en: 'Need additional assumption: **overlap**'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要额外的假设：**重叠**
- en: 19.5.8 Other Methods
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.5.8 其他方法
- en: Causal inference is hard, and covariate adjustment is often not the best approach
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 因果推断很难，协变量调整通常不是最佳方法
- en: 'Many other methods are some combination of:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 许多其他方法是一些组合：
- en: Modeling treatment T as a function of covariates x
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将处理T建模为协变量x的函数
- en: Modeling the outcome y as a function of x, T
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将结果y建模为x，T的函数
- en: What if we don’t believe in ignorability? Other methods look for a
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不相信可忽略性呢？其他方法寻找一个
- en: 'Favorite example: **regression discontinuity**'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最喜欢的例子：**回归不连续**
- en: 19.6 (Bonus) Proof of Bias-Variance Decomposition
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 19.6（奖励）偏差-方差分解的证明
- en: This section walks through the detailed derivation of the Bias-Variance Decomposition
    in the Bias-Variance Tradeoff section earlier in this note.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 本节详细推导了偏差-方差分解在前面笔记中的偏差-方差权衡部分。
- en: '*Click to show* **We want to prove that the model risk can be decomposed as'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '*点击显示* **我们想证明模型风险可以分解为'
- en: \[ \begin{align*} E\left[(Y(x)-\hat{Y}(x))^2\right] &= E[\epsilon^2] + \left(g(x)-E\left[\hat{Y}(x)\right]\right)^2
    + E\left[\left(E\left[\hat{Y}(x)\right] - \hat{Y}(x)\right)^2\right]. \end{align*}
    \]
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{align*} E\left[(Y(x)-\hat{Y}(x))^2\right] &= E[\epsilon^2] + \left(g(x)-E\left[\hat{Y}(x)\right]\right)^2
    + E\left[\left(E\left[\hat{Y}(x)\right] - \hat{Y}(x)\right)^2\right]. \end{align*}
    \]
- en: 'To prove this, we will first need the following lemma:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明这一点，我们首先需要以下引理：
- en: If \(V\) and \(W\) are independent random variables then \(E[VW] = E[V]E[W]\).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 如果\(V\)和\(W\)是独立的随机变量，则\(E[VW] = E[V]E[W]\)。
- en: We will prove this in the discrete finite case. Trust that it’s true in greater
    generality.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在离散有限的情况下证明这一点。相信它在更广泛的情况下也是成立的。
- en: The job is to calculate the weighted average of the values of \(VW\), where
    the weights are the probabilities of those values. Here goes.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 工作是计算\(VW\)值的加权平均值，其中权重是这些值的概率。开始吧。
- en: \[\begin{align*} E[VW] ~ &= ~ \sum_v\sum_w vwP(V=v \text{ and } W=w) \\ &= ~
    \sum_v\sum_w vwP(V=v)P(W=w) ~~~~ \text{by independence} \\ &= ~ \sum_v vP(V=v)\sum_w
    wP(W=w) \\ &= ~ E[V]E[W] \end{align*}\]
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{align*} E[VW] ~ &= ~ \sum_v\sum_w vwP(V=v \text{ and } W=w) \\ &= ~
    \sum_v\sum_w vwP(V=v)P(W=w) ~~~~ \text{根据独立性} \\ &= ~ \sum_v vP(V=v)\sum_w wP(W=w)
    \\ &= ~ E[V]E[W] \end{align*}\]
- en: 'Now we go into the actual proof:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们进入实际的证明：
- en: 19.6.1 Goal
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.6.1 目标
- en: Decompose the model risk into recognizable components.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型风险分解为可识别的组成部分。
- en: 19.6.2 Step 1
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.6.2 步骤1
- en: \[ \begin{align*} \text{model risk} ~ &= ~ E\left[\left(Y - \hat{Y}(x)\right)^2
    \right] \\ &= ~ E\left[\left(g(x) + \epsilon - \hat{Y}(x)\right)^2 \right] \\
    &= ~ E\left[\left(\epsilon + \left(g(x)- \hat{Y}(x)\right)\right)^2 \right] \\
    &= ~ E\left[\epsilon^2\right] + 2E\left[\epsilon \left(g(x)- \hat{Y}(x)\right)\right]
    + E\left[\left(g(x) - \hat{Y}(x)\right)^2\right]\\ \end{align*} \]
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \begin{align*} \text{模型风险} ~ &= ~ E\left[\left(Y - \hat{Y}(x)\right)^2 \right]
    \\ &= ~ E\left[\left(g(x) + \epsilon - \hat{Y}(x)\right)^2 \right] \\ &= ~ E\left[\left(\epsilon
    + \left(g(x)- \hat{Y}(x)\right)\right)^2 \right] \\ &= ~ E\left[\epsilon^2\right]
    + 2E\left[\epsilon \left(g(x)- \hat{Y}(x)\right)\right] + E\left[\left(g(x) -
    \hat{Y}(x)\right)^2\right]\\ \end{align*} \]
- en: 'On the right hand side:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 右边：
- en: The first term is the observation variance \(\sigma^2\).
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一项是观测方差\(\sigma^2\)。
- en: The cross product term is 0 because \(\epsilon\) is independent of \(g(x) -
    \hat{Y}(x)\) and \(E(\epsilon) = 0\)
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉乘积项为0，因为\(\epsilon\)与\(g(x) - \hat{Y}(x)\)独立，且\(E(\epsilon) = 0\)
- en: The last term is the mean squared difference between our predicted value and
    the value of the true function at \(x\)
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一项是我们预测值与\(x\)处真实函数值之间的均方差差
- en: 19.6.3 Step 2
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.6.3 步骤2
- en: At this stage we have
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 到这个阶段我们有
- en: \[ \text{model risk} ~ = ~ E\left[\epsilon^2\right] + E\left[\left(g(x) - \hat{Y}(x)\right)^2\right]
    \]
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{模型风险} ~ = ~ E\left[\epsilon^2\right] + E\left[\left(g(x) - \hat{Y}(x)\right)^2\right]
    \]
- en: We don’t yet have a good understanding of \(g(x) - \hat{Y}(x)\). But we do understand
    the deviation \(D_{\hat{Y}(x)} = \hat{Y}(x) - E\left[\hat{Y}(x)\right]\). We know
    that
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还不太了解\(g(x) - \hat{Y}(x)\)。但我们了解偏差\(D_{\hat{Y}(x)} = \hat{Y}(x) - E\left[\hat{Y}(x)\right]\)。我们知道
- en: \(E\left[D_{\hat{Y}(x)}\right] ~ = ~ 0\)
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(E\left[D_{\hat{Y}(x)}\right] ~ = ~ 0\)
- en: \(E\left[D_{\hat{Y}(x)}^2\right] ~ = ~ \text{model variance}\)
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(E\left[D_{\hat{Y}(x)}^2\right] ~ = ~ \text{模型方差}\)
- en: So let’s add and subtract \(E\left[\hat{Y}(x)\right]\) and see if that helps.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们添加并减去\(E\left[\hat{Y}(x)\right]，看看是否有帮助。
- en: \[ g(x) - \hat{Y}(x) ~ = ~ \left(g(x) - E\left[\hat{Y}(x)\right] \right) + \left(E\left[\hat{Y}(x)\right]
    - \hat{Y}(x)\right) \]
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: \[ g(x) - \hat{Y}(x) ~ = ~ \left(g(x) - E\left[\hat{Y}(x)\right] \right) + \left(E\left[\hat{Y}(x)\right]
    - \hat{Y}(x)\right) \]
- en: The first term on the right hand side is the model bias at \(x\). The second
    term is \(-D_{\hat{Y}(x)}\). So
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 右边的第一项是\(x\)处的模型偏差。第二项是\(-D_{\hat{Y}(x)}\)。所以
- en: \[ g(x) - \hat{Y}(x) ~ = ~ \text{model bias} - D_{\hat{Y}(x)} \]
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: \[ g(x) - \hat{Y}(x) ~ = ~ \text{模型偏差} - D_{\hat{Y}(x)} \]
- en: 19.6.4 Step 3
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.6.4 步骤3
- en: Remember that the model bias at \(x\) is a constant, not a random variable.
    Think of it as your favorite number, say 10\. Then \[ \begin{align*} E\left[ \left(g(x)
    - \hat{Y}(x)\right)^2 \right] ~ &= ~ \text{model bias}^2 - 2(\text{model bias})E\left[D_{\hat{Y}(x)}\right]
    + E\left[D_{\hat{Y}(x)}^2\right] \\ &= ~ \text{model bias}^2 - 0 + \text{model
    variance} \\ &= ~ \text{model bias}^2 + \text{model variance} \end{align*} \]
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在\(x\)处的模型偏差是一个常数，不是一个随机变量。把它看作你最喜欢的数字，比如10。那么 \[ \begin{align*} E\left[
    \left(g(x) - \hat{Y}(x)\right)^2 \right] ~ &= ~ \text{模型偏差}^2 - 2(\text{模型偏差})E\left[D_{\hat{Y}(x)}\right]
    + E\left[D_{\hat{Y}(x)}^2\right] \\ &= ~ \text{模型偏差}^2 - 0 + \text{模型方差} \\ &=
    ~ \text{模型偏差}^2 + \text{模型方差} \end{align*} \]
- en: Again, the cross-product term is \(0\) because \(E\left[D_{\hat{Y}(x)}\right]
    ~ = ~ 0\).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，交叉乘积项为0，因为\(E\left[D_{\hat{Y}(x)}\right] ~ = ~ 0\)。
- en: '19.6.5 Step 4: Bias-Variance Decomposition'
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19.6.5 第4步：偏差-方差分解
- en: In Step 2 we had
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2步中我们有
- en: \[ \text{model risk} ~ = ~ \text{observation variance} + E\left[\left(g(x) -
    \hat{Y}(x)\right)^2\right] \]
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{模型风险} ~ = ~ \text{观测方差} + E\left[\left(g(x) - \hat{Y}(x)\right)^2\right]
    \]
- en: Step 3 showed
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 第3步显示
- en: \[ E\left[ \left(g(x) - \hat{Y}(x)\right)^2 \right] ~ = ~ \text{model bias}^2
    + \text{model variance} \]
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: \[ E\left[ \left(g(x) - \hat{Y}(x)\right)^2 \right] ~ = ~ \text{模型偏差}^2 + \text{模型方差}
    \]
- en: 'Thus we have shown the bias-variance decomposition:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经展示了偏差-方差分解：
- en: \[ \text{model risk} = \text{observation variance} + \text{model bias}^2 + \text{model
    variance}. \]
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \text{模型风险} = \text{观测方差} + \text{模型偏差}^2 + \text{模型方差}。 \]
- en: That is,
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，
- en: \[ E\left[(Y(x)-\hat{Y}(x))^2\right] = \sigma^2 + \left(E\left[\hat{Y}(x)\right]
    - g(x)\right)^2 + E\left[\left(\hat{Y}(x)-E\left[\hat{Y}(x)\right]\right)^2\right]
    \]*****
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: \[ E\left[(Y(x)-\hat{Y}(x))^2\right] = \sigma^2 + \left(E\left[\hat{Y}(x)\right]
    - g(x)\right)^2 + E\left[\left(\hat{Y}(x)-E\left[\hat{Y}(x)\right]\right)^2\right]
    \]*****
