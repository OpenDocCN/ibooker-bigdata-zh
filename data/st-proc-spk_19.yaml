- en: 'Chapter 15\. Experimental Areas: Continuous Processing and Machine Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第15章。实验性领域：连续处理与机器学习
- en: Structured Streaming first appeared in Spark 2.0 as an experimental API, offering
    a new streaming model aimed at simplifying the way we think about streaming applications.
    In Spark 2.2, Structured Streaming “graduated” to *production-ready*, giving the
    signal that this new model was all set for industry adoption. With Spark 2.3,
    we saw further improvements in the area of streaming joins, and it also introduced
    a new experimental continuous execution model for low-latency stream processing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化流处理首次出现在Spark 2.0中作为一个实验性API，提供了一个新的流处理模型，旨在简化我们思考流应用的方式。在Spark 2.2中，结构化流处理“毕业”成为*适用于生产环境*，表明这种新模型已准备好供行业采用。在Spark
    2.3中，我们看到在流连接方面进一步改进，并引入了一个新的实验性连续执行模型，用于低延迟流处理。
- en: As with any new successful development, we can expect Structured Streaming to
    keep advancing at a fast pace. Although industry adoption will contribute evolutionary
    feedback on important features, market trends such as the increasing popularity
    of machine learning will drive the roadmap of the releases to come.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何新的成功开发一样，我们可以期待结构化流处理保持快速进展。尽管行业采用将为重要特性提供进化反馈，但市场趋势如机器学习日益增长的流行性将推动未来发布的路线图。
- en: In this chapter, we want to provide insights into some of the areas under development
    that will probably become mainstream in upcoming releases.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们希望深入探讨一些正在开发中的领域，这些领域可能会成为未来版本的主流。
- en: Continuous Processing
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续处理
- en: '*Continuous processing* is an alternative execution mode for Structured Streaming
    that allows for low-latency processing of individual events. It has been included
    as an experimental feature in Spark v2.3 and is still under active development,
    in particular in the areas of delivery semantics, stateful operation support,
    and monitoring.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*连续处理*是结构化流处理的一种替代执行模式，允许对单个事件进行低延迟处理。它作为Spark v2.3中的实验性功能被包含进来，并且仍在积极开发中，特别是在交付语义、有状态操作支持和监控领域。'
- en: Understanding Continuous Processing
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解连续处理
- en: The initial streaming API for Spark, Spark Streaming, was conceived with the
    idea of reusing the batch capabilities of Spark. In a nutshell, the data stream
    is split into small chunks that are given to Spark for processing, using the core
    engine in its native batch execution mode. Using a scheduled repetition of this
    process at short time intervals, the input stream is constantly consumed and results
    are produced in a streaming fashion. This is called the *microbatch model*, which
    we discussed early on in [Chapter 5](ch05.xhtml#distributed-processing). We study
    the application of this model in more detail when we talk about Spark Streaming
    in the next part of the book. The important part to remember for now, is that
    the definition of that interval of time, called *batch interval*, is the keystone
    of the original microbatch implementation.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的初始流处理API，Spark Streaming，旨在重用Spark的批处理能力。简而言之，数据流被分成小块交给Spark进行处理，使用其本机批处理执行模式的核心引擎。在短时间间隔内定期重复此过程，不断消耗输入流并以流式方式生成结果。这被称为*微批处理模型*，我们在[第5章](ch05.xhtml#distributed-processing)早期已经讨论过。在本书的后续部分讨论Spark
    Streaming时，我们将更详细地研究该模型的应用。现在要记住的重要部分是，称为*批处理间隔*的时间间隔定义是原始微批处理实现的关键。
- en: Microbatch in Structured Streaming
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结构化流处理中的微批处理
- en: When Structured Streaming was introduced, a similar evolution took place. Instead
    of introducing an alternative processing model, Structured Streaming was embedded
    into the `Dataset` API and reused the existing capabilities of the underlying
    Spark SQL engine. As a result, Structured Streaming offers a unified API with
    the more traditional batch mode and fully benefits from the performance optimizations
    introduced by Spark SQL, such as query optimization and Tungsten’s code generation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当引入结构化流处理时，发生了类似的演进。与引入替代处理模型不同，结构化流处理被嵌入到`Dataset` API中，并重用了底层Spark SQL引擎的现有功能。因此，结构化流处理提供了统一的API，与传统的批处理模式完全融合，并充分利用了Spark
    SQL引入的性能优化，如查询优化和Tungsten代码生成。
- en: In that effort, the underlying engine received additional capabilities to sustain
    a streaming workload, like incremental query execution and the support of resilient
    state management over time.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一努力中，底层引擎获得了额外的能力来支持流处理工作负载，如增量查询执行和随时间的弹性状态管理的支持。
- en: At the API surface level, Structured Streaming avoided making the notion of
    time an explicit user-facing parameter. This is what allows for the implementation
    of event-time aggregations, as the notion of time is inferred from the data stream,
    instead. Internally, the execution engine still relies on a microbatch architecture,
    but the abstraction of time allows for the creation of engines with different
    models of execution.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在 API 表面上，结构化流处理避免了将时间概念作为显式用户参数。这使得可以实现基于事件时间的聚合，因为时间概念是从数据流中推断出来的。在内部，执行引擎仍然依赖微批处理架构，但时间的抽象允许创建具有不同执行模型的引擎。
- en: The first execution model that departs from the fixed-time microbatch is the
    *best-effort* execution in Structured Streaming, which is the default mode when
    no `trigger` is specified. In best-effort mode, the next microbatch starts as
    soon as the previous one ends. This creates the observable continuity of the resulting
    stream and improves the usage of the underlying computing resources.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 离开固定时间微批处理的第一个执行模型是结构化流处理中的*尽力而为*执行，在未指定`trigger`时是默认模式。在尽力而为模式下，下一个微批处理会在上一个结束后立即开始。这创建了结果流的可观察连续性，并改善了底层计算资源的使用。
- en: The microbatch execution engine uses a task-dispatching model. Task dispatching
    and coordination over the cluster is rather expensive and the minimal latency
    possible is roughly 100 ms.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 微批处理执行引擎采用任务调度模型。在集群上进行任务调度和协调非常昂贵，最小的可能延迟大约为 100 毫秒。
- en: In [Figure 15-1](#micro-batch-latency), you can observe how the process of filtering
    the incoming “circles” and transforming them to “triangles” works with the microbatch
    model. We collect all elements that arrive in a certain interval and apply our
    function *f* to all of them at the same time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 15-1](#micro-batch-latency) 中，您可以观察到使用微批处理模型过滤传入的“圆形”并将其转换为“三角形”的过程。我们收集在特定间隔内到达的所有元素，并同时对它们应用我们的函数
    *f*。
- en: '![spas 1501](Images/spas_1501.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![spas 1501](Images/spas_1501.png)'
- en: Figure 15-1\. Microbatch latency
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 15-1\. 微批处理延迟
- en: The processing latency is the time duration between the arrival of the event
    in the *source* stream and the production of a result in the *sink*. As we can
    appreciate, in the microbatch model, the latency upper limit is the batch interval
    plus the time it takes to process the data, which consists of the computation
    itself and the coordination needed to execute such computation in some executor
    of the cluster.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 处理延迟是在*源*流中事件到达和在*sink*中产生结果之间的时间间隔。正如我们所了解的，在微批处理模型中，延迟的上限是批处理间隔加上处理数据所需的时间，其中包括计算本身以及在集群的执行器中执行此类计算所需的协调。
- en: 'Introducing continuous processing: A low-latency streaming mode'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 引入连续处理：低延迟流处理模式
- en: Taking advantage of the time abstraction in Structured Streaming, it is possible
    to introduce new modes of execution without changing the user-facing API.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 利用结构化流处理中的时间抽象，可以引入新的执行模式，而无需更改面向用户的 API。
- en: 'In the continuous processing execution mode, the data-processing query is implemented
    as a long-running task that executes *continuously* on the executors. The parallelism
    model is simple: for each input partition, we will have such a task running on
    a node of the cluster. This task subscribes to the input partition and continuously
    processes incoming individual events. The deployment of a query under continuous
    processing creates a topology of tasks in the cluster.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在连续处理执行模式中，数据处理查询作为长时间运行的任务在执行器上*持续*执行。并行模型很简单：对于每个输入分区，集群的节点上会运行这样一个任务。该任务订阅输入分区并持续处理传入的各个事件。在连续处理查询部署下，集群中会创建一组任务的拓扑结构。
- en: As illustrated in [Figure 15-2](#continuous-processing-latency), this new execution
    model eliminates the microbatch delay and produces a result for each element as
    soon as it’s processed. This model is similar to Apache Flink.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [15-2](#continuous-processing-latency) 所示，这种新的执行模型消除了微批处理延迟，并在每个元素处理完毕后立即生成结果。此模型类似于
    Apache Flink。
- en: '![spas 1502](Images/spas_1502.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![spas 1502](Images/spas_1502.png)'
- en: Figure 15-2\. Continuous processing latency
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 15-2\. 连续处理延迟
- en: Using Continuous Processing
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用连续处理
- en: 'All that is required to use the continuous processing execution mode is to
    specify `Trigger.Continuous` as a `trigger` and provide it with the time interval
    for the asynchronous checkpoint function, like we show in this minimalistic example:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用连续处理执行模式所需的所有操作是指定`Trigger.Continuous`作为`trigger`并提供一个时间间隔给异步检查点函数，如我们在这个简约示例中所展示的：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Warning
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Do not confuse the time interval provided in `Trigger.Continuous(<time-interval>)`
    with a microbatch interval. This is the time interval of the asynchronous checkpoint
    operation, done by the *continuous query* executor.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 不要将`Trigger.Continuous(<time-interval>)`提供的时间间隔与微批次间隔混淆。这是异步检查点操作的时间间隔，由*连续查询*执行器完成。
- en: Limitations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: Although there are no changes at the API level, there are a number of restrictions
    on the type of queries that are supported in continuous mode. The intuition is
    that continuous mode works with queries that can be applied on a per-element basis.
    In SQL terms, we can use selections, projections, and transformations, including
    SQL functions except for aggregations. In functional terms, we can use `filter`,
    `map`, `flatMap`, and `mapPartitions`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在API级别没有变化，但在连续模式下支持的查询类型有一些限制。直觉上，连续模式与可以逐元素应用的查询一起工作。在SQL术语中，我们可以使用选择、投影和转换，包括SQL函数，除了聚合之外。在函数式术语中，我们可以使用`filter`、`map`、`flatMap`和`mapPartitions`。
- en: 'When using aggregations and window functions, in particular with event-based
    data, we have much longer deadlines to wait for late and out-of-order data. The
    very nature of a time period in a window and related concepts such as *watermarks*
    do not benefit from the low-latency characteristics of this execution model. In
    such cases, the recommended approach is to fall back to the microbatch-based engine,
    replacing `Trigger.Continuous(<checkpoint-interval>)` with a microbatch trigger
    definition: `Trigger.ProcessingTime(<trigger-interval>)`.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用聚合和窗口函数时，特别是处理基于事件的数据时，我们必须等待迟到和乱序数据的时间更长。窗口中的时间段及相关概念，如*水印*，并不能从这种执行模型的低延迟特性中受益。在这种情况下，推荐的方法是退回到基于微批次的引擎，将`Trigger.Continuous(<checkpoint-interval>)`替换为微批次触发器定义：`Trigger.ProcessingTime(<trigger-interval>)`。
- en: The support of arbitrary stateful processing such as `[flat]mapGroupsWithState`
    is currently under development.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 支持任意状态处理，例如`[flat]mapGroupsWithState`，目前正在开发中。
- en: Machine Learning
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: As the amount of available data and its rate of arrival increases, traditional
    techniques of understanding signals in the data become a major block to extract
    actionable insights from it.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 随着可用数据量和其到达速度的增加，传统的信号理解技术成为从数据中提取可操作见解的主要障碍。
- en: Machine learning is, in essence, the combination of algorithms and statistical
    analysis techniques to *learn* from the data and use that learning to provide
    an answer to certain questions. Machine learning uses data to estimate a model,
    a mathematical representation of some aspect of the world. Once a model has been
    determined, it can be queried on existing or new data to obtain an answer.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习本质上是算法和统计分析技术的结合，用于从数据中*学习*，并利用这种学习为某些问题提供答案。机器学习使用数据来估计模型，即对世界某个方面的数学表示。一旦确定了模型，就可以在现有或新数据上查询以获得答案。
- en: 'The nature of the answer we want from the data divides the aim of the machine
    learning algorithms into three groups:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从数据中期望得到的答案的性质将机器学习算法的目标分为三类：
- en: Regression
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 回归
- en: 'We want to predict a value in a continuous range. Example: using data about
    a student’s number of absences and hours of study for a given class, predict the
    score in their final exam.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望在连续范围内预测一个值。示例：使用关于学生缺课次数和某课程学习小时数的数据，预测他们在期末考试中的成绩。
- en: Classification
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 分类
- en: 'We want to separate data points into one of several categories. Example: given
    a text sample, we want to estimate the language.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望将数据点分为几个类别之一。示例：给定一段文本样本，我们希望估计其语言。
- en: Clustering
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类
- en: 'Given a set of elements, we want to divide it into subsets using some notion
    of similarity. Example: in an online wine store, we want to group customers with
    similar purchase behavior.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组元素，我们希望使用某种相似性概念将其划分为子集。示例：在一个在线葡萄酒商店，我们希望将具有相似购买行为的客户分组。
- en: In the learning process, we also have the notion of *supervision*. We talk about
    *supervised learning* when the algorithm being trained requires data that maps
    a number of observations to an outcome. Regression and classification techniques
    fall under the category of *supervised learning*. Using our previous example of
    the exam score, to build our regression model, we require a dataset of historical
    student performance that contains the exam scores along with the number of absences
    and hours of study reported by the students. Obtaining *good* data is the most
    challenging aspect of a machine learning task.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习过程中，我们还有*监督*的概念。当被训练的算法需要将一些观测映射到结果的数据时，我们称之为*监督学习*。回归和分类技术属于*监督学习*范畴。以我们之前的考试成绩为例，要建立我们的回归模型，我们需要一个包含学生历史表现数据的数据集，其中包括学生报告的考试成绩、缺席次数和学习时间。获取*好*的数据是机器学习任务中最具挑战性的方面。
- en: Learning Versus Exploiting
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习与利用
- en: 'We can identify two phases in the application of machine learning techniques:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以识别出机器学习技术应用中的两个阶段：
- en: A learning phase, in which data is prepared and used to estimate a model. This
    is also known as *training* or *learning*.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习阶段，其中数据被准备并用于估计模型。这也被称为*训练*或*学习*。
- en: An exploit phase, in which the estimated model is queried on new data. This
    phase is known as *prediction* or *scoring*.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用阶段，估计模型在新数据上被查询。这个阶段被称为*预测*或*评分*。
- en: The training phase in machine learning is typically done using historical datasets.
    These datasets are usually cleaned and prepared for the target application. The
    machine learning methodology also calls for a validation phase in which the resulting
    model is evaluated against a dataset of known results, usually called the *testing*
    or *validation* set. The result of the testing phase are metrics that report how
    well the learned model performs on data that it didn’t see during the training.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的训练阶段通常使用历史数据集。这些数据集通常被清理并准备用于目标应用。机器学习方法还需要一个验证阶段，其中结果模型将针对已知结果的数据集进行评估，通常称为*测试*或*验证*集。测试阶段的结果是报告学习模型在训练期间未见过的数据上表现如何的度量指标。
- en: Applying a Machine Learning Model to a Stream
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将机器学习模型应用于流数据
- en: As we mentioned earlier, creating a machine learning model is usually a batch-based
    process that uses historical data to train a statistical model. As soon as that
    model is available, it can be used to *score* new data to obtain an estimate of
    the specific aspect for which the model was trained.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，创建机器学习模型通常是一个基于批处理的过程，使用历史数据来训练统计模型。一旦该模型可用，就可以对新数据进行*评分*，以获取该模型训练的特定方面的估计值。
- en: The unified *structured* APIs of Apache Spark across batch, machine learning,
    and streaming make it straightforward to apply a previously trained model to a
    streaming `DataFrame`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark统一的*结构化*API在批处理、机器学习和流处理中使得将先前训练的模型应用于流式`DataFrame`变得简单。
- en: 'Assuming that the model is stored on disk, the process consists of two steps:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 假设模型已存储在磁盘上，该过程包括两个步骤：
- en: Load the model.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载模型。
- en: Use its `transform` method to apply the model to the streaming `DataFrame`.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用其`transform`方法将模型应用于流式`DataFrame`。
- en: Let’s see the API in action with an example.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来看看API的实际应用。
- en: 'Example: Estimating Room Occupancy by Using Ambient Sensors'
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例：使用环境传感器估计房间占用情况
- en: During the development of this part of the book, we have been using sensor information
    as a running theme. Up to now, we have used the sensor data to explore the data
    processing and analytic capabilities of Structured Streaming. Now, imagine that
    we have such ambient sensors in a series of rooms, but instead of keeping track
    of temperature or humidity data over time, we want to use that information to
    drive a novel application. We would like to estimate whether the room is occupied
    at a certain moment by using the sensor data. Although temperature or humidity
    alone are probably not sufficient to determine whether a room is in use, maybe
    a combination of these factors is able to predict occupancy to a certain degree
    of accuracy.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本书的这部分内容时，我们一直在使用传感器信息作为主题。到目前为止，我们已经利用传感器数据探索了结构化流处理的数据处理和分析能力。现在，假设我们在一系列房间中放置了这样的环境传感器，但我们不是追踪温度或湿度数据的变化，而是想利用这些信息驱动一个新颖的应用。我们希望通过使用传感器数据来估计某一时刻房间是否被占用。虽然单独的温度或湿度可能不足以确定房间是否在使用中，但也许这些因素的组合能够在一定程度上预测占用情况。
- en: Online Resources
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线资源
- en: For this example, we will use the `occupancy_detection_model` and `occupancy_streaming_prediction`
    notebooks in the online resources for the book, located at [*https://github.com/stream-processing-with-spark*](https://github.com/stream-processing-with-spark).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本例，我们将在书籍的在线资源中使用`occupancy_detection_model`和`occupancy_streaming_prediction`笔记本，位于[*https://github.com/stream-processing-with-spark*](https://github.com/stream-processing-with-spark)。
- en: 'For this example, we are going to use an occupancy dataset that was collected
    with the intention of answering that question. The [dataset](http://bit.ly/2PH7De8)
    consists of the following schema:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本例，我们将使用一个占用数据集，该数据集是为了回答该问题而收集的。该[数据集](http://bit.ly/2PH7De8)包含以下模式：
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The occupancy information in the training dataset was obtained using camera
    images of the room to detect with certainty the presence of people in it.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集中的占用信息是通过房间的摄像头图像获得的，以确定其中是否有人员存在。
- en: Using this data, we trained a logistic regression model that estimates the occupancy,
    represented by the binomial outcome [0,1], where 0 = not occupied and 1 = occupied.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些数据，我们训练了一个逻辑回归模型，用于估计占用情况，表示为二项结果[0,1]，其中0 = 未占用，1 = 占用。
- en: Note
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For this example, we assume that the trained model is already available on disk.
    The complete training phase of this example is available in the book’s online
    resources.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本例，我们假设训练好的模型已经在磁盘上可用。这个例子的完整训练阶段可以在书籍的在线资源中找到。
- en: 'The first step is to load the previously trained model:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是加载先前训练的模型：
- en: '[PRE2]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This call results in a model that contains information over the stages of our
    pipeline.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此调用会生成一个包含我们流水线各个阶段信息的模型。
- en: 'With the call to `model.stages`, we can visualize these stages:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用`model.stages`，我们可以可视化这些阶段：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Our pipeline consists of two stages: a `VectorAssembler` and a `LogisticRegression`
    classifier. The `VectorAssembler` is a transformation that selectively transforms
    the chosen fields in the input data into a numeric `Vector` that serves as input
    for the model. The `LogisticRegression` stage is the trained logistic regression
    classifier. It uses the learned parameters to transform the input `Vector` into
    three fields that are added to the `streaming` `DataFrame`: `rawPrediction`, `probability`,
    and `prediction`.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的流水线包括两个阶段：`VectorAssembler`和`LogisticRegression`分类器。`VectorAssembler`是一个转换器，将输入数据中选择的字段选择性地转换为数值`Vector`，作为模型的输入。`LogisticRegression`阶段是经过训练的逻辑回归分类器。它使用学习到的参数将输入`Vector`转换为三个字段，这些字段将添加到`streaming`
    `DataFrame`中：`rawPrediction`、`probability`和`prediction`。
- en: For our application, we are interested in the `prediction` value that will tell
    us whether the room is in use (1) or not (0).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的应用程序，我们感兴趣的是`prediction`值，该值将告诉我们房间是否正在使用（1）或未使用（0）。
- en: The next step, shown in [Example 15-1](#structured_streaming_ml_scoring), is
    to apply the model to the streaming `DataFrame`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步，如[示例 15-1](#structured_streaming_ml_scoring)所示，是将模型应用于流`DataFrame`。
- en: Example 15-1\. Using a trained machine learning model in Structured Streaming
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 15-1\. 在结构化流中使用训练好的机器学习模型
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: At this point, we have a streaming `DataFrame` that contains the prediction
    of our original streaming data.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们有一个包含原始流数据预测的流`DataFrame`。
- en: 'The final step in our streaming prediction is to do something with the prediction
    data. In this example, we are going to limit this step to querying the data using
    the memory sink to access the resulting data as a SQL table:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们流预测的最后一步是处理预测数据。在这个例子中，我们将限制此步骤，使用内存接收器查询数据，以访问结果数据作为SQL表：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Given that we are using a test dataset to drive our stream, we also have access
    to the original occupancy data. In this limited sample, we can observe that the
    actual occupancy and the prediction are accurate most but not all of the time.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们使用测试数据集来驱动我们的流，我们还可以访问原始占用数据。在这个有限的样本中，我们可以观察到实际占用和预测大多数但不是所有时间都是准确的。
- en: For real-world applications, we will typically be interested in offering this
    service to other applications. Maybe in the form of an HTTP-based API or through
    pub/sub messaging interactions. We can use any of the available sinks to write
    the results to other systems for further use.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实际应用，我们通常有兴趣将此服务提供给其他应用程序。也许以基于HTTP的API形式，或通过发布/订阅消息交互。我们可以使用任何可用的接收器将结果写入其他系统以供进一步使用。
- en: The challenge of model serving
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型服务的挑战
- en: Trained machine learning models are seldom perfect. There are always opportunities
    to train a model with more or better data, or tweak its parameters to improve
    the prediction accuracy. With ever-evolving trained models, the challenge becomes
    to upgrade our streaming scoring process with a new model whenever it becomes
    available.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 训练好的机器学习模型很少是完美的。总是有机会用更多或更好的数据训练模型，或者调整其参数以提高预测准确性。随着训练好的模型不断发展，挑战在于在新模型可用时升级我们的流处理评分过程。
- en: This process of managing the life cycle of machine learning models from the
    training stage to their exploitation in an application is usually known by the
    broad concept of *model serving*.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练阶段到应用中利用机器学习模型的生命周期管理过程通常被称为*模型服务*的广义概念。
- en: Model serving comprises the process of transitioning trained models into a production
    platform and keeping those online *serving* processes up to date with the most
    recent trained models.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 模型服务包括将训练好的模型转移到生产平台并保持这些在线*服务*过程与最新训练好的模型保持更新的过程。
- en: Model serving in Structured Streaming
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结构化流处理中的模型服务
- en: In Structured Streaming, updating a running query is not possible. Like we saw
    in [Example 15-1](#structured_streaming_ml_scoring), we include the model scoring
    step as a transformation in our streaming process. After we start the corresponding
    streaming query, that declaration becomes part of the query plan that is deployed
    and will run until the query is stopped. Hence, updating machine learning models
    in Structured Streaming is not directly supported. It is, nevertheless, possible
    to create a managing system that calls the Structured Streaming APIs to stop,
    update, and restart a query for which a new model becomes available.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在结构化流处理中，无法更新正在运行的查询。就像我们在[示例 15-1](#structured_streaming_ml_scoring)中看到的那样，在我们的流处理过程中将模型评分步骤作为转换包含其中。在启动相应的流查询之后，该声明成为部署的查询计划的一部分，并将在查询停止之前运行。因此，在结构化流处理中直接支持更新机器学习模型是不可能的。然而，可以创建一个管理系统，调用结构化流处理API停止、更新和重新启动查询，以便提供新模型。
- en: The topic of model serving is an ongoing discussion in the Spark community and
    will certainly see an evolution in future versions of Spark and Structured Streaming.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 模型服务的主题在Spark社区中是一个持续讨论的话题，并且肯定会在未来版本的Spark和结构化流处理中看到进展。
- en: Online Training
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线训练
- en: In the machine learning process we described earlier, we made a distinction
    between the learning and scoring phases, in which the learning step was mainly
    an offline process. In the context of a streaming application, it is possible
    to train a machine learning model as data arrives. This is also called *online
    learning*. Online learning is particularly interesting when we want to adapt to
    evolving patterns in the data, such as the changing interests of a social network
    or trend analysis in financial markets.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们早些描述的机器学习过程中，我们区分了学习和评分阶段，其中学习步骤主要是离线过程。在流应用的上下文中，可以随着数据的到来训练机器学习模型。这也称为*在线学习*。当我们希望适应数据中的变化模式时，例如社交网络的兴趣变化或者金融市场的趋势分析时，在线学习尤为有趣。
- en: Online learning poses a new set of challenges because its implementation mandates
    that each data point is observed only once and that should take into consideration
    that the total amount of data observed might be endless.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在线学习提出了一套新的挑战，因为其实施要求每个数据点只被观察一次，并且必须考虑到观察到的数据总量可能是无限的。
- en: In its current form, Structured Streaming does not offer support for *online
    training*. There are efforts to implement some (limited) form of online learning
    on Structured Streaming, the most notable being [Holden Karau and Seth Hendrickson](https://oreil.ly/2IZwIQU)
    and [Ram Sriharsha and Vlad Feinberg](http://bit.ly/2VFUV4J).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在其当前形式下，结构化流处理不支持*在线训练*。正在努力实现一些（有限的）结构化流处理在线学习的形式，其中最显著的是[霍尔登·卡劳和塞思·亨德里克森](https://oreil.ly/2IZwIQU)以及[拉姆·斯里哈沙和弗拉德·费恩伯格](http://bit.ly/2VFUV4J)。
- en: It would seem that early initiatives to implement online learning on top of
    Structured Streaming have lost momentum. This might change in the future, so check
    new releases of Structured Streaming for potential updates in this area.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来在结构化流处理之上实施在线学习的早期尝试已经失去了动力。这种情况可能会在未来发生改变，因此请关注结构化流处理的新版本，以获取此领域的潜在更新。
