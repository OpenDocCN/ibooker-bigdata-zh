- en: Chapter 12 Modeling categorical relationships
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章 建模分类关系
- en: 原文：[https://statsthinking21.github.io/statsthinking21-core-site/modeling-categorical-relationships.html](https://statsthinking21.github.io/statsthinking21-core-site/modeling-categorical-relationships.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 链接：[https://statsthinking21.github.io/statsthinking21-core-site/modeling-categorical-relationships.html](https://statsthinking21.github.io/statsthinking21-core-site/modeling-categorical-relationships.html)
- en: So far we have discussed the general concepts of statistical modeling and hypothesis
    testing, and applied them to some simple analyses; now we will turn to the question
    of how to model particular kinds of relationships in our data. In this chapter
    we will focus on the modeling of *categorical* relationships, by which we mean
    relationships between variables that are measured qualitatively. These data are
    usually expressed in terms of counts; that is, for each value of the variable
    (or combination of values of multiple variables), how many observations take that
    value? For example, when we count how many people from each major are in our class,
    we are fitting a categorical model to the data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了统计建模和假设检验的一般概念，并将它们应用于一些简单的分析；现在我们将转向如何在我们的数据中建模特定类型的关系的问题。在本章中，我们将重点关注*分类*关系的建模，这意味着我们测量的变量之间的关系是定性的。这些数据通常用计数来表示；也就是说，对于变量的每个值（或多个变量的组合的值），有多少观察值取该值？例如，当我们统计我们班上每个专业的人数时，我们正在对数据进行分类建模。
- en: '12.1 Example: Candy colors'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 示例：糖果颜色
- en: 'Let’s say that I have purchased a bag of 100 candies, which are labeled as
    having 1/3 chocolates, 1/3 licorices, and 1/3 gumballs. When I count the candies
    in the bag, we get the following numbers: 30 chocolates, 33 licorices, and 37
    gumballs. Because I like chocolate much more than licorice or gumballs, I feel
    slightly ripped off and I’d like to know if this was just a random accident. To
    answer that question, I need to know: What is the likelihood that the count would
    come out this way if the true probability of each candy type is the averaged proportion
    of 1/3 each?'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我购买了一袋100颗糖果，标有1/3巧克力、1/3甘露和1/3甘露的标签。当我数袋子里的糖果时，我们得到以下数字：30颗巧克力，33颗甘露和37颗甘露。因为我比甘露或甘露更喜欢巧克力，我觉得有点被欺骗，我想知道这是否只是一个偶然事件。为了回答这个问题，我需要知道：如果每种糖果的真实概率是平均比例的1/3，那么计数出现这种情况的可能性是多少？
- en: 12.2 Pearson’s chi-squared test
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 皮尔逊卡方检验
- en: 'The Pearson chi-squared test provides us with a way to test whether a set of
    observed counts differs from some specific expected values that define the null
    hypothesis:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Pearson卡方检验为我们提供了一种测试一组观察计数是否与定义零假设的特定期望值不同的方法：
- en: \[ \chi^2 = \sum_i\frac{(observed_i - expected_i)^2}{expected_i} \]
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: \[ \chi^2 = \sum_i\frac{(observed_i - expected_i)^2}{expected_i} \]
- en: 'In the case of our candy example, the null hypothesis is that the proportion
    of each type of candy is equal. To compute the chi-squared statistic, we first
    need to come up with our expected counts under the null hypothesis: since the
    null is that they are all the same, then this is just the total count split across
    the three categories (as shown in Table [12.1](modeling-categorical-relationships.html#tab:candyDf)).
    We then take the difference between each count and its expectation under the null
    hypothesis, square them, divide them by the null expectation, and add them up
    to obtain the chi-squared statistic.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们糖果的例子中，零假设是每种类型的糖果的比例相等。要计算卡方统计量，我们首先需要在零假设下得出我们的期望计数：因为零假设是它们都相同，那么这只是在三个类别之间分割的总计数（如表[12.1](modeling-categorical-relationships.html#tab:candyDf)所示）。然后我们取每个计数与其在零假设下的期望值之间的差异，对它们进行平方，除以零假设，然后将它们相加以获得卡方统计量。
- en: 'Table 12.1: Observed counts, expectations under the null hypothesis, and squared
    differences in the candy data'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 表12.1：糖果数据中的观察计数、零假设下的期望值和平方差
- en: '| Candy Type | count | nullExpectation | squared difference |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 糖果类型 | 计数 | 零假设 | 平方差 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| chocolate | 30 | 33 | 11.11 |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 巧克力 | 30 | 33 | 11.11 |'
- en: '| licorice | 33 | 33 | 0.11 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 甘露 | 33 | 33 | 0.11 |'
- en: '| gumball | 37 | 33 | 13.44 |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 口香糖 | 37 | 33 | 13.44 |'
- en: The chi-squared statistic for this analysis comes out to 0.74, which on its
    own is not interpretable, since it depends on the number of different values that
    were added together. However, we can take advantage of the fact that the chi-squared
    statistic is distributed according to a specific distribution under the null hypothesis,
    which is known as the *chi-squared* distribution. This distribution is defined
    as the sum of squares of a set of standard normal random variables; it has a number
    of degrees of freedom that is equal to the number of variables being added together.
    The shape of the distribution depends on the number of degrees of freedom. The
    left panel of Figure [12.1](modeling-categorical-relationships.html#fig:chisqDist)
    shows examples of the distribution for several different degrees of freedom.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分析的卡方统计量为0.74，单独来看是无法解释的，因为它取决于被加在一起的不同值的数量。然而，我们可以利用卡方统计量在零假设下分布的事实，这被称为*卡方*分布。该分布被定义为一组标准正态随机变量的平方和；它的自由度数量等于被加在一起的变量的数量。分布的形状取决于自由度的数量。图[12.1](modeling-categorical-relationships.html#fig:chisqDist)的左面板显示了几个不同自由度的分布示例。
- en: '![Left: Examples of the chi-squared distribution for various degrees of freedom.  Right:
    Simulation of sum of squared random normal variables.   The histogram is based
    on the sum of squares of 50,000 sets of 8 random normal variables; the dotted
    line shows the values of the theoretical chi-squared distribution with 8 degrees
    of freedom.](../Images/562cf7fb316215fd27c3ca3fbebe8860.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![左：不同自由度的卡方分布示例。右：随机正态变量平方和的模拟。直方图基于50,000组8个随机正态变量的平方和；虚线显示了具有8个自由度的理论卡方分布的值。](../Images/562cf7fb316215fd27c3ca3fbebe8860.png)'
- en: 'Figure 12.1: Left: Examples of the chi-squared distribution for various degrees
    of freedom. Right: Simulation of sum of squared random normal variables. The histogram
    is based on the sum of squares of 50,000 sets of 8 random normal variables; the
    dotted line shows the values of the theoretical chi-squared distribution with
    8 degrees of freedom.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1：左：不同自由度下卡方分布的示例。右：随机正态变量平方和的模拟。直方图基于50,000组8个随机正态变量的平方和；虚线显示了具有8个自由度的理论卡方分布的值。
- en: Let’s verify that the chi-squared distribution accurately describes the sum
    of squares of a set of standard normal random variables, using simulation. To
    do this, we repeatedly draw sets of 8 random numbers, and add up each set after
    squaring each value. The right panel of Figure [12.1](modeling-categorical-relationships.html#fig:chisqDist)
    shows that the theoretical distribution matches closely with the results of a
    simulation that repeatedly added together the squares of a set of random normal
    variables.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过模拟验证卡方分布是否准确描述了一组标准正态随机变量的平方和，为此，我们反复抽取8个随机数，并在平方每个值后将每组相加。图[12.1](modeling-categorical-relationships.html#fig:chisqDist)的右面板显示，理论分布与重复添加一组随机正态变量的平方的模拟结果非常接近。
- en: For the candy example, we can compute the likelihood of our observed chi-squared
    value of 0.74 under the null hypothesis of equal frequency across all candies.
    We use a chi-squared distribution with degrees of freedom equal to k - 1 (where
    k = the number of categories) since we lost one degree of freedom when we computed
    the mean in order to generate the expected values. The resulting p-value (P(Chi-squared)
    > 0.74 = 0.691) shows that the observed counts of candies are not particularly
    surprising based on the proportions printed on the bag of candy, and we would
    not reject the null hypothesis of equal proportions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于糖果的例子，我们可以计算在所有糖果上频率相等的零假设下观察到的卡方值0.74的可能性。我们使用自由度等于k - 1的卡方分布（其中k = 类别数），因为当我们计算均值以生成期望值时，我们失去了一个自由度。得到的p值（P(Chi-squared)
    > 0.74 = 0.691）显示，根据糖果袋上印刷的比例，观察到的糖果数量并不特别令人惊讶，我们不会拒绝等比例的零假设。
- en: 12.3 Contingency tables and the two-way test
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 列联表和双向检验
- en: Another way that we often use the chi-squared test is to ask whether two categorical
    variables are related to one another. As a more realistic example, let’s take
    the question of whether a Black driver is more likely to be searched when they
    are pulled over by a police officer, compared to a white driver. The Stanford
    Open Policing Project ([https://openpolicing.stanford.edu/](https://openpolicing.stanford.edu/))
    has studied this, and provides data that we can use to analyze the question. We
    will use the data from the State of Connecticut since they are fairly small and
    thus easier to analyze.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常使用卡方检验的另一种方式是询问两个分类变量是否彼此相关。作为更现实的例子，让我们来看看一个问题，即当警察拦下一名司机时，黑人司机是否比白人司机更有可能被搜查。斯坦福开放警务项目([https://openpolicing.stanford.edu/](https://openpolicing.stanford.edu/))对此进行了研究，并提供了我们可以用来分析这个问题的数据。我们将使用康涅狄格州的数据，因为它们相对较小，因此更容易分析。
- en: The standard way to represent data from a categorical analysis is through a
    *contingency table*, which presents the number or proportion of observations falling
    into each possible combination of values for each of the variables. Table [12.2](modeling-categorical-relationships.html#tab:policeCT)
    below shows the contingency table for the police search data. It can also be useful
    to look at the contingency table using proportions rather than raw numbers, since
    they are easier to compare visually, so we include both absolute and relative
    numbers here.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 用*列联表*来表示分类分析数据的标准方法，它展示了每个变量可能组合的观察数量或比例。下面的表[12.2](modeling-categorical-relationships.html#tab:policeCT)显示了警察搜查数据的列联表。使用比例而不是原始数字来查看列联表也是有用的，因为它们在视觉上更容易比较，因此我们在这里包括了绝对和相对数字。
- en: 'Table 12.2: Contingency table for police search data'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 表12.2：警察搜查数据的列联表
- en: '| searched | Black | White | Black (relative) | White (relative) |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| searched | Black | White | Black (relative) | White (relative) |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| FALSE | 36244 | 239241 | 0.13 | 0.86 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| FALSE | 36244 | 239241 | 0.13 | 0.86 |'
- en: '| TRUE | 1219 | 3108 | 0.00 | 0.01 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| TRUE | 1219 | 3108 | 0.00 | 0.01 |'
- en: 'The Pearson chi-squared test allows us to test whether observed frequencies
    are different from expected frequencies, so we need to determine what frequencies
    we would expect in each cell if searches and race were unrelated – which we can
    define as being *independent.* Remember from the chapter on probability that if
    X and Y are independent, then:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 皮尔逊卡方检验允许我们测试观察频率是否与期望频率不同，因此我们需要确定如果搜查和种族无关，即我们可以定义为*独立*，则每个单元格中我们期望的频率是什么。请记住，从概率章节中可以知道，如果X和Y是独立的，那么：
- en: \[ P(X \cap Y) = P(X) * P(Y) \] That is, the joint probability under the null
    hypothesis of independence is simply the product of the *marginal* probabilities
    of each individual variable. The marginal probabilities are simply the probabilities
    of each event occuring regardless of other events. We can compute those marginal
    probabilities, and then multiply them together to get the expected proportions
    under independence.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: \[ P(X \cap Y) = P(X) * P(Y) \] 也就是说，在独立性的零假设下，联合概率简单地是每个单独变量的*边际*概率的乘积。边际概率只是每个事件发生的概率，而不考虑其他事件。我们可以计算这些边际概率，然后将它们相乘以得到独立性下的期望比例。
- en: '|  | Black | White |  |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  | 黑色 | 白色 |  |'
- en: '| --- | --- | --- | --- |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Not searched | P(NS)*P(B) | P(NS)*P(W) | P(NS) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Not searched | P(NS)*P(B) | P(NS)*P(W) | P(NS) |'
- en: '| Searched | P(S)*P(B) | P(S)*P(W) | P(S) |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Searched | P(S)*P(B) | P(S)*P(W) | P(S) |'
- en: '|  | P(B) | P(W) |  |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | P(B) | P(W) |  |'
- en: 'We then compute the chi-squared statistic, which comes out to 828.3. To compute
    a p-value, we need to compare it to the null chi-squared distribution in order
    to determine how extreme our chi-squared value is compared to our expectation
    under the null hypothesis. The degrees of freedom for this distribution are \(df
    = (nRows - 1) * (nColumns - 1)\) - thus, for a 2X2 table like the one here, \(df
    = (2-1)*(2-1)=1\). The intuition here is that computing the expected frequencies
    requires us to use three values: the total number of observations and the marginal
    probability for each of the two variables. Thus, once those values are computed,
    there is only one number that is free to vary, and thus there is one degree of
    freedom. Given this, we can compute the p-value for the chi-squared statistic,
    which is about as close to zero as one can get: \(3.79 \times 10^{-182}\). This
    shows that the observed data would be highly unlikely if there was truly no relationship
    between race and police searches, and thus we should reject the null hypothesis
    of independence.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们计算卡方统计量，结果为828.3。为了计算p值，我们需要将其与零假设下的卡方分布进行比较，以确定我们的卡方值与零假设下的预期相比有多极端。这个分布的自由度是\(df
    = (nRows - 1) * (nColumns - 1)\) - 因此，对于像这里的2X2表，\(df = (2-1)*(2-1)=1\)。直觉在于计算期望频率需要我们使用三个值：观察总数和两个变量的边际概率。因此，一旦这些值被计算出来，就只有一个数字可以自由变化，因此只有一个自由度。鉴于此，我们可以计算卡方统计量的p值，这个p值接近于零：\(3.79
    \times 10^{-182}\)。这表明如果种族和警察搜查真的没有关系，观察到的数据将是非常不可能的，因此我们应该拒绝独立性的零假设。
- en: 'We can also perform this test easily using our statistical software:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用我们的统计软件轻松进行这个测试。
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 12.4 Standardized residuals
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 标准化残差
- en: 'When we find a significant effect with the chi-squared test, this tells us
    that the data are unlikely under the null hypothesis, but it doesn’t tell us *how*
    the data differ. To get a deeper insight into how the data differ from what we
    would expect under the null hypothesis, we can examine the residuals from the
    model, which reflects the deviation of the data (i.e., the observed frequencies)
    from the model (i.e., the expected frequencies) in each cell. Rather than looking
    at the raw residuals (which will vary simply depending on the number of observations
    in the data), it’s more common to look at the *standardized residuals* (sometimes
    called *Pearson residuals*), which are computed as:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在卡方检验中发现显著效应时，这告诉我们数据在零假设下不太可能发生，但它并不告诉我们数据有何不同。为了更深入地了解数据与零假设下的预期有何不同，我们可以检查模型的残差，这反映了数据（即观察频率）与模型（即期望频率）在每个单元格中的偏差。与查看原始残差（这将仅根据数据中的观察次数而变化）不同，更常见的是查看*标准化残差*（有时称为*皮尔逊残差*），计算公式如下：
- en: \[ standardized\ residual_{ij} = \frac{observed_{ij} - expected_{ij}}{\sqrt{expected_{ij}}}
    \] where \(i\) and \(j\) are the indices for the rows and columns respectively.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 标准化残差_{ij} = \frac{观察_{ij} - 期望_{ij}}{\sqrt{期望_{ij}}} \] 其中\(i\)和\(j\)分别是行和列的索引。
- en: Table [12.3](modeling-categorical-relationships.html#tab:stdRes) shows these
    for the police stop data. These standardized residuals can be interpreted as Z
    scores – in this case, we see that the number of searches for Black individuals
    are substantially higher than expected based on independence, and the number of
    searches for white individuals are substantially lower than expected. This provides
    us with the context that we need to interpret the signficant chi-squared result.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 表[12.3](modeling-categorical-relationships.html#tab:stdRes)显示了警察停车数据的标准化残差。这些标准化残差可以解释为Z分数
    - 在这种情况下，我们看到黑人被搜查的次数远远高于独立性预期，而白人被搜查的次数远远低于预期。这为我们提供了解释显著卡方结果所需的背景。
- en: 'Table 12.3: Summary of standardized residuals for police stop data'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 表12.3：警察停车数据的标准化残差总结
- en: '| searched | driver_race | Standardized residuals |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 搜查 | 驾驶员种族 | 标准化残差 |'
- en: '| --- | --- | --- |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| FALSE | Black | -3.3 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| FALSE | 黑人 | -3.3 |'
- en: '| TRUE | Black | 26.6 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| TRUE | 黑人 | 26.6 |'
- en: '| FALSE | White | 1.3 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| FALSE | 白人 | 1.3 |'
- en: '| TRUE | White | -10.4 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| TRUE | 白人 | -10.4 |'
- en: 12.5 Odds ratios
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.5 赔率比
- en: 'We can also represent the relative likelihood of different outcomes in the
    contingency table using the odds ratio that we introduced earlier, in order to
    better understand the magnitude of the effect. First, we represent the odds of
    being stopped for each race, then we compute their ratio:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用我们之前介绍的赔率比来表示列联表中不同结果的相对可能性，以更好地理解效应的大小。首先，我们表示每个种族被停车的赔率，然后计算它们的比率：
- en: \[ odds_{searched|black} = \frac{N_{searched\cap black}}{N_{not\ searched\cap
    black}} = \frac{1219}{36244} = 0.034 \]
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 赔率_{黑人被搜查} = \frac{N_{黑人被搜查}}{N_{黑人未被搜查}} = \frac{1219}{36244} = 0.034 \]
- en: \[ odds_{searched|white} = \frac{N_{searched\cap white}}{N_{not\ searched\cap
    white}} = \frac{3108}{239241} = 0.013 \] \[ odds\ ratio = \frac{odds_{searched|black}}{odds_{searched|white}}
    = 2.59 \]
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: \[ 赔率_{白人被搜查} = \frac{N_{白人被搜查}}{N_{白人未被搜查}} = \frac{3108}{239241} = 0.013 \]
    \[ 赔率\ 比 = \frac{赔率_{黑人被搜查}}{赔率_{白人被搜查}} = 2.59 \]
- en: The odds ratio shows that the odds of being searched are 2.59 times higher for
    Black versus white drivers, based on this dataset.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 赔率比显示，根据这个数据集，黑人被搜查的赔率是白人的2.59倍。
- en: 12.6 Bayes factor
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.6 贝叶斯因子
- en: 'We discussed Bayes factors in the earlier chapter on Bayesian statistics –
    you may remember that it represents the ratio of the likelihood of the data under
    each of the two hypotheses: \[ K = \frac{P(data|H_A)}{P(data|H_0)} = \frac{P(H_A|data)*P(H_A)}{P(H_0|data)*P(H_0)}
    \] We can compute the Bayes factor for the police search data using our statistical
    software:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在之前关于贝叶斯统计的章节中讨论了贝叶斯因子 - 你可能还记得它代表了数据在两个假设下的可能性比：\[ K = \frac{P(data|H_A)}{P(data|H_0)}
    = \frac{P(H_A|data)*P(H_A)}{P(H_0|data)*P(H_0)} \] 我们可以使用我们的统计软件计算警察搜查数据的贝叶斯因子：
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This shows that the evidence in favor of a relationship between driver race
    and police searches in this dataset is exceedingly strong — \(1.8 * 10^{142}\)
    is about as close to infinity as we can imagine getting in statistics.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明在这个数据集中，关于驾驶员种族和警察搜查之间关系的证据非常强大——\(1.8 * 10^{142}\)接近无穷大，这在统计学中是我们能想象到的最接近无穷大的了。
- en: 12.7 Categorical analysis beyond the 2 X 2 table
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.7超过2X2表的分类分析
- en: Categorical analysis can also be applied to contingency tables where there are
    more than two categories for each variable.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 分类分析也可以应用于列联表，其中每个变量有两个以上的类别。
- en: For example, let’s look at the NHANES data and compare the variable *Depressed*
    which denotes the “self-reported number of days where the participant felt down,
    depressed or hopeless”. This variable is coded as `None`, `Several`, or `Most`.
    Let’s test whether this variable is related to the *SleepTrouble* variable which
    denotes whether the individual has reported sleeping problems to a doctor.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们看看NHANES数据，并比较变量*Depressed*，它表示“参与者感到沮丧、抑郁或绝望的天数”。这个变量编码为`None`、`Several`或`Most`。让我们测试一下这个变量是否与*SleepTrouble*变量相关，后者表示个体是否向医生报告了睡眠问题。
- en: 'Table 12.4: Relationship between depression and sleep problems in the NHANES
    dataset'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 12.4表：NHANES数据集中抑郁和睡眠问题之间的关系
- en: '| Depressed | NoSleepTrouble | YesSleepTrouble |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Depressed | NoSleepTrouble | YesSleepTrouble |'
- en: '| --- | --- | --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| None | 2614 | 676 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| None | 2614 | 676 |'
- en: '| Several | 418 | 249 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| Several | 418 | 249 |'
- en: '| Most | 138 | 145 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| Most | 138 | 145 |'
- en: 'Simply by looking at these data, we can tell that it is likely that there is
    a relationship between the two variables; notably, while the total number of people
    with sleep trouble is much less than those without, for people who report being
    depresssed most days the number with sleep problems is greater than those without.
    We can quantify this directly using the chi-squared test:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅通过观察这些数据，我们就可以得知这两个变量之间可能存在关系；值得注意的是，尽管有睡眠问题的人数远少于没有睡眠问题的人数，但对于报告大部分时间感到抑郁的人来说，有睡眠问题的人数大于没有睡眠问题的人数。我们可以直接使用卡方检验来量化这一点：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This test shows that there is a strong relationship between depression and
    sleep trouble. We can also compute the Bayes factor to quantify the strength of
    the evidence in favor of the alternative hypothesis:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个检验表明抑郁和睡眠问题之间存在着强烈的关系。我们还可以计算贝叶斯因子来量化支持备择假设的证据的强度：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here we see that the Bayes factor is very large (\(1.8 * 10^{35}\)), showing
    that the evidence in favor of a relation between depression and sleep problems
    is very strong.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到贝叶斯因子非常大（\(1.8 * 10^{35}\)），表明抑郁和睡眠问题之间的关系证据非常强大。
- en: 12.8 Beware of Simpson’s paradox
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.8小心辛普森悖论
- en: 'The contingency tables presented above represent summaries of large numbers
    of observations, but summaries can sometimes be misleading. Let’s take an example
    from baseball. The table below shows the batting data (hits/at bats and batting
    average) for Derek Jeter and David Justice over the years 1995-1997:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 上面呈现的列联表代表了大量观察结果的总结，但总结有时可能会产生误导。让我们以棒球为例。下表显示了1995-1997年间Derek Jeter和David
    Justice的击球数据（安打/打数和击球平均率）：
- en: '| Player | 1995 |  | 1996 |  | 1997 |  | Combined |  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Player | 1995 |  | 1996 |  | 1997 |  | Combined |  |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Derek Jeter | 12/48 | .250 | 183/582 | .314 | 190/654 | .291 | 385/1284 |
    **.300** |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Derek Jeter | 12/48 | .250 | 183/582 | .314 | 190/654 | .291 | 385/1284 |
    **.300** |'
- en: '| David Justice | 104/411 | **.253** | 45/140 | **.321** | 163/495 | **.329**
    | 312/1046 | .298 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| David Justice | 104/411 | **.253** | 45/140 | **.321** | 163/495 | **.329**
    | 312/1046 | .298 |'
- en: 'If you look closely, you will see that something odd is going on: In each individual
    year Justice had a higher batting average than Jeter, but when we combine the
    data across all three years, Jeter’s average is actually higher than Justice’s!
    This is an example of a phenomenon known as *Simpson’s paradox*, in which a pattern
    that is present in a combined dataset may not be present in any of the subsets
    of the data. This occurs when there is another variable that may be changing across
    the different subsets – in this case, the number of at-bats varies across years,
    with Justice batting many more times in 1995 (when batting averages were low).
    We refer to this as a *lurking variable*, and it’s always important to be attentive
    to such variables whenever one examines categorical data.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察，你会发现有些奇怪的事情发生了：在每个单独的年份里，贾斯蒂斯的击球平均率都高于杰特，但当我们将所有三年的数据合并时，杰特的平均率实际上高于贾斯蒂斯的！这是辛普森悖论的一个例子，即在合并数据集中存在的模式可能在数据子集中不存在。这是因为在不同的子集中可能有另一个变量在变化——在这种情况下，打数在不同年份中变化，贾斯蒂斯在1995年击球次数更多（当时击球平均率较低）。我们称之为*潜在变量*，在检验分类数据时，始终要注意这些变量是非常重要的。
- en: 12.9 Learning objectives
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.9学习目标
- en: Describe the concept of a contingency table for categorical data.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述分类数据的列联表概念。
- en: Describe the concept of the chi-squared test for association and compute it
    for a given contingency table.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述卡方检验的关联概念，并为给定的列联表计算它。
- en: Describe Simpson’s paradox and why it is important for categorical data analysis.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述辛普森悖论及其对分类数据分析的重要性。
- en: 12.10 Additional readings
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.10额外阅读
- en: '[Simpson’s paradox in psychological science: a practical guide](https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00513/full)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[心理科学中的辛普森悖论：实用指南](https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00513/full)'
