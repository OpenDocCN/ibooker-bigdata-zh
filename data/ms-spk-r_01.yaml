- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: In a world where information is growing exponentially, leading tools like Apache
    Spark provide support to solve many of the relevant problems we face today. From
    companies looking for ways to improve based on data-driven decisions, to research
    organizations solving problems in health care, finance, education, and energy,
    Spark enables analyzing much more information faster and more reliably than ever
    before.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息呈指数级增长的世界中，领先的工具如Apache Spark提供支持，以解决今天我们面临的许多相关问题。从寻求基于数据驱动决策改进的公司，到在健康保健、金融、教育和能源领域解决问题的研究机构，Spark使得分析更多信息比以往任何时候更快速、更可靠地实现。
- en: 'Various books have been written for learning Apache Spark; for instance, [*Spark:
    The Definitive Guide*](https://oreil.ly/gMaGP) is a comprehensive resource, and
    [*Learning Spark*](https://oreil.ly/1-4CA) is an introductory book meant to help
    users get up and running (both are from O’Reilly). However, as of this writing,
    there is neither a book to learn Apache Spark using the R computing language nor
    a book specifically designed for the R user or the aspiring R user.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '已经有各种书籍写作用于学习Apache Spark；例如，[*Spark: The Definitive Guide*](https://oreil.ly/gMaGP)是一个全面的资源，而[*Learning
    Spark*](https://oreil.ly/1-4CA)则是一本入门书籍，旨在帮助用户快速上手（均出自O’Reilly）。然而，截至目前，尚无一本专门用于学习使用R语言进行Apache
    Spark的书籍，也没有专门为R用户或有意成为R用户的人设计的书籍。'
- en: There are some resources online to learn Apache Spark with R, most notably the
    [spark.rstudio.com](https://spark.rstudio.com) site and the Spark documentation
    site at [spark.apache.org](http://bit.ly/31H2nMl). Both sites are great online
    resources; however, the content is not intended to be read from start to finish
    and assumes you, the reader, have some knowledge of Apache Spark, R, and cluster
    computing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些在线资源可供学习使用R语言学习Apache Spark，尤其是[spark.rstudio.com](https://spark.rstudio.com)网站和Spark文档网站在[spark.apache.org](http://bit.ly/31H2nMl)。这两个网站都是很好的在线资源；然而，内容并不打算从头到尾阅读，并假定您作为读者对Apache
    Spark、R和集群计算有一定的了解。
- en: The goal of this book is to help anyone get started with Apache Spark using
    R. Additionally, because the R programming language was created to simplify data
    analysis, it is also our belief that this book provides the easiest path for you
    to learn the tools used to solve data analysis problems with Spark. The first
    chapters provide an introduction to help anyone get up to speed with these concepts
    and present the tools required to work on these problems on your own computer.
    We then quickly ramp up to relevant data science topics, cluster computing, and
    advanced topics that should interest even the most experienced users.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是帮助任何人开始使用R语言进行Apache Spark的学习。另外，由于R编程语言的创建是为了简化数据分析，我们相信本书为您提供了学习使用Spark解决数据分析问题的最简单途径。前几章提供了一个介绍，帮助任何人快速掌握这些概念，并介绍在您自己的计算机上处理这些问题所需的工具。然后我们迅速进入相关的数据科学主题、集群计算和即使对经验丰富的用户也感兴趣的高级主题。
- en: Therefore, this book is intended to be a useful resource for a wide range of
    users, from beginners curious to learn Apache Spark, to experienced readers seeking
    to understand why and how to use Apache Spark from R.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本书旨在成为广泛用户群的有用资源，从初学者对学习Apache Spark感兴趣，到有经验的读者希望了解为什么以及如何从R语言使用Apache Spark。
- en: 'This book has the following general outline:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的一般概述如下：
- en: Introduction
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍
- en: In the first two chapters, [Chapter 1, *Introduction*](ch01.html#intro), and
    [Chapter 2, *Getting Started*](ch02.html#starting), you learn about Apache Spark,
    R and the tools to perform data analysis with Spark and R.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两章中，[第1章，*介绍*](ch01.html#intro)，和[第2章，*入门*](ch02.html#starting)，您将了解Apache
    Spark、R语言以及使用Spark和R进行数据分析的工具。
- en: Analysis
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 分析
- en: In [Chapter 3, *Analysis*](ch03.html#analysis), you learn how to analyze, explore,
    transform, and visualize data in Apache Spark with R.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章，*分析*](ch03.html#analysis)中，您将学习如何使用R语言在Apache Spark中分析、探索、转换和可视化数据。
- en: Modeling
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 建模
- en: In the [Chapter 4, *Modeling*](ch04.html#modeling) and [Chapter 5, *Pipelines*](ch05.html#pipelines),
    you learn how to create statistical models with the purpose of extracting information,
    predicticting outcomes, and automating this process in production-ready workflows.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章，*建模*](ch04.html#modeling)和[第5章，*管道*](ch05.html#pipelines)中，您将学习如何创建统计模型，目的是提取信息、预测结果，并在生产准备好的工作流程中自动化此过程。
- en: Scaling
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展
- en: Up to this point, the book has focused on performing operations on your personal
    computer and with limited data formats. [Chapter 6, *Clusters*](ch06.html#clusters),
    [Chapter 7, *Connections*](ch07.html#connections), [Chapter 8, *Data*](ch08.html#data),
    and [Chapter 9, *Tuning*](ch09.html#tuning), introduce distributed computing techniques
    required to perform analysis and modeling across many machines and data formats
    to tackle the large-scale data and computation problems for which Apache Spark
    was designed.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，本书集中讨论了在个人计算机上执行操作以及使用有限数据格式。[第 6 章，*集群*](ch06.html#clusters)，[第 7 章，*连接*](ch07.html#connections)，[第
    8 章，*数据*](ch08.html#data) 和 [第 9 章，*调整*](ch09.html#tuning)，介绍了分布式计算技术，这些技术用于跨多台机器和数据格式执行分析和建模，以解决
    Apache Spark 设计用于处理的大规模数据和计算问题。
- en: Extensions
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展
- en: '[Chapter 10, *Extensions*](ch10.html#extensions), describes optional components
    and extended functionality applicable to specific, relevant use cases. You learn
    about alternative modeling frameworks, graph processing, preprocessing data for
    deep learning, geospatial analysis, and genomics at scale.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 10 章，*扩展*](ch10.html#extensions)，描述了特定相关用例适用的可选组件和扩展功能。您将了解替代建模框架、图处理、深度学习预处理数据、地理空间分析和大规模基因组学。'
- en: Advanced
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 高级
- en: The book closes with a set of advanced chapters, [Chapter 11, *Distributed R*](ch11.html#distributed),
    [Chapter 12, *Streaming*](ch12.html#streaming), and [Chapter 13, *Contributing*](ch13.html#contributing);
    these will be of greatest interest to advanced users. However, by the time you
    reach this section, the content won’t seem as intimidating; instead, these chapters
    will be equally relevant, useful, and interesting as the previous ones.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本书以一组高级章节结束，[第 11 章，*分布式 R*](ch11.html#distributed)，[第 12 章，*流处理*](ch12.html#streaming)
    和 [第 13 章，*贡献*](ch13.html#contributing)；这些章节对高级用户最感兴趣。然而，当您到达本节时，内容不会显得那么令人生畏；相反，这些章节与前面的章节一样相关、有用和有趣。
- en: 'The first group of chapters, [1](ch01.html#intro)–[5](ch05.html#pipelines),
    provides a gentle introduction to performing data science and machine learning
    at scale. If you are planning to read this book while also following along with
    code examples, these are great chapters to consider executing the code line by
    line. Because these chapters teach all of the concepts using your personal computer,
    you won’t be taking advantage of multiple computers, which Spark was designed
    to use. But worry not: the next set of chapters will teach this in detail!'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第一组章节，[第 1 章](ch01.html#intro)–[第 5 章](ch05.html#pipelines)，提供了在规模化数据科学和机器学习上执行温和介绍。如果您计划在阅读本书的同时按照代码示例进行操作，那么这些章节是考虑逐行执行代码的好选择。因为这些章节使用您的个人计算机教授所有概念，所以您不会利用
    Spark 被设计用于使用的多台计算机。但不要担心：接下来的章节将详细教授这一点！
- en: The second group of chapters, [6](ch06.html#clusters)–[9](ch09.html#tuning),
    introduces fundamental concepts in the exciting world of cluster computing using
    Spark. To be honest, they also introduce some of the not-so-fun parts of cluster
    computing, but believe us, it’s worth learning the concepts we present. Besides,
    the overview sections in each chapter are especially interesting, informative,
    and easy to read, and help you develop intuitions as to how cluster computing
    truly works. For these chapters, we actually don’t recommend executing the code
    line by line—especially not if you are trying to learn Spark from start to finish.
    You can always come back and execute code after you have a proper Spark cluster.
    If you already have a cluster at work or you are really motivated to get one,
    however, you might want to use [Chapter 6](ch06.html#clusters) to pick one and
    then [Chapter 7](ch07.html#connections) to connect to it.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第二组章节，[第 6 章](ch06.html#clusters)–[第 9 章](ch09.html#tuning)，介绍了在使用 Spark 进行集群计算的令人兴奋的世界中的基本概念。说实话，它们也介绍了集群计算中一些不那么有趣的部分，但请相信我们，学习我们提出的概念是值得的。此外，每章的概述部分特别有趣、信息丰富且易于阅读，有助于您对集群计算的工作原理形成直观的理解。对于这些章节，我们实际上不建议逐行执行代码——特别是如果您试图从头到尾学习
    Spark。在您拥有适当的 Spark 集群之后，您随时可以回来执行代码。然而，如果您在工作中已经有了一个集群，或者您真的很有动力想要得到一个集群，您可能希望使用
    [第 6 章](ch06.html#clusters) 来选择一个，然后使用 [第 7 章](ch07.html#connections) 连接到它。
- en: The third group of chapters, [10](ch10.html#extensions)–[13](ch13.html#contributing),
    presents tools that should be quite interesting to most readers and will make
    it easier to follow along. Many advanced topics are presented, and it is natural
    to be more interested in some topics than others; for instance, you might be interested
    in analyzing geographic datasets, or perhaps you’re more interested in processing
    real-time datasets, or maybe you’d like to do both! Based on your personal interests
    or problems at hand, we encourage you to execute the code examples that are most
    relevant to you. All of the code in these chapters is written to be executed on
    your personal computer, but you are also encouraged to use proper Spark clusters
    given that you’ll have the tools required to troubleshoot issues and tune large-scale
    computations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第三组章节，[10](ch10.html#extensions)–[13](ch13.html#contributing)，介绍了对大多数读者都很有趣的工具，将有助于更好地跟踪内容。这些章节涵盖了许多高级主题，自然而然地，你可能对某些主题更感兴趣；例如，你可能对分析地理数据集感兴趣，或者你可能更喜欢处理实时数据集，甚至两者兼顾！根据你的个人兴趣或手头的问题，我们鼓励你执行最相关的代码示例。这些章节中的所有代码都是为了在你的个人计算机上执行而编写的，但是我们也鼓励你使用适当的
    Spark 集群，因为你将拥有解决问题和调优大规模计算所需的工具。
- en: Formatting
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 格式化
- en: 'Tables generated from code are formatted as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从代码生成的表格的格式如下：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The dimensions of the table (number of rows and columns) are described in the
    first row, followed by column names in the second row and column types in the
    third row. There are also various subtle visual improvements provided by the `tibble`
    package that we make use of throughout this book.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 表格的尺寸（行数和列数）在第一行描述，接着是第二行的列名和第三行的列类型。此外，我们在整本书中还使用了 `tibble` 包提供的各种微小视觉改进。
- en: Most plots are rendered using the `ggplot2` package and a custom theme available
    in the appendix; however, because this book is not focused on data visualization,
    we only provide code to render a basic plot that won’t match the formatting we
    applied. If you are interested in learning more about visualization in R, consider
    specialized books like [*R Graphics Cookbook*](https://oreil.ly/bIF4l) (O’Reilly).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数图表使用 `ggplot2` 包及附录中提供的自定义主题进行渲染；然而，由于本书不侧重数据可视化，我们仅提供了一个基本绘图的代码，可能与我们应用的格式不符合。如果你有兴趣学习更多关于
    R 中可视化的内容，可以考虑专门的书籍，比如 [*R Graphics Cookbook*](https://oreil.ly/bIF4l)（O'Reilly）。
- en: Acknowledgments
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: 'We thank the package authors that enabled Spark with R: Javier Luraschi, Kevin
    Kuo, Kevin Ushey, and JJ Allaire (`sparklyr`); Romain François and Hadley Wickham
    (`dbplyr`); Hadley Wickham and Edgar Ruiz (`dpblyr`); Kirill Mülller (`DBI`);
    and the authors of the Apache Spark project itself, and its original author Matei
    Zaharia.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢使 Spark 与 R 集成的包作者们：Javier Luraschi、Kevin Kuo、Kevin Ushey 和 JJ Allaire（`sparklyr`）；Romain
    François 和 Hadley Wickham（`dbplyr`）；Hadley Wickham 和 Edgar Ruiz（`dpblyr`）；Kirill
    Mülller（`DBI`）；以及 Apache Spark 项目本身的作者及其原始作者 Matei Zaharia。
- en: 'We thank the package authors that released extensions to enrich the Spark and
    R ecosystem: Akhil Nair (`crassy`); Harry Zhu (`geospark`); Kevin Kuo (`graphframes`,
    `mleap`, `sparktf`, and `sparkxgb`); Jakub Hava, Navdeep Gill, Erin LeDell, and
    Michal Malohlava (`rsparkling`); Jan Wijffels (`spark.sas7bdat`); Aki Ariga (`sparkavro`);
    Martin Studer (`sparkbq`); Matt Pollock (`sparklyr.nested`); Nathan Eastwood (`sparkts`);
    and Samuel Macêdo (`variantspark`).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢那些发布扩展以丰富 Spark 和 R 生态系统的包作者们：Akhil Nair（`crassy`）；Harry Zhu（`geospark`）；Kevin
    Kuo（`graphframes`、`mleap`、`sparktf` 和 `sparkxgb`）；Jakub Hava、Navdeep Gill、Erin
    LeDell 和 Michal Malohlava（`rsparkling`）；Jan Wijffels（`spark.sas7bdat`）；Aki Ariga（`sparkavro`）；Martin
    Studer（`sparkbq`）；Matt Pollock（`sparklyr.nested`）；Nathan Eastwood（`sparkts`）；以及
    Samuel Macêdo（`variantspark`）。
- en: We thank our wonderful editor, Melissa Potter, for providing us with guidance,
    encouragement, and countless hours of detailed feedback to make this book the
    best we could have ever written.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢我们出色的编辑 Melissa Potter，她为我们提供了指导、鼓励和无数小时的详细反馈，使这本书成为我们能够写出的最好的作品。
- en: To Bradley Boehmke, Bryan Adams, Bryan Jonas, Dusty Turner, and Hossein Falaki,
    we thank you for your technical reviews, time, and candid feedback, and for sharing
    your expertise with us. Many readers will have a much more pleasant experience
    thanks to you.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 致谢 Bradley Boehmke、Bryan Adams、Bryan Jonas、Dusty Turner 和 Hossein Falaki，感谢你们的技术审查、时间和坦诚反馈，以及与我们分享专业知识。多亏了你们，许多读者将会有更愉快的阅读体验。
- en: Thanks to RStudio, JJ Allaire, and Tareef Kawaf for supporting this work, and
    the R community itself for its continuous support and encouragement.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢RStudio、JJ Allaire和Tareef Kawaf支持这项工作，以及R社区本身对其持续的支持和鼓励。
- en: 'Max Kuhn, thank you for your invaluable feedback on [Chapter 4](ch04.html#modeling),
    in which, with his permission, we adapted examples from his wonderful book *Feature
    Engineering and Selection: A Practical Approach for Predictive Models* (CRC Press).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 'Max Kuhn，感谢您在[第4章](ch04.html#modeling)中对模型的宝贵反馈，我们在此章节中经过他的允许，从他精彩的书籍*Feature
    Engineering and Selection: A Practical Approach for Predictive Models*（CRC Press）中改编了示例。'
- en: We also thank everyone indirectly involved but not explicitly listed in this
    section; we are truly standing on the shoulders of giants.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也要感谢那些间接参与但未在本节明确列出的每个人；我们确实站在巨人的肩膀上。
- en: This book itself was written in R using `bookdown` by Yihui Xie, `rmarkdown`
    by JJ Allaire and Yihui Xie, and `knitr` by Yihui Xie; we drew the visualizations
    using `ggplot2` by Hadley Wickham and Winston Chang; we created the diagrams using
    `nomnoml` by Daniel Kallin and Javier Luraschi; and we did the document conversions
    using `pandoc` by John MacFarlane.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本书本身是使用`bookdown`（由谢益辉开发）、`rmarkdown`（由JJ Allaire和谢益辉开发）以及`knitr`（由谢益辉开发）编写的，我们使用`ggplot2`（由Hadley
    Wickham和Winston Chang开发）绘制了可视化，使用`nomnoml`（由Daniel Kallin和Javier Luraschi开发）创建了图表，并使用`pandoc`（由John
    MacFarlane开发）进行了文档转换。
- en: Conventions Used in This Book
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书使用的约定
- en: 'The following typographical conventions are used in this book:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用了以下排版约定：
- en: '*Italic*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*斜体*'
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 表示新术语、URL、电子邮件地址、文件名和文件扩展名。
- en: '`Constant width`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`等宽`'
- en: Used for program listings as well as within paragraphs to refer to program elements
    such as variable or function names, databases, data types, environment variables,
    statements, and keywords.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 用于程序清单以及段落内引用程序元素，例如变量或函数名、数据库、数据类型、环境变量、语句和关键字。
- en: '**`Constant width bold`**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**`等宽粗体`**'
- en: Shows commands or other text that should be typed literally by the user.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 显示用户应按原样输入的命令或其他文本。
- en: '*`Constant width italic`*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*`等宽斜体`*'
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应替换为用户提供值或由上下文确定值的文本。
- en: Tip
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This element signifies a tip or suggestion.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示提示或建议。
- en: Note
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This element signifies a general note.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示一般说明。
- en: Using Code Examples
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用代码示例
- en: Supplemental material (code examples, exercises, etc.) is available for download
    at [*https://github.com/r-spark/the-r-in-spark*]( https://github.com/r-spark/the-r-in-spark).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 补充材料（代码示例、练习等）可从[*https://github.com/r-spark/the-r-in-spark*]( https://github.com/r-spark/the-r-in-spark)下载。
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing a CD-ROM
    of examples from O’Reilly books does require permission. Answering a question
    by citing this book and quoting example code does not require permission. Incorporating
    a significant amount of example code from this book into your product’s documentation
    does require permission.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在帮助您完成工作。一般情况下，如果本书提供了示例代码，您可以在您的程序和文档中使用它。除非您要复制代码的大部分，否则无需征得我们的许可。例如，编写一个使用本书多个代码块的程序不需要许可。售卖或分发包含O’Reilly书籍示例的CD-ROM则需要许可。引用本书并引述示例代码以回答问题也不需要许可。将本书中大量示例代码整合到产品文档中则需要许可。
- en: 'We appreciate, but do not require, attribution. An attribution usually includes
    the title, author, publisher, and ISBN. For example: “*Mastering Spark with R*
    by Javier Luraschi, Kevin Kuo, and Edgar Ruiz (O’Reilly). Copyright 2020 Javier
    Luraschi, Kevin Kuo, and Edgar Ruiz, 978-1-492-04637-0.”'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢，但不要求署名。署名通常包括书名、作者、出版商和ISBN。例如：“*Mastering Spark with R* by Javier Luraschi,
    Kevin Kuo, and Edgar Ruiz (O’Reilly). Copyright 2020 Javier Luraschi, Kevin Kuo,
    and Edgar Ruiz, 978-1-492-04637-0.”
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您认为您对代码示例的使用超出了合理使用范围或上述许可的限制，请随时通过[*permissions@oreilly.com*](mailto:permissions@oreilly.com)联系我们。
- en: O’Reilly Online Learning
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O’Reilly在线学习
- en: Note
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For almost 40 years, [*O’Reilly Media*](http://oreilly.com) has provided technology
    and business training, knowledge, and insight to help companies succeed.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 近40年来，[*O’Reilly Media*](http://oreilly.com)一直致力于为公司提供技术和商业培训、知识和见解，帮助它们取得成功。
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, conferences, and our online learning platform. O’Reilly’s
    online learning platform gives you on-demand access to live training courses,
    in-depth learning paths, interactive coding environments, and a vast collection
    of text and video from O’Reilly and 200+ other publishers. For more information,
    please visit [*http://oreilly.com*](http://oreilly.com).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过图书、文章、会议和我们的在线学习平台分享他们的知识和专业知识。O’Reilly的在线学习平台让您随时访问现场培训课程、深度学习路径、交互式编码环境以及来自O’Reilly和其他200多家出版商的大量文本和视频。欲了解更多信息，请访问[*http://oreilly.com*](http://oreilly.com)。
- en: How to Contact Us
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 请将有关本书的评论和问题发送至出版商：
- en: O’Reilly Media, Inc.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O’Reilly Media，Inc.
- en: 1005 Gravenstein Highway North
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gravenstein Highway North，1005号
- en: Sebastopol, CA 95472
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加利福尼亚州，Sebastopol，95472
- en: 800-998-9938 (in the United States or Canada)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-998-9938（美国或加拿大）
- en: 707-829-0515 (international or local)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0515（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/SparkwithR*](https://oreil.ly/SparkwithR).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为本书设有网页，列出勘误、示例和任何额外信息。您可以访问此页面[*https://oreil.ly/SparkwithR*](https://oreil.ly/SparkwithR)。
- en: To comment or ask technical questions about this book, send email to [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要就本书发表评论或提出技术问题，请发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)。
- en: For more information about our books, courses, conferences, and news, see our
    website at [*http://www.oreilly.com*](http://www.oreilly.com).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们的图书、课程、会议和新闻的更多信息，请访问我们的网站[*http://www.oreilly.com*](http://www.oreilly.com)。
- en: 'Find us on Facebook: [*http://facebook.com/oreilly*](http://facebook.com/oreilly)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在Facebook上找到我们：[*http://facebook.com/oreilly*](http://facebook.com/oreilly)
- en: 'Follow us on Twitter: [*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在Twitter上关注我们：[*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)
- en: 'Watch us on YouTube: [*http://www.youtube.com/oreillymedia*](http://www.youtube.com/oreillymedia)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在YouTube上关注我们：[*http://www.youtube.com/oreillymedia*](http://www.youtube.com/oreillymedia)
