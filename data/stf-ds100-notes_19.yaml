- en: 18  Estimators, Bias, and Variance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 18  估计器、偏差和方差
- en: 原文：[https://ds100.org/course-notes/probability_2/probability_2.html](https://ds100.org/course-notes/probability_2/probability_2.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://ds100.org/course-notes/probability_2/probability_2.html](https://ds100.org/course-notes/probability_2/probability_2.html)'
- en: '*Learning Outcomes* ***   Explore commonly seen random variables like Bernoulli
    and Binomial distributions'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*学习成果* ***   探索常见的随机变量，如伯努利和二项式分布'
- en: Apply the Central Limit Theorem to approximate parameters of a population
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用中心极限定理来近似总体参数
- en: Use sampled data to model an estimation of and infer the true underlying distribution
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用抽样数据对真实的潜在分布进行建模估计
- en: 'Estimate the true population distribution from a sample using the bootstrapping
    technique**  **Last time, we introduced the idea of random variables: numerical
    functions of a sample. Most of our work in the last lecture was done to build
    a background in probability and statistics. Now that we’ve established some key
    ideas, we’re in a good place to apply what we’ve learned to our original goal
    – understanding how the randomness of a sample impacts the model design process.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自助法技术从样本中估计真实总体分布**  **上次，我们介绍了随机变量的概念：样本的数值函数。在上一讲中，我们的大部分工作是建立概率和统计学的背景。现在我们已经建立了一些关键的思想，我们可以将我们学到的知识应用到我们最初的目标上
    - 理解样本的随机性如何影响模型设计过程。
- en: In this lecture, we will delve more deeply into the idea of fitting a model
    to a sample. We’ll explore how to re-express our modeling process in terms of
    random variables and use this new understanding to steer model complexity.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本讲座中，我们将更深入地探讨将模型拟合到样本的想法。我们将探讨如何用随机变量重新表达我们的建模过程，并利用这种新的理解来引导模型的复杂性。
- en: 18.1 Common Random Variables
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 18.1 常见随机变量
- en: 'There are several cases of random variables that appear often and have useful
    properties. Below are the ones we will explore further in this course. The numbers
    in parentheses are the parameters of a random variable, which are constants. Parameters
    define a random variable’s shape (i.e., distribution) and its values. For this
    lecture, we’ll focus more heavily on the bolded random variables and their special
    properties, but you should familiarize yourself with all the ones listed below:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种经常出现并且具有有用特性的随机变量情况。以下是我们将在本课程中进一步探讨的情况。括号中的数字是随机变量的参数，这些参数是常数。参数定义了随机变量的形状（即分布）和其值。在本讲座中，我们将更加重点关注加粗的随机变量及其特殊性质，但你应该熟悉下面列出的所有随机变量：
- en: '**Bernoulli(p)**'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伯努利(p)**'
- en: Takes on value 1 with probability p, and 0 with probability 1 - p.
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以概率p取值1，以概率1-p取值0。
- en: AKA the “indicator” random variable.
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 又称“指示”随机变量。
- en: Let X be a Bernoulli(p) random variable
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设X是一个伯努利(p)随机变量
- en: \(\mathbb{E}[X] = 1 * p + 0 * (1-p) = p\)
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{E}[X] = 1 * p + 0 * (1-p) = p\)
- en: \(\mathbb{E}[X^2] = 1^2 * p + 0 * (1-p) = p\)
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{E}[X^2] = 1^2 * p + 0 * (1-p) = p\)
- en: \(\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2 = p - p^2 = p(1-p)\)
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2 = p - p^2 = p(1-p)\)
- en: '**Binomial(n, p)**'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二项式(n, p)**'
- en: Number of 1s in \(n\) independent Bernoulli(p) trials.
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(n\) 独立伯努利(p)试验中的1的数量。
- en: Let \(Y\) be a Binomial(n, p) random variable.
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设\(Y\)是一个二项式(n, p)随机变量。
- en: 'The distribution of \(Y\) is given by the binomial formula, and we can write
    \(Y = \sum_{i=1}^n X_i\) where:'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(Y\)的分布由二项式公式给出，我们可以写成\(Y = \sum_{i=1}^n X_i\)，其中：
- en: \(X_i\) s the indicator of success on trial i. \(X_i = 1\) if trial i is a success,
    else 0.
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(X_i\)是第\(i\)次试验成功的指示。如果第\(i\)次试验成功，则\(X_i = 1\)，否则为0。
- en: All \(X_i\) are i.i.d. and Bernoulli(p).
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有的\(X_i\)都是独立同分布的伯努利(p)。
- en: \(\mathbb{E}[Y] = \sum_{i=1}^n \mathbb{E}[X_i] = np\)
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\mathbb{E}[Y] = \sum_{i=1}^n \mathbb{E}[X_i] = np\)
- en: \(\text{Var}(X) = \sum_{i=1}^n \text{Var}(X_i) = np(1-p)\)
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(\text{Var}(X) = \sum_{i=1}^n \text{Var}(X_i) = np(1-p)\)
- en: \(X_i\)’s are independent, so \(\text{Cov}(X_i, X_j) = 0\) for all i, j.
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(X_i\)是独立的，所以对于所有的i, j，\(\text{Cov}(X_i, X_j) = 0\)。
- en: Uniform on a finite set of values
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有限值集上均匀分布
- en: Probability of each value is 1 / (number of possible values).
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个值的概率是1 / (可能的值的数量)。
- en: For example, a standard/fair die.
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，一个标准/公平的骰子。
- en: Uniform on the unit interval (0, 1)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单位区间(0, 1)上均匀分布
- en: Density is flat at 1 on (0, 1) and 0 elsewhere.
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密度在(0, 1)上为1，在其他地方为0。
- en: Normal(\(\mu, \sigma^2\))
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正态(\(\mu, \sigma^2\))
- en: \(f(x) = \frac{1}{\sigma\sqrt{2\pi}} \exp\left( -\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{\!2}\,\right)\)
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: \(f(x) = \frac{1}{\sigma\sqrt{2\pi}} \exp\left( -\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{\!2}\,\right)\)
- en: 18.1.1 Example
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.1.1 例子
- en: Suppose you win cash based on the number of heads you get in a series of 20
    coin flips. Let \(X_i = 1\) if the \(i\)-th coin is heads, 0 otherwise. Which
    payout strategy would you choose?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你根据20次抛硬币中得到的正面数量赢得现金。如果第\(i\)次抛硬币得到正面，则令\(X_i = 1\)，否则为0。你会选择哪种支付策略？
- en: A. \(Y_A = 10 * X_1 + 10 * X_2\)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: A. \(Y_A = 10 * X_1 + 10 * X_2\)
- en: B. \(Y_B = \sum_{i=1}^{20} X_i\)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: B. \(Y_B = \sum_{i=1}^{20} X_i\)
- en: C. \(Y_C = 20 * X_1\)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: C. \(Y_C = 20 * X_1\)
- en: '*Solution* **Let \(X_1, X_2, ... X_{20}\) be 20 i.i.d Bernoulli(0.5) random
    variables. Since the \(X_i\)’s are independent, \(\text{Cov}(X_i, X_j) = 0\) for
    all pairs \(i, j\). Additionally, Since \(X_i\) is Bernoulli(0.5), we know that
    \(\mathbb{E}[X] = p = 0.5\) and \(\text{Var}(X) = p(1-p) = 0.25\). We can calculate
    the following for each scenario:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*解决方案* **设\(X_1, X_2, ... X_{20}\)是20个独立同分布的伯努利(0.5)随机变量。由于\(X_i\)是独立的，对于所有的\(i,
    j\)对，\(\text{Cov}(X_i, X_j) = 0\)。另外，由于\(X_i\)是伯努利(0.5)，我们知道\(\mathbb{E}[X] =
    p = 0.5\)和\(\text{Var}(X) = p(1-p) = 0.25\)。我们可以计算每种情况的如下内容：'
- en: '|  | A. \(Y_A = 10 * X_1 + 10 * X_2\) | B. \(Y_B = \sum_{i=1}^{20} X_i\) |
    C. \(Y_C = 20 * X_1\) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | A. \(Y_A = 10 * X_1 + 10 * X_2\) | B. \(Y_B = \sum_{i=1}^{20} X_i\) |
    C. \(Y_C = 20 * X_1\) |'
- en: '| --- | --- | --- | --- |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Expectation | \(\mathbb{E}[Y_A] = 10 (0.5) + 10(0.5) = 10\) | \(\mathbb{E}[Y_B]
    = 0.5 + ... + 0.5 = 10\) | \(\mathbb{E}[Y_C] = 20(0.5) = 10\) |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 期望 | \(\mathbb{E}[Y_A] = 10 (0.5) + 10(0.5) = 10\) | \(\mathbb{E}[Y_B] =
    0.5 + ... + 0.5 = 10\) | \(\mathbb{E}[Y_C] = 20(0.5) = 10\) |'
- en: '| Variance | \(\text{Var}(Y_A) = 10^2 (0.25) + 10^2 (0.25) = 50\) | \(\text{Var}(Y_B)
    = 0.25 + ... + 0.25 = 5\) | \(\text{Var}(Y_C) = 20^2 (0.25) = 100\) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 方差 | \(\text{Var}(Y_A) = 10^2 (0.25) + 10^2 (0.25) = 50\) | \(\text{Var}(Y_B)
    = 0.25 + ... + 0.25 = 5\) | \(\text{Var}(Y_C) = 20^2 (0.25) = 100\) |'
- en: '| Standard Deviation | \(\text{SD}(Y_A) \approx 7.07\) | \(\text{SD}(Y_B) \approx
    2.24\) | \(\text{SD}(Y_C) = 10\) |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 标准差 | \(\text{SD}(Y_A) \approx 7.07\) | \(\text{SD}(Y_B) \approx 2.24\) |
    \(\text{SD}(Y_C) = 10\) |'
- en: As we can see, all the scenarios have the same expected value but different
    variances. The higher the variance, the greater the risk and uncertainty, so the
    “right” strategy depends on your personal preference. Would you choose the “safest”
    option B, the most “risky” option C, or somewhere in the middle (option A)?**  **##
    18.2 Sample Statistics
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，所有的情景都有相同的期望值，但方差不同。方差越大，风险和不确定性就越大，因此“正确”的策略取决于个人的偏好。你会选择“最安全”的选项B，最“冒险”的选项C，还是介于两者之间的选项A？**  **##
    18.2 样本统计
- en: 'Today, we’ve talked extensively about populations; if we know the distribution
    of a random variable, we can reliably compute expectation, variance, functions
    of the random variable, etc. Note that:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我们已经广泛讨论了总体；如果我们知道随机变量的分布，我们可以可靠地计算期望、方差、随机变量的函数等。请注意：
- en: The distribution of a *population* describes how a random variable behaves across
    *all* individuals of interest.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*总体*的分布描述了随机变量在*所有*感兴趣的个体中的行为。'
- en: The distribution of a *sample* describes how a random variable behaves in a
    *specific sample* from the population.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*样本*的分布描述了随机变量在来自总体的*特定样本*中的行为。'
- en: In Data Science, however, we often do not have access to the whole population,
    so we don’t know its distribution. As such, we need to collect a sample and use
    its distribution to estimate or infer properties of the population. In cases like
    these, we can take several samples of size \(n\) from the population (an easy
    way to do this is using `df.sample(n, replace=True)`), and compute the mean of
    each *sample*. When sampling, we make the (big) assumption that we sample uniformly
    at random with replacement from the population; each observation in our sample
    is a random variable drawn i.i.d from our population distribution. Remember that
    our sample mean is a random variable since it depends on our randomly drawn sample!
    On the other hand, our population mean is simply a number (a fixed value).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在数据科学中，我们经常无法接触到整个总体，因此我们不知道它的分布。因此，我们需要收集一个样本，并使用它的分布来估计或推断总体的属性。在这种情况下，我们可以从总体中取几个大小为\(n\)的样本（一个简单的方法是使用`df.sample(n,
    replace=True)`），并计算每个*样本*的均值。在抽样时，我们做出（很大的）假设，即我们从总体中均匀随机地进行有放回抽样；我们样本中的每个观察都是从我们的总体分布中独立同分布地随机抽取的随机变量。请记住，我们的样本均值是一个随机变量，因为它取决于我们随机抽取的样本！另一方面，我们的总体均值只是一个数字（一个固定的值）。
- en: 18.2.1 Sample Mean
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.2.1 样本均值
- en: Consider an i.i.d. sample \(X_1, X_2, ..., X_n\) drawn from a population with
    mean 𝜇 and SD 𝜎. We define the sample mean as \[\bar{X}_n = \frac{1}{n} \sum_{i=1}^n
    X_i\]
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个从具有均值𝜇和标准差𝜎的总体中抽取的i.i.d.样本\(X_1, X_2, ..., X_n\)。我们定义样本均值为\[\bar{X}_n =
    \frac{1}{n} \sum_{i=1}^n X_i\]
- en: 'The expectation of the sample mean is given by: \[\begin{align} \mathbb{E}[\bar{X}_n]
    &= \frac{1}{n} \sum_{i=1}^n \mathbb{E}[X_i] \\ &= \frac{1}{n} (n \mu) \\ &= \mu
    \end{align}\]'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 样本均值的期望值由以下公式给出：\[\begin{align} \mathbb{E}[\bar{X}_n] &= \frac{1}{n} \sum_{i=1}^n
    \mathbb{E}[X_i] \\ &= \frac{1}{n} (n \mu) \\ &= \mu \end{align}\]
- en: 'The variance is given by: \[\begin{align} \text{Var}(\bar{X}_n) &= \frac{1}{n^2}
    \text{Var}( \sum_{i=1}^n X_i) \\ &= \frac{1}{n^2} \left( \sum_{i=1}^n \text{Var}(X_i)
    \right) \\ &= \frac{1}{n^2} (n \sigma^2) = \frac{\sigma^2}{n} \end{align}\]'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 方差由以下公式给出：\[\begin{align} \text{Var}(\bar{X}_n) &= \frac{1}{n^2} \text{Var}(
    \sum_{i=1}^n X_i) \\ &= \frac{1}{n^2} \left( \sum_{i=1}^n \text{Var}(X_i) \right)
    \\ &= \frac{1}{n^2} (n \sigma^2) = \frac{\sigma^2}{n} \end{align}\]
- en: \(\bar{X}_n\) is normally distributed by the Central Limit Theorem (CLT).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: \(\bar{X}_n\)根据中心极限定理（CLT）呈正态分布。
- en: 18.2.2 Central Limit Theorem
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.2.2 中心极限定理
- en: In [Data 8](https://inferentialthinking.com/chapters/14/4/Central_Limit_Theorem.html?)
    and in the previous lecture, you encountered the **Central Limit Theorem (CLT)**.
    This is a powerful theorem for estimating the distribution of a population with
    mean \(\mu\) and standard deviation \(\sigma\) from a collection of smaller samples.
    The CLT tells us that if an i.i.d sample of size \(n\) is large, then the probability
    distribution of the **sample mean** is **roughly normal** with mean \(\mu\) and
    SD of \(\frac{\sigma}{\sqrt{n}}\). More generally, any theorem that provides the
    rough distribution of a statistic and **doesn’t need the distribution of the population**
    is valuable to data scientists! This is because we rarely know a lot about the
    population.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Data 8](https://inferentialthinking.com/chapters/14/4/Central_Limit_Theorem.html?)和之前的讲座中，你遇到了**中心极限定理（CLT）**。这是一个强大的定理，用于从一系列较小的样本中估计具有均值\(\mu\)和标准差\(\sigma\)的总体的分布。中心极限定理告诉我们，如果一个大小为\(n\)的i.i.d样本很大，那么**样本均值**的概率分布**大致正态**，均值为\(\mu\)，标准差为\(\frac{\sigma}{\sqrt{n}}\)。更一般地，任何提供统计量粗略分布并且**不需要总体分布**的定理对于数据科学家来说都是有价值的！这是因为我们很少对总体了解很多。
- en: '![clt](../Images/727e911a7179e45a5d63f8ada1128247.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![clt](../Images/727e911a7179e45a5d63f8ada1128247.png)'
- en: Importantly, the CLT assumes that each observation in our samples is drawn i.i.d
    from the distribution of the population. In addition, the CLT is accurate only
    when \(n\) is “large”, but what counts as a “large” sample size depends on the
    specific distribution. If a population is highly symmetric and unimodal, we could
    need as few as \(n=20\); if a population is very skewed, we need a larger \(n\).
    If in doubt, you can bootstrap the sample mean and see if the bootstrapped distribution
    is bell-shaped. Classes like Data 140 investigate this idea in great detail.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，中心极限定理假设我们样本中的每个观察都是从总体的分布中抽取的i.i.d。此外，中心极限定理仅在\(n\)“大”时才准确，但什么样的“大”样本量取决于特定的分布。如果一个总体高度对称和单峰，我们可能只需要\(n=20\)；如果一个总体非常倾斜，我们需要更大的\(n\)。如果有疑问，可以对样本均值进行自举，并查看自举分布是否呈钟形。像Data
    140这样的课程会对这个想法进行详细的探讨。
- en: For a more in-depth demo, check out [onlinestatbook](https://onlinestatbook.com/stat_sim/sampling_dist/).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更详细的演示，请查看[onlinestatbook](https://onlinestatbook.com/stat_sim/sampling_dist/)。
- en: 18.2.3 Using the Sample Mean to Estimate the Population Mean
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.2.3 使用样本均值估计总体均值
- en: Now let’s say we want to use the sample mean to **estimate** the population
    mean, for example, the average height of Cal undergraduates. We can typically
    collect a **single sample**, which has just one average. However, what if we happened,
    by random chance, to draw a sample with a different mean or spread than that of
    the population? We might get a skewed view of how the population behaves (consider
    the extreme case where we happen to sample the exact same value \(n\) times!).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们想使用样本均值来**估计**总体均值，例如，加州大学本科生的平均身高。通常我们可以收集一个**单一样本**，其中只有一个平均值。但是，如果我们碰巧以随机方式抽取了一个具有不同均值或扩展性的样本，会怎么样呢？我们可能会对总体行为有一个偏斜的看法（考虑极端情况，我们碰巧抽取了相同的值
    \(n\) 次！）。
- en: '![clt](../Images/25c1dbe1b23509eeff51ea2073a35f3f.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![clt](../Images/25c1dbe1b23509eeff51ea2073a35f3f.png)'
- en: For example, notice the difference in variation between these two distributions
    that are different in sample size. The distribution with a bigger sample size
    (\(n=800\)) is tighter around the mean than the distribution with a smaller sample
    size (\(n=200\)). Try plugging in these values into the standard deviation equation
    for the normal distribution to make sense of this!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，注意这两个分布之间的变化差异，这两个分布在样本大小上是不同的。样本量更大的分布（\(n=800\)）比样本量较小的分布（\(n=200\)）更紧密地围绕均值。尝试将这些值代入正态分布的标准偏差方程中，以理解这一点！
- en: Applying the CLT allows us to make sense of all of this and resolve this issue.
    By drawing many samples, we can consider how the sample distribution varies across
    multiple subsets of the data. This allows us to approximate the properties of
    the population without the need to survey every single member.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 应用中心极限定理使我们能够理解所有这些并解决这个问题。通过抽取许多样本，我们可以考虑样本分布在数据的多个子集中的变化。这使我们能够近似总体的属性，而无需调查每个成员。
- en: 'Given this potential variance, it is also important that we consider the **average
    value and spread** of all possible sample means, and what this means for how big
    \(n\) should be. For every sample size, the expected value of the sample mean
    is the population mean: \[\mathbb{E}[\bar{X}_n] = \mu\]. We call the sample mean
    an **unbiased estimator** of the population mean and will explore this idea more
    in the next lecture.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这种潜在的差异，我们还要考虑所有可能的样本均值的**平均值和扩展性**，以及这对 \(n\) 应该有多大的影响。对于每个样本量，样本均值的期望值是总体均值：\[\mathbb{E}[\bar{X}_n]
    = \mu\]。我们称样本均值是总体均值的**无偏估计量**，并将在下一讲中更多地探讨这个想法。
- en: '*Data 8 Recap: Square Root Law* **The square root law ([Data 8](https://inferentialthinking.com/chapters/14/5/Variability_of_the_Sample_Mean.html#the-square-root-law))
    states that if you increase the sample size by a factor, the SD decreases by the
    square root of the factor. \[\text{SD}(\bar{X_n}) = \frac{\sigma}{\sqrt{n}}\]
    The sample mean is more likely to be close to the population mean if we have a
    larger sample size.**  **## 18.3 Prediction and Inference'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*Data 8 Recap: 平方根定律* **平方根定律（[Data 8](https://inferentialthinking.com/chapters/14/5/Variability_of_the_Sample_Mean.html#the-square-root-law)）指出，如果将样本量增加一个因子，标准偏差将减少该因子的平方根。
    \[\text{SD}(\bar{X_n}) = \frac{\sigma}{\sqrt{n}}\] 如果我们有更大的样本量，样本均值更有可能接近总体均值。**  **##
    18.3 预测和推断'
- en: 'At this point in the course, we’ve spent a great deal of time working with
    models. When we first introduced the idea of modeling a few weeks ago, we did
    so in the context of **prediction**: using models to make *accurate predictions*
    about unseen data. Another reason we might build models is to better understand
    complex phenomena in the world around us. **Inference** is the task of using a
    model to infer the true underlying relationships between the feature and response
    variables. For example, if we are working with a set of housing data, *prediction*
    might ask: given the attributes of a house, how much is it worth? *Inference*
    might ask: how much does having a local park impact the value of a house?'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在课程的这一阶段，我们花了大量时间研究模型。几周前我们首次介绍了建模的概念时，是在**预测**的背景下：使用模型对未知数据进行*准确预测*。我们构建模型的另一个原因是更好地理解我们周围复杂的现象。**推断**是使用模型推断特征和响应变量之间真实的基本关系的任务。例如，如果我们正在处理一组房屋数据，*预测*可能会问：根据房屋的属性，它值多少钱？*推断*可能会问：当地公园对房屋价值有多大影响？
- en: A major goal of inference is to draw conclusions about the full population of
    data given only a random sample. To do this, we aim to estimate the value of a
    **parameter**, which is a numerical function of the *population* (for example,
    the population mean \(\mu\)). We use a collected sample to construct a **statistic**,
    which is a numerical function of the random *sample* (for example, the sample
    mean \(\bar{X}_n\)). It’s helpful to think “p” for “parameter” and “population,”
    and “s” for “sample” and “statistic.”
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 推断的一个主要目标是仅凭随机样本对完整数据总体进行推断。为此，我们旨在估计*参数*的值，这是*总体*的数值函数（例如，总体均值 \(\mu\)）。我们使用收集的样本来构建**统计量**，这是随机*样本*的数值函数（例如，样本均值
    \(\bar{X}_n\)）。将“p”视为“参数”和“总体”，将“s”视为“样本”和“统计量”是有帮助的。
- en: Since the sample represents a *random* subset of the population, any statistic
    we generate will likely deviate from the true population parameter, and it *could
    have been different*. We say that the sample statistic is an **estimator** of
    the true population parameter. Notationally, the population parameter is typically
    called \(\theta\), while its estimator is denoted by \(\hat{\theta}\).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于样本代表总体的*随机*子集，我们生成的任何统计量可能会偏离真实的总体参数，并且*可能会有所不同*。我们说样本统计量是真实总体参数的**估计量**。在符号上，总体参数通常称为
    \(\theta\)，而其估计量用 \(\hat{\theta}\) 表示。
- en: 'To address our inference question, we aim to construct estimators that closely
    estimate the value of the population parameter. We evaluate how “good” an estimator
    is by answering three questions:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答我们的推断问题，我们旨在构建能够紧密估计总体参数值的估计量。我们通过回答三个问题来评估估计量的“好坏”：
- en: Do we get the right answer for the parameter, on average?
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们平均得到参数的正确答案吗？
- en: How variable is the answer?
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案有多大的变化？
- en: How close is our answer to the parameter?
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的答案与参数有多接近？
- en: 18.3.1 Modeling as Estimation
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18.3.1 建模作为估计
- en: Now that we’ve established the idea of an estimator, let’s see how we can apply
    this learning to the modeling process. To do so, we’ll take a moment to formalize
    our data collection and models in the language of random variables.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了估计量的概念，让我们看看如何将这种学习应用到建模过程中。为此，我们将花一点时间用随机变量的语言来形式化我们的数据收集和模型。
- en: Say we are working with an input variable, \(x\), and a response variable, \(Y\).
    We assume that \(Y\) and \(x\) are linked by some relationship \(g\); in other
    words, \(Y = g(x)\). \(g\) represents some “universal truth” or “law of nature”
    that defines the underlying relationship between \(x\) and \(Y\). In the image
    below, \(g\) is denoted by the red line.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在处理一个输入变量\(x\)和一个响应变量\(Y\)。我们假设\(Y\)和\(x\)通过某种关系\(g\)相关联；换句话说，\(Y = g(x)\)。\(g\)代表一些定义\(x\)和\(Y\)之间基础关系的“普遍真理”或“自然法则”。在下面的图像中，\(g\)由红线表示。
- en: As data scientists, however, we have no way of directly “seeing” the underlying
    relationship \(g\). The best we can do is collect observed data out in the real
    world to try to understand this relationship. Unfortunately, the data collection
    process will always have some inherent error (think of the randomness you might
    encounter when taking measurements in a scientific experiment). We say that each
    observation comes with some random error or **noise** term, \(\epsilon\). This
    error is assumed to be a random variable with expectation \(\mathbb{E}(\epsilon)=0\),
    variance \(\text{Var}(\epsilon) = \sigma^2\), and be i.i.d. across each observation.
    The existence of this random noise means that our observations, \(Y(x)\), are
    *random variables*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，作为数据科学家，我们无法直接“看到”基础关系\(g\)。我们能做的最好的事情就是收集在现实世界中观察到的数据，以尝试理解这种关系。不幸的是，数据收集过程总会存在一些固有的误差（想象一下在科学实验中进行测量时可能遇到的随机性）。我们说每个观察都伴随着一些随机误差或**噪声**项\(\epsilon\)。假定这个误差是一个随机变量，期望为\(\mathbb{E}(\epsilon)=0\)，方差为\(\text{Var}(\epsilon)
    = \sigma^2\)，并且在每个观察中都是独立同分布的。这种随机噪声的存在意味着我们的观察\(Y(x)\)是*随机变量*。
- en: '![data](../Images/5eaf9077fe8626eeeaef0e0b08df0c17.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![data](../Images/5eaf9077fe8626eeeaef0e0b08df0c17.png)'
- en: We can only observe our random sample of data, represented by the blue points
    above. From this sample, we want to estimate the true relationship \(g\). We do
    this by constructing the model \(\hat{Y}(x)\) to estimate \(g\).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只能观察到我们的随机数据样本，用蓝色点表示。从这个样本中，我们想要估计真实关系\(g\)。我们通过构建模型\(\hat{Y}(x)\)来估计\(g\)。
- en: '\[\text{True relationship: } g(x)\]'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '\[\text{真实关系: } g(x)\]'
- en: '\[\text{Observed relationship: }Y = g(x) + \epsilon\]'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '\[\text{观察到的关系: }Y = g(x) + \epsilon\]'
- en: '\[\text{Prediction: }\hat{Y}(x)\]'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '\[\text{预测: }\hat{Y}(x)\]'
- en: '![y_hat](../Images/b824b58c6845393488f502df80032368.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![y_hat](../Images/b824b58c6845393488f502df80032368.png)'
- en: 18.3.1.1 Estimating a Linear Relationship
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18.3.1.1 估计线性关系
- en: If we assume that the true relationship \(g\) is linear, we can express the
    response as \(Y = f_{\theta}(x)\), where our true relationship is modeled by \[Y
    = g(x) + \epsilon\] \[ f_{\theta}(x) = Y = \theta_0 + \sum_{j=1}^p \theta_j x_j
    + \epsilon\]
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们假设真实关系\(g\)是线性的，我们可以将响应表示为\(Y = f_{\theta}(x)\)，其中我们的真实关系由\[Y = g(x) + \epsilon\]
    \[ f_{\theta}(x) = Y = \theta_0 + \sum_{j=1}^p \theta_j x_j + \epsilon\]来建模。
- en: '*Which Expressions are random?* *In our two equations above, the true relationship
    \(g(x) = \theta_0 + \sum_{j=1}^p \theta_j x_j\) is not random, but \(\epsilon\)
    is random. Hence, \(Y = f_{\theta}(x)\) is also random.*  *This true relationship
    has true, unobservable parameters \(\theta\), and it has random noise \(\epsilon\),
    so we can never observe the true relationship. Instead, the next best thing we
    can do is obtain a sample \(\Bbb{X}\), \(\Bbb{Y}\) of \(n\) observed relationships,
    \((x, Y)\) and use it to train a model and obtain an estimate of \(\hat{\theta}\)
    \[\hat{Y}(x) = f_{\hat{\theta}}(x) = \hat{\theta_0} + \sum_{j=1}^p \hat{\theta_j}
    x_j\]'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*哪些表达式是随机的？* *在我们上面的两个方程中，真实关系\(g(x) = \theta_0 + \sum_{j=1}^p \theta_j x_j\)不是随机的，但\(\epsilon\)是随机的。因此，\(Y
    = f_{\theta}(x)\)也是随机的。* *这个真实关系有真实的、不可观测的参数\(\theta\)，并且它有随机噪声\(\epsilon\)，所以我们永远无法观察到真实关系。相反，我们能做的下一个最好的事情就是获得一个样本\(\Bbb{X}\)，\(\Bbb{Y}\)的\(n\)个观察关系\((x,
    Y)\)，并用它来训练一个模型并获得\(\hat{\theta}\)的估计\[\hat{Y}(x) = f_{\hat{\theta}}(x) = \hat{\theta_0}
    + \sum_{j=1}^p \hat{\theta_j} x_j\]'
- en: '*Which Expressions are random?* *In our estimating equation above, our sample
    \(\Bbb{X}\), \(\Bbb{Y}\) are random. Hence, the estimates we calculate from our
    samples \(\hat{\theta}\) are also random, so our predictor \(\hat{Y}(x)\) is also
    random.*  *Now taking a look at our original equations, we can see that they both
    have differing sources of randomness. For our observed relationship, \(Y = g(x)
    + \epsilon\), \(\epsilon\) represents measurement errors and reflects randomness
    from the future. For the estimation model, the data we have is a random sample
    collected from the population, so the randomness from the past.**  **## 18.4 Bootstrap
    Resampling (Review)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*哪些表达式是随机的？* *在我们上面的估计方程中，我们的样本\(\Bbb{X}\)，\(\Bbb{Y}\)是随机的。因此，我们从样本中计算的估计\(\hat{\theta}\)也是随机的，所以我们的预测\(\hat{Y}(x)\)也是随机的。*
    *现在看一下我们的原始方程，我们可以看到它们都有不同的随机来源。对于我们观察到的关系，\(Y = g(x) + \epsilon\)，\(\epsilon\)代表测量误差并反映未来的随机性。对于估计模型，我们拥有的数据是从总体中收集的随机样本，因此是过去的随机性。**  **##
    18.4 自助法重采样（复习）'
- en: To determine properties of the sampling distribution of an estimator like variance,
    we’d need to have access to the population so that we can consider all possible
    samples and compute an estimate for each sample.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 确定估计量的抽样分布的属性，比如方差，我们需要访问总体，以便我们可以考虑所有可能的样本并计算每个样本的估计。
- en: '![y_hat](../Images/8f88835b8fbe9546a2e01246ba83fe92.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![y_hat](../Images/8f88835b8fbe9546a2e01246ba83fe92.png)'
- en: However, we don’t have access to the population; we only have *one* random sample
    from the population. How can we consider all possible samples if we only have
    one?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们无法访问总体；我们只有来自总体的*一个*随机样本。如果我们只有一个样本，我们如何考虑所有可能的样本呢？
- en: The idea of bootstrapping is to treat our random sample as a “population” and
    resample from it *with replacement*. Intuitively, a random sample resembles the
    population, so a random *resample* also resamples a random sample.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 自助法的想法是将我们的随机样本视为“总体”，并从中进行*有放回*的重新采样。直观地说，随机样本类似于总体，因此随机*重新采样*也重新对随机样本进行重新采样。
- en: '![y_hat](../Images/47acea8264d72e12383558934a21e252.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![y_hat](../Images/47acea8264d72e12383558934a21e252.png)'
- en: 'Bootstrap resampling is a technique for estimating the sampling distribution
    of an estimator. To execute it, we can follow the pseudocode below:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Bootstrap重采样是一种估计估计量抽样分布的技术。要执行它，我们可以按照下面的伪代码进行：
- en: '[PRE0]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Why must we resample *with replacement*?* **Given an original sample of size
    \(n\), we want a resample that has the same size \(n\) as the original. Sampling
    *without* replacement will give us the original sample with shuffled rows. Hence,
    when we calculate summary statistics like the average, our sample *without* replacement
    will always have the same average as the original sample, defeating the purpose
    of a bootstrap.**  **How well does bootstrapping actually represent our population?
    The bootstrapped sampling distribution of an estimator does not exactly match
    the sampling distribution of that estimator, but it is often close. Similarly,
    the variance of the bootstrapped distribution is often close to the true variance
    of the estimator. The example below displays the results from different bootstraps
    from a *known* population using a sample size of \(n=50\).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*为什么我们必须进行*有放回*的重新采样？* **给定大小为\(n\)的原始样本，我们希望得到与原始样本相同大小\(n\)的重新采样。*不*进行替换的抽样将给我们洗牌后的原始样本。因此，当我们计算像平均值这样的摘要统计时，我们*不*进行替换的样本将始终具有与原始样本相同的平均值，从而破坏了自助法的目的。**
    **自助法实际上如何代表我们的总体？估计量的自助法抽样分布并不完全匹配该估计量的抽样分布，但通常是接近的。同样，自助法分布的方差通常接近于估计量的真实方差。下面的示例显示了使用样本大小\(n=50\)从*已知*总体进行不同自助法的结果。**'
- en: '![y_hat](../Images/5317e1d1c656f7443e965bfcc4ce9b05.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![y_hat](../Images/5317e1d1c656f7443e965bfcc4ce9b05.png)'
- en: In the real world, we don’t know the population distribution. The center of
    the boostrapped distribution is the estimator applied to our original sample,
    so we have no way of recovering the estimator’s true expected value. The quality
    of our bootstrapped distribution depends on the quality of our original sample;
    if our original sample was not representative of the population, bootstrap is
    next to useless.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，我们不知道总体分布。自助法分布的中心是应用于我们原始样本的估计量，因此我们无法恢复估计量的真实期望值。我们的自助法分布的质量取决于我们原始样本的质量；如果我们的原始样本不代表总体，自助法几乎没有用处。
- en: One thing to note is that the bootstrap often does not work well for some statistics,
    like the median or other quantile-based statistics, that depend heavily on a small
    number of observations out of a larger sample. **Bootstrapping does not overcome
    the weakness of small samples as a basis for inference**. Indeed, for the very
    smallest samples, it may be better to make additional assumptions such as a parametric
    family.**********
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，自助法通常对某些统计量（如中位数或其他基于分位数的统计量）效果不佳，这些统计量严重依赖于较大样本中的少数观察结果。**自助法无法克服小样本作为推断依据的弱点**。事实上，对于非常小的样本，最好是做出额外的假设，比如参数族。
