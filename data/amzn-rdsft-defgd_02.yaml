- en: Chapter 1\. AWS for Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 AWS 数据
- en: It is a capital mistake to theorize before one has data.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在有数据之前进行理论推测是一个严重的错误。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Sherlock Holmes
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Sherlock Holmes
- en: Data is ubiquitous and powers everything we do today. Who would have thought
    you could generate data just by walking and monitor your steps in real time on
    your wrist as you call your friend? From mobile phones, smartwatches, and web
    clicks to the Internet of Things (IoT), we are generating various types of data
    in abundance, and organizations are faced with the challenge of deriving meaning
    out of all of this data to deliver insights. You have to analyze this data to
    present unbiased information in a simple way for leaders to make business decisions.
    Data is the underlying force that fuels the insights and predictions that lead
    to better decision making and innovation. Although challenging, it is imperative
    that you harness this data and reinvent your business to stay relevant now and
    in the future. Amazon Redshift is a fully managed, petabyte (PB)-scale data warehouse
    service in the cloud that powers a modern data architecture to store data from
    all sources in a centralized or decentralized architecture. It enables you to
    query data across your data warehouses, data lakes, and operational databases
    to gain faster and deeper insights not possible otherwise.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是无处不在的，驱动着我们今天所做的一切。谁能想到仅通过行走就能生成数据，并在你打电话给朋友时实时监测你的步数？从手机、智能手表和网页点击到物联网（IoT），我们正在大量生成各种类型的数据，组织面临着从所有这些数据中提取意义以提供洞察的挑战。您必须分析这些数据，以简单的方式呈现无偏见的信息，供领导者做出业务决策。数据是推动洞察和预测、促进更好决策和创新的基础力量。尽管具有挑战性，但必须利用这些数据，重塑您的业务，以保持在现在和将来的相关性。Amazon
    Redshift是一个完全托管的PB级云数据仓库服务，支持现代数据架构，可将来自所有来源的数据存储在集中或分散的架构中。它使您能够在数据仓库、数据湖和操作性数据库之间查询数据，获得其他方式无法实现的更快速和更深入的洞察。
- en: In this chapter, we will cover the core tenants of the Amazon Web Services (AWS)
    for data framework including what makes [“Data-Driven Organizations”](#data-driven-organizations)
    successful, the core tenants of a [“Modern Data Strategy”](#modern_data_strategy),
    and what goes into building a [“Modern Data Architecture”](#modern_data_architecture).
    Finally, we’ll dive into some popular ways organizations are using [“Data Mesh
    and Data Fabric”](#datamesh_datafabric) to satisfy their needs for each analytics
    user group in a scalable way.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖亚马逊网络服务（AWS）数据框架的核心要素，包括是什么让[“数据驱动的组织”](#data-driven-organizations)成功，[“现代数据战略”](#modern_data_strategy)的核心要素，以及构建[“现代数据架构”](#modern_data_architecture)的要点。最后，我们将深入探讨一些流行的方法，组织如何利用[“数据网格和数据布局”](#datamesh_datafabric)以可伸缩的方式满足每个分析用户群体的需求。
- en: Data-Driven Organizations
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据驱动组织
- en: Data-driven organizations treat data like an asset; they make it available and
    accessible not just to business users, but to all who need data to make decisions
    so they can make more informed decisions. These organizations recognize the intrinsic
    value of data and realize the value that good data brings to the organization
    and its economic impact. They democratize data and make it available for business
    decision makers to measure the key performance indicators (KPIs). The saying “You
    can’t improve what you don’t measure,” attributed to Peter Drucker, is all the
    more relevant for today’s businesses.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 数据驱动的组织将数据视为一种资产；它们不仅使其对业务用户可用和可访问，而且对所有需要数据来做决策的人都可用，以便他们能做出更为明智的决策。这些组织认识到数据的内在价值，并意识到优质数据为组织及其经济影响带来的价值。它们民主化数据，并为业务决策者提供衡量关键绩效指标（KPIs）的数据。彼得·德鲁克归因于的名言“不能提升不可测量的事物”对当今的企业更为相关。
- en: Most businesses have a range of KPIs that they regularly monitor to drive growth
    and improve productivity. These KPIs could range from the common ones like growth,
    sales, market share, number of customers, and cost of customer acquisition to
    more domain-specific ones like sell through, capacity utilization, email opt-out
    rates, or shopping cart abandonment rates. A good KPI is specific, measurable,
    and impactful to overall business goals and could vary from business to business.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数企业都有一系列常规监控以推动增长和提高生产力的KPI。这些KPI可能从常见的增长、销售、市场份额、客户数量和客户获取成本到更多领域特定的指标如销售量、产能利用率、电子邮件退出率或购物车放弃率。一个好的KPI是具体的、可测量的，并对整体业务目标有影响，可能会因企业而异。
- en: Though some attributes like employee morale, confidence, and integrity of an
    organization cannot really be measured, there is a lot that can get measured and
    monitored for progress. Having access to this data means leaders can employ strategies
    to move the business in a certain direction. For example, after acquiring a power
    tool company, a manufacturer was flying blind until their IT team integrated the
    data into the core enterprise resource planning (ERP) system. The executive remarked
    that it was like turning the lights on for them to see where they were headed
    on the road with this business.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些属性，如员工士气、信心和组织的诚信，实际上无法进行真正的衡量，但有很多可以进行测量和监控以实现进展。访问这些数据意味着领导者可以采取策略将企业朝特定方向发展。例如，一家制造商收购了一家电动工具公司后，直到他们的IT团队将数据集成到核心企业资源计划（ERP）系统中，他们才像是打开了灯，看清了他们在业务道路上的前进方向。执行官评论说，这对他们来说就像是开启了光明，让他们看到了这个业务的前进方向。
- en: In his book *Infonomics* (Gartner, Inc.), Doug Laney talks about how it is essential
    for organizations to go beyond thinking and merely talking about information as
    an asset to actually valuing and treating it as one. He argues that information
    should be considered a new asset class in that it has measurable economic value
    and should be administered like any other type of asset. Laney provides a framework
    for businesses to monetize, manage, and measure information as an actual asset.
    He talks about how monetizing is not all about selling data, or exchange of cash.
    It is about realizing the value of information and thinking more broadly about
    the methods used to have an impact on your customers and generate profits. It
    is about working backward from your customers’ requirements and interests and
    aligning your business and operational strategy to fulfill the priorities of your
    customer. Analytics helps organizations make better decisions and enables key
    strategic initiatives. It also helps you improve relationships with both your
    customers and your business partners.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在他的书《信息经济学》（Gartner, Inc.）中，道格·兰尼讨论了组织超越仅仅思考和谈论信息作为资产的重要性，实际上评估和对待它作为一个资产。他认为信息应被视为一种新的资产类别，因为它具有可衡量的经济价值，并应像管理其他类型的资产一样加以管理。兰尼为企业提供了一个框架，以将信息作为实际资产进行货币化、管理和衡量。他谈到，货币化并不仅仅是卖数据或交换现金。它是关于实现信息价值，更广泛地思考影响客户并产生利润的方法。这是关于从客户需求和兴趣出发，逆向思考，将业务和运营策略与客户的优先事项对齐。分析帮助组织做出更好的决策，推动关键战略举措。它还帮助你改善与客户和业务伙伴的关系。
- en: At AWS re:Invent 2021, Adam Selipsky talked about how Florence Nightingale analyzed
    soldier mortality rates from the Crimean War. Nightingale, a nurse, used data
    and analytics to gain an insight that the majority of soldiers had not died in
    combat, but instead from preventable diseases caused by poor sanitary conditions
    in the hospital. Nightingale analyzed the data she collected and created a simple
    but powerful visualization diagram ([Figure 1-1](#nightingale-analytics)) depicting
    the causes of soldier mortality. This Rose Chart, also known as a polar area chart,
    allowed multiple comparisons in one diagram showing mortality rates for each month
    from diseases, wounds, and other causes. This visual helped Nightingale convince
    Queen Victoria and generals that more men had died from disease than from wounds,
    especially in winter, and highlighted the need for hospital reform and care for
    soldiers. This is a great example of the storytelling impact of data; it really
    changed the conversation to help save lives.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS re:Invent 2021上，亚当·塞利普斯基谈到了佛罗伦萨·南丁格尔如何分析克里米亚战争期间士兵的死亡率。护士南丁格尔利用数据和分析得出一个结论，即大多数士兵不是在战斗中死亡，而是在医院因恶劣的卫生条件导致的可预防疾病中死亡。南丁格尔分析了她收集的数据，并创建了一个简单但强大的可视化图表（[图1-1](#nightingale-analytics)），描述了士兵死亡原因的玫瑰图。这种玫瑰图，也称为极地面积图，允许在一个图表中进行多个比较，展示了每个月因疾病、伤口和其他原因的死亡率。这种可视化帮助南丁格尔说服维多利亚女王和将军们，更多士兵是因疾病而非伤口死亡，尤其是在冬季，突显了对医院改革和对士兵的关爱的需求。这是数据讲述影响的一个很好的例子；它确实改变了对话以帮助挽救生命。
- en: '![Florence Nightingale Rose Chart for causes of mortality](assets/ardg_0101.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![佛罗伦萨·南丁格尔死因玫瑰图](assets/ardg_0101.png)'
- en: Figure 1-1\. Florence Nightingale’s Rose Chart for causes of mortality
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 佛罗伦萨·南丁格尔的死因玫瑰图
- en: Today, you may expect to have real-time insights and prefer to access the data
    as soon as it lands. There are many inspiring examples of data-driven companies
    focusing on and adapting to changes in their customers’ preferences by using analytics.
    Dow Jones, a global news provider, increased response rates by 50% to 100% for
    mail communication by using analytics and making data accessible. Magellan Rx
    modernized its data warehouse and is able to improve patient outcomes by bringing
    drugs to market sooner and reduce operational costs by 20%. Moderna is using Amazon
    Redshift for simple, cost-effective data warehousing to avoid silos and establish
    a single source of truth for data across the organization. Nasdaq migrated its
    growing data warehouse to a more modern data lake architecture and was able to
    support the jump from 30 billion records to 70 billion records a day because of
    the flexibility and scalability of Amazon Simple Storage Service (S3) and Amazon
    Redshift. Netflix uses data to create blockbuster hit series like *House of Cards*.
    Their managers have collected and analyzed data from the digital transformation
    of media and entertainment to build lucrative markets where none previously existed.
    Coco Cola Andina, which produces and distributes products licensed by The Coca-Cola
    Company within South America, increased the productivity of its analysis team
    by 80% by creating a data lake that became the single source of data generated
    by SAP ERP and other legacy databases.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，您可能期望能够即时获取洞察，并倾向于在数据到达后立即访问数据。有许多激励人心的数据驱动型公司的例子，它们通过使用分析工具专注于并适应客户偏好变化。全球新闻提供商道琼斯通过使用分析工具并使数据可访问，将其邮件沟通的回应率提高了50%至100%。Magellan
    Rx 现代化其数据仓库，能够通过更快地将药物推向市场和减少运营成本20%，从而改善患者结果。Moderna 使用Amazon Redshift 进行简单且具有成本效益的数据仓库，以避免信息孤岛并为整个组织建立真正的单一数据来源。纳斯达克将其不断增长的数据仓库迁移到更现代的数据湖架构，并能够通过Amazon
    Simple Storage Service (S3) 和 Amazon Redshift 的灵活性和可伸缩性支持每天从30亿条记录增加到70亿条记录。Netflix
    利用数据创造了像《纸牌屋》这样的大热剧集。他们的管理者通过分析媒体和娱乐行业数字化转型的数据，建立了以前不存在的利润市场。可口可乐安迪纳在南美生产和分销可口可乐公司授权的产品，通过创建一个数据湖提高了其分析团队的生产力80%，该数据湖成为由SAP
    ERP和其他遗留数据库生成的数据的单一来源。
- en: A common theme with these successful data-driven companies is the democratization
    of data and placing insights in the hands of decision makers. Having reliable
    data is the foundation to getting actionable insights, and a well-designed data
    architecture and technology stack can enhance the reliability of data. Limiting
    movement of data within the organization is one way to avoid data inconsistencies,
    and enhance integrity and trust in the data. This does not necessarily mean building
    a single store for all data. With Amazon S3, you can store data from different
    sources in different formats in a single store. But organizations are also looking
    to query data in place from source systems or independent data warehouses. This
    has given rise to new concepts like data mesh and data fabric, which we will see
    later in this chapter. Organizations that are data driven and focus on building
    trust and scale with the data are better positioned to gain real-time insights
    to compete in the marketplace.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些成功的数据驱动型公司的共同主题是数据民主化，并将洞察力交给决策者手中。拥有可靠的数据是获取可操作洞察力的基础，良好设计的数据架构和技术堆栈可以增强数据的可靠性。限制数据在组织内的流动是避免数据不一致的一种方式，可以增强数据的完整性和信任度。这并不一定意味着建立一个所有数据的单一存储库。使用Amazon
    S3，你可以将来自不同来源的数据以不同格式存储在一个存储库中。但组织也在考虑从源系统或独立数据仓库中直接查询数据。这促使了数据网格和数据布置等新概念的产生，我们将在本章后面看到。那些以数据驱动为核心，并专注于建立与数据的信任和规模的组织，更有利于在市场竞争中获得实时洞察。
- en: Business Use Cases
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务使用案例
- en: From small businesses to global corporations, data and analytics are critical
    to gain insights into the state of the business or organization. We have picked
    some of the common use cases to demonstrate how you can derive business insights
    using AWS analytics services with specific data models in this book. Let’s look
    at some of the most common use cases and how analytics can deliver business outcomes.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 从小企业到全球企业，数据和分析对于获取对业务或组织状态的洞察至关重要。我们挑选了一些常见的使用案例，以展示您如何在本书中使用AWS分析服务和特定数据模型获得业务洞察。让我们看看一些最常见的使用案例及分析如何提供业务成果。
- en: Supply chain management
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 供应链管理
- en: With the impact of ecommerce on traditional brick-and-mortar retailers, companies
    have to use analytics to transform the way they define and manage supply chains.
    Using data and quantitative methods, demand and supply planners can improve decision
    making across the supply chain cycle. Manufacturers and retailers can apply statistical
    methods to improve supply chain decision making to have the product at the right
    time at the right place for their consumers. They can analyze inventory and plan
    their supply based on demand signals. A good example is Amazon, which [processes
    51,000 daily queries to drive supply chain excellence using Amazon Redshift](https://oreil.ly/-Veb6).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 随着电子商务对传统实体零售商的影响，公司必须利用分析来转变他们定义和管理供应链的方式。使用数据和定量方法，需求和供应规划者可以在整个供应链周期中改善决策制定。制造商和零售商可以应用统计方法来改善供应链决策，确保产品在适当的时间和地点供应给消费者。他们可以分析库存并根据需求信号计划供应。亚马逊是一个很好的例子，他们通过Amazon
    Redshift每天处理51,000个查询，以推动供应链的卓越表现。
- en: Finance
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 金融
- en: Financial and banking organizations help their customers make investment decisions
    and provide money management solutions. Today, many banks use artificial intelligence
    (AI) and machine learning (ML) to identify fraud, predict customer churn, and
    proactively engage to prevent fraud or churn. For example, you may have had your
    credit card disabled at some point while you were on a vacation or visiting a
    new place. This is ML working behind the scenes to detect unusual activity and
    block a possible fraud transaction before it is too late. Having the right data
    available and easily accessible makes this possible.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 金融和银行组织帮助客户进行投资决策，并提供资金管理解决方案。如今，许多银行利用人工智能（AI）和机器学习（ML）来识别欺诈、预测客户流失，并积极参与以预防欺诈或客户流失。例如，您可能在度假或访问新地方时曾经遇到过信用卡被停用的情况。这就是机器学习在幕后工作，检测异常活动并在可能发生欺诈交易之前阻止。正确的数据的可用性和易访问性使这一切成为可能。
- en: Customer relationship management (CRM)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 客户关系管理（CRM）
- en: Implementing a data warehousing data model for CRM can enable businesses to
    consolidate customer data from multiple touchpoints, such as sales, marketing,
    and customer support. By analyzing this data, businesses can gain insights into
    customer behavior, preferences, and satisfaction levels. This information can
    be used to personalize marketing campaigns, improve customer service, and foster
    long-term customer relationships.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 实施客户关系管理（CRM）数据仓储数据模型可以帮助企业整合来自多个接触点（如销售、营销和客户支持）的客户数据。通过分析这些数据，企业可以深入了解客户行为、偏好和满意度水平。这些信息可以用来个性化营销活动，改善客户服务，并促进长期客户关系。
- en: Education
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 教育
- en: Analytics in education can make a big difference in student experience and outcomes.
    The traditional educational method of classroom teaching has its challenges for
    today’s children immersed in a digital world. Schools are dealing with high dropout
    rates, ineffective outcomes, and outdated syllabi. Moving to a personalized learning
    approach would mean students can take advantage of flexibility and learn at their
    own pace. This also means adopting hybrid learning with online learning management
    solutions with the ability to provide customized content for learners. Data from
    student interactions with online learning environments combined with data from
    test scores can be used to analyze and provide insights into where the student
    might need additional help. With AI and machine learning, educators could predict
    the outcomes of individual students and take proactive steps to provide a positive
    outcome and experience.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 教育分析可以在学生的学习体验和结果中产生重大影响。传统的课堂教学方法对今天沉浸在数字世界的孩子们有其挑战。学校面临高辍学率、低效结果和过时的课程大纲等问题。转向个性化学习方法意味着学生可以利用灵活性，按自己的节奏学习。这也意味着采用混合学习，结合在线学习管理解决方案，能够为学习者提供定制内容。来自学生与在线学习环境的互动数据，再加上测试成绩的数据，可以用来分析并提供对学生可能需要额外帮助的见解。借助人工智能和机器学习，教育工作者可以预测个别学生的结果，并采取积极措施，以确保积极的结果和体验。
- en: Healthcare industry
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗保健行业
- en: Data plays a crucial role in the healthcare industry, revolutionizing the way
    patient care is delivered, medical research is conducted, and rising costs are
    controlled with operational efficiency. Healthcare organizations can unlock valuable
    insights that drive evidence-based decision making by harnessing the power of
    data to improve patient outcomes and enhance overall healthcare delivery. By identifying
    patterns, trends, and correlations in large datasets, healthcare professionals
    can gain a deeper understanding of diseases and treatment effectiveness based
    on patient response. With predictive analytics, these organizations can detect
    diseases early and administer personalized medicine for at-risk patient groups.
    These organizations can also detect fraudulent claims by analyzing claims data
    and identifying patterns of fraudulent activities.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据在医疗行业中发挥着关键作用，改革了提供患者护理、进行医学研究以及通过运营效率控制成本的方式。医疗组织可以利用数据的力量解锁有价值的洞见，推动基于证据的决策，以改善患者结果并提升整体医疗服务。通过在大型数据集中识别模式、趋势和相关性，医疗专业人员可以更深入地理解疾病和基于患者反应的治疗效果。通过预测分析，这些组织可以早期发现疾病，并为高风险患者群体提供个性化药物治疗。这些组织还可以通过分析索赔数据并识别欺诈活动的模式来检测虚假索赔。
- en: New Business Use Cases with Generative AI
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用生成式 AI 的新商业用例
- en: 'Generative AI and data warehousing can complement each other to enhance various
    aspects of data analysis and decision-making processes. Next, we will outline
    some ways in which generative AI can be integrated with data warehousing:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 和数据仓库可以相辅相成，增强数据分析和决策过程的各个方面。接下来，我们将概述生成式 AI 如何与数据仓库集成的几种方式：
- en: Code generation
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 代码生成
- en: Generative AI models can be trained on vast code repositories and programming
    languages to generate code completions and suggestions. When developers are writing
    code, the AI model can provide real-time suggestions that help programmer efficiency
    by suggesting or writing snippets. This can also help reduce errors and improve
    overall developer productivity to bring products to market quicker.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 模型可以在广泛的代码仓库和编程语言上进行训练，以生成代码完成和建议。当开发人员编写代码时，AI 模型可以提供实时建议，帮助提高程序员的效率，通过建议或编写代码片段来完成。这也有助于减少错误，并提高整体开发者生产力，以更快地推向市场。
- en: Natural language generation
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言生成
- en: Data warehousing often involves extracting insights and presenting them in a
    meaningful way to stakeholders. Generative AI models can generate human-readable
    reports or narratives based on the data stored in the warehouse. This can also
    be summarizing or automated generation of descriptive analytics, making it easier
    for decision makers to understand and interpret the data or the content of a report.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库通常涉及从数据中提取洞见并以有意义的方式呈现给利益相关者。生成式 AI 模型可以基于仓库中存储的数据生成人类可读的报告或叙述。这也可以是描述性分析的自动化生成或总结，使决策者更容易理解和解释数据或报告的内容。
- en: Synthetic data generation
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据生成
- en: To train a machine learning model, the quality of data determines the accuracy
    of the prediction. Generative AI models can be used to generate synthetic data
    that mimics the characteristics of real-world data. This synthetic data can be
    combined with actual data in a data warehouse to expand the dataset and create
    more comprehensive and diverse training sets for machine learning models. It helps
    overcome data scarcity issues and improves the accuracy and robustness of analytical
    models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练机器学习模型，数据的质量决定了预测的准确性。生成式 AI 模型可用于生成模拟真实数据特征的合成数据。这些合成数据可以与数据仓库中的实际数据结合使用，扩展数据集并为机器学习模型创建更全面和多样化的训练集。它有助于克服数据稀缺问题，提高分析模型的准确性和鲁棒性。
- en: Anomaly detection
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测
- en: Generative AI models, such as Generative Adversarial Networks (GANs), can be
    employed for anomaly detection in data warehousing. By training the GAN on normal
    data patterns, it can learn to identify anomalies by comparing the generated data
    with the actual data stored in the warehouse. This can help you detect unusual
    patterns and outliers for you to identify potential fraudulent transactions or
    operations.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 模型，如生成对抗网络（GANs），可以用于数据仓库中的异常检测。通过在正常数据模式上训练 GAN，它可以通过比较生成的数据与仓库中实际数据来学习识别异常。这可以帮助您检测到异常模式和离群值，以识别潜在的欺诈交易或操作。
- en: Data imputation and augmentation
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 数据填补和增强
- en: Incomplete or missing data can affect the accuracy of data analysis and decision
    making. Generative AI techniques can be used to impute missing values by learning
    the underlying patterns in the available data. By training a generative model
    on the existing data, it can generate plausible values for missing data points,
    filling in the gaps and improving the integrity of the data warehouse. You can
    augment existing datasets in a data warehouse generating new synthetic samples
    based on the existing data, and create a larger and more diverse dataset for training
    analytical models. This can improve the performance and generalization ability
    of machine learning algorithms and enable better predictions and insights.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 不完整或缺失的数据可能会影响数据分析和决策的准确性。生成式AI技术可以通过学习现有数据中的潜在模式来填补缺失值。通过在现有数据上训练生成模型，它可以为缺失的数据点生成合理的值，填补空白并提升数据仓库的完整性。您可以基于现有数据扩充数据仓库中的现有数据集，生成新的合成样本，从而创建一个更大更多样化的数据集，用于训练分析模型。这可以提高机器学习算法的性能和泛化能力，从而实现更好的预测和洞察。
- en: Recommendation systems
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统
- en: Generative AI techniques can enhance recommendation systems by generating personalized
    recommendations for users. By leveraging user behavior data stored in a data warehouse,
    generative models can learn user preferences and generate personalized recommendations
    for products, services, or content. This helps businesses improve customer engagement
    and drive sales or user satisfaction.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI技术可以通过为用户生成个性化推荐来增强推荐系统。通过利用存储在数据仓库中的用户行为数据，生成模型可以学习用户偏好并生成针对产品、服务或内容的个性化推荐。这有助于企业提升客户参与度，推动销售或用户满意度。
- en: Integrating generative AI with data warehousing expands the capabilities of
    data analysis, enhances data quality, and enables advanced analytics and decision-making
    processes. However, it’s essential to ensure ethical considerations, privacy,
    and security when generating and utilizing synthetic data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将生成式AI与数据仓库集成可以扩展数据分析的能力，增强数据质量，并支持高级分析和决策过程。然而，在生成和利用合成数据时，确保道德考虑、隐私和安全至关重要。
- en: Modern Data Strategy
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现代数据策略
- en: The concept of data gravity was first coined by Dave McCrory in 2010\. In his
    analogy, he compares data to a planet and talks about data mass that is built
    when organizations collect data in one place. Applications and services are attracted
    to this mass because proximity to data leads to better performance and throughput.
    This accelerates growth of data, and eventually it becomes almost impossible to
    move data around. Data generated by IoT, smart devices, cloud applications, and
    social media is continuing to grow exponentially. You need ways to easily and
    cost-effectively analyze all of this data with minimal time-to-insight, regardless
    of the format or where the data is stored.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 数据引力的概念最早由Dave McCrory在2010年提出。在他的类比中，他将数据比作一个行星，并讨论了组织在一个地方收集数据时形成的数据质量。应用程序和服务被吸引到这个数据质量附近，因为接近数据会带来更好的性能和吞吐量。这加速了数据的增长，最终使得数据几乎不可能再移动。由物联网、智能设备、云应用和社交媒体生成的数据正在继续呈指数增长。您需要一种简单且具有成本效益的方法来分析所有这些数据，无论数据的格式或存储位置如何，以在最短时间内获取洞察。
- en: Data is at the center of every application, process, and business decision.
    It is the cornerstone of almost every organization’s digital transformation. It
    fuels new experiences and leads to insights that spur innovation. But building
    a strategy that unlocks the value of data for your entire organization is not
    an easy and straightforward journey. Data systems are often sprawling, siloed,
    and complex, with diverse datasets spread out across data lakes, data warehouses,
    cloud databases, software as a service (SaaS) applications, IoT devices, and on-premises
    systems. Many organizations are sitting on a treasure trove of data, but don’t
    know where to start to get value out of it. Companies struggle to get a handle
    on where all their data sits, how to connect and act on that data effectively,
    and how to manage access to that data. And as data volumes grow, this only gets
    more difficult. The inability to use data effectively can hinder rapid decision
    making and sustained innovation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据位于每个应用程序、流程和业务决策的中心。它几乎是每个组织数字转型的基石。它推动新体验，并带来促进创新的洞见。但要制定一个能够为整个组织释放数据价值的策略并不容易和直接。数据系统通常是庞杂、孤立和复杂的，各种数据集散布在数据湖、数据仓库、云数据库、软件即服务（SaaS）应用程序、物联网设备和本地系统之间。许多组织掌握着丰富的数据宝库，但不知道从何处着手获取其价值。企业难以掌握所有数据的位置，如何有效连接和处理这些数据，并管理对这些数据的访问。随着数据量的增长，这些问题只会变得更加棘手。无法有效利用数据会妨碍快速决策和持续创新。
- en: 'To harness the value of their data, organizations need more than a single database,
    data lake, data warehouse, or business intelligence service. The reality is that
    each organization has multiple use cases, types of data, and users and applications
    that require different tools. And these needs will evolve over time. To truly
    unlock the value of your data to drive timely insights and innovation, you need
    to implement an end-to-end data strategy that makes working with data easier at
    every step of the data journey for everyone who needs it in your organization.
    An end-to-end data strategy combines tools, resources, and processes for ingesting,
    storing, and querying data, analyzing data, and building machine learning models,
    and ultimately helping end users develop data-driven insights. This end-to-end
    data strategy must have:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要挖掘数据的价值，组织需要的不仅仅是单一数据库、数据湖、数据仓库或商业智能服务。事实上，每个组织都有多种用例、数据类型、用户和应用程序，这些需要不同的工具。这些需求会随时间演变。要真正释放数据的价值，驱动及时洞见和创新，您需要实施一个端到端的数据战略，在数据旅程的每一步都让数据处理更加轻松，以满足组织中每个需要数据的人员的需求。端到端数据战略结合了工具、资源和流程，用于数据摄取、存储和查询、分析数据以及构建机器学习模型，最终帮助最终用户开发基于数据驱动的洞见。这种端到端数据战略必须具备：
- en: A comprehensive set of capabilities for any data use case
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于任何数据用例的全面功能集
- en: A comprehensive set of tools that accounts for the scale, variety of data, and
    many purposes for which you want to use it now and in the future
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个全面的工具集，考虑到当前和未来使用数据的规模、多样性以及多种目的。
- en: An integrated set of tools to easily connect all your data
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一套集成工具，轻松连接所有数据
- en: The ability to integrate data stored and analyzed in different tools and systems
    to gain a better understanding of your business and predict what will happen
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 整合存储和分析不同工具和系统中的数据能力，以更好地理解您的业务并预测未来发展。
- en: End-to-end data governance
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端数据治理
- en: Governance of all your data to securely give data access when and where your
    users need it
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 管理所有数据的治理，确保在用户需要时在何地安全地提供数据访问权限。
- en: With these three pillars (shown in [Figure 1-2](#modern_data_reference_architecture)),
    you can store the ever-increasing data at scale, access that data seamlessly,
    and manage who has access to the data with security and governance controls.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这三大支柱（如[图1-2](#modern_data_reference_architecture)所示），您可以规模化存储不断增长的数据，无缝访问这些数据，并通过安全和治理控制管理数据访问权限。
- en: '![Pillars of end-to-end Modern Data Strategy](assets/ardg_0102.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![端到端现代数据战略的支柱](assets/ardg_0102.png)'
- en: Figure 1-2\. Pillars of end-to-end modern data strategy
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. 端到端现代数据战略的支柱
- en: AWS provides you with the capabilities you need for an end-to-end data strategy
    with built-in intelligence and automation in its data services. Let’s dive a bit
    deeper into each of these pillars and learn what it entails.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: AWS为您提供了一整套数据服务中所需的能力，具备内置智能和自动化功能，助您实施端到端的数据战略。让我们更深入地了解每个支柱及其涵盖的内容。
- en: Comprehensive Set of Capabilities
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全面的能力集
- en: To understand your business and scale with changing workloads, streamline processes,
    and make better decisions, you need to build data strategies that can meet your
    needs now and in the future. It takes more than just a single data lake, data
    warehouse, or business intelligence tool to effectively harness data. You need
    a comprehensive set of tools that accounts for the scale, variety of data, and
    many purposes for which you want to use it.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解您的业务并随着工作负载的变化进行扩展、简化流程并做出更好的决策，您需要构建能够满足现在和未来需求的数据策略。有效利用数据不仅仅需要单一的数据湖、数据仓库或商业智能工具，还需要一套全面的工具集，考虑到数据的规模、多样性以及您希望使用它的多种目的。
- en: You can modernize your data architecture at various stages of the data journey,
    and that means breaking free from legacy databases and moving to fully managed
    and purpose-built data services. If you are running legacy, on-premises data stores
    or self-managing databases in the cloud, you still have to take care of management
    tasks such as database provisioning, patching, configuration, and backups. By
    transitioning to managed services on AWS cloud or other hyperscalers, you can
    benefit from the cloud providers’ experience, maturity, reliability, security,
    and performance for hosting and managing your applications.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在数据旅程的各个阶段现代化您的数据架构，这意味着摆脱遗留数据库并转向完全托管和专为特定用途设计的数据服务。如果您正在运行遗留的本地数据存储或在云中自我管理的数据库，您仍然需要处理诸如数据库配置、补丁管理和备份等管理任务。通过过渡到AWS云或其他超大规模云服务提供商的托管服务，您可以受益于云提供商在托管和管理应用程序方面的经验、成熟性、可靠性、安全性和性能。
- en: For an end-to-end data strategy, you need to store data in databases optimized
    for your type of workloads, integrating from multiple sources and enabling access
    to business decision makers using the tool of their choice to act on the information.
    As shown in [Figure 1-3](#modern_data_strategy_storequery_integrate_act), AWS
    provides a comprehensive set of data capabilities to store, integrate, act, and
    govern for various types of data workloads. A one-size-fits-all approach to modernizing
    the analytics platform can eventually lead to compromises, so AWS offers purpose-built
    engines to support diverse data models, including relational, key-value, document,
    in-memory, graph, time series, wide column, and ledger databases. These sets of
    capabilities help you access data wherever it resides, analyze it, and act on
    the insights.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现端到端数据策略，您需要将数据存储在针对您的工作负载优化的数据库中，从多个来源进行集成，并使用他们选择的工具使业务决策者能够访问信息并采取行动。如图[1-3](#modern_data_strategy_storequery_integrate_act)所示，AWS提供了一套全面的数据能力，用于存储、集成、执行和管理各种类型的数据工作负载。采用一种适合所有情况的方法来现代化分析平台最终可能会导致妥协，因此AWS提供了专为支持各种数据模型设计的目的构建引擎，包括关系型、键值、文档、内存、图形、时间序列、宽列和分类账数据库。这些能力集帮助您在数据存储的任何位置访问数据、分析数据并根据洞察行动。
- en: '![end-to-end data strategy](assets/ardg_0103.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![端到端数据策略](assets/ardg_0103.png)'
- en: Figure 1-3\. End-to-end data strategy
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3\. 端到端数据策略
- en: 'These data services and analysis tools are optimized for specific types of
    workloads, and AWS provides tools to integrate and govern the data stored in the
    purpose-built data services:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据服务和分析工具针对特定类型的工作负载进行了优化，AWS提供了工具来集成和管理存储在专为特定用途设计的数据服务中的数据。
- en: AWS Glue
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Glue
- en: A serverless, scalable extract, transform, and load (ETL) and data integration
    service that makes it easier to discover, prepare, move, and integrate data from
    multiple sources for analytics and machine learning.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个无服务器、可扩展的抽取、转换和加载（ETL）以及数据集成服务，使发现、准备、移动和集成来自多个来源的数据以进行分析和机器学习变得更加容易。
- en: Amazon DynamoDB
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊DynamoDB
- en: A fully managed, serverless, key-value NoSQL database designed to run high-performance
    applications at any scale. DynamoDB offers built-in security, continuous backups,
    automated multiregion replication, in-memory caching, and data import and export
    tools.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一个完全托管的、无服务器的键值NoSQL数据库，旨在以任意规模运行高性能应用程序。DynamoDB提供内置安全性、持续备份、自动多区域复制、内存缓存以及数据导入和导出工具。
- en: Amazon EMR
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊EMR
- en: A big data solution for PB-scale data processing on the cloud with capabilities
    for interactive analytics and machine learning using open source frameworks such
    as Apache Spark, Apache Hive, and Presto.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一个大数据解决方案，用于在云上处理PB级数据，具备交互式分析和机器学习能力，使用诸如Apache Spark、Apache Hive和Presto等开源框架。
- en: OpenSearch
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: OpenSearch
- en: A distributed, community-driven, Apache 2.0-licensed, open source search and
    analytics suite used for a broad set of use cases like real-time application monitoring,
    log analytics, and website search.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分布式、社区驱动、Apache 2.0 许可的开源搜索和分析套件，用于广泛的用例，如实时应用监控、日志分析和网站搜索。
- en: Amazon Simple Storage Service (Amazon S3)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Simple Storage Service（Amazon S3）
- en: An object storage service offering high scalability, data availability, security,
    and performance. You can store and protect structured and unstructured data for
    use cases such as data lakes, cloud native applications, and mobile apps.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一种对象存储服务，提供高可扩展性、数据可用性、安全性和性能。您可以存储和保护结构化和非结构化数据，用于数据湖、云原生应用和移动应用等用例。
- en: Amazon QuickSight
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon QuickSight
- en: A serverless service for users that helps you meet varying analytic needs from
    the same source of truth through modern interactive dashboards, paginated reports,
    embedded analytics, and natural language queries.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一种为用户提供的无服务器服务，通过现代交互式仪表板、分页报告、嵌入式分析和自然语言查询，帮助您从同一真实数据源满足各种分析需求。
- en: Amazon Kinesis
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kinesis
- en: Makes it easy to collect, process, and analyze real-time, streaming data so
    you can get timely insights and react quickly to new information. Amazon Kinesis
    offers capabilities to cost-effectively process streaming data at scale, along
    with the flexibility to choose the tools that best suit the requirements of your
    application.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使收集、处理和分析实时流数据变得简单，使您能够及时获取见解并快速对新信息做出反应。Amazon Kinesis 提供能力以成本效益的方式处理规模化的流数据，同时灵活选择最适合应用程序需求的工具。
- en: Amazon Redshift
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift
- en: A fully managed, PB-scale data warehouse service in the cloud. With Amazon Redshift,
    you can modernize your data warehouse on the cloud with compliance, security,
    and governance, and leverage the scaling feature to meet your variable requirements.
    You can securely ingest, combine, and run historical, real-time, or predictive
    analytics on all your data using a serverless or provisioned deployment option.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一个在云中完全托管的PB级数据仓库服务。使用 Amazon Redshift，您可以通过符合性、安全性和治理现代化云数据仓库，并利用扩展功能来满足您的可变需求。您可以安全地摄取、组合和运行历史、实时或预测性分析，使用无服务器或预配部署选项处理所有数据。
- en: Amazon SageMaker
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker
- en: A fully managed service to prepare data and build, train, and deploy machine
    learning models for any use case with fully managed infrastructure, tools, and
    workflows.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一个完全托管的服务，用于准备数据和构建、训练和部署任何用例的机器学习模型，提供完全托管的基础设施、工具和工作流程。
- en: These services are tightly integrated and can talk to each other to leverage
    data from each other.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些服务紧密集成并能相互通信，以利用彼此的数据。
- en: Integrated Set of Tools
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一套集成工具
- en: The most impactful data-driven insights come from getting a full picture of
    your business and your customers. This can be achieved only when you connect the
    dots between your different data sources across multiple departments, services,
    on-premises tools, and third-party applications such as business intelligence
    (BI) systems or statistical modeling tools. Typically, connecting data across
    different data sources requires data replication or complex ETL pipelines, which
    can take hours, if not days. That’s just not fast enough to keep up with the speed
    of decision making. ETL needs to be easier and in many cases, eliminated.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最有影响力的数据驱动洞见来自于全面了解您的业务和客户的全貌。只有当您在多个部门、服务、本地工具和第三方应用（如商业智能系统或统计建模工具）之间连接数据源时，才能实现这一点。通常，跨不同数据源连接数据需要数据复制或复杂的
    ETL 管道，这可能需要数小时，甚至数天的时间。这只是不够快以跟上决策速度。ETL 需要更简单化，甚至在许多情况下需要消除。
- en: Great business leaders see opportunities to transform their business all along
    the value chain. But making such a transformation requires data that enables decision
    makers to get a full picture of the business and single source of truth. This
    necessitates breaking down data silos and making data accessible and shared in
    a secure way to unlock the value of data across the organization.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 伟大的业务领袖看到了在价值链上实现业务转型的机会。但要实现这样的转型，需要数据来帮助决策者全面了解业务并建立真实的单一数据源。这需要打破数据孤岛，以安全的方式使数据可访问和共享，从而释放组织中数据的价值。
- en: To make decisions quickly, you need new data stores that will scale and grow
    as your business needs change. You also want to be able to connect everything
    together, including your data lake, data warehouse, and all the purpose-built
    data stores into a coherent system that is secure and well governed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要快速做出决策，您需要新的数据存储，这些存储将随着业务需求的变化而扩展和增长。您还希望能够将所有内容连接在一起，包括数据湖、数据仓库和所有目的构建的数据存储，形成一个安全且良好治理的连贯系统。
- en: 'That consolidated view can be achieved in many ways: federated querying, low/no-code
    data synchronization, or tradition ETL using serverless or server-based execution.
    Amazon Redshift provides options for each of these, with tight integration with
    other AWS services. The zero-ETL feature between Amazon Aurora and Amazon Redshift
    enables you to near real-time synchronize transactional data into your data warehouse.
    Amazon Redshift allows for querying data from your Amazon S3 data lake, and the
    federated query feature allows querying data securely and directly from operational
    databases. For analytics workloads, where you want to isolate compute, you may
    build ETL pipelines to extract, transform, and load data into a target data store.
    The tight integration with AWS Glue allows you to easily create spark-based jobs
    in AWS Glue Studio for execution using a serverless framework. For more details
    on Amazon Redshift data transformation strategies, see [Chapter 4, “Data Transformation
    Strategies”](ch04.html#AR_TGD_CH4).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这种综合视图，有多种方法：联合查询、低代码/无代码数据同步，或传统的使用无服务器或服务器执行的ETL。Amazon Redshift为这些方法提供了选择，与其他AWS服务紧密集成。Amazon
    Aurora与Amazon Redshift之间的零ETL功能使您能够将事务数据近乎实时地同步到数据仓库中。Amazon Redshift允许从您的Amazon
    S3数据湖中查询数据，而联合查询功能则允许从操作数据库安全地直接查询数据。对于需要隔离计算的分析工作负载，您可以构建ETL管道，将数据提取、转换并加载到目标数据存储中。与AWS
    Glue的紧密集成允许您在AWS Glue Studio中轻松创建基于Spark的作业，并使用无服务器框架执行。有关Amazon Redshift数据转换策略的更多详细信息，请参见[第4章，“数据转换策略”](ch04.html#AR_TGD_CH4)。
- en: For exposing your data to data analysts and data scientists, Amazon Redshift
    has simplified the access path. In the past, machine learning has been limited
    to highly skilled data scientists or programmers with deep skills in programming
    languages such as Python, R, etc. With tight integration with Amazon SageMaker,
    Amazon Redshift data analysts can use Amazon Redshift ML to run machine learning
    workloads from within the data warehouse or data lake without having to select,
    build, or train an ML model. For more details on Amazon Redshift machine learning,
    see [Chapter 6, “Amazon Redshift Machine Learning”](ch06.html#AR_TGD_CH6). In
    addition, business analysts can use tools like Amazon QuickSight to autodiscover
    their Amazon Redshift data warehouse and connect to the data stores to quickly
    produce impactful dashboards with business insights. For more details on the different
    options for getting to your Amazon Redshift data warehouse, see [Chapter 2, “Getting
    Started with Amazon Redshift”](ch02.html#AR_TGD_CH2).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向数据分析师和数据科学家公开您的数据，Amazon Redshift简化了访问路径。过去，机器学习局限于高技能的数据科学家或具有Python、R等编程语言深度技能的程序员。通过与Amazon
    SageMaker的紧密集成，Amazon Redshift数据分析师可以使用Amazon Redshift ML从数据仓库或数据湖内运行机器学习工作负载，而无需选择、构建或训练ML模型。有关Amazon
    Redshift机器学习的更多详细信息，请参见[第6章，“Amazon Redshift机器学习”](ch06.html#AR_TGD_CH6)。此外，业务分析师可以使用Amazon
    QuickSight等工具自动发现他们的Amazon Redshift数据仓库，并连接到数据存储，快速生成具有业务见解的有影响力的仪表板。有关到达Amazon
    Redshift数据仓库的不同选项的更多详细信息，请参见[第2章，“开始使用Amazon Redshift”](ch02.html#AR_TGD_CH2)。
- en: End-to-End Data Governance
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全流程数据治理
- en: Establishing the right governance lets you balance control and access and gives
    people within your organization trust and confidence in the data. It encourages
    innovation, rather than restricts it, because the right people can quickly find,
    access, and share data when they need it.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 建立正确的治理机制可以帮助您平衡控制与访问权限，并使组织内的人员对数据充满信任和信心。它鼓励创新，而不是限制，因为合适的人员可以在需要时快速找到、访问和共享数据。
- en: To spur innovation, organizations should endorse the concept of data security
    as meaning how you can set your data free in a secure manner, rather than meaning
    how you can secure data and limit access to your users. With end-to-end data governance
    on AWS, you have control over where your data sits, who has access to it, and
    what can be done with it at every step of the data workflow.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了激发创新，组织应该支持数据安全的概念，意味着如何以安全的方式释放您的数据，而不是意味着如何保护数据并限制用户访问。在AWS上进行端到端的数据治理，您可以在数据工作流的每个步骤控制数据的位置、访问者以及可以对其执行的操作。
- en: For data engineers and developers, AWS has fine-grained controls, catalogs,
    and metadata within services like AWS Glue and AWS Lake Formation. AWS Glue enables
    you to catalog data across data lakes, data warehouses, and databases. AWS Glue
    comes with data quality rules that check for data freshness, accuracy, and integrity.
    With AWS Lake Formation, you can govern and audit the actions taken on the data
    in your data lake on Amazon S3 and data sharing in Amazon Redshift. If you have
    a data lake on Amazon S3, you can also use Amazon S3 Access Points to create unique
    access control policies and easily control access to shared datasets.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据工程师和开发人员，AWS在服务如AWS Glue和AWS Lake Formation中提供了精细的控制、目录和元数据。AWS Glue使您能够在数据湖、数据仓库和数据库中对数据进行目录化。AWS
    Glue还具有数据质量规则，用于检查数据的新鲜度、准确性和完整性。通过AWS Lake Formation，您可以管理和审计在Amazon S3数据湖上的数据操作以及在Amazon
    Redshift中的数据共享。如果您在Amazon S3上拥有数据湖，您还可以使用Amazon S3访问点创建唯一的访问控制策略，轻松控制对共享数据集的访问。
- en: Data scientists can use governance controls in SageMaker to gain end-to-end
    visibility into ML models, including training, version history, and model performance
    all in one place.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家可以使用SageMaker中的治理控制来获得对ML模型的端到端可见性，包括训练、版本历史和模型性能，一切尽在一个地方。
- en: Finally, Amazon DataZone is a data management service to catalog, discover,
    share, and govern data. It makes it easy for data engineers, data scientists,
    product managers, analysts, and other business users to discover, use, and collaborate
    with that data to drive insights for your business.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Amazon DataZone是一个数据管理服务，用于目录化、发现、共享和治理数据。它使数据工程师、数据科学家、产品经理、分析师和其他业务用户能够发现、使用和共享数据，从而为您的业务带来洞察。
- en: In summary, it is becoming increasingly clear that harnessing data is the next
    wave of digital transformation. Modernizing means unifying the best of data lakes
    and purpose-built data stores and making it easy to innovate with ML. With these
    three pillars—comprehensive, integrated, and governance—your modern data strategy
    with AWS can help you build an architecture that scales based on demand and reduce
    operational costs.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，越来越清楚的是，利用数据是数字转型的下一个浪潮。现代化意味着统一数据湖和专用数据存储的最佳方案，并使其易于通过ML进行创新。通过全面性、集成性和治理性这三大支柱，AWS的现代数据战略可以帮助您构建根据需求扩展并降低运营成本的架构。
- en: Modern Data Architecture
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现代数据架构
- en: When you embark on a modern data strategy, you have to think about how to handle
    any amount of data, at low cost, and in open, standards-based data formats. The
    strategy should also let you break down data silos, empower your teams to run
    analytics or machine learning using their preferred tool or technique, and manage
    who has access to data with the proper security and data governance controls.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当你着手进行现代数据战略时，你必须考虑如何以低成本处理任意数量的数据，并且使用开放的、基于标准的数据格式。该战略还应该让你打破数据孤岛，使团队能够使用他们喜欢的工具或技术进行分析或机器学习，并管理谁可以访问数据，确保适当的安全性和数据治理控制。
- en: To execute a modern data strategy, you need a *modern data architecture*. You
    may have heard about data warehouses, data lakes, and data mesh, and you may also
    be considering one of these strategies. A *data warehouse* enables you to store
    structured data and enable fast query access on a large mass of data. A *data
    lake* is a central repository where you store all structured and unstructured
    data and have it easily accessible. A *data mesh* allows you to access data in
    place while decentralizing ownership and governance of data. A modern data architecture
    needs to support all of these aspects to gain business insights from the ever-increasing
    data mass.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行现代数据策略，您需要一个*现代数据架构*。您可能听说过数据仓库、数据湖和数据网格，您可能也在考虑其中一种策略。*数据仓库*使您能够存储结构化数据并在大量数据上进行快速查询访问。*数据湖*是一个中央仓库，您可以在其中存储所有结构化和非结构化数据，并轻松访问。*数据网格*允许您在原地访问数据，同时分散数据的所有权和治理。现代数据架构需要支持所有这些方面，以从不断增长的数据质量中获得业务洞察。
- en: AWS modern data architecture is built on a model that includes purpose-built
    data stores to optimize for scale, availability, performance, and cost. It enables
    integrating a data lake, a data warehouse, and purpose-built stores, enabling
    unified governance and easy data movement. Amazon Redshift and Amazon S3 form
    the core for your modern data architecture, with tight integration with other
    purpose-built services.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: AWS现代数据架构建立在包括专用数据存储在内的模型之上，以优化规模、可用性、性能和成本。它支持集成数据湖、数据仓库和专用存储，实现统一治理和简化数据移动。Amazon
    Redshift和Amazon S3构成了您现代数据架构的核心，与其他专用服务紧密集成。
- en: 'In the modern data architecture shown in [Figure 1-4](#modern_data_architecturefig),
    there are three different patterns for data movement: inside-out, outside-in,
    and around the perimeter.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在所示的现代数据架构中（见[图 1-4](#modern_data_architecturefig)），有三种不同的数据移动模式：内部移动、外部移动和周边移动。
- en: '![Modern data architecture with purpose-built databases](assets/ardg_0104.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![使用专用数据库构建的现代数据架构](assets/ardg_0104.png)'
- en: Figure 1-4\. Modern data architecture using purpose-built services
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-4\. 使用专用服务构建的现代数据架构
- en: Inside-out data movement
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 内部移动数据
- en: A subset of data in a central data store is sometimes moved to a purpose-built
    data store, such as Amazon Redshift for online analytical processing (OLAP) workloads,
    Amazon OpenSearch Service cluster, or Amazon Neptune cluster to support specialized
    analytics such as search analytics, building knowledge graphs, or both. In the
    context of Amazon Redshift, you may use Amazon Redshift for your central data
    store where other services like AWS Glue or other Amazon Redshift data warehouses
    can access the data through data sharing. Alternatively, you can consume data
    from an Amazon S3 data lake into Amazon Redshift by loading it via the `COPY`
    command or directly querying it as an external Amazon S3 schema.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 有时会将中央数据存储中的数据子集移动到专用数据存储中，例如用于在线分析处理（OLAP）工作负载的Amazon Redshift，Amazon OpenSearch
    Service集群或Amazon Neptune集群，以支持专业分析，如搜索分析、构建知识图谱或两者兼而有之。在Amazon Redshift的背景下，您可以使用Amazon
    Redshift作为中央数据存储，其他服务（如AWS Glue或其他Amazon Redshift数据仓库）可以通过数据共享访问数据。或者，您可以通过`COPY`命令将Amazon
    S3数据湖中的数据加载到Amazon Redshift中，或者直接查询作为外部Amazon S3模式的数据。
- en: Outside-in data movement
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 外部移动数据
- en: Organizations start with data stores that best fit their applications and later
    move that data into a central data store for collaboration. For example, to offload
    historical data that is not frequently accessed, you may want to `UNLOAD` this
    data from Amazon Redshift to your Amazon S3 data lake. A gaming company might
    choose Amazon DynamoDB as the data store to maintain game state, player data,
    session history, and leaderboards. This data can later be exported to an Amazon
    S3 data lake for additional analytics to improve the gaming experience for its
    players.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 组织机构从最适合其应用程序的数据存储开始，随后将这些数据移动到中央数据存储以进行协作。例如，为了卸载不经常访问的历史数据，您可能希望从Amazon Redshift将这些数据`UNLOAD`到您的Amazon
    S3数据湖中。游戏公司可能会选择Amazon DynamoDB作为维护游戏状态、玩家数据、会话历史和排行榜的数据存储。这些数据稍后可以导出到Amazon S3数据湖中，以进行额外的分析，以改善玩家的游戏体验。
- en: Around the perimeter
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 周边移动
- en: There are also scenarios where the data is moved from one specialized data store
    to another. For example, you can use the federated query capability of Amazon
    Redshift to query data directly from operational data stores like Amazon Aurora
    or use Amazon Redshift ML capability to run a model that will trigger a process
    in Amazon SageMaker.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些场景，数据从一个专门的数据存储移动到另一个。例如，您可以使用Amazon Redshift的联合查询功能直接从操作数据存储（如Amazon Aurora）查询数据，或者使用Amazon
    Redshift ML功能运行模型，这将触发Amazon SageMaker中的流程。
- en: You can innovate at various stages of the modern data strategy by moving away
    from building tightly coupled monolithic applications. Instead, you can build
    modular applications with independent components called microservices. These native,
    purpose-built, integrated AWS services are well suited for building modular applications
    while leveraging new emerging technologies like ML and AI.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过避免构建紧密耦合的单块应用程序，而是构建具有独立组件（称为微服务）的模块化应用程序，在现代数据战略的各个阶段进行创新。这些本地的、专为目的而建的集成AWS服务非常适合构建模块化应用程序，同时利用ML和AI等新兴技术。
- en: Role of Amazon Redshift in a Modern Data Architecture
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Redshift在现代数据架构中的角色
- en: Amazon Redshift powers the modern data architecture and enables you to store
    data in a centralized or decentralized architecture and break down data silos
    by enabling access to all data in your organization. With a modern data architecture,
    you can store and access data within the data warehouse tables in structured columnar
    format and open file formats in your Amazon S3 data lake. The capability to query
    data across your data warehouse, data lake, and operational databases with security
    and governance helps unify and make data easily available to your business users
    and other applications.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift推动现代数据架构，并使您能够在集中式或分散式架构中存储数据，并通过使组织中的所有数据可访问来打破数据孤岛。借助现代数据架构，您可以在Amazon
    S3数据湖中以结构化列格式和开放文件格式存储和访问数据仓库表中的数据。通过安全和治理能力在数据仓库、数据湖和操作数据库之间查询数据有助于统一并使数据轻松可用于您的业务用户和其他应用程序。
- en: Some of the key capabilities of Amazon Redshift and the benefit of tight integration
    to native services are shown in [Figure 1-5](#roleof_redshift_modern_data_architecture).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift的一些关键功能及与本地服务紧密集成的好处显示在[图1-5](#roleof_redshift_modern_data_architecture)中。
- en: '![Amazon Redshift in a modern data architecture](assets/ardg_0105.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift在现代数据架构中](assets/ardg_0105.png)'
- en: Figure 1-5\. Amazon Redshift in a modern data architecture
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5\. Amazon Redshift在现代数据架构中
- en: 'We will discuss the features in detail in later chapters, but here is a brief
    summary of each:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后续章节详细讨论这些功能，但这里是每个功能的简要摘要：
- en: Massively parallel processing (MPP) data warehouse
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模并行处理（MPP）数据仓库
- en: Amazon Redshift is based on MPP architecture, which enables fast run of the
    complex queries operating on large amounts of data by distributing the query processing
    to multiple nodes and virtual processing units within each node of your data warehouse.
    An MPP architecture has the added benefit of co-locating like data in processing
    units through the use of distribution keys, therefore making analytics processing
    more cost performant. In [Chapter 2, “Getting Started with Amazon Redshift”](ch02.html#AR_TGD_CH2),
    you will learn more about the importance of MPP architecture.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift基于MPP架构，通过将查询处理分布到数据仓库中的多个节点和每个节点内的虚拟处理单元来快速运行复杂查询，这使其能够处理大量数据。MPP架构通过使用分布键将类似数据放置在处理单元中，从而使分析处理更具成本效益。在[第2章，“开始使用Amazon
    Redshift”](ch02.html#AR_TGD_CH2)，您将了解有关MPP架构重要性的更多信息。
- en: Separation of storage and compute
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 存储和计算分离
- en: With the Redshift architecture generation 3 (RA3), Amazon Redshift has separation
    of storage and compute, which helps you to scale storage or compute independently
    based on the requirements of your workloads. In [Chapter 2](ch02.html#AR_TGD_CH2),
    you will learn more about the architecture of Amazon Redshift and how to get started.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Redshift架构第3代（RA3），Amazon Redshift实现了存储和计算的分离，这有助于根据工作负载需求独立扩展存储或计算。在[第2章](ch02.html#AR_TGD_CH2)，您将进一步了解Amazon
    Redshift的架构及其如何入门。
- en: Serverless
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器
- en: Amazon Redshift offers a serverless option, so you can run and scale analytics
    without having to provision and manage data warehouses. With Amazon Redshift serverless,
    you don’t have to choose a node type or the number of nodes you need for a specific
    workload; instead, you set an initial configuration for compute unit, which is
    measured in Redshift Processing Unit (RPU). Amazon Redshift automatically provisions
    and scales data warehouse capacity to meet the requirements of demanding and unpredictable
    workloads, and you pay only for the capacity you use. Amazon Redshift serverless
    is compatible with the provisioned cluster, so you can migrate your applications
    from a provisioned cluster to serverless without changing your existing analytics
    or BI applications. In [Chapter 2, “Getting Started with Amazon Redshift”](ch02.html#AR_TGD_CH2),
    you will learn more about creating an Amazon Redshift serverless data warehouse.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 提供了一种无服务器选项，因此您可以在不需要预配和管理数据仓库的情况下运行和扩展分析工作负载。使用亚马逊 Redshift 无服务器，您无需选择特定工作负载所需的节点类型或节点数量；相反，您设置一个计算单元的初始配置，该计算单元以
    Redshift 处理单元（RPU）进行衡量。亚马逊 Redshift 自动预配和扩展数据仓库容量，以满足要求严格和不可预测的工作负载的需求，您只需支付所使用的容量费用。亚马逊
    Redshift 无服务器兼容预配的集群，因此您可以将应用程序从预配的集群迁移到无服务器，而无需更改现有的分析或 BI 应用程序。在 [第 2 章，“使用亚马逊
    Redshift 入门”](ch02.html#AR_TGD_CH2) 中，您将了解如何创建亚马逊 Redshift 无服务器数据仓库。
- en: Data lake analytics
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖分析
- en: Amazon Redshift can efficiently query and transform structured and semistructured
    data from files in Amazon S3 without having to load the data into Amazon Redshift
    tables. Amazon Redshift queries external S3 data with only the required data sent
    to your Amazon Redshift data warehouse. In [Chapter 3, “Setting Up Your Data Models
    and Ingesting Data”](ch03.html#AR_TGD_CH3), you will learn more about how to query
    and transform data from Amazon S3.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 可以高效地查询和转换存储在亚马逊 S3 中的结构化和半结构化数据，而无需将数据加载到亚马逊 Redshift 表中。亚马逊 Redshift
    查询外部 S3 数据，仅将所需数据发送到您的亚马逊 Redshift 数据仓库。在 [第 3 章，“设置数据模型和数据摄入”](ch03.html#AR_TGD_CH3)
    中，您将了解如何从亚马逊 S3 查询和转换数据。
- en: Secure and consistent data sharing
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 安全且一致的数据共享
- en: Amazon Redshift data sharing allows you to share live data between data warehouses
    internal within your organization or with external partners. This feature allows
    you to extend benefits of a single data warehouse to multiple data warehouse deployments
    without the need to copy or move it. This enables you to access and query data
    where it is stored by sharing data across organizational boundaries and different
    data domains where data mass is accumulated. In [Chapter 7, “Collaboration with
    Data Sharing”](ch07.html#AR_TGD_CH7), you will learn more about Amazon Redshift
    data sharing and how you can use this for collaboration with internal and external
    stakeholders.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift 数据共享允许您在组织内部或与外部合作伙伴之间共享实时数据仓库数据。此功能使您能够在多个数据仓库部署中扩展单个数据仓库的好处，而无需复制或移动数据。这使您可以通过跨组织边界和数据领域共享数据来访问和查询存储数据。在
    [第 7 章，“数据共享协作”](ch07.html#AR_TGD_CH7) 中，您将了解更多关于亚马逊 Redshift 数据共享的信息，以及如何与内部和外部利益相关者进行协作。
- en: Machine learning using SQL
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SQL 进行机器学习
- en: Amazon Redshift ML makes it easy for data analysts and database developers to
    create, train, and apply machine learning models using familiar Standard Query
    Language (SQL) commands in Amazon Redshift data warehouses. With Amazon Redshift
    ML, you can reduce ML model development time by using SQL-based prediction model
    creation and taking advantage of integration with [Amazon SageMaker](https://oreil.ly/aG8L1),
    a fully managed machine learning service, without learning new tools or languages.
    In [Chapter 6, “Amazon Redshift Machine Learning”](ch06.html#AR_TGD_CH6), you’ll
    learn more about the types of machine learning problems you can solve using Amazon
    Redshift ML.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Redshift ML 使数据分析师和数据库开发人员能够使用熟悉的标准查询语言（SQL）命令在亚马逊 Redshift 数据仓库中创建、训练和应用机器学习模型变得更加简单。通过亚马逊
    Redshift ML，您可以减少使用基于 SQL 的预测模型创建和利用与 [Amazon SageMaker](https://oreil.ly/aG8L1)
    完全托管的机器学习服务集成的 ML 模型开发时间，无需学习新工具或语言。在 [第 6 章，“亚马逊 Redshift 机器学习”](ch06.html#AR_TGD_CH6)
    中，您将了解如何使用亚马逊 Redshift ML 解决各种机器学习问题类型。
- en: Zero-ETL
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 零 ETL
- en: Amazon Aurora supports zero-ETL integration with Amazon Redshift to enable near
    real-time analytics using Amazon Redshift on transactional data. Using log-based
    replication, transactional data written into Aurora is available in Amazon Redshift
    within a few seconds. Once data is available in Amazon Redshift, you can query
    data as is or apply transformation rules using either SQL or stored procedures.
    In [Chapter 3](ch03.html#AR_TGD_CH3), you’ll learn more about how to set up zero-ETL
    integration with Amazon Redshift.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Aurora支持与Amazon Redshift的零ETL集成，以便使用Amazon Redshift对交易数据进行近实时分析。使用基于日志的复制，写入Aurora的交易数据在几秒钟内可在Amazon
    Redshift中使用。一旦数据在Amazon Redshift中可用，您可以按原样查询数据，或者使用SQL或存储过程应用转换规则。在[第3章](ch03.html#AR_TGD_CH3)，您将学习如何设置与Amazon
    Redshift的零ETL集成。
- en: Spark application development
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Spark应用程序开发
- en: With [Apache Spark integration](https://oreil.ly/tkSCj), you can build Apache
    Spark applications in a variety of languages such as Java, Scala, and Python,
    and the connector is natively installed on Amazon EMR (previously called Amazon
    Elastic MapReduce), AWS Glue, and SageMaker. These applications can read from
    and write to your Amazon Redshift data warehouse without compromising on the performance
    of the applications or transactional consistency of the data, as well as performance
    improvements with pushdown optimizations. In [Chapter 3](ch03.html#AR_TGD_CH3),
    you’ll learn how to take advantage of the Spark connector for ingestion and in
    [Chapter 4, “Data Transformation Strategies”](ch04.html#AR_TGD_CH4), you’ll learn
    how to use the Spark connector for data transformation.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[Apache Spark集成](https://oreil.ly/tkSCj)，您可以在Java、Scala和Python等多种语言中构建Apache
    Spark应用程序，并且该连接器原生安装在Amazon EMR（以前称为Amazon Elastic MapReduce）、AWS Glue和SageMaker上。这些应用程序可以读取和写入您的Amazon
    Redshift数据仓库，而不会影响应用程序的性能或数据的事务一致性，同时通过推送优化提高性能。在[第3章](ch03.html#AR_TGD_CH3)，您将学习如何利用Spark连接器进行摄取，在[第4章，“数据转换策略”](ch04.html#AR_TGD_CH4)，您将学习如何使用Spark连接器进行数据转换。
- en: Auto ingestion of Amazon S3 files
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 自动摄取Amazon S3文件
- en: You can set up continuous file ingestion rules to track your Amazon S3 paths
    and automatically load new files into Amazon Redshift without the need for additional
    tools or custom solutions. Using a `COPY` command is the best practice for ingestion
    of data into Amazon Redshift. You can store a `COPY` statement into a copy job,
    which automatically loads the new files detected in the specified Amazon S3 path.
    In [Chapter 3](ch03.html#AR_TGD_CH3), we will describe the different options for
    loading data and how to configure auto ingestion.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以设置连续文件摄取规则来跟踪您的Amazon S3路径，并自动将新文件加载到Amazon Redshift中，无需额外的工具或自定义解决方案。使用`COPY`命令是将数据摄取到Amazon
    Redshift的最佳实践。您可以将`COPY`语句存储到复制作业中，该作业会自动加载检测到的指定Amazon S3路径中的新文件。在[第3章](ch03.html#AR_TGD_CH3)，我们将描述加载数据的不同选项以及如何配置自动摄取。
- en: Query transactional data using federated query
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 使用联合查询查询交易数据
- en: With federated queries, you can incorporate live data as part of your BI and
    reporting applications. With this feature, you can query current real-time data
    from external databases like PostgreSQL or MySQL from within Amazon Redshift and
    combine it with historical data stored in data warehouses to provide a combined
    view for your business users. In [Chapter 4](ch04.html#AR_TGD_CH4), you’ll learn
    how to set up a federated source and query that data in real time for use in reporting
    and transformation.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用联合查询，您可以将实时数据作为BI和报告应用程序的一部分。通过此功能，您可以从Amazon Redshift内部查询来自外部数据库（如PostgreSQL或MySQL）的当前实时数据，并将其与存储在数据仓库中的历史数据结合起来，为业务用户提供综合视图。在[第4章](ch04.html#AR_TGD_CH4)，您将学习如何设置联合数据源，并实时查询用于报告和转换的数据。
- en: Use your favorite BI tool
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您喜爱的BI工具
- en: You can use your BI tool of choice to query your Amazon Redshift data warehouses
    using standard Java Database Connectivity (JDBC) and Open Database Connectivity
    (ODBC) connections or using APIs and provide business insights. [Amazon QuickSight](https://oreil.ly/ZgXHL)
    is an AWS native service to create modern interactive dashboards, paginated reports,
    embedded analytics, and natural language queries on multiple data sources including
    Amazon Redshift. In [Chapter 2](ch02.html#AR_TGD_CH2), you’ll learn about the
    many ways you can connect your client tools to Amazon Redshift.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用您选择的BI工具通过标准的Java数据库连接（JDBC）和开放数据库连接（ODBC）连接或使用API查询您的Amazon Redshift数据仓库，并提供业务洞察。[Amazon
    QuickSight](https://oreil.ly/ZgXHL)是AWS的本地服务，用于创建现代交互式仪表板、分页报告、嵌入式分析和多数据源的自然语言查询，包括Amazon
    Redshift。在[第2章](ch02.html#AR_TGD_CH2)中，您将了解将客户端工具连接到Amazon Redshift的多种方式。
- en: Discover and share data
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 发现和分享数据
- en: Amazon Redshift also supports integration with [Amazon DataZone](https://oreil.ly/HtHqd),
    which allows you to discover and share data at scale across organizational boundaries
    with governance and access controls. In [Chapter 7, “Collaboration with Data Sharing”](ch07.html#AR_TGD_CH7),
    you will learn how Amazon DataZone gives you federated data governance where the
    data owners and subject matter experts of that dataset can enforce security and
    access controls on their relevant data assets.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift还支持与[Amazon DataZone](https://oreil.ly/HtHqd)集成，使您能够在组织边界内以规模发现和共享数据，并具有治理和访问控制。在[第7章，“数据共享协作”](ch07.html#AR_TGD_CH7)中，您将了解Amazon
    DataZone如何为您提供联合数据治理，数据集的数据所有者和主题专家可以对其相关数据资产实施安全和访问控制。
- en: Real-World Benefits of Adopting a Modern Data Architecture
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 采用现代数据架构的真实世界益处
- en: Results of research conducted by many analysts show us that organizations who
    make data accessible even by a few percentage points will see a significant increase
    in net income. According to [Richard Joyce, senior analyst at Forrester](https://oreil.ly/VFZJu),
    “Just a 10% increase in data accessibility will result in more than $65 million
    additional net income for a typical Fortune 1000 company.” Analytics can explore
    new markets or new lines of business through insights that can have an impact
    on the top line and cost of operations.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 多位分析师进行的研究结果显示，使数据即使提高几个百分点的组织将会看到净收入显著增加。根据[理查德·乔伊斯，Forrester的高级分析师](https://oreil.ly/VFZJu)的说法，“数据可访问性增加10%将使典型的财富1000强公司的净收入增加6500万美元以上。”分析可以通过对顶线和运营成本有影响的见解来探索新市场或新业务线。
- en: 'Here are some real-world examples:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些真实世界的例子：
- en: Intuit migrated to an Amazon Redshift–based solution in an effort to make data
    more accessible. The solution scaled to more than 7 times the data volume and
    delivered 20 times the performance over the company’s previous solution. This
    resulted in a 25% reduction in team costs, 60% to 80% less time spent on maintenance,
    20% to 40% cost savings overall, and a 90% reduction in time to deploy models.
    This freed up the teams to spend more time developing the next wave of innovations.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Intuit迁移到基于Amazon Redshift的解决方案，以使数据更易访问。该解决方案的规模扩展到了公司以前解决方案的7倍以上，并提供了20倍的性能。这导致团队成本减少了25%，维护时间减少了60%至80%，整体成本节约了20%至40%，部署模型的时间减少了90%。这使团队有更多时间开发下一波创新。
- en: Nasdaq decreased time to market for data access from months to weeks by consolidating
    the company’s data products into a centralized location on the cloud. They used
    Amazon S3 to build a data lake, allowing them to ingest 70 billion records per
    day. The exchange now loads financial market data five hours faster and runs Amazon
    Redshift queries 32% faster.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nasdaq通过将公司的数据产品整合到云上的集中位置，将数据访问的上线时间从几个月缩短到几周。他们使用Amazon S3构建数据湖，每天可以摄入700亿条记录。交易所现在加载金融市场数据比以前快了五个小时，并且Amazon
    Redshift的查询速度提高了32%。
- en: The Expedia Group processes over 600 billion AI predictions per year with AWS
    data services powered by 70 PB of data. Samsung’s 1.1 billion users make 80,000
    requests per second, and Pinterest stores over an exabyte of data on Amazon S3.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Expedia集团每年通过AWS数据服务处理超过6000亿次AI预测，数据量达到70PB。三星的11亿用户每秒发出80,000次请求，Pinterest在Amazon
    S3上存储超过1EB的数据。
- en: Toyota migrated from an on-premises data lake and now collects and combines
    data from in-vehicle sensors, operational systems, and data warehouses at PB scale.
    Their teams have secure access to that data when they need it, giving them the
    autonomy and agility to innovate quickly. Now Toyota can do things like monitor
    vehicle health and resolve issues before they impact customers. Philips built
    a secure and HIPAA-compliant digital cloud platform to serve as a base for application
    suites that could store, interpret, unify, and extract insights from customers’
    data from different sources.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丰田从本地数据湖迁移到云端，并从车载传感器、运营系统和数据仓库中收集和结合PB级别的数据。他们的团队在需要时可以安全地访问这些数据，从而赋予他们快速创新的自主权和灵活性。现在，丰田可以做一些像监控车辆健康状况并在影响客户之前解决问题的事情。飞利浦建立了一个安全和符合HIPAA标准的数字云平台，作为应用套件的基础，可以存储、解释、统一和从不同来源提取客户数据的平台。
- en: Reference Architecture for Modern Data Architecture
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代数据架构参考架构
- en: Now that you understand the benefits of a modern data architecture and the value
    of storing data in both a data lake and a data warehouse, let’s take a look at
    a reference architecture for a data warehouse workload using AWS analytics services.
    [Figure 1-6](#modern_data_reference_architecture_1) illustrates how you can use
    AWS services to implement various aspects of your modern data architecture from
    collecting or extracting data from various sources and applications into your
    Amazon S3 data lake to how you can leverage Amazon Redshift to ingest and process
    data, to how you can use Amazon QuickSight and Amazon SageMaker to analyze the
    data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您了解了现代数据架构的好处以及将数据存储在数据湖和数据仓库中的价值，让我们来看看使用AWS分析服务实现数据仓库工作负载的参考架构。[图1-6](#modern_data_reference_architecture_1)说明了您如何使用AWS服务从各种来源和应用程序中收集或提取数据到您的Amazon
    S3数据湖，以及如何利用Amazon Redshift摄取和处理数据，以及如何使用Amazon QuickSight和Amazon SageMaker分析数据。
- en: '![Modern Data Reference Architecture](assets/ardg_0106.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![现代数据参考架构](assets/ardg_0106.png)'
- en: Figure 1-6\. Modern data reference architecture
  id: totrans-150
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6\. 现代数据参考架构
- en: Data Sourcing
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据采集
- en: The modern data architecture enables you to ingest and analyze data from a variety
    of sources. Many of these sources such as line of business (LOB) applications,
    ERP applications, and CRM applications generate highly structured batches of data
    at fixed intervals. In addition to internal structured sources, you can receive
    data from modern sources such as web applications, mobile devices, sensors, video
    streams, and social media. These modern sources typically generate semistructured
    and unstructured data, often as continuous streams.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现代数据架构使您能够从各种来源接收和分析数据。其中许多来源，如业务线（LOB）应用程序、ERP应用程序和CRM应用程序，会定期生成高度结构化的数据批次。除了内部结构化来源外，您还可以从现代来源（如Web应用程序、移动设备、传感器、视频流和社交媒体）接收数据。这些现代来源通常生成半结构化和非结构化数据，通常作为连续的数据流。
- en: The data is either temporarily or persistently stored in Amazon S3 as a data
    lake in open file formats such as Apache Parquet, Avro, CSV, ORC, and JSON, to
    name a few. The same data from your Amazon S3 data lake can serve as your single
    source of truth and can be used in other analytical services such as Amazon Redshift,
    Amazon Athena, Amazon EMR, and Amazon SageMaker. The data lake allows you to have
    a single place to run analytics across most of your data while the purpose-built
    analytics services provide the speed you need for specific use cases like data
    warehouse, real-time dashboards, and log analytics.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 数据以Amazon S3的形式临时或持久存储为数据湖，采用开放文件格式如Apache Parquet、Avro、CSV、ORC和JSON等。来自您的Amazon
    S3数据湖的相同数据可以作为您的真实数据源，并可用于Amazon Redshift、Amazon Athena、Amazon EMR和Amazon SageMaker等其他分析服务。数据湖允许您在大多数数据上运行分析的单一位置，而专为目的构建的分析服务提供您所需的速度，例如数据仓库、实时仪表板和日志分析。
- en: Extract, Transform, and Load
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取、转换和加载
- en: The ETL layer is responsible for extracting data from multiple sources, transforming
    data based on business rules, and populating cleansed and curated areas of the
    storage layer. It provides the ability to connect to internal and external data
    sources over a variety of protocols. It can ingest and deliver batch as well as
    real-time streaming data into a data warehouse as well as a data lake.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ETL层负责从多个来源提取数据，根据业务规则转换数据，并填充存储层的清理和筛选区域。它可以连接到各种协议的内部和外部数据源。它可以将批处理和实时流数据导入数据仓库以及数据湖中。
- en: To provide highly curated, conformed, and trusted data, prior to storing data,
    you may put the source data through preprocessing, validation, and transformation.
    Changes to data warehouse data and schemas should be tightly governed and validated
    to provide a highly trusted source of truth dataset across business domains.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供高度精选、符合标准和可信的数据，在存储数据之前，您可以通过预处理、验证和转换处理源数据。对数据仓库数据和模式的更改应受严格控制和验证，以提供高度可信的真实数据集，跨业务领域。
- en: A common architecture pattern you may have followed in the past was to store
    frequently accessed data that needed high performance inside a database or data
    warehouse like Amazon Redshift and cold data that was queried occasionally in
    a data lake. For example, a financial or banking organization might need to keep
    over 10 years of historical transactions for legal compliance purposes, but need
    only 2 or 3 years of data for analysis. The modern architecture provides the flexibility
    to store the recent three years of data in local storage, and persist the historical
    data beyond three years to the data lake.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 过去可能采用的一种常见架构模式是将需要高性能的频繁访问数据存储在类似Amazon Redshift的数据库或数据仓库中，而只偶尔查询的冷数据存储在数据湖中。例如，金融或银行组织可能需要保留超过10年的历史交易以符合法律合规要求，但仅需分析2或3年的数据。现代架构提供了灵活性，可以在本地存储中存储最近三年的数据，并将超过三年的历史数据持久化到数据湖中。
- en: Following this pattern, Amazon Redshift has a built-in tiered storage model
    when using the RA3 node type or the serverless deployment option. The storage
    and compute are separated where the data is stored in Amazon Redshift Managed
    Storage (RMS) so you scan scale your compute independent of storage. Amazon Redshift
    manages the hot and cold data by hydrating the frequently used blocks of data
    closer to the compute, replacing less-frequently used data. With this architecture,
    while you can still persist the historical data in your data lake to run analytics
    across other analytics services, you do not have to offload as much, if any, data
    from your data warehouse.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这种模式，当使用RA3节点类型或服务器无关部署选项时，Amazon Redshift具有内置的分层存储模型。存储和计算被分离，数据存储在Amazon
    Redshift托管存储（RMS）中，使您能够独立于存储扩展计算。Amazon Redshift通过将频繁使用的数据块靠近计算来管理热数据和冷数据，替换不经常使用的数据。通过这种架构，虽然您仍然可以将历史数据持久化到数据湖中以在其他分析服务上运行分析，但您不必从数据仓库中卸载太多数据，甚至不需要卸载任何数据。
- en: Storage
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储
- en: The data storage layer is responsible for providing durable, scalable, and cost-effective
    components to store and manage vast quantities of data. The data warehouse and
    data lake natively integrate to provide an integrated cost-effective storage layer
    that supports unstructured and semistructured as well as highly structured and
    modeled data. The storage layer can store data in different states of consumption
    readiness, including raw, trusted-conformed, enriched, and modeled.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 数据存储层负责提供耐用、可扩展和具有成本效益的组件来存储和管理大量数据。数据仓库和数据湖本地集成，提供一体化的成本效益存储层，支持非结构化、半结构化以及高度结构化和建模数据。存储层可以存储数据在不同消费就绪状态下，包括原始数据、信任-符合数据、丰富数据和建模数据。
- en: Storage in the data warehouse
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据仓库中的存储
- en: The data warehouse originated from the need to store and access large volumes
    of data. MPP–based architectures were built to distribute the processing across
    a scalable set of expensive, highly performant compute nodes.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库源于需要存储和访问大量数据。基于MPP架构的系统被设计为在可扩展的一组昂贵且高性能的计算节点上分布处理。
- en: Historically, the data warehouse stored conformed, highly trusted data structured
    into star, snowflake, data vault, or denormalized schemas and was typically sourced
    from highly structured sources such as transactional systems, relational databases,
    and other structured operational sources. The data warehouse was typically loaded
    in batches and performed OLAP queries.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，数据仓库存储符合标准且高度可信的数据，结构化成星型、雪花型、数据保险库或非规范化模式，并且通常来自高度结构化的来源，如事务系统、关系数据库和其他结构化操作来源。数据仓库通常是批量加载并执行OLAP查询。
- en: Amazon Redshift was the first fully managed MPP-based cloud data warehouse,
    supporting all the functions of a traditional data warehouse, but has evolved
    to have elastic storage, reducing the amount of compute nodes needed, store semistructured
    data, access real-time data, and perform predictive analysis. [Figure 1-7](#data_warehouse)
    shows a typical data warehouse workflow.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 是第一个完全托管的基于 MPP 的云数据仓库，支持传统数据仓库的所有功能，但已发展出具有弹性存储、减少所需计算节点数量、存储半结构化数据、访问实时数据并执行预测分析的功能。[图 1-7](#data_warehouse)
    显示了典型的数据仓库工作流程。
- en: '![Typical data warehouse workflow](assets/ardg_0107.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![典型的数据仓库工作流程](assets/ardg_0107.png)'
- en: Figure 1-7\. Typical data warehouse workflow
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-7\. 典型的数据仓库工作流程
- en: Storage in the data lake
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据湖中的存储
- en: A data lake is the centralized data repository that stores all of an organization’s
    data. It supports storage of data in structured, semistructured, and unstructured
    formats and can scale to store exabytes of data. Typically, a data lake is segmented
    into landing, raw, trusted, and curated zones to store data depending on its consumption
    readiness. Because data can be ingested and stored without having to first define
    a schema, a data lake can accelerate ingestion and reduce time needed for preparation
    before data can be explored. The data lake enables analysis of diverse datasets
    using diverse methods, including big data processing and ML. Native integration
    between a data lake and data warehouse also reduces storage costs by allowing
    you to access any of the data lake data you need to explore and load only that
    which is most valuable. A data lake built on AWS uses Amazon S3, as shown in [Figure 1-8](#data_lake),
    as its primary storage platform.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖是存储组织所有数据的集中式数据存储库。它支持结构化、半结构化和非结构化格式的数据存储，并能够扩展存储至 Exabytes 级别。通常，数据湖根据数据的消费准备情况被分为落地、原始、可信和策划区域以存储数据。由于数据可以在不需要首先定义模式的情况下被摄取和存储，数据湖可以加速数据摄入并减少数据探索前的准备时间。数据湖支持使用多种方法对多样化的数据集进行分析，包括大数据处理和机器学习。数据湖与数据仓库之间的原生集成还通过允许您访问所需的任何数据湖数据并仅加载最有价值的数据来降低存储成本。构建在
    AWS 上的数据湖使用 Amazon S3 作为其主要存储平台，如 [图 1-8](#data_lake) 所示。
- en: '![Data Lake](assets/ardg_0108.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![数据湖](assets/ardg_0108.png)'
- en: Figure 1-8\. Use cases for data lake
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-8\. 数据湖的用例
- en: Analysis
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析
- en: You can analyze the data stored in the data lake and data warehouse with interactive
    SQL queries using query editors, visual dashboards using Amazon QuickSight, or
    by running prediction machine learning models using Amazon SageMaker.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用查询编辑器进行交互式 SQL 查询，使用 Amazon QuickSight 的可视化仪表板，或者通过运行预测机器学习模型使用 Amazon
    SageMaker 分析存储在数据湖和数据仓库中的数据。
- en: When using these services, there is no need to continually move and transform
    data, and AWS has native and fully integrated services for core use cases rather
    than a collection of partially integrated services from other vendors.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些服务时，无需不断移动和转换数据，AWS 提供原生且完全集成的核心用例服务，而非来自其他供应商的部分集成服务的集合。
- en: Comparing transactional databases, data warehouses, and data lakes
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较事务性数据库、数据仓库和数据湖
- en: While a transaction database, a data warehouse, and a data lake may all be organized
    into a similar collection of data stored and accessed electronically through simple
    *Structured Query Language* (SQL), let’s take a closer look at key differentiating
    characteristics of each of these.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管事务数据库、数据仓库和数据湖可能都被组织成类似的数据集合，并可以通过简单的 *结构化查询语言*（SQL）存储和访问电子化数据，但让我们更仔细地看看每个的关键区别特征。
- en: A transactional database is a system where the underlying table structures are
    designed for fast and efficient data inserts and updates on individual rows. The
    data model is typically highly normalized, and the storage is designed to store
    a large number of transactions. To support a high transaction volume on particular
    rows of data, all the data in a row is physically stored together on disk (row-based
    storage). This type of database is used for building online transaction processing
    (OLTP) systems. Online purchases, sales orders, stock trades, and banking credits
    or debits are some of examples of use cases for a transactional database.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 事务性数据库是一种系统，其底层表结构设计用于快速高效地对单个行进行数据插入和更新。数据模型通常高度规范化，并且存储设计为存储大量交易。为了支持特定数据行的高交易量，在磁盘上所有数据行都会物理存储在一起（基于行的存储）。这种类型的数据库用于构建在线事务处理（OLTP）系统。在线购买、销售订单、股票交易以及银行的存款或取款是事务性数据库的一些使用案例。
- en: A data warehouse is a database optimized to analyze relational data coming from
    transactional systems and LOB applications and semistructured non-relational data
    from mobile apps, IoT devices, and social media. Data is cleaned, enriched, and
    transformed so it can act as the “single source of truth” that users can trust.
    The data structure and schema are optimized for fast summarizing of large quantities
    of data or large batch processing. The results are used for reporting and analysis.
    Some examples of analytical use cases include analyzing year-over-year retail
    and online sales, trend analysis for customer purchase preferences, and determining
    top 10 profitable products.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库是一种专为分析来自事务系统和LOB应用程序的关系数据以及来自移动应用程序、物联网设备和社交媒体的半结构化非关系型数据而优化的数据库。数据经过清洗、增强和转换，以便作为用户可以信任的“单一数据源”。数据结构和模式被优化为快速汇总大量数据或大批处理。结果用于报告和分析。一些分析用例的示例包括分析年度零售和在线销售、客户购买偏好的趋势分析以及确定前10个利润最高的产品。
- en: The key differentiating characteristics of transactional databases and data
    warehouses are listed in [Table 1-1](#fig:dw_db).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 事务性数据库和数据仓库的关键区别特征列在[表 1-1](#fig:dw_db)中。
- en: Table 1-1\. Data warehouse versus database
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1-1\. 数据仓库与数据库比较
- en: '| Characteristics | Data warehouse | Transactional database |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 特征 | 数据仓库 | 事务性数据库 |'
- en: '| --- | --- | --- |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Suitable workloads | Analytics at scale, reporting, big data | Transaction
    processing, operational reporting |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 适用工作负载 | 大规模分析、报告、大数据 | 事务处理、运营报告 |'
- en: '| Data source | Data collected and normalized from many sources | Data captured
    as-is from a single source, such as a transactional system |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 数据来源 | 从多个来源收集并规范化的数据 | 直接从单一来源（如事务系统）捕获的数据 |'
- en: '| Data capture | Bulk write operations typically on a predetermined batch schedule
    | Optimized for continuous write operations as new data is available to maximize
    transaction throughput |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 数据捕获 | 典型地批量写入操作，通常在预定的批处理时间表上进行 | 优化为连续写入操作，以便在新数据可用时最大化事务吞吐量 |'
- en: '| Data normalization | Denormalized schemas, such as the star schema or snowflake
    schema | Highly normalized, static schemas |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 数据规范化 | 非规范化模式，如星型模式或雪花模式 | 高度规范化的静态模式 |'
- en: '| Data storage | Optimized for simplicity of access and high-speed query performance
    using columnar storage | Optimized for high throughout write operations to a single
    row-oriented physical block |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 数据存储 | 优化为简化访问和高速查询性能，使用列存储 | 优化为对单行物理块进行高吞吐量写操作 |'
- en: '| Data access | Optimized to minimize I/O and maximize data throughput | High
    volumes of small read operations |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 数据访问 | 优化以最小化I/O并最大化数据吞吐量 | 大量小型读操作 |'
- en: A data lake also stores relational data from LOB applications and semistructured
    data, but it can also store completely unstructured data. The structure of the
    data or schema is not defined when data is captured. This means you can store
    data without initial design and create a catalog on top of the data based on business
    user query requirements.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖还存储来自LOB应用程序和半结构化数据的关系数据，但也可以存储完全非结构化的数据。在捕获数据时，数据的结构或模式未定义。这意味着您可以在没有初始设计的情况下存储数据，并根据业务用户查询需求创建目录。
- en: As organizations with data warehouses see the benefits of data lakes, they require
    a platform that enables both use cases. They are evolving their warehouses to
    include data lakes and enable diverse query capabilities.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 随着拥有数据仓库的组织看到数据湖的好处，他们需要一个能够支持两种用例的平台。他们正在发展他们的仓库，以包括数据湖，并实现多样化的查询能力。
- en: '[Table 1-2](#fig:dw_lake) includes key differentiating characteristics of data
    warehouses and data lakes.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 1-2](#fig:dw_lake) 包含数据仓库和数据湖的关键区别特征。'
- en: Table 1-2\. Data warehouse versus data lake
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1-2\. 数据仓库与数据湖
- en: '| Characteristics | Data warehouse | Data lake |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 特征 | 数据仓库 | 数据湖 |'
- en: '| --- | --- | --- |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Data | Relational data from transactional systems, operational databases,
    JSON with streaming ingestion, and line of business applications | All data, including
    structured, semistructured, and unstructured |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 数据 | 来自事务系统、操作数据库、具有流入功能的 JSON 和业务应用程序的关系数据 | 所有数据，包括结构化、半结构化和非结构化数据 |'
- en: '| Schema | Often designed prior to the data warehouse implementation but also
    can be written at the time of analysis (schema-on-write or schema-on-read) | Written
    at the time of analysis (schema-on-read) |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 模式 | 通常在数据仓库实施之前设计，但也可以在分析时编写（写时模式或读时模式） | 在分析时编写（读时模式） |'
- en: '| Price/performance | Fastest query results using local storage | Query results
    getting faster using low-cost storage and decoupling of compute and storage |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 价格/性能 | 使用本地存储获取最快的查询结果 | 使用低成本存储和计算与存储的解耦合，查询结果变得更快 |'
- en: '| Data quality | Highly curated data that serves as the central version of
    the truth | Any data that may or may not be curated (i.e., raw data) |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 数据质量 | 高度策划的数据，用作真实版本的中心 | 可能是或可能不是策划的任何数据（即原始数据） |'
- en: '| Users | Business analysts, data scientists, data architects, and data engineers
    | Business analysts (using curated data), data scientists, data developers, data
    engineers, and data architects |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 用户 | 业务分析师、数据科学家、数据架构师和数据工程师 | 商业分析师（使用策划的数据）、数据科学家、数据开发人员、数据工程师和数据架构师 |'
- en: '| Analytics | Batch reporting, BI, and visualizations, machine learning | Machine
    learning, exploratory analytics, data discovery, streaming, operational analytics,
    big data, and profiling |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 分析 | 批量报告、商业智能和可视化、机器学习 | 机器学习、探索性分析、数据发现、流处理、运营分析、大数据和数据剖析 |'
- en: Data Mesh and Data Fabric
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据网格和数据织物
- en: Data mesh and data fabric are two approaches to implementing a modern data architecture
    in a distributed and complex environment. They share some common principles such
    as the use of distributed architectures and the importance of data quality and
    governance. However, they have different goals and approaches to data management.
    Data mesh is focused on decentralization and autonomy of data domains, while data
    fabric is focused on integration and consistency of data across different sources
    and systems. Data fabric is a top-down technology solution, whereas data mesh
    is a bottom-up approach focusing more on teams and processes and less about architecture
    enforcement.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 数据网格和数据织物是在分布式和复杂环境中实施现代数据架构的两种方法。它们共享一些共同原则，如使用分布式架构和数据质量及治理的重要性。然而，它们在数据管理的目标和方法上有所不同。数据网格专注于数据领域的分散化和自治，而数据织物专注于在不同来源和系统之间实现数据的集成和一致性。数据织物是一种自上而下的技术解决方案，而数据网格是一种自下而上的方法，更注重团队和流程，而不是架构执行。
- en: Data Mesh
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据网格
- en: In a data mesh architecture, data is organized around business capabilities
    or domains, and each domain is responsible for its own data management, quality,
    and governance. The data is treated as a product, with data teams responsible
    for creating and maintaining data products that can be consumed by other teams.
    The goal of data mesh is to improve the agility and scalability of data management
    in a complex and rapidly changing environment by reducing dependencies and improving
    collaboration between teams.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据网格架构中，数据围绕业务能力或领域组织，每个领域负责其自身的数据管理、质量和治理。数据被视为产品，数据团队负责创建和维护可供其他团队消费的数据产品。数据网格的目标是通过减少依赖关系和改善团队之间的协作，提高在复杂和快速变化环境中的数据管理的灵活性和可扩展性。
- en: Data mesh encourages distributed teams to own and architect their domain-oriented
    solution independently how they see fit; refer to [Figure 1-9](#data_mesh_2_2_3_2),
    which depicts domains for Sales, Marketing, Finance, R&D, and their own teams.
    This architecture then asks each team to provide data as a product via a self-service
    infrastructure platform, as shown in the last slab of [Figure 1-9](#data_mesh_2_2_3_2).
    For the data mesh to maintain global interoperability, the oversight is the responsibility
    of a federated governance team, as shown in the top slab of the figure.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 数据网格鼓励分布式团队独立拥有和构建他们认为合适的面向领域的解决方案；参见 [图 1-9](#data_mesh_2_2_3_2)，展示了销售、营销、财务、研发以及各自团队的领域。然后要求每个团队通过自助式基础设施平台提供数据作为产品，如
    [图 1-9](#data_mesh_2_2_3_2) 的最后一块所示。为了数据网格能够保持全球互操作性，监督责任由联邦治理团队负责，如图的顶部所示。
- en: '![A data mesh architecture](assets/ardg_0109.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![数据网格架构](assets/ardg_0109.png)'
- en: Figure 1-9\. A data mesh architecture
  id: totrans-206
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-9\. 数据网格架构
- en: This domain-oriented data ownership and architecture allows the ecosystem to
    scale as needed. Providing data as a product enables easy discovery across many
    domains. A self-service infrastructure platform enables the various domain teams
    to create data products as well as to consume data products by abstracting the
    complexity. The federated governance teams are responsible for defining global
    standardization rules for interoperability of the entire data mesh ecosystem and
    more importantly, to balance what needs global standardization and what should
    be left for the domain-oriented teams to decide.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这种面向领域的数据所有权和架构允许生态系统按需扩展。提供数据作为产品能够在多个领域之间轻松发现。自助式基础设施平台使各个领域团队能够通过抽象复杂性创建和消费数据产品。联邦治理团队负责为整个数据网格生态系统的互操作性定义全球标准化规则，更重要的是平衡需要全球标准化的内容和应由面向领域的团队决定的内容。
- en: With each team freely architecting their own solutions, the Amazon Redshift
    data sharing feature can provide the data infrastructure platform required to
    stand up the data mesh architecture. With [Amazon DataZone](https://oreil.ly/HtHqd),
    you can build a data mesh architecture where you can share data products with
    consumers with the decentralized and governed model.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 每个团队都可以自由构建自己的解决方案，Amazon Redshift 数据共享功能可以提供构建数据网格架构所需的数据基础设施平台。通过 [Amazon
    DataZone](https://oreil.ly/HtHqd)，您可以构建一个数据网格架构，其中您可以使用去中心化和治理模型与消费者共享数据产品。
- en: Data Fabric
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据布局
- en: '*Data fabric* is an approach to data integration and orchestration that emphasizes
    data consistency, quality, and accessibility across different sources and systems.
    In a data fabric architecture, data is organized into a unified virtual layer
    that provides a single view of the data to the users, regardless of its location
    or format. The data is transformed, enriched, and harmonized as it moves through
    the fabric, using a combination of automated and manual processes. The goal of
    data fabric is to simplify data access and analysis and to enable organizations
    to make faster and more accurate decisions based on trusted data.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据布局* 是一种数据集成和编排方法，强调跨不同来源和系统的数据一致性、质量和可访问性。在数据布局架构中，数据组织成统一的虚拟层，为用户提供数据的单一视图，无论其位置或格式如何。数据在通过布局时进行转换、丰富和协调，使用自动化和手动处理的组合。数据布局的目标是简化数据访问和分析，使组织能够基于可信数据做出更快速和更准确的决策。'
- en: Alongside the data that has been gathered are the challenges associated with
    access, discovery, integration, security, governance, and lineage. The data fabric
    solution delivers capabilities to solve these challenges.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 随着收集到的数据，伴随而来的是与访问、发现、整合、安全性、治理和谱系相关的挑战。数据布局解决方案提供了解决这些挑战的能力。
- en: 'The data fabric is a metadata-driven method of connecting data management tools
    to enable self-service data consumption. Referring to [Figure 1-10](#data_fabric_Eckerson_group),
    the central elements represent the tools provided by the data fabric. The actual
    data sources or silos (shown on the left) remain distributed, but the management
    is unified by the data fabric overlay. Having a singular data fabric layer over
    all data sources provides a unified experience to personas (shown in the top section:
    Reporting, Analytics and Data Science) that can both provide and use the data
    across the organization. The various components typically interchange data in
    JSON format via APIs.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 数据织物是一种基于元数据驱动的方法，用于连接数据管理工具，以实现自助式数据消费。参考[图 1-10](#data_fabric_Eckerson_group)，中央元素代表数据织物提供的工具。实际数据源或数据孤岛（显示在左侧）仍然分布，但通过数据织物覆盖进行统一管理。在所有数据源上建立单一的数据织物层为人物角色（在顶部显示：报告、分析和数据科学）提供了统一的体验，这些角色既可以提供数据，也可以使用整个组织的数据。各个组件通常通过API以JSON格式交换数据。
- en: The data fabric can be considered a living, breathing, and continuously learning
    element by incorporating AI and machine learning components that aid in automatic
    discovery and the lineage processes. The challenge here is to obtain agreement
    for the unified management from the various departments and teams owning and maintaining
    their individual datasets.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 数据织物可以被视为一个生动、具有持续学习能力的元素，它包括AI和机器学习组件，帮助自动发现和谱系过程。这里的挑战在于获得各部门和团队对统一管理的一致认可，这些部门和团队负责拥有和维护其各自的数据集。
- en: '![A data fabric consists of multiple data management layers (Image source:
    Eckerson Group)](assets/ardg_0110.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![数据织物由多个数据管理层组成（图片来源：Eckerson Group）](assets/ardg_0110.png)'
- en: 'Figure 1-10\. A data fabric consists of multiple data management layers (Image
    source: Eckerson Group)'
  id: totrans-215
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-10\. 数据织物由多个数据管理层组成（图片来源：Eckerson Group）
- en: Amazon Redshift’s integration with [AWS Lake Formation](https://oreil.ly/9Gi-I)
    can be used to provide ease of access, security, and governance. In [Chapter 8,
    “Securing and Governing Data”](ch08.html#AR_TGD_CH8), you’ll learn how to set
    up access controls when working with AWS Lake Formation. And, [Amazon SageMaker](https://oreil.ly/C0ChL)
    can be leveraged to build the machine learning capabilities of the data fabric
    architecture on AWS. In [Chapter 6, “Amazon Redshift Machine Learning”](ch06.html#AR_TGD_CH6),
    you’ll learn how Amazon Redshift is tightly integrated with Amazon SageMaker.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift与[AWS Lake Formation](https://oreil.ly/9Gi-I)的集成可用于提供访问便捷性、安全性和治理。在[第
    8 章，“安全和数据治理”](ch08.html#AR_TGD_CH8)中，您将学习如何在使用AWS Lake Formation时设置访问控制。此外，[Amazon
    SageMaker](https://oreil.ly/C0ChL)可以用来在AWS上构建数据织物架构的机器学习能力。在[第 6 章，“Amazon Redshift
    机器学习”](ch06.html#AR_TGD_CH6)中，您将了解Amazon Redshift如何与Amazon SageMaker紧密集成。
- en: Summary
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered how organizations can become data-driven by building
    a modern data architecture using the purpose-built AWS for data services. A modern
    data strategy will help you drive your roadmap to migrate your data workloads
    to the cloud, and we saw how Amazon Redshift is the foundation for the modern
    data architecture.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们探讨了如何通过使用专为数据服务而构建的现代数据架构，使组织变得数据驱动。现代数据策略将帮助您推动迁移数据工作负载到云端的路线图，我们看到了Amazon
    Redshift如何成为现代数据架构的基础。
- en: The remaining chapters explore how you can use Amazon Redshift to transform
    your data workloads to the cloud, democratize data, and provide business insights
    to all your users. You will also learn how you can implement some of the modern
    architectures like data mesh using Amazon Redshift and leverage the tight integration
    with other AWS native analytics services.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的章节探讨了如何使用Amazon Redshift将数据工作负载转换到云端，民主化数据，并为所有用户提供业务洞见。您还将学习如何使用Amazon Redshift实现数据网格等现代架构，并利用其与其他AWS原生分析服务的紧密集成。
