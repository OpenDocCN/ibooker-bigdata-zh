- en: 6  Regular Expressions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 正则表达式
- en: 原文：[https://ds100.org/course-notes/regex/regex.html](https://ds100.org/course-notes/regex/regex.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://ds100.org/course-notes/regex/regex.html](https://ds100.org/course-notes/regex/regex.html)
- en: '*Learning Outcomes* ***   Understand Python string manipulation, `pandas` `Series`
    methods'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*学习成果* ***   了解Python字符串操作，`pandas` `Series`方法'
- en: Parse and create regex, with a reference table
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析和创建正则表达式，使用参考表
- en: Use vocabulary (closure, metacharacters, groups, etc.) to describe regex metacharacters**  ****This
    content is covered in lectures 6 and 7.**
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用词汇（闭包、元字符、组等）描述正则表达式元字符**  ****这些内容在第6和第7讲中涵盖。**
- en: 6.1 Why Work with Text?
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 为什么处理文本？
- en: 'Last lecture, we learned of the difference between quantitative and qualitative
    variable types. The latter includes string data — the primary focus of lecture
    6\. In this note, we’ll discuss the necessary tools to manipulate text: `python`
    string manipulation and regular expressions.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 上一堂课，我们了解了定量和定性变量类型之间的区别。后者包括字符串数据——第6讲的主要焦点。在本笔记中，我们将讨论操纵文本所需的工具：`python`字符串操作和正则表达式。
- en: There are two main reasons for working with text.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 处理文本有两个主要原因。
- en: 'Canonicalization: Convert data that has multiple formats into a standard form.'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 规范化：将具有多种格式的数据转换为标准形式。
- en: By manipulating text, we can join tables with mismatched string labels.
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过操纵文本，我们可以将具有不匹配字符串标签的表格连接起来。
- en: Extract information into a new feature.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将信息提取到新特征中。
- en: For example, we can extract date and time features from text.
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，我们可以从文本中提取日期和时间特征。
- en: 6.2 Python String Methods
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 Python字符串方法
- en: First, we’ll introduce a few methods useful for string manipulation. The following
    table includes a number of string operations supported by `python` and `pandas`.
    The `python` functions operate on a single string, while their equivalent in `pandas`
    are **vectorized** — they operate on a `Series` of string data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍一些有用的字符串操作方法。以下表格包括`python`和`pandas`支持的一些字符串操作。`python`函数操作单个字符串，而它们在`pandas`中的等效函数是**矢量化**的——它们操作字符串数据的`Series`。
- en: '| Operation | Python | `Pandas` (`Series`) |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | Python | `Pandas` (`Series`) |'
- en: '| --- | --- | --- |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Transformation |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 转换 |'
- en: '`s.lower()`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s.lower()`'
- en: '`s.upper()`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s.upper()`'
- en: '|'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`ser.str.lower()`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ser.str.lower()`'
- en: '`ser.str.upper()`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ser.str.upper()`'
- en: '|'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Replacement + Deletion |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 替换 + 删除 |'
- en: '`s.replace(_)`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s.replace(_)`'
- en: '|'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`ser.str.replace(_)`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ser.str.replace(_)`'
- en: '|'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Split |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 分割 |'
- en: '`s.split(_)`'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s.split(_)`'
- en: '|'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`ser.str.split(_)`'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ser.str.split(_)`'
- en: '|'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Substring |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 子字符串 |'
- en: '`s[1:4]`'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s[1:4]`'
- en: '|'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`ser.str[1:4]`'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ser.str[1:4]`'
- en: '|'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Membership |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 成员资格 |'
- en: '`''_'' in s`'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''_'' in s`'
- en: '|'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`ser.str.contains(_)`'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ser.str.contains(_)`'
- en: '|'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Length |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 长度 |'
- en: '`len(s)`'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`len(s)`'
- en: '|'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`ser.str.len()`'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ser.str.len()`'
- en: '|'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: We’ll discuss the differences between `python` string functions and `pandas`
    `Series` methods in the following section on canonicalization.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在规范化的下一节讨论`python`字符串函数和`pandas` `Series`方法之间的区别。
- en: 6.2.1 Canonicalization
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 规范化
- en: Assume we want to merge the given tables.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要合并给定的表格。
- en: <details><summary>Code</summary>
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE0]</details>'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE0]</details>'
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|  | County | State |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | 县 | 州 |'
- en: '| --- | --- | --- |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0 | De Witt County | IL |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 德维特县 | IL |'
- en: '| 1 | Lac qui Parle County | MN |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 拉克奎帕尔县 | MN |'
- en: '| 2 | Lewis and Clark County | MT |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 路易斯和克拉克县 | MT |'
- en: '| 3 | St John the Baptist Parish | LS |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 圣约翰大教堂教区 | LS |'
- en: '|  | County | Population |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '|  | 县 | 人口 |'
- en: '| --- | --- | --- |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0 | DeWitt | 16798 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 德维特 | 16798 |'
- en: '| 1 | Lac Qui Parle | 8067 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 拉克奎帕尔 | 8067 |'
- en: '| 2 | Lewis & Clark | 55716 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 路易斯和克拉克 | 55716 |'
- en: '| 3 | St. John the Baptist | 43044 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 圣约翰大教堂 | 43044 |'
- en: Last time, we used a **primary key** and **foreign key** to join two tables.
    While neither of these keys exist in our `DataFrame`s, the `"County"` columns
    look similar enough. Can we convert these columns into one standard, canonical
    form to merge the two tables?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 上次，我们使用**主键**和**外键**来连接两个表格。虽然这两个键都不存在于我们的`DataFrame`中，但是`"County"`列看起来足够相似。我们能否将这些列转换为一个标准的规范形式，以便合并这两个表格？
- en: 6.2.1.1 Canonicalization with `python` String Manipulation
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1.1 使用`python`字符串操作进行规范化
- en: The following function uses `python` string manipulation to convert a single
    county name into canonical form. It does so by eliminating whitespace, punctuation,
    and unnecessary text.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数使用`python`字符串操作将单个县名转换为规范形式。它通过消除空格、标点和不必要的文本来实现这一点。
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We will use the `pandas` `map` function to apply the `canonicalize_county` function
    to every row in both `DataFrame`s. In doing so, we’ll create a new column in each
    called `clean_county_python` with the canonical form.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`pandas` `map`函数将`canonicalize_county`函数应用于每个`DataFrame`中的每一行。这样做，我们将在每个`DataFrame`中创建一个名为`clean_county_python`的新列，其中包含规范形式。
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '|  | County | State | clean_county_python |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | 县 | 州 | clean_county_python |'
- en: '| --- | --- | --- | --- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | De Witt County | IL | dewitt |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 德维特县 | IL | 德维特 |'
- en: '| 1 | Lac qui Parle County | MN | lacquiparle |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 拉克奎帕尔县 | MN | 拉克奎帕尔 |'
- en: '| 2 | Lewis and Clark County | MT | lewisandclark |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 路易斯和克拉克县 | MT | 路易斯和克拉克 |'
- en: '| 3 | St John the Baptist Parish | LS | stjohnthebaptist |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 圣约翰大教堂教区 | LS | 圣约翰大教堂 |'
- en: '|  | County | Population | clean_county_python |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  | 县 | 人口 | clean_county_python |'
- en: '| --- | --- | --- | --- |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | DeWitt | 16798 | dewitt |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 德维特 | 16798 | 德维特 |'
- en: '| 1 | Lac Qui Parle | 8067 | lacquiparle |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 拉克奎帕尔 | 8067 | 拉克奎帕尔 |'
- en: '| 2 | Lewis & Clark | 55716 | lewisandclark |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 路易斯和克拉克 | 55716 | 路易斯和克拉克 |'
- en: '| 3 | St. John the Baptist | 43044 | stjohnthebaptist |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 圣约翰大教堂 | 43044 | 圣约翰大教堂 |'
- en: 6.2.1.2 Canonicalization with Pandas Series Methods
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1.2 使用Pandas Series方法进行规范化
- en: Alternatively, we can use `pandas` `Series` methods to create this standardized
    column. To do so, we must call the `.str` attribute of our `Series` object prior
    to calling any methods, like `.lower` and `.replace`. Notice how these method
    names match their equivalent built-in Python string functions.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用`pandas` `Series`方法来创建这个标准化的列。为此，我们必须在调用任何方法之前调用我们`Series`对象的`.str`属性，比如`.lower`和`.replace`。注意这些方法名称与它们在内置的Python字符串函数中的等效函数名称相匹配。
- en: Chaining multiple `Series` methods in this manner eliminates the need to use
    the `map` function (as this code is vectorized).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式链接多个 `Series` 方法可以消除使用 `map` 函数的需要（因为这段代码是矢量化的）。
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '|  | County | Population | clean_county_python | clean_county_pandas |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | 县 | 人口 | clean_county_python | clean_county_pandas |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | DeWitt | 16798 | dewitt | dewitt |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 0 | DeWitt | 16798 | dewitt | dewitt |'
- en: '| 1 | Lac Qui Parle | 8067 | lacquiparle | lacquiparle |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Lac Qui Parle | 8067 | lacquiparle | lacquiparle |'
- en: '| 2 | Lewis & Clark | 55716 | lewisandclark | lewisandclark |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Lewis & Clark | 55716 | lewisandclark | lewisandclark |'
- en: '| 3 | St. John the Baptist | 43044 | stjohnthebaptist | stjohnthebaptist |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 3 | St. John the Baptist | 43044 | stjohnthebaptist | stjohnthebaptist |'
- en: '|  | County | State | clean_county_python | clean_county_pandas |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | 县 | 州 | clean_county_python | clean_county_pandas |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | De Witt County | IL | dewitt | dewitt |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 0 | De Witt County | IL | dewitt | dewitt |'
- en: '| 1 | Lac qui Parle County | MN | lacquiparle | lacquiparle |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Lac qui Parle County | MN | lacquiparle | lacquiparle |'
- en: '| 2 | Lewis and Clark County | MT | lewisandclark | lewisandclark |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Lewis and Clark County | MT | lewisandclark | lewisandclark |'
- en: '| 3 | St John the Baptist Parish | LS | stjohnthebaptist | stjohnthebaptist
    |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 3 | St John the Baptist Parish | LS | stjohnthebaptist | stjohnthebaptist
    |'
- en: 6.2.2 Extraction
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 提取
- en: Extraction explores the idea of obtaining useful information from text data.
    This will be particularily important in model building, which we’ll study in a
    few weeks.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 提取探讨了从文本数据中获取有用信息的想法。这在模型构建中将特别重要，我们将在几周内学习这个问题。
- en: Say we want to read some data from a `.txt` file.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要从一个 `.txt` 文件中读取一些数据。
- en: '[PRE7]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Suppose we want to extract the day, month, year, hour, minutes, seconds, and
    time zone. Unfortunately, these items are not in a fixed position from the beginning
    of the string, so slicing by some fixed offset won’t work.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要提取日、月、年、小时、分钟、秒和时区。不幸的是，这些项目不是从字符串的开头固定位置开始的，所以通过一些固定偏移量进行切片是行不通的。
- en: Instead, we can use some clever thinking. Notice how the relevant information
    is contained within a set of brackets, further seperated by `/` and `:`. We can
    hone in on this region of text, and split the data on these characters. `Python`’s
    built-in `.split` function makes this easy.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以进行一些巧妙的思考。注意到相关信息包含在一组方括号中，进一步由 `/` 和 `:` 分隔。我们可以聚焦在文本的这个区域，并在这些字符上分割数据。`Python`
    的内置 `.split` 函数使这变得容易。
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'There are two problems with this code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码有两个问题：
- en: '`Python`’s built-in functions limit us to extract data one record at a time,'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Python` 的内置函数限制我们一次只能提取一条记录的数据，'
- en: This can be resolved using the `map` function or `pandas` `Series` methods.
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这可以使用 `map` 函数或 `pandas` `Series` 方法来解决。
- en: The code is quite verbose.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这段代码相当冗长。
- en: This is a larger issue that is trickier to solve
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个更大的问题，更难解决
- en: In the next section, we’ll introduce regular expressions - a tool that solves
    problem 2.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍正则表达式 - 一种解决问题 2 的工具。
- en: 6.3 Regex Basics
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 正则表达式基础知识
- en: A **regular expression (“RegEx”)** is a sequence of characters that specifies
    a search pattern. They are written to extract specific information from text.
    Regular expressions are essentially part of a smaller programming language embedded
    in `python`, made available through the `re` module. As such, they have a stand-alone
    syntax and methods for various capabilities.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**正则表达式（“RegEx”）**是一个指定搜索模式的字符序列。它们被编写用来从文本中提取特定信息。正则表达式本质上是 `python` 中嵌入的一种较小的编程语言，通过
    `re` 模块提供。因此，它们有独立的语法和各种功能的方法。'
- en: Regular expressions are useful in many applications beyond data science. For
    example, Social Security Numbers (SSNs) are often validated with regular expressions.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式在数据科学之外的许多应用中都很有用。例如，社会安全号码（SSN）经常使用正则表达式进行验证。
- en: '[PRE11]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'There are a ton of resources to learn and experiment with regular expressions.
    A few are provided below:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多资源可以学习和实验正则表达式。以下是一些资源：
- en: '[Official Regex Guide](https://docs.python.org/3/howto/regex.html)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[官方正则表达式指南](https://docs.python.org/3/howto/regex.html)'
- en: '[Data 100 Reference Sheet](https://ds100.org/sp22/resources/assets/hw/regex_reference.pdf)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data 100 参考资料](https://ds100.org/sp22/resources/assets/hw/regex_reference.pdf)'
- en: '[Regex101.com](https://regex101.com/)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Regex101.com](https://regex101.com/)'
- en: Be sure to check `Python` under the category on the left.
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保在左侧的类别下选择 `Python`。
- en: 6.3.1 Basics Regex Syntax
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.1 基础正则表达式语法
- en: There are four basic operations with regular expressions.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式有四种基本操作。
- en: '| Operation | Order | Syntax Example | Matches | Doesn’t Match |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 顺序 | 语法示例 | 匹配 | 不匹配 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| `Or`: `&#124;` | 4 | AA&#124;BAAB | AA BAAB | every other string |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| `或`：`&#124;` | 4 | AA&#124;BAAB | AA BAAB | 每隔一个字符串 |'
- en: '| `Concatenation` | 3 | AABAAB | AABAAB | every other string |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| `连接` | 3 | AABAAB | AABAAB | 每隔一个字符串 |'
- en: '| `Closure`: `*` (zero or more) | 2 | AB*A | AA ABBBBBBA | AB ABABA |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| `闭包`：`*`（零个或多个） | 2 | AB*A | AA ABBBBBBA | AB ABABA |'
- en: '| `Group`: `()` (parenthesis) | 1 | A(A&#124;B)AAB'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '| `分组`：`()`（括号） | 1 | A(A&#124;B)AAB'
- en: (AB)*A | AAAAB ABAAB
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: (AB)*A | AAAAB ABAAB
- en: A
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: A
- en: ABABABABA | every other string
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ABABABABA | 每隔一个字符串
- en: AA
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: AA
- en: ABBA |
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ABBA |
- en: Notice how these metacharacter operations are ordered. Rather than being literal
    characters, these **metacharacters** manipulate adjacent characters. `()` takes
    precedence, followed by `*`, and finally `|`. This allows us to differentiate
    between very different regex commands like `AB*` and `(AB)*`. The former reads
    “`A` then zero or more copies of `B`”, while the latter specifies “zero or more
    copies of `AB`”.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这些元字符操作的顺序。这些**元字符**不是字面字符，而是操作相邻字符。`()` 优先级最高，然后是 `*`，最后是 `|`。这使我们能够区分非常不同的正则表达式命令，比如
    `AB*` 和 `(AB)*`。前者读作“`A` 然后零个或多个 `B`”，而后者指定“零个或多个 `AB`”。
- en: 6.3.1.1 Examples
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.1.1 示例
- en: '**Question 1**: Give a regular expression that matches `moon`, `moooon`, etc.
    Your expression should match any even number of `o`s except zero (i.e. don’t match
    `mn`).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题 1**：给出一个匹配 `moon`、`moooon` 等的正则表达式。你的表达式应该匹配任何偶数个 `o`，但不包括零个（即不匹配 `mn`）。'
- en: '**Answer 1**: `moo(oo)*n`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案 1**：`moo(oo)*n`'
- en: Hardcoding `oo` before the capture group ensures that `mn` is not matched.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在捕获组之前硬编码`oo`可以确保不匹配`mn`。
- en: A capture group of `(oo)*` ensures the number of `o`’s is even.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(oo)*`的捕获组确保`o`的数量是偶数。'
- en: '**Question 2**: Using only basic operations, formulate a regex that matches
    `muun`, `muuuun`, `moon`, `moooon`, etc. Your expression should match any even
    number of `u`s or `o`s except zero (i.e. don’t match `mn`).'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题2**：只使用基本操作，制定一个正则表达式，匹配`muun`，`muuuun`，`moon`，`moooon`等。你的表达式应该匹配任何偶数个`u`或`o`，但不包括零（即不匹配`mn`）。'
- en: '**Answer 2**: `m(uu(uu)*|oo(oo)*)n`'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案2**：`m(uu(uu)*|oo(oo)*)n`'
- en: The leading `m` and trailing `n` ensures that only strings beginning with `m`
    and ending with `n` are matched.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以`m`开头和`n`结尾确保只匹配以`m`开头和以`n`结尾的字符串。
- en: Notice how the outer capture group surrounds the `|`.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意外部捕获组围绕着`|`。
- en: Consider the regex `m(uu(uu)*)|(oo(oo)*)n`. This incorrectly matches `muu` and
    `oooon`.
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑正则表达式`m(uu(uu)*)|(oo(oo)*)n`。这错误地匹配了`muu`和`oooon`。
- en: Each OR clause is everything to the left and right of `|`. The incorrect solution
    matches only half of the string, and ignores either the beginning `m` or trailing
    `n`.
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个OR子句是`|`左右两侧的所有内容。不正确的解决方案只匹配字符串的一半，并且忽略了`m`开头或`n`结尾。
- en: A set of parenthesis must surround `|`. That way, each OR clause is everything
    to the left and right of `|` **within** the group. This ensures both the beginning
    `m` *and* trailing `n` are matched.
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须在`|`周围加上括号。这样，每个OR子句都是`|`**组内**左右两侧的所有内容。这确保了`m`开头*和*`n`结尾都被匹配。
- en: 6.4 Regex Expanded
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 正则表达式扩展
- en: Provided below are more complex regular expression functions.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下提供了更复杂的正则表达式函数。
- en: '| Operation | Syntax Example | Matches | Doesn’t Match |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 语法示例 | 匹配 | 不匹配 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| `Any Character`: `.` (except newline) | .U.U.U. | CUMULUS JUGULUM | SUCCUBUS
    TUMULTUOUS |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| `任意字符`：`.`（除换行符外） | .U.U.U. | CUMULUS JUGULUM | SUCCUBUS TUMULTUOUS |'
- en: '| `Character Class`: `[]` (match one character in `[]`) | [A-Za-z][a-z]* |
    word Capitalized | camelCase 4illegal |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| `字符类`：`[]`（匹配`[]`中的一个字符） | [A-Za-z][a-z]* | 单词首字母大写 | 驼峰命名 4illegal |'
- en: '| `Repeated "a" Times`: `{a}`  | j[aeiou]{3}hn | jaoehn jooohn | jhn jaeiouhn
    |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| `重复"a"次`：`{a}`  | j[aeiou]{3}hn | jaoehn jooohn | jhn jaeiouhn |'
- en: '| `Repeated "from a to b" Times`: `{a, b}`  | j[0u]{1,2}hn | john juohn | jhn
    jooohn |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| `重复"a到b"次`：`{a, b}`  | j[0u]{1,2}hn | john juohn | jhn jooohn |'
- en: '| `At Least One`: `+` | jo+hn | john joooooohn | jhn jjohn |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| `至少一个`：`+` | jo+hn | john joooooohn | jhn jjohn |'
- en: '| `Zero or One`: `?` | joh?n | jon john | any other string |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| `零或一次`：`?` | joh?n | jon john | 任何其他字符串 |'
- en: 'A character class matches a single character in it’s class. These characters
    can be hardcoded – in the case of `[aeiou]` – or shorthand can be specified to
    mean a range of characters. Examples include:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 字符类匹配其类中的单个字符。这些字符可以是硬编码的 - 在`[aeiou]`的情况下 - 或者可以指定简写以表示一系列字符。例如：
- en: '`[A-Z]`: Any capitalized letter'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[A-Z]`：任何大写字母'
- en: '`[a-z]`: Any lowercase letter'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[a-z]`：任何小写字母'
- en: '`[0-9]`: Any single digit'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[0-9]`：任何单个数字'
- en: '`[A-Za-z]`: Any capitalized of lowercase letter'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[A-Za-z]`：任何大写或小写字母'
- en: '`[A-Za-z0-9]`: Any capitalized or lowercase letter or single digit'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[A-Za-z0-9]`：任何大写或小写字母或单个数字'
- en: 6.4.0.1 Examples
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.0.1 示例
- en: Let’s analyze a few examples of complex regular expressions.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一些复杂正则表达式的例子。
- en: '| Matches | Does Not Match |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 匹配 | 不匹配 |'
- en: '| --- | --- |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '|'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`.*SPB.*`'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.*SPB.*`'
- en: '|  |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| RASPBERRY SPBOO | SUBSPACE SUBSPECIES |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| RASPBERRY SPBOO | SUBSPACE SUBSPECIES |'
- en: '|'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`[0-9]{3}-[0-9]{2}-[0-9]{4}`'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[0-9]{3}-[0-9]{2}-[0-9]{4}`'
- en: '|  |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| 231-41-5121 573-57-1821 | 231415121 57-3571821 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 231-41-5121 573-57-1821 | 231415121 57-3571821 |'
- en: '|'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '`[a-z]+@([a-z]+\.)+(edu&#124;com)`'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[a-z]+@([a-z]+\.)+(edu&#124;com)`'
- en: '|  |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '| horse@pizza.com horse@pizza.food.com | frank_99@yahoo.com hug@cs |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| horse@pizza.com horse@pizza.food.com | frank_99@yahoo.com hug@cs |'
- en: '**Explanations**'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**解释**'
- en: '`.*SPB.*` only matches strings that contain the substring `SPB`.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.*SPB.*`只匹配包含子字符串`SPB`的字符串。'
- en: The `.*` metacharacter matches any amount of non-negative characters. Newlines
    do not count.
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.*`元字符匹配任意数量的非负字符。换行符不计入其中。'
- en: This regular expression matches 3 of any digit, then a dash, then 2 of any digit,
    then a dash, then 4 of any digit.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个正则表达式匹配任意3个数字，然后是一个破折号，然后是任意2个数字，然后是一个破折号，然后是任意4个数字。
- en: You’ll recognize this as the familiar Social Security Number regular expression.
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你会认出这是熟悉的社会安全号码正则表达式。
- en: Matches any email with a `com` or `edu` domain, where all characters of the
    email are letters.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 匹配任何带有`com`或`edu`域的电子邮件，其中电子邮件的所有字符都是字母。
- en: At least one `.` must precede the domain name. Including a backslash `\` before
    any metacharacter (in this case, the `.`) tells RegEx to match that character
    exactly.
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 域名前必须至少有一个`.`。在任何元字符（在本例中是`.`）之前包括一个反斜杠`\`告诉正则表达式精确匹配该字符。
- en: 6.5 Convenient Regex
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 方便的正则表达式
- en: Here are a few more convenient regular expressions.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些更方便的正则表达式。
- en: '| Operation | Syntax Example | Matches | Doesn’t Match |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 语法示例 | 匹配 | 不匹配 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| `built in character class` | `\w+` `\d+`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '| `内置字符类` | `\w+` `\d+`'
- en: '`\s+`'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '`\s+`'
- en: '| Fawef_03 231123'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '| Fawef_03 231123'
- en: '`whitespace` | this person 423 people'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`空白` | this person 423 people'
- en: '`non-whitespace` |'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`非空白` |'
- en: '| `character class negation`: `[^]` (everything except the given characters)
    | [^a-z]+. | PEPPERS3982 17211!↑å | porch CLAmS |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| `字符类否定`：`[^]`（除了给定的字符之外的所有内容） | [^a-z]+. | PEPPERS3982 17211!↑å | porch CLAmS
    |'
- en: '| `escape character`: `\` (match the literal next character) | cow\.com | cow.com
    | cowscom |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| `转义字符`：`\`（匹配下一个字符的字面意义） | cow\.com | cow.com | cowscom |'
- en: '| `beginning of line`: `^` | ^ark | ark two ark o ark | dark |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| `行首`：`^` | ^ark | ark two ark o ark | dark |'
- en: '| `end of line`: `$` | ark$ | dark ark o ark | ark two |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '`行尾`：`$` | ark$ | dark ark o ark | ark two |'
- en: '| `lazy version of zero or more` : `*?` | 5.*?5 | 5005 55 | 5005005 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| `零或更多的懒惰版本`：`*?` | 5.*?5 | 5005 55 | 5005005 |'
- en: 6.5.1 Greediness
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.1 贪婪性
- en: 'In order to fully understand the last operation in the table, we have to discuss
    greediness. RegEx is greedy – it will look for the longest possible match in a
    string. To motivate this with an example, consider the pattern `<div>.*</div>`.
    Given the sentence below, we would hope that the bolded portions would be matched:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分理解表中的最后一个操作，我们必须讨论贪婪性。RegEx是贪婪的 - 它会在字符串中寻找最长可能的匹配。为了举例说明这一点，考虑模式`<div>.*</div>`。给定下面的句子，我们希望粗体部分会被匹配：
- en: “This is a **<div>example</div>** of greediness <div>in</div> regular expressions.”
    ”
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: “这是一个**<div>示例</div>**关于正则表达式中的贪婪性的例子。”
- en: 'In actuality, the way RegEx processes the text given that pattern is as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，RegEx处理给定模式的文本的方式如下：
- en: “Look for the exact string <>”
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “寻找确切的字符串<>”
- en: then, “look for any character 0 or more times”
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，“寻找任何字符0次或更多次”
- en: then, “look for the exact string </div>”
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，“寻找确切的字符串</div>”
- en: The result would be all the characters starting from the leftmost <div> and
    the rightmost </div> (inclusive). We can fix this making our the pattern non-greedy,
    `<div>.*?</div>`. You can read up more on the documentation [here](https://docs.python.org/3/howto/regex.html#greedy-versus-non-greedy).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将是从最左边的<div>到最右边的</div>（包括在内）的所有字符。我们可以通过使我们的模式非贪婪来修复这个问题，`<div>.*?</div>`。您可以在文档中阅读更多信息[这里](https://docs.python.org/3/howto/regex.html#greedy-versus-non-greedy)。
- en: 6.5.2 Examples
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.2 示例
- en: Let’s revist our earlier problem of extracting date/time data from the given
    `.txt` files. Here is how the data looked.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新审视一下从给定的`.txt`文件中提取日期/时间数据的早期问题。数据看起来是这样的。
- en: '[PRE13]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Question**: Give a regular expression that matches everything contained within
    and including the brackets - the day, month, year, hour, minutes, seconds, and
    time zone.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：给出一个正则表达式，匹配括号内和包括括号在内的所有内容 - 天，月，年，小时，分钟，秒和时区。'
- en: '**Answer**: `\[.*\]`'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案**：`\[.*\]`'
- en: Notice how matching the literal `[` and `]` is necessary. Therefore, an escape
    character `\` is required before both `[` and `]` — otherwise these metacharacters
    will match character classes.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意匹配字面上的`[`和`]`是必要的。因此，在`[`和`]`之前都需要转义字符`\` — 否则这些元字符将匹配字符类。
- en: We need to match a particular format between `[` and `]`. For this example,
    `.*` will suffice.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要匹配`[`和`]`之间的特定格式。对于这个例子，`.*`就足够了。
- en: '**Alternative Solution**: `\[\w+/\w+/\w+:\w+:\w+:\w+\s-\w+\]`'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**备选方案**：`\[\w+/\w+/\w+:\w+:\w+:\w+\s-\w+\]`'
- en: This solution is much safer.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个解决方案更安全。
- en: Imagine the data between `[` and `]` was garbage - `.*` will still match that.
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想象一下在`[`和`]`之间的数据是垃圾 - `.*`仍然会匹配它。
- en: The alternate solution will only match data that follows the correct format.
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备选方案只会匹配符合正确格式的数据。
- en: 6.6 Regex in Python and Pandas (RegEx Groups)
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python和Pandas中的正则表达式（RegEx组）
- en: 6.6.1 Canonicalization
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.1 规范化
- en: 6.6.1.1 Canonicalization with RegEx
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.6.1.1 使用正则表达式进行规范化
- en: 'Earlier in this note, we examined the process of canonicalization using `python`
    string manipulation and `pandas` `Series` methods. However, we mentioned this
    approach had a major flaw: our code was unnecessarily verbose. Equipped with our
    knowledge of regular expressions, let’s fix this.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在本笔记的早期，我们使用`python`字符串操作和`pandas`的`Series`方法来检查规范化的过程。然而，我们提到这种方法有一个主要缺陷：我们的代码过于冗长。有了我们对正则表达式的知识，让我们来修复这个问题。
- en: 'To do so, we need to understand a few functions in the `re` module. The first
    of these is the substitute function: `re.sub(pattern, rep1, text)`. It behaves
    similarly to `python`’s built-in `.replace` function, and returns text with all
    instances of `pattern` replaced by `rep1`.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要了解`re`模块中的一些函数。其中之一是替换函数：`re.sub(pattern, rep1, text)`。它的行为类似于`python`内置的`.replace`函数，并返回所有`pattern`的实例被`rep1`替换后的文本。
- en: The regular expression here removes text surrounded by `<>` (also known as HTML
    tags).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的正则表达式删除了被`<>`（也称为HTML标签）包围的文本。
- en: 'In order, the pattern matches … 1\. a single `<` 2\. any character that is
    not a `>` : div, td valign…, /td, /div 3\. a single `>`'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 按顺序，模式匹配... 1\. 单个`<` 2\. 任何不是`>`的字符：div，td valign...，/td，/div 3\. 单个`>`
- en: Any substring in `text` that fulfills all three conditions will be replaced
    by `''`.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在`text`中的任何子字符串，只要满足所有三个条件，都将被替换为`''`。
- en: '[PRE15]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Notice the `r` preceding the regular expression pattern; this specifies the
    regular expression is a raw string. Raw strings do not recognize escape sequences
    (i.e., the Python newline metacharacter `\n`). This makes them useful for regular
    expressions, which often contain literal `\` characters.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在正则表达式模式之前的`r`；这指定了正则表达式是原始字符串。原始字符串不识别转义序列（即Python换行元字符`\n`）。这使它们对于正则表达式非常有用，因为正则表达式通常包含字面上的`\`字符。
- en: In other words, don’t forget to tag your RegEx with an `r`.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，不要忘记用`r`标记你的RegEx。
- en: 6.6.1.2 Canonicalization with `pandas`
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.6.1.2 使用`pandas`进行规范化
- en: 'We can also use regular expressions with `pandas` `Series` methods. This gives
    us the benefit of operating on an entire column of data as opposed to a single
    value. The code is simple:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`pandas`的`Series`方法进行正则表达式。这使我们能够操作整列数据，而不是单个值。代码很简单：
- en: '`ser.str.replace(pattern, repl, regex=True`).'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`ser.str.replace(pattern, repl, regex=True`).'
- en: Consider the following `DataFrame` `html_data` with a single column.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下带有单列的`DataFrame` `html_data`。
- en: <details><summary>Code</summary>
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE17]</details>'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE17]</details>'
- en: '[PRE18]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '|  | HTML |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|  | HTML |'
- en: '| --- | --- |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0 | <div><td valign=''top''>Moo</td></div> |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 0 | <div><td valign=''top''>Moo</td></div> |'
- en: '| 1 | <a href=''http://ds100.org''>Link</a> |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 1 | <a href=''http://ds100.org''>链接</a> |'
- en: '| 2 | <b>Bold text</b> |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 2 | <b>粗体文本</b> |'
- en: '[PRE19]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 6.6.2 Extraction
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.2 提取
- en: 6.6.2.1 Extraction with RegEx
  id: totrans-253
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.6.2.1 使用正则表达式进行提取
- en: 'Just like with canonicalization, the `re` module provides capability to extract
    relevant text from a string:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 就像规范化一样，`re`模块提供了从字符串中提取相关文本的功能：
- en: '`re.findall(pattern, text)`. This function returns a list of all matches to
    `pattern`.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`re.findall(pattern, text)`。此函数返回与`pattern`匹配的所有实例的列表。'
- en: 'Using the familiar regular expression for Social Security Numbers:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 使用熟悉的社会安全号码的正则表达式：
- en: '[PRE21]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 6.6.2.2 Extraction with `pandas`
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.6.2.2 使用`pandas`进行提取
- en: '`pandas` similarily provides extraction functionality on a `Series` of data:
    `ser.str.findall(pattern)`'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`类似地在数据`Series`上提供提取功能：`ser.str.findall(pattern)`'
- en: Consider the following `DataFrame` `ssn_data`.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下`DataFrame` `ssn_data`。
- en: <details><summary>Code</summary>
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: <details><summary>代码</summary>
- en: '[PRE23]</details>'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE23]</details>'
- en: '[PRE24]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '|  | SSN |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '|  | SSN |'
- en: '| --- | --- |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0 | 987-65-4321 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 987-65-4321 |'
- en: '| 1 | forty |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 四十 |'
- en: '| 2 | 123-45-6789 bro or 321-45-6789 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 123-45-6789 bro or 321-45-6789 |'
- en: '| 3 | 999-99-9999 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 999-99-9999 |'
- en: '[PRE25]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This function returns a list for every row containing the pattern matches in
    a given string.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数返回一个列表，其中包含给定字符串中模式匹配的每一行。
- en: 'As you may expect, there are similar `pandas` equivalents for other `re` functions
    as well. `Series.str.extract` takes in a pattern and returns a `DataFrame` of
    each capture group’s first match in the string. In contrast, `Series.str.extractall`
    returns a multi-indexed `DataFrame` of all matches for each capture group. You
    can see the difference in the outputs below:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所期望的，`pandas`还为其他`re`函数提供了类似的等效功能。`Series.str.extract`接受一个模式，并返回字符串中每个捕获组的第一个匹配的`DataFrame`。相比之下，`Series.str.extractall`返回每个捕获组的所有匹配的多索引`DataFrame`。你可以在下面的输出中看到差异：
- en: '[PRE27]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '|  | 0 | 1 | 2 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '|  | 0 | 1 | 2 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 987 | 65 | 4321 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 987 | 65 | 4321 |'
- en: '| 1 | NaN | NaN | NaN |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 1 | NaN | NaN | NaN |'
- en: '| 2 | 123 | 45 | 6789 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 123 | 45 | 6789 |'
- en: '| 3 | 999 | 99 | 9999 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 999 | 99 | 9999 |'
- en: '[PRE28]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '|  |  | 0 | 1 | 2 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 0 | 1 | 2 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '|  | match |  |  |  |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '|  | 匹配 |  |  |  |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0 | 987 | 65 | 4321 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 987 | 65 | 4321 |'
- en: '| 2 | 0 | 123 | 45 | 6789 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0 | 123 | 45 | 6789 |'
- en: '| 1 | 321 | 45 | 6789 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 321 | 45 | 6789 |'
- en: '| 3 | 0 | 999 | 99 | 9999 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0 | 999 | 99 | 9999 |'
- en: 6.6.3 Regular Expression Capture Groups
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.3 正则表达式捕获组
- en: Earlier we used parentheses `(` `)` to specify the highest order of operation
    in regular expressions. However, they have another meaning; parentheses are often
    used to represent **capture groups**. Capture groups are essentially, a set of
    smaller regular expressions that match multiple substrings in text data.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 早些时候，我们使用括号`（` `）`来指定正则表达式中操作的最高顺序。然而，它们还有另一层含义；括号经常用来表示**捕获组**。捕获组本质上是一组较小的正则表达式，用于匹配文本数据中的多个子字符串。
- en: Let’s take a look at an example.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个例子。
- en: 6.6.3.1 Example 1
  id: totrans-294
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.6.3.1 示例1
- en: '[PRE29]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Say we want to capture all occurences of time data (hour, minute, and second)
    as *seperate entities*.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要捕获时间数据（小时，分钟和秒）的所有出现作为*单独的实体*。
- en: '[PRE30]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Notice how the given pattern has 3 capture groups, each specified by the regular
    expression `(\d\d)`. We then use `re.findall` to return these capture groups,
    each as tuples containing 3 matches.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 注意给定的模式有3个捕获组，每个都由正则表达式`(\d\d)`指定。然后我们使用`re.findall`返回这些捕获组，每个都包含3个匹配的元组。
- en: These regular expression capture groups can be different. We can use the `(\d{2})`
    shorthand to extract the same data.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这些正则表达式捕获组可以是不同的。我们可以使用`(\d{2})`的速记法来提取相同的数据。
- en: '[PRE32]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 6.6.3.2 Example 2
  id: totrans-303
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.6.3.2 示例2
- en: With the notion of capture groups, convince yourself how the following regular
    expression works.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 有了捕获组的概念，让自己相信以下正则表达式是如何工作的。
- en: '[PRE34]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 6.7 Limitations of Regular Expressions
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.7 正则表达式的局限性
- en: Today, we explored the capabilities of regular expressions in data wrangling
    with text data. However, there are a few things to be wary of.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我们探讨了在数据整理中使用正则表达式处理文本数据的能力。然而，还有一些需要注意的事项。
- en: Writing regular expressions is like writing a program.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 编写正则表达式就像编写程序一样。
- en: Need to know the syntax well.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要熟悉语法。
- en: Can be easier to write than to read.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 写起来可能比读起来更容易。
- en: Can be difficult to debug.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能很难调试。
- en: 'Regular expressions are terrible at certain types of problems:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式在某些类型的问题上表现糟糕：
- en: For parsing a hierarchical structure, such as JSON, use the `json.load()` parser,
    not RegEx!
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于解析分层结构，比如JSON，使用`json.load()`解析器，而不是RegEx！
- en: Complex features (e.g. valid email address).
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂特性（例如有效的电子邮件地址）。
- en: Counting (same number of instances of a and b). (impossible)
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计数（a和b的实例数相同）。 （不可能）
- en: Complex properties (palindromes, balanced parentheses). (impossible)
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂属性（回文，平衡括号）。 （不可能）
- en: 'Ultimately, the goal is not to memorize all regular expressions. Rather, the
    aim is to:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的目标不是记住所有的正则表达式。相反，目标是：
- en: Understand what RegEx is capable of.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解RegEx的能力。
- en: Parse and create RegEx, with a reference table
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析和创建RegEx，使用参考表
- en: Use vocabulary (metacharacter, escape character, groups, etc.) to describe regex
    metacharacters.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用词汇（元字符，转义字符，组等）描述正则表达式元字符。
- en: Differentiate between (), [], {}
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分`()`，`[]`，`{}`
- en: Design your own character classes with , , […-…], ^, etc.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计自己的字符类，使用，，[…-…]，^等。
- en: Use `python` and `pandas` RegEx methods.**
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`python`和`pandas`的RegEx方法。**
