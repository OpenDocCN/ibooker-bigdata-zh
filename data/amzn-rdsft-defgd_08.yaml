- en: Chapter 7\. Collaboration with Data Sharing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章\. 数据共享的合作
- en: Data sharing is a business necessity to accelerate digital transformation.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据共享是加速数字转型的业务必需品。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Gartner](https://oreil.ly/wmkIV)'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Gartner](https://oreil.ly/wmkIV)'
- en: '*Data sharing* is the ability to provide access to information for internal
    and external stakeholders that they can’t access in their own data systems. Data
    sharing allows stakeholders to access data produced or collected and stored in
    the producer’s domain and collaborate on shared business goals and priorities.
    Data organizations are moving away from being a single large monolithic department,
    which usually causes slow-moving data platforms to small distributed teams to
    create modular fast-moving data products. This [Modern Data Community](https://oreil.ly/b30m_)
    is an organizational and cultural shift from monolithic data organizations to
    decoupled, agile, smaller teams.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据共享*是为内部和外部利益相关者提供信息访问的能力，他们无法在自己的数据系统中访问。数据共享允许利益相关者访问生产者领域中产生或收集并存储的数据，并共同合作实现共享的业务目标和优先事项。数据组织正在从单一的大型单体部门转变为小型分布式团队，这通常导致数据平台运行缓慢，以创建模块化快速移动的数据产品。'
- en: By building a robust data sharing architecture, data and analytics leaders will
    have access to the right data at the right time to deliver meaningful business
    outcomes. Organizations like National Institutes of Health (NIH) have implemented
    [data management and sharing policies](https://oreil.ly/KWuJI) to establish that
    data sharing is a fundamental component of the research process to maximize public
    access to research results.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 通过构建强大的数据共享架构，数据和分析领导者将能够在适当的时间访问正确的数据，以实现有意义的业务成果。像国家卫生研究院（NIH）这样的组织已经实施了[数据管理和共享政策](https://oreil.ly/KWuJI)，以确立数据共享是研究过程的基本组成部分，以最大化公众对研究结果的访问。
- en: Data sharing encourages making use of the information and resources available
    to us in the present moment wherever it resides and taking action based on that
    information. The sooner a company starts sharing data and using it to inform their
    decision making, the more time they will have to deliver business outcomes.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据共享鼓励我们利用当前信息和资源，并根据这些信息采取行动。公司越早开始共享数据并将其用于决策，就越有时间交付业务成果。
- en: The phrase *data is the new oil* was originally coined by Clive Humby, a British
    mathematician and data science entrepreneur, and this has proven to be true over
    the last two decades. Data drives business decisions, informs research, and powers
    technology. Organizations are collecting and storing more data than ever before.
    But with the abundance of data comes the challenge of how to effectively share
    and collaborate on that data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: “数据是新石油”的说法最初由英国数学家和数据科学企业家Clive Humby创造，这在过去二十年中被证明是正确的。数据驱动业务决策，支持研究并推动技术发展。组织正在比以往任何时候都更多地收集和存储数据。但随着数据的丰富，如何有效地共享和协作成为了挑战。
- en: In this chapter, you’ll learn how to use Amazon Redshift to share and collaborate
    on large amounts of data. We’ll start by providing an [“Amazon Redshift Data Sharing
    Overview”](#Amazon-Redshift-data-sharing-overview) and describe different [“Data
    Sharing Use Cases”](#Data-sharing-use-cases). Next, we’ll dive deeper into the
    [“Key Concepts of Data Sharing”](#Key-concepts-of-data-sharing) with Amazon Redshift
    and walk through [“How to Use Data Sharing”](#Creating-a-data-share). We’ll explore
    options for [“Sharing Data Across Accounts Using Cross-Account Data Sharing”](#Cross-account-and-cross-region-sharing)
    and show different options for using Amazon Redshift data sharing in an [“Analytics
    as a Service Use Case with Multi-Tenant Storage Patterns”](#Multi-tenant-patterns-using-data-sharing).
    Next, we’ll talk about how you can enable [“External Data Sharing with AWS ADX
    Integration”](#External-Sharing-Amazon-ADX-integration) to monetize your data
    and provide your customers with instant access to data using their Amazon Redshift
    compute. We’ll also briefly cover how you can [“Query from the Data Lake and Unload
    to the Data Lake”](#Querying-datalake-unloading-to-datalake) as your mechanism
    for data sharing. Lastly, we’ll cover how to catalog and govern access to your
    data-shares by using [“Amazon DataZone to Discover and Share Data”](#Using-Amazon-DataZone-to-discover-and-share-data).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习如何使用Amazon Redshift共享和协作大量数据。我们将从提供[“Amazon Redshift数据共享概述”](#Amazon-Redshift-data-sharing-overview)开始，并描述不同的[“数据共享使用案例”](#Data-sharing-use-cases)。接下来，我们将深入探讨使用Amazon
    Redshift的[“数据共享关键概念”](#Key-concepts-of-data-sharing)，并逐步介绍如何[“使用数据共享”](#Creating-a-data-share)。我们将探讨使用跨账户数据共享的[“跨账户和跨区域共享数据”](#Cross-account-and-cross-region-sharing)的选项，并展示在[“使用多租户存储模式进行分析服务用例”](#Multi-tenant-patterns-using-data-sharing)中使用Amazon
    Redshift数据共享的不同选项。接下来，我们将讨论如何启用[“AWS ADX集成的外部数据共享”](#External-Sharing-Amazon-ADX-integration)以从您的数据中赚钱，并使用其Amazon
    Redshift计算为客户提供即时数据访问。最后，我们将简要介绍如何通过[“从数据湖查询和卸载到数据湖”](#Querying-datalake-unloading-to-datalake)作为数据共享的机制。最后，我们将介绍如何使用[“Amazon
    DataZone来发现和共享数据”](#Using-Amazon-DataZone-to-discover-and-share-data)来对数据分享进行目录化和管理访问权限。
- en: Amazon Redshift Data Sharing Overview
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon Redshift数据共享概述
- en: 'Amazon Redshift data sharing enables instant, granular, and live data access
    across data warehouses without the need to copy or move data. This enables you
    to create a multiwarehouse architecture and scale each data warehouse for various
    types of workloads. Amazon Redshift data sharing is included with your serverless
    or RA3 provisioned data warehouse and provides the following capabilities:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift数据共享无需复制或移动数据即可实现跨数据仓库的即时、细粒度和实时数据访问。这使您能够创建多仓库架构，并为各种工作负载的每个数据仓库进行扩展。Amazon
    Redshift数据共享包含在您的无服务器或RA3预配的数据仓库中，并提供以下功能：
- en: Live and transactionally consistent views of data across all consumers
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有消费者之间的数据的实时和事务一致视图
- en: Secure and governed collaboration within and across organizations
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全和受管制的组织内及组织间协作
- en: Sharing data with external parties to monetize your data
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与外部方共享数据以从中获利
- en: The live access and transactionally consistent views of data ensures users always
    see the most up-to-date and consistent information as it is updated in the data
    warehouse. You can securely share data with Amazon Redshift data warehouses in
    the same account or different AWS accounts within the same region or across regions.
    When building a scalable architecture for analytics, you’ll need to consider performance
    of the query and ingestion workloads, elasticity, and price for performance to
    meet the requirements of dynamic workloads. The Amazon Redshift data sharing feature
    provides another mechanism to scale and meet demands of various types of workloads.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库中的实时访问和事务一致视图确保用户始终看到最新和一致的信息，因为数据仓库中的更新信息已更新。您可以安全地与同一区域或跨区域的同一AWS帐户或不同AWS帐户的Amazon
    Redshift数据仓库共享数据。在构建用于分析的可扩展架构时，您需要考虑查询和摄入工作负载的性能、弹性和性能价格比，以满足动态工作负载的要求。Amazon
    Redshift数据共享功能提供了另一种机制来扩展并满足各种工作负载的需求。
- en: Amazon Redshift RA3 architecture enables the data sharing feature. In the RA3
    architecture, data stored in Amazon RMS is committed to Amazon S3 but is also
    available in a solid-state drive (SSD) local cache to the compute nodes for faster
    processing of recently used data. The queries from the consumer data warehouse
    read data directly from the Amazon RMS layer. Hence there is no impact in performance
    of the producer data warehouse, and workloads accessing shared data are isolated
    from each other. This architecture is shown in [Figure 7-1](#data_sharing_architecture),
    and it enables you to set up a multiwarehouse architecture with separate consumer
    data warehouses for different types of workloads. You can provision flexible compute
    resources that meet workload-specific price performance requirements and be scaled
    independently as needed in a self-service fashion.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift RA3架构支持数据共享功能。在RA3架构中，存储在Amazon RMS中的数据提交到Amazon S3，但也可在固态驱动器（SSD）本地缓存中供计算节点快速处理最近使用的数据。来自消费者数据仓库的查询直接从Amazon
    RMS层读取数据。因此，生产者数据仓库的性能不受影响，访问共享数据的工作负载彼此隔离。该架构显示在[图 7-1](#data_sharing_architecture)中，它使您能够设置一个多仓库架构，具有为不同类型的工作负载分别设置的消费者数据仓库。您可以按需自助方式提供符合工作负载特定价格性能要求的灵活计算资源，并进行独立扩展。
- en: '![Amazon Redshift data sharing architecture](assets/ardg_0701.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon Redshift数据共享架构](assets/ardg_0701.png)'
- en: Figure 7-1\. Amazon Redshift data sharing architecture
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-1\. Amazon Redshift数据共享架构
- en: Amazon Redshift data sharing is not available on the DC2 node type because DC2
    nodes do not take advantage of Redshift Managed Storage (RMS). See the [Upgrading
    to RA3 Node Types documentation](https://oreil.ly/rc-ms) or the [Migrating to
    Amazon Redshift Serverless documentation](https://oreil.ly/9eZSf) for details
    on how to take advantage of data sharing.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 由于DC2节点不利用Redshift Managed Storage（RMS），因此Amazon Redshift数据共享在DC2节点类型上不可用。有关如何利用数据共享的详细信息，请参阅[升级到RA3节点类型文档](https://oreil.ly/rc-ms)或[迁移到Amazon
    Redshift无服务器文档](https://oreil.ly/9eZSf)。
- en: Data Sharing Use Cases
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据共享用例
- en: 'According to [Gartner](https://oreil.ly/1WsD6), “Data and analytics leaders
    who share data externally generate three times more measurable economic benefit
    than those who do not.” Data sharing has proven to have measurable economic benefits,
    and organizations who have a data sharing strategy outperform their peers. Use
    cases for data sharing range from helping you enhance scalability by separation
    of workloads, increase collaboration, build Analytics as a Service (AaaS) solutions,
    and improve operational efficiency, data quality, and generally improve access
    to data. Let’s take a closer look at these use cases:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[Gartner](https://oreil.ly/1WsD6)的数据，“与不共享数据的数据和分析领导者相比，外部共享数据的领导者产生的经济效益是后者的三倍。”
    数据共享已被证明具有可衡量的经济效益，有数据共享战略的组织表现优于同行。数据共享的用例范围从帮助增强可伸缩性（通过工作负载分离），增加协作，构建Analytics
    as a Service（AaaS）解决方案，改善操作效率，数据质量，以及普遍提高数据访问。让我们更详细地看看这些用例：
- en: Separation of workloads
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 工作负载分离
- en: When you have a heavy ETL workload, you can separate the ETL workload from query
    workloads by having a multiwarehouse architecture to scale by using one data warehouse
    for ingestion and another data warehouse for queries. Each can be tuned and optimized
    for its intended workload.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有大量的ETL工作负载时，可以通过多仓库架构将ETL工作负载与查询工作负载分离，通过使用一个数据仓库用于数据摄入，另一个数据仓库用于查询来进行扩展。每个仓库可以针对其预期工作负载进行调优和优化。
- en: Cross-group collaboration
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 跨团队协作
- en: Different departments within a company can share and access data, leading to
    more efficient and effective decision making. For example, the marketing team
    can use data stored in Amazon Redshift to better target their campaigns, while
    the finance team can use the same data to forecast revenue. Sharing data across
    groups while still isolating workloads to use their own compute resources ensures
    that each team’s processing needs will not collide with the others. See [Figure 7-2](#data_sharing_usecase12)
    for an example.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 公司内不同部门可以共享和访问数据，从而实现更高效和更有效的决策。例如，市场团队可以使用存储在Amazon Redshift中的数据更好地定位他们的活动，而财务团队可以使用相同的数据来预测收入。即使跨部门共享数据，但仍然隔离工作负载以使用自己的计算资源，以确保每个团队的处理需求不会相互冲突。参见[图 7-2](#data_sharing_usecase12)作为示例。
- en: '![Data sharing use cases separation of workload and collaboration ](assets/ardg_0702.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![数据共享用例 - 工作负载分离与协作](assets/ardg_0702.png)'
- en: Figure 7-2\. Data sharing use cases separation of workload and collaboration
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-2\. 数据共享用例工作负载分离和协作
- en: Analytics as a Service
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 分析即服务
- en: AaaS providers can collect and aggregate data from various sources such as social
    media, web analytics, and ERP systems into the data warehouse and add business
    insight transformations before sharing with subscribers. For example, using the
    student data model defined in [Chapter 3, “Setting Up Your Data Models and Ingesting
    Data”](ch03.html#AR_TGD_CH3), an educational technology AaaS provider can collect
    data about student attendance and grades, and derive insights on how to improve
    student outcomes. They can then share these insights using a subscription model
    using [AWS Data Exchange (ADX) integration](https://oreil.ly/_FDWr) with the educational
    institutions and monetize the data that they already collected through their transactional
    systems. Producers of data can also use [AWS Clean Rooms](https://aws.amazon.com/clean-rooms)
    to collaborate with partners or other AWS users without sharing raw data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: AaaS提供商可以从各种来源（如社交媒体、网络分析和ERP系统）收集和聚合数据到数据仓库，并在与订阅者分享之前添加业务洞察转换。例如，使用在[第3章，“设置您的数据模型和数据摄入”](ch03.html#AR_TGD_CH3)中定义的学生数据模型，教育技术AaaS提供商可以收集有关学生出勤和成绩的数据，并派生出如何改善学生成绩的见解。然后，他们可以使用订阅模型使用[AWS数据交换（ADX）集成](https://oreil.ly/_FDWr)与教育机构分享这些见解，并通过他们的事务系统已经收集的数据进行货币化。数据的生产者还可以使用[AWS
    Clean Rooms](https://aws.amazon.com/clean-rooms)与合作伙伴或其他AWS用户协作，而不必共享原始数据。
- en: Improved agility for software development life cycle (SDLC)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 改进软件开发生命周期（SDLC）的灵活性
- en: During the development lifecycle of applications, most organizations struggle
    with not having good data for testing in development or quality systems in the
    DevOps landscape. With data sharing, you can share data from your production to
    development systems to improve your quality of testing by validating all test
    cases, and accelerate delivery of applications. If you have specific security
    policies around sharing production data in other environments, you can also use
    the [dynamic data masking (DDM)](https://oreil.ly/h9mGq) capability of Amazon
    Redshift to mask certain Personally Identifiable Information (PII) data. See [Figure 7-3](#data_sharing_usecase34)
    for an example.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序开发生命周期中，大多数组织在DevOps领域中没有足够的测试数据而感到困惑。通过数据共享，您可以将生产系统的数据分享到开发系统，通过验证所有测试用例来提高测试质量，并加快应用程序的交付速度。如果您在将生产数据分享到其他环境时有特定的安全策略，您还可以使用[动态数据脱敏（DDM）](https://oreil.ly/h9mGq)功能在Amazon
    Redshift中屏蔽特定的个人身份信息（PII）数据。有关示例，请参见[图7-3](#data_sharing_usecase34)。
- en: '![Data sharing use cases analytics as a service and development agility](assets/ardg_0703.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![数据共享用例分析即服务和开发灵活性](assets/ardg_0703.png)'
- en: Figure 7-3\. Data sharing use cases analytics as a service and development agility
  id: totrans-32
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-3\. 数据共享用例分析即服务和开发灵活性
- en: Key Concepts of Data Sharing
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据共享的关键概念
- en: A *datashare* is the unit of sharing data in Amazon Redshift (see [Figure 7-5](#data_sharing_key_concepts)).
    A data owner can add database objects to the datashare to share with subscribers.
    A datashare acts as a container to hold references to other database objects.
    A data owner who produces and shares data is called a *producer*, and a subscriber
    is called a *consumer*. Amazon Redshift allows you to set up access controls and
    permissions, ensuring that sensitive data is shared only with authorized personnel.
    This is especially important when sharing data with external partners or other
    AWS users who have stringent data governance and security requirements. Each datashare
    is associated to a specific database in your Amazon Redshift data warehouse.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据共享*是在Amazon Redshift中共享数据的单位（请参见[图7-5](#data_sharing_key_concepts)）。数据所有者可以将数据库对象添加到数据共享中以与订阅者共享。数据共享充当容器，用于保存对其他数据库对象的引用。生成和共享数据的数据所有者称为*生产者*，订阅者称为*消费者*。Amazon
    Redshift允许您设置访问控制和权限，确保敏感数据仅与授权人员共享。在与外部合作伙伴或其他具有严格数据治理和安全要求的AWS用户分享数据时，这一点尤为重要。每个数据共享都与您Amazon
    Redshift数据仓库中特定的数据库相关联。'
- en: Data producers are Amazon Redshift data warehouses that own the data and from
    where the data is being shared from. Producer data warehouse administrators and
    database owners can create datashares using the `CREATE DATASHARE` command. You
    can add database objects such as schemas, tables, views, and SQL UDFs to a datashare
    in the producer to share with consumers. Amazon Redshift data warehouses that
    share data can be in the same or different AWS account or different AWS regions,
    so you can share data across organizations and collaborate with other parties.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据生产者是拥有数据并从中共享数据的亚马逊Redshift数据仓库。生产者数据仓库管理员和数据库所有者可以使用 `CREATE DATASHARE` 命令创建数据共享。您可以向生产者的数据共享添加数据库对象，例如模式、表、视图和SQL
    UDFs，以便与消费者共享。共享数据的亚马逊Redshift数据仓库可以位于相同的AWS账户中，也可以位于不同的AWS账户或AWS区域中，因此您可以跨组织共享数据并与其他方进行协作。
- en: Data consumers are Amazon Redshift data warehouses that receive datashares from
    producer data warehouses. When producers grant datashare access to a consumer,
    consumer data warehouse administrators can create a database referencing the datashare
    to the consumer-shared data. Note that this database is a reference to the datashare
    and not a physical persistent storage on the consumer side. The administrator
    then assigns permissions for the database to users and groups in the consumer
    data warehouse. After permissions are granted, users and groups can query the
    datashare objects using a three-part notation `database.schema.object`. Authorized
    users can also list the shared objects using standard metadata queries, and track
    usage. For cross-account datasharing, it is an additional step on the producer
    side to authorize the datashare, and on the consumer side to associate one or
    more Amazon Redshift data warehouses to the datashare.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据消费者是接收来自生产者数据仓库的数据共享的亚马逊Redshift数据仓库。当生产者授予数据共享访问权限给消费者时，消费者数据仓库管理员可以创建一个引用数据共享的数据库。请注意，这个数据库是对数据共享的引用，而不是消费者端的物理持久存储。然后管理员为数据库中的用户和组分配权限。授予权限后，用户和组可以使用三部分标记
    `database.schema.object` 查询数据共享对象。授权用户还可以使用标准元数据查询列出共享对象并跟踪使用情况。对于跨账户数据共享，生产者需要额外的步骤来授权数据共享，而消费者需要将一个或多个亚马逊Redshift数据仓库与数据共享关联起来。
- en: Namespaces are identifiers that identify an Amazon Redshift provisioned or serverless
    data warehouse. A namespace Globally Unique Identifier (GUID) is automatically
    created and assigned to your Amazon Redshift data warehouse. A namespace Amazon
    Resource Name (ARN) is in the `arn:{partition}:redshift:{region}:{account-id}:namespace:{namespace-guid}`
    format for provisioned and `arn:{partition}:redshift-serverless:{region}:{account-id}:namespace:{namespace-guid}`
    for serverless. You can see the namespace details of a data warehouse in the Amazon
    Redshift console general information page (see [Figure 7-4](#data_sharing_namespace)).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间是标识亚马逊Redshift预配置或无服务器数据仓库的标识符。命名空间的全局唯一标识符（GUID）会自动创建并分配给您的亚马逊Redshift数据仓库。预配置的命名空间Amazon资源名称（ARN）格式为
    `arn:{partition}:redshift:{region}:{account-id}:namespace:{namespace-guid}`，无服务器的为
    `arn:{partition}:redshift-serverless:{region}:{account-id}:namespace:{namespace-guid}`。您可以在亚马逊Redshift控制台的一般信息页面上查看数据仓库的命名空间详细信息（参见
    [图7-4](#data_sharing_namespace)）。
- en: '![Data sharing namespace](assets/ardg_0704.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![数据共享命名空间](assets/ardg_0704.png)'
- en: Figure 7-4\. Data sharing namespace
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-4\. 数据共享命名空间
- en: In the data sharing workflow, the namespace GUID value and the namespace ARN
    are used to share data with other Amazon Redshift data warehouses in the AWS account.
    You can also find the namespace for the current data warehouse by using the `current_namespace`
    function. For cross-account data sharing, AWS accounts can be consumers for datashares
    and are each represented by a 12-digit AWS account ID. Consumer accounts can then
    associate one or more Amazon Redshift data warehouses to the datashare to read
    that data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据共享工作流程中，命名空间GUID值和命名空间ARN用于与AWS账户中的其他亚马逊Redshift数据仓库共享数据。您还可以使用 `current_namespace`
    函数查找当前数据仓库的命名空间。对于跨账户数据共享，AWS账户可以作为数据共享的消费者，并分别由12位AWS账户ID表示。消费者账户可以将一个或多个亚马逊Redshift数据仓库与数据共享关联，以读取该数据。
- en: With Amazon Redshift, you can share data through the database objects at different
    levels, and you can create multiple datashares for a given database. A datashare
    can contain objects from multiple schemas in the database on which sharing is
    created. However, you can share only the datashare object and not individual objects
    to consumers. By having this flexibility in sharing data, you get fine-grained
    access control. You can tailor this control for different users and businesses
    that need access to Amazon Redshift data. For example, you may want to share only
    the student details from a particular school with a school administrator. In businesses,
    you may want to control sharing the sales details with a vendor for the corresponding
    items they supply ([Figure 7-5](#data_sharing_key_concepts)).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Amazon Redshift，您可以通过不同级别的数据库对象共享数据，并且您可以为给定数据库创建多个数据共享。数据共享可以包含创建共享的数据库中多个模式的对象。但是，您只能向消费者共享数据共享对象，而不能共享单个对象。通过这种数据共享的灵活性，您可以获得细粒度的访问控制。您可以为需要访问
    Amazon Redshift 数据的不同用户和企业定制此控制。例如，您可能希望仅向学校管理员共享特定学校的学生详细信息。在企业中，您可能希望控制向供应商共享对应供应的销售详细信息（[图 7-5](#data_sharing_key_concepts)）。
- en: '![Key concepts of data sharing and how it works](assets/ardg_0705.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![数据共享的关键概念及其工作原理](assets/ardg_0705.png)'
- en: Figure 7-5\. Key concepts of data sharing and how it works
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-5\. 数据共享的关键概念及其工作原理
- en: How to Use Data Sharing
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用数据共享
- en: To use data sharing, first identify the data you want to share and identify
    the respective schema, tables, and views that have the relevant data. To share
    data, create a `DATASHARE` metadata object and add database objects including
    schemas, tables, and views to this datashare. Then, grant access to other namespaces
    within the same account or to another AWS account. Let’s look at a specific example
    and walk through the whole process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用数据共享，首先确定要共享的数据以及具有相关数据的相应模式、表和视图。要共享数据，请创建 `DATASHARE` 元数据对象，并将数据库对象（包括模式、表和视图）添加到此数据共享中。然后，向同一账户内的其他命名空间或另一个
    AWS 账户授予访问权限。让我们看一个具体的例子，并走过整个过程。
- en: Sharing Data Within the Same Account
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在同一账户内共享数据
- en: Let’s use the student learning dataset from [Example 3-1](ch03.html#creating_sis_data_model)
    to understand how you can share data. This section shows you how to share a student
    learning dataset within the same account with the consumers within the organization.
    You can use the console or SQL scripts to create and share a datashare. The following
    scripts in Examples [7-1](#ex7_1) and [7-2](#ex7_2) provide you with the steps.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用来自 [示例 3-1](ch03.html#creating_sis_data_model) 的学生学习数据集来理解如何共享数据。本节展示了如何在同一账户内向组织内的消费者共享学生学习数据集。您可以使用控制台或
    SQL 脚本来创建和共享数据共享。示例 [7-1](#ex7_1) 和 [7-2](#ex7_2) 中的以下脚本为您提供了操作步骤。
- en: Example 7-1\. Creating a datashare
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-1\. 创建数据共享
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the previous statement, `learnshare` is the name of the datashare. The datashare
    name must be unique in the namespace. `SET PUBLICACCESSIBLE` is a clause that
    specifies whether the datashare can be shared to data warehouses that are publicly
    accessible. The default value for `SET PUBLICACCESSIBLE` is `FALSE`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述语句中，`learnshare` 是数据共享的名称。数据共享名称在命名空间中必须是唯一的。`SET PUBLICACCESSIBLE` 是一个子句，用于指定数据共享是否可以共享给公共访问的数据仓库。`SET
    PUBLICACCESSIBLE` 的默认值为 `FALSE`。
- en: Example 7-2\. Adding objects to datashare
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-2\. 向数据共享添加对象
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '| share_name | share_owner | source_database | consumer_database | share_type
    | createdate |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| share_name | share_owner | source_database | consumer_database | share_type
    | createdate |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| learnshare_adx | 100 | dev | null | OUTBOUND | 2023-03-18 19:51:28 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| learnshare_adx | 100 | dev | null | OUTBOUND | 2023-03-18 19:51:28 |'
- en: '| learnshare | 100 | dev | null | OUTBOUND | 2023-02-24 18:32:28 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| learnshare | 100 | dev | null | OUTBOUND | 2023-02-24 18:32:28 |'
- en: '| is_publicaccessible | share_acl | producer_account | producer_namespace |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| is_publicaccessible | share_acl | producer_account | producer_namespace |'
- en: '| --- | --- | --- | --- |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| true | null | <awsaccount> | xxxxc8ee-f6a5-xxxx-xxxx-yyyy66d7zzzz |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| true | null | <awsaccount> | xxxxc8ee-f6a5-xxxx-xxxx-yyyy66d7zzzz |'
- en: '| true | null | <awsaccount> | xxxxc7ee-xxxx-468f-xxxx-yyyy77d7zzzz |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| true | null | <awsaccount> | xxxxc7ee-xxxx-468f-xxxx-yyyy77d7zzzz |'
- en: 'To add all tables in a schema, use the following syntax:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加模式中的所有表，请使用以下语法：
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To get the namespace of the consumer, you can log in to the consumer Amazon
    Redshift data warehouse and run the SQL in [Example 7-3](#select_current_namespace)
    to select the `current_namespace`, or you may get it from the console.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取消费者的命名空间，您可以登录到消费者的 Amazon Redshift 数据仓库，并运行 [示例 7-3](#select_current_namespace)
    中的 SQL 来选择 `current_namespace`，或者您可以从控制台获取。
- en: Example 7-3\. Viewing current user and namespace
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-3\. 查看当前用户和命名空间。
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now, with the namespace `<<consumer namespace>>` of your data warehouse, you
    can grant usage on the datashare from the producer to the consumer using the `GRANT`
    command as shown in [Example 7-4](#grant_usage_namespace).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过您的数据仓库的命名空间 `<<consumer namespace>>`，您可以使用 `GRANT` 命令向消费者授予从生产者到消费者的数据共享权限，如
    [示例 7-4](#grant_usage_namespace) 所示。
- en: Example 7-4\. Granting access to datashare
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-4\. 授予对数据共享的访问权限。
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: On the consumer side, create a database referencing the datashare on the producer
    or serverless data warehouse. Note that this database is just a pointer to the
    datashare and does not hold any data on its own. Once you create the database,
    you can query the data live as shown in [Example 7-5](#consumer_createdb_query)
    using a three-part notation of `db_name.schema.view`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在消费者端，创建一个数据库，引用生产者或无服务器数据仓库上的数据共享。请注意，这个数据库只是指向数据共享的指针，并不保存任何数据。创建数据库后，您可以像在
    [示例 7-5](#consumer_createdb_query) 中展示的那样，使用 `db_name.schema.view` 的三部分表示法实时查询数据。
- en: Example 7-5\. Creating local database from remote datashare
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-5\. 从远程数据共享创建本地数据库。
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Optionally, you can create an external schema in the consumer data warehouse
    pointing to the schema in the database of the producer data warehouse. Creating
    a local external schema in the consumer data warehouse allows schema-level access
    controls within the consumer data warehouse and allows you to use a two-part notation
    when referencing shared data objects (`localschema.table` versus `external_db.producerschema.table`),
    as shown in [Example 7-6](#consumer_createschema_query).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，您可以在消费者数据仓库中创建一个外部模式，指向生产者数据仓库中的模式。在消费者数据仓库中创建本地外部模式允许在消费者数据仓库内进行模式级访问控制，并允许您在引用共享数据对象时使用两部分表示法（`localschema.table`
    与 `external_db.producerschema.table`），如 [示例 7-6](#consumer_createschema_query)
    所示。
- en: Example 7-6\. Creating external schema from local database
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-6\. 从本地数据库创建外部模式。
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Sharing Data Across Accounts Using Cross-Account Data Sharing
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用跨账户数据共享跨账户共享数据。
- en: 'In addition to internal data sharing to break down data silos within an organization,
    you can also share your data securely to external organizations using the cross-account
    data sharing feature. Here are some common use cases:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 除了内部数据共享以打破组织内的数据孤岛外，您还可以使用跨账户数据共享功能安全地向外部组织共享数据。以下是一些常见的使用案例：
- en: A subsidiary organization reporting back financial statements to its parent
    organization
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子公司向其母公司报告财务报表。
- en: A business organization or government agency sharing data with another organization
    or related agency
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 企业组织或政府机构与另一组织或相关机构共享数据。
- en: An AaaS provider sharing data with their subscribers
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AaaS（作为服务提供者）向其订阅者共享数据。
- en: A healthcare organization sharing data with a government agency
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 医疗组织与政府机构共享数据。
- en: When you share data across accounts, you will create a `datashare` object and
    add the database object you want to share, similar to sharing within an account.
    But here you will grant access to a consumer AWS account to access that datashare,
    as shown in [Example 7-7](#grant_usage_cross_account). On the consumer side, an
    administrator can associate one or more data warehouses to be able to read the
    datashare.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当您跨账户共享数据时，您将创建一个 `datashare` 对象，并添加您想要共享的数据库对象，类似于在账户内共享。但是在这里，您将授予消费者 AWS
    账户访问该数据共享的权限，如 [示例 7-7](#grant_usage_cross_account) 所示。在消费者端，管理员可以关联一个或多个数据仓库以能够读取数据共享。
- en: Amazon Redshift supports data sharing for data warehouses with homogeneous encryption
    configuration. In other words, you can share data among two or more encrypted
    Amazon Redshift data warehouses. Or you can share data among two or more unencrypted
    Amazon Redshift data warehouses for data warehouses that are within the same AWS
    account. When sharing data between encrypted data warehouses, you can use different
    encryption keys for each data warehouse. For cross-account and cross-region data
    sharing, both the producer and consumer data warehouse must be encrypted.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift支持具有同质加密配置的数据仓库数据共享。换句话说，您可以在两个或多个加密的Amazon Redshift数据仓库之间共享数据。或者，您可以在相同AWS账户内的两个或多个未加密的Amazon
    Redshift数据仓库之间共享数据。在加密数据仓库之间共享数据时，您可以为每个数据仓库使用不同的加密密钥。对于跨账户和跨区域的数据共享，生产者和消费者数据仓库必须都加密。
- en: Example 7-7\. Granting access to AWS account on datashare
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-7\. 授权AWS账户访问数据共享
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For cross-account sharing, there is an additional step to authorize the datashare
    before it becomes visible for a consumer account. This process allows for a manager
    or a data owner to approve the datashare, as shown in [Figure 7-6](#data_sharing_crossaccount_authorize).
    Once authorized, the datashare will be available for the consumer account.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于跨账户共享，还需要额外的授权步骤，以便消费者账户能够看到数据共享。此过程允许管理者或数据所有者批准数据共享，如图 [7-6](#data_sharing_crossaccount_authorize)
    所示。一旦授权完成，数据共享将对消费者账户可见。
- en: '![Authorize step for cross-account data sharing](assets/ardg_0706.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![跨账户数据共享的授权步骤](assets/ardg_0706.png)'
- en: Figure 7-6\. Authorize step for cross-account data sharing
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-6\. 跨账户数据共享的授权步骤
- en: Users can manage multiple datashares across multiple Amazon Redshift data warehouses
    in different accounts and regions. To centrally manage all datashares across all
    accounts, with designated owners or administrators to authorize or associate datashare,
    you may build a custom web interface. To automate the process of authorization
    and association, you can also use the CLI commands [`authorize-data-share`](https://oreil.ly/pduVL)
    and [`associate-data-share-consumer`](https://oreil.ly/TDvF8).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以在不同账户和区域的多个Amazon Redshift数据仓库中管理多个数据共享。要集中管理所有账户中的所有数据共享，可以建立一个自定义的Web界面，并指定所有者或管理员来授权或关联数据共享。要自动化授权和关联过程，还可以使用CLI命令[`authorize-data-share`](https://oreil.ly/pduVL)和[`associate-data-share-consumer`](https://oreil.ly/TDvF8)。
- en: On the consumer side, you can associate one or more Amazon Redshift data warehouses
    to the datashare. Note that the datashare will show up in the “From other accounts”
    tab when you choose the datashares menu option. You can choose the datashare and
    click the Associate button to associate the consumer to the datashare, as shown
    in [Figure 7-7](#associate_consumer_data_share).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在消费者端，您可以将一个或多个Amazon Redshift数据仓库与数据共享关联起来。请注意，当您选择数据共享菜单选项时，数据共享将显示在“来自其他账户”选项卡中。您可以选择数据共享，然后点击“关联”按钮将消费者关联到数据共享，如图
    [7-7](#associate_consumer_data_share) 所示。
- en: '![Associate consumer data warehouse to producer datashare](assets/ardg_0707.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![将消费者数据仓库关联到生产者数据共享](assets/ardg_0707.png)'
- en: Figure 7-7\. Associate consumer data warehouse to producer datashare
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-7\. 将消费者数据仓库关联到生产者数据共享
- en: Once you associate the consumer data warehouse to the datashare, you can log
    in to the consumer data warehouse that you associated and query the data from
    the objects in the datashare with just a couple of steps. First, create a database
    reference to the datashare, then use a three-part notation with `db_name.schema.table`
    as shown in [Example 7-8](#consumer_query_cross_account)’s SQL scripts.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将消费者数据仓库关联到数据共享，您可以登录到关联的消费者数据仓库，并只需几个步骤即可查询数据共享中对象的数据。首先，创建到数据共享的数据库引用，然后使用`db_name.schema.table`的三部分表示法，如示例
    [7-8](#consumer_query_cross_account) 中的SQL脚本所示。
- en: Example 7-8\. Creating local database from remote datashare
  id: totrans-93
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-8\. 从远程数据共享创建本地数据库
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: When this query is passed to the producer from this consumer, the `current_namespace`
    variable will have the namespace of this consumer. Hence the materialized view
    will filter the records just from this consumer based on the join condition from
    the school table. As discussed earlier, you can create an external schema to use
    a two-part notation when referencing shared data objects (e.g. `external_schema.table`)
    versus a three-part notation (`external_db.producer_schema.table`).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当此查询从消费者传递给生产者时，`current_namespace`变量将具有此消费者的命名空间。因此，材料化视图将根据学校表的连接条件仅从此消费者过滤记录。正如前面讨论的，您可以创建一个外部模式来使用两部分符号表示法引用共享数据对象（例如`external_schema.table`），而不是三部分符号表示法（`external_db.producer_schema.table`）。
- en: For detailed steps on setting up cross-account data sharing, refer to the documentation
    on [sharing data across AWS accounts](https://oreil.ly/Uk_sp).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 有关设置跨AWS账户数据共享的详细步骤，请参阅[跨AWS账户共享数据](https://oreil.ly/Uk_sp)的文档。
- en: Analytics as a Service Use Case with Multi-Tenant Storage Patterns
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多租户存储模式的分析即服务用例
- en: AaaS providers offer subscription-based analytics capabilities in the cloud
    for their users. These service providers typically have to store data for multiple
    users and securely provide access to the subscribers of the analytics service
    they provide. Using a multi-tenant storage strategy allows them to build a cost-effective
    architecture and scale based on demand. Multi-tenancy means a single instance
    of software and its supporting infrastructure is shared to serve multiple users.
    For example, a software service provider could generate data that is housed in
    a single data warehouse, but accessed securely by multiple users. This storage
    strategy offers an opportunity to centralize management of data, simplify ETL
    processes, and optimize costs. Without data sharing, it is challenging for service
    providers to manage a multi-tenant environment because they have to balance between
    cost and providing a better user experience.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: AaaS提供商在云中为用户提供基于订阅的分析能力。这些服务提供商通常需要存储多个用户的数据，并安全地为其提供分析服务的订阅者访问权限。采用多租户存储策略可以帮助它们构建成本效益高且能够根据需求进行扩展的架构。多租户意味着一个软件实例及其支持基础设施被共享以服务多个用户。例如，软件服务提供商可以生成存储在单个数据仓库中的数据，但可以安全地被多个用户访问。这种存储策略提供了集中管理数据、简化ETL流程和优化成本的机会。没有数据共享，服务提供商很难在多租户环境中找到平衡，因为他们需要在成本和提供更好的用户体验之间权衡。
- en: Scaling Your Multi-tenant Architecture Using Data Sharing
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用数据共享来扩展您的多租户架构
- en: AaaS providers implementing multi-tenant architectures were previously limited
    to resources of a single data warehouse to meet the compute and concurrency requirements
    of users across all the tenants. As the number of tenants increased, you could
    either turn on Concurrency Scaling or create additional data warehouses. However,
    the addition of new data warehouses means additional ingestion pipelines and increased
    operational overhead.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，实施多租户架构的AaaS提供商受限于单个数据仓库的资源，以满足所有租户跨计算和并发需求。随着租户数量的增加，您可以选择开启并发缩放或创建额外的数据仓库。然而，增加新的数据仓库意味着额外的数据摄取管道和增加的运营开销。
- en: With [data sharing in Amazon Redshift](https://oreil.ly/5SXnv), you can scale
    and meet both objectives of managing costs by simplifying storage and ETL pipelines
    while still providing consistent performance. You can ingest data into a data
    warehouse designated as a producer and share this live data with one or more consumers.
    Data ingested into the producer is shared with one or more consumers, which allows
    total separation of ETL and BI workloads. Clusters accessing this shared data
    are isolated from each other, therefore performance of a producer isn’t impacted
    by workloads on consumers. This enables consumers to get consistent performance
    based on their individual compute capacity.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 通过[Amazon Redshift中的数据共享](https://oreil.ly/5SXnv)，您可以在简化存储和ETL管道的同时满足成本管理和提供一致性性能的双重目标。您可以将数据摄取到指定为生产者的数据仓库，并与一个或多个消费者共享这些实时数据。生产者中摄取的数据与一个或多个消费者共享，从而允许ETL和BI工作负载的完全分离。访问此共享数据的集群彼此隔离，因此生产者的性能不会受到消费者工作负载的影响。这使得消费者可以根据其各自的计算能力获得一致的性能。
- en: Several consumers can read data from the managed storage of a producer. This
    enables instant, granular, and high-performance access to data without copies
    or movement. Workloads accessing shared data are isolated from each other and
    the producer. You can distribute workloads across multiple data warehouses while
    simplifying and consolidating the ETL ingestion pipeline into one main producer
    data warehouse, providing optimal price for performance.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 几个消费者可以从生产者的托管存储中读取数据。这使得可以即时、细粒度和高性能地访问数据，无需复制或移动。访问共享数据的工作负载彼此隔离，也与生产者隔离。您可以将工作负载分布在多个数据仓库中，同时简化和整合ETL摄取管道到一个主要的生产者数据仓库，提供最佳的性价比。
- en: Consumer data warehouses can in turn be producers for the datasets they own.
    You can optimize costs even further by co-locating multiple tenants on the same
    consumer. For instance, you can group low volume tier 3 tenants into a single
    consumer to provider a lower cost offering, while high volume tier 1 tenants get
    their own isolated compute data warehouses. Consumer data warehouses can be created
    in the same account as the producer or in a different AWS account. With this you
    can have [separate billing](https://oreil.ly/kY718) for the consumers, where you
    can charge-back to the business group that uses the consumer or even allow your
    users to use their own Amazon Redshift data warehouse in their account, so they
    pay for usage of the consumer data warehouse. [Figure 7-8](#data_sharing_multi_vs_single_tenant)
    shows the difference in ETL and consumer access patterns in a multi-tenant architecture
    using data sharing versus a single data warehouse approach without data sharing.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者数据仓库可以反过来成为其拥有的数据集的生产者。您可以通过在同一个消费者上共享多个租户来进一步优化成本。例如，您可以将低容量第三层租户组合到一个单一的消费者中，以提供更低成本的服务，而高容量第一层租户则有他们自己独立的计算数据仓库。消费者数据仓库可以在与生产者相同的账户中创建，也可以在不同的AWS账户中创建。通过这种方式，您可以对消费者进行[单独计费](https://oreil.ly/kY718)，可以向使用消费者的业务组收费，甚至允许用户在其账户中使用自己的Amazon
    Redshift数据仓库，这样他们就可以为使用消费者数据仓库的费用付费。[图 7-8](#data_sharing_multi_vs_single_tenant)展示了在使用数据共享的多租户架构中ETL和消费者访问模式与不使用数据共享的单一数据仓库方法之间的差异。
- en: '![Multitenant architecture with data sharing compared to the single data warehouse
    approach](assets/ardg_0708.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![使用数据共享的多租户架构与单一数据仓库方法的比较](assets/ardg_0708.png)'
- en: Figure 7-8\. Multi-tenant architecture with data sharing compared to the single
    data warehouse approach
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-8\. 使用数据共享的多租户架构与单一数据仓库方法的比较
- en: Multi-tenant Storage Patterns Using Data Sharing
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用数据共享的多租户存储模式
- en: In a *multi-tenant* strategy, data is stored in a shared location for all tenants,
    enabling simplification of the ETL ingestion pipeline and data management. There
    are a few storage strategies to support this kind of multi-tenant access pattern,
    as shown in [Figure 7-9](#multitenant_storage_patterns).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在*多租户*策略中，数据存储在所有租户共享的位置，从而简化ETL摄取管道和数据管理。有几种存储策略支持这种多租户访问模式，如[图 7-9](#multitenant_storage_patterns)所示。
- en: Pool model
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 池模型
- en: Data is stored in a single database schema for all tenants, and a new column
    (tenant_id) is used to scope and control access to individual tenant data. Access
    to the multi-tenant data is controlled using views built on the tables.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 数据存储在所有租户的单个数据库模式中，新列（tenant_id）用于限定和控制对各个租户数据的访问。对多租户数据的访问是通过建立在表上的视图进行控制的。
- en: Bridge model
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 桥接模型
- en: Storage and access to data for each tenant is maintained in separate schemas
    in the same database.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个租户的数据的存储和访问是在同一数据库中的单独模式中维护的。
- en: Silo model
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 独立模型
- en: Storage and access control to data for each tenant is maintained in separate
    databases.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个租户的数据的存储和访问控制是在单独的数据库中维护的。
- en: '![Multitenant storage patterns](assets/ardg_0709.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![多租户存储模式](assets/ardg_0709.png)'
- en: Figure 7-9\. Multi-tenant storage patterns
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-9\. 多租户存储模式
- en: We will use the student analytics data model to demonstrate multiple strategies
    that leverage data sharing to implement a scalable multi-tenant architecture.
    We will cover detailed steps involved for each strategy using the data model we
    created in [Chapter 3, “Setting Up Your Data Models and Ingesting Data”](ch03.html#AR_TGD_CH3).
    In this use case, the producer is an AaaS provider and is responsible for loading
    and processing the data in one Amazon Redshift data warehouse. The consumers (tenants)
    are schools who have subscribed to the student insights dataset in one or many
    other Amazon Redshift data warehouses.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用学生分析数据模型来演示利用数据共享实施可扩展的多租户架构的多种策略。我们将详细介绍每种策略涉及的步骤，使用我们在[第 3 章，“设置数据模型和导入数据”](ch03.html#AR_TGD_CH3)中创建的数据模型。在此用例中，生产者是AaaS提供商，负责在一个Amazon
    Redshift数据仓库中加载和处理数据。消费者（租户）是订阅了学生洞察数据集的学校，在一个或多个Amazon Redshift数据仓库中。
- en: 'The high-level steps involved in enabling data sharing across data warehouses
    are as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 实施跨数据仓库启用数据共享的高级步骤如下：
- en: Create a datashare in the producer and assign database objects to the datashare.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生产者中创建数据共享并将数据库对象分配给数据共享。
- en: From the producer, grant usage on the datashare to the consumer, identified
    by namespace or AWS account.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从生产者那里，授予消费者对数据共享的使用权，通过命名空间或AWS账户来识别。
- en: From the consumer, create an external database using the datashare from the
    producer.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从消费者端，使用生产者的数据共享创建外部数据库。
- en: Query the tables in the datashare through the external shared database in the
    consumer. Grant access to other users to access this shared database and objects.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过消费者中的外部共享数据库查询数据共享中的表。授予其他用户访问此共享数据库和对象的权限。
- en: In the following examples, we will use the school table to identify our consumers
    (tenants). Since all the tables have the `school_id` column, you can use this
    column to differentiate and securely share only the authorized data to the respective
    consumers.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的示例中，我们将使用学校表来识别我们的消费者（租户）。由于所有表都有`school_id`列，您可以使用此列来区分并安全共享仅授权给相应消费者的数据。
- en: Before we get started, get the namespaces of the producer and consumer data
    warehouses. You can do this by using the AWS console, or you can log into each
    of the data warehouses and execute the `SELECT CURRENT_NAMESPACE` statement.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请获取生产者和消费者数据仓库的命名空间。您可以通过使用AWS控制台或登录到每个数据仓库并执行`SELECT CURRENT_NAMESPACE`语句来执行此操作。
- en: In the following code samples, replace the `producer_namespace` and `consumer_namespace`
    placeholders with the corresponding namespaces from your environment.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码示例中，用您环境中的相应命名空间替换`producer_namespace`和`consumer_namespace`占位符。
- en: To demonstrate the multi-tenant architecture patterns, we will use a modified
    version of the Open University Learning Analytics dataset and include `school_id`
    to all tables to store data for multiple schools. The multi-tenant version of
    the dataset with `school_id` added is available in [Amazon S3](https://oreil.ly/aQaBC).
    You can use this dataset to ingest into Amazon Redshift after you create the tables
    using the scripts in [Example 7-9](#multitenant_sis_data_model). Note that there
    is a new table school, to store the details of individual schools, and the `school_id`
    column is added to each of the tables. The sample data consists of data for two
    different schools, which we will use to demonstrate how you can build a multi-tenant
    storage strategy using the Amazon Redshift data sharing feature.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示多租户架构模式，我们将使用Open University Learning Analytics数据集的修改版本，并在所有表中包含`school_id`以存储多个学校的数据。添加了`school_id`的多租户版本数据集可在[Amazon
    S3](https://oreil.ly/aQaBC)中找到。您可以使用这个数据集，在使用[示例 7-9](#multitenant_sis_data_model)中的脚本创建表后，将其导入到Amazon
    Redshift中。请注意，有一个新的school表，用于存储各个学校的详细信息，并在每个表中添加了`school_id`列。示例数据包括两所不同学校的数据，我们将使用这些数据来演示如何利用Amazon
    Redshift数据共享功能构建多租户存储策略。
- en: Example 7-9\. Creating schema and tables for student information data
  id: totrans-126
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-9\. 为学生信息数据创建模式和表
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To ingest the multi-tenant version of the sample student information dataset,
    use the commands as shown in [Example 7-10](#load_multi_sis_data_model).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要导入样本学生信息数据集的多租户版本，请使用如下命令，如[示例 7-10](#load_multi_sis_data_model)所示。
- en: Example 7-10\. Create schema and tables for student information data
  id: totrans-129
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-10\. 为学生信息数据创建模式和表
- en: '[PRE10]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Pool model
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 池模型
- en: The *pool model* represents an all-in, multi-tenant model where all tenants
    share the same storage constructs, and it provides the most benefit in simplifying
    the AaaS solution. With this model, data storage is centralized in one database,
    and data for all tenants is stored in the same data models. Data security to prevent
    cross-tenant access is one of the main aspects to address with the pool model.
    You can implement row-level filtering and provide secure access to the data using
    database views and apply dynamic filtering based on the tenant querying the data
    through the use of the `current_namespace` variable. To scope and control access
    to tenant data, add a column (`consumer_namespace`) that serves as a unique identifier
    for each tenant.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*池模型*代表了一个全面、多租户的模型，其中所有租户共享相同的存储结构，并且在简化AaaS解决方案方面提供了最大的好处。通过这种模型，数据存储集中在一个数据库中，所有租户的数据存储在相同的数据模型中。数据安全是使用池模型需要解决的主要方面之一，以防止跨租户访问。您可以实现基于行级过滤，并使用数据库视图提供对数据的安全访问，并根据通过使用`current_namespace`变量查询数据的租户应用动态过滤。为了限定和控制对租户数据的访问，添加一个列(`consumer_namespace`)作为每个租户的唯一标识符。'
- en: Let’s continue working through the use case and add the `consumer_namespace`
    to the school table to control access for subscribers from various schools through
    their Amazon Redshift data warehouse. When you run the query in [Example 7-11](#school_namespace_query),
    you can see the `consumer_namespace` has unique values for each of the schools.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续通过用例并向学校表添加`consumer_namespace`来控制从各学校的订阅者通过他们的Amazon Redshift数据仓库访问的情况。当您运行[示例 7-11](#school_namespace_query)中的查询时，您可以看到`consumer_namespace`对每所学校都有唯一的值。
- en: Example 7-11\. School mapping to `consumer_namespace`
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-11\. 学校映射到`consumer_namespace`
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '| school_id | school_name | address | city | website_url | consumer_namespace
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| school_id | school_name | address | city | website_url | consumer_namespace
    |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 101 | New York Public School | null | New York | www.nyps.edu | xxxxc8ee-f6a5-xxxx-xxxx-yyyy66d7zzzz
    |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 101 | 纽约公立学校 | null | New York | www.nyps.edu | xxxxc8ee-f6a5-xxxx-xxxx-yyyy66d7zzzz
    |'
- en: '| 102 | California Public School | null | Sacramento | www.caps.edu | xxxxc7ee-xxxx-468f-xxxx-yyyy77d7zzzz
    |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 102 | 加利福尼亚公立学校 | null | Sacramento | www.caps.edu | xxxxc7ee-xxxx-468f-xxxx-yyyy77d7zzzz
    |'
- en: '[Figure 7-10](#data_sharing_pool_model) illustrates the pool model architecture.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 7-10](#data_sharing_pool_model)说明了池模型架构。'
- en: '![Pool model multi-tenant architecture with data sharing compared to the single
    data warehouse approach](assets/ardg_0710.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![使用数据共享的池模型多租户架构与单个数据仓库方法进行比较](assets/ardg_0710.png)'
- en: Figure 7-10\. Pool model multi-tenant architecture with data sharing compared
    to the single data warehouse approach
  id: totrans-142
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-10\. 使用数据共享的池模型多租户架构与单个数据仓库方法进行比较
- en: Creating database views in the producer
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在生产者中创建数据库视图
- en: For the multi-tenant architecture, you can create a materialized view as we
    did earlier in [“Building a Star Schema”](ch03.html#create_star_schema_materialized_view).
    But here you include the school table and use `school_id` in the `where` clause
    to manage row-level security. You can use the script in [Example 7-12](#creatematview_student_lmsactivites_and_score)
    to create the materialized view for the multi-tenant pool model. Note that we
    are using a different schema `openlearnm` to store database objects related to
    the multi-tenant model.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多租户架构，您可以像我们之前在[“构建星型模式”](ch03.html#create_star_schema_materialized_view)中所做的那样创建一个物化视图。但是在这里，您包括学校表，并在`where`子句中使用`school_id`来管理行级安全性。您可以使用[示例 7-12](#creatematview_student_lmsactivites_and_score)中的脚本为多租户池模型创建物化视图。请注意，我们使用了一个不同的模式`openlearnm`来存储与多租户模型相关的数据库对象。
- en: 'Example 7-12\. Student activities: `total_score` and `mean_score`'
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-12\. 学生活动：`total_score`和`mean_score`
- en: '[PRE12]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To control and restrict row-level access to allow access to only the students
    of the school from which the consumer is accessing the data, you can create a
    view `v_student_lmsactivites_and_score` and filter the records based on the consumer
    namespace that is querying the data. The view in [Example 7-13](#createview_student_lmsactivites_and_score)
    is a join between *mv_student_lmsactivities_and_score* and the table *school*
    with a where condition to filter values based on [`current_namespace`](https://oreil.ly/OfJWE).
    This system variable `current_namespace` contains the value of the namespace of
    the consumer data warehouse from which the query is initiated.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 要控制和限制行级访问权限，仅允许学生从其所在学校访问的数据，您可以创建一个视图 `v_student_lmsactivites_and_score`，并根据查询数据的消费者命名空间过滤记录。[示例 7-13](#createview_student_lmsactivites_and_score)中的视图是
    *mv_student_lmsactivities_and_score* 和表 *school* 的连接，并且有一个基于 [`current_namespace`](https://oreil.ly/OfJWE)
    进行值过滤的 where 条件。系统变量 `current_namespace` 包含了发起查询的消费者数据仓库的命名空间值。
- en: Example 7-13\. Creating view for calculating student scores
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-13\. 创建用于计算学生分数的视图
- en: '[PRE13]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Creating datashares in producer and granting usage to the consumer
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生产者中创建数据共享并授予消费者使用权限
- en: Now you are ready to create a datashare and share the view with the consumers.
    Connect to your producer data warehouse and create the datashare `learnsharem`,
    add the openlearn schema, and add the view you created to be shared with the consumers
    as in [Example 7-14](#create_datashare_grant_usage_pool). In the `GRANT USAGE`
    statement, replace the *`consumer namespace`* with the namespace of your data
    warehouse.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以创建一个数据共享并与消费者共享视图了。连接到您的生产者数据仓库，创建数据共享 `learnsharem`，添加 `openlearn` 模式，并添加您创建的视图以与消费者共享，如[示例 7-14](#create_datashare_grant_usage_pool)中所示。在
    `GRANT USAGE` 语句中，用消费者数据仓库的命名空间替换 *`consumer namespace`*。
- en: Example 7-14\. Setting up producer datashare
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-14\. 设置生产者数据共享
- en: '[PRE14]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note the name of the datashare ends with *m*, indicating schema for for multi-tenant
    as a naming convention to differentiate from the earlier datashare `learnshare`
    you created.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 注意数据共享的名称以 *m* 结尾，这是一个命名约定，用于区分您之前创建的 `learnshare` 数据共享的多租户模式模式。
- en: Now connect to your consumer to create a database referencing the datashare
    on the producer, as in [Example 7-15](#consumer_create_database_pool). Note again
    that this database is just a pointer to the datashare and does not hold any data
    on its own.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在连接到您的消费者，创建一个引用生产者上数据共享的数据库，如[示例 7-15](#consumer_create_database_pool)所示。再次注意，这个数据库只是指向数据共享的指针，并不存储任何数据。
- en: Example 7-15\. Creating local database from remote datashare
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-15\. 从远程数据共享创建本地数据库
- en: '[PRE15]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Once you create the database, you can query the data live using a three-part
    notation of `db_name.schema.view` as in [Example 7-16](#consumer_query_database_pool).
    When you query from the consumer, note that even without the where clause to filter
    out certain records, data returned will be for only the students that correspond
    to the consumer cluster from which the query is being triggered. This is controlled
    at the view level, where the data is restricted based on the `consumer namespace`,
    which is joined to the school table.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '创建数据库后，您可以使用 `db_name.schema.view` 的三部分表示法实时查询数据，如[示例 7-16](#consumer_query_database_pool)所示。当从消费者查询时，请注意，即使没有
    `where` 子句来过滤特定记录，返回的数据也只会是与发起查询的消费者集群对应的学生的数据。这在视图级别进行控制，根据连接到学校表的 `consumer
    namespace` 限制数据。  '
- en: Example 7-16\. Querying the view
  id: totrans-159
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-16\. 查询视图
- en: '[PRE16]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: When you select from the view `v_student_lmsactivities_and_score`, you will
    see only the data associated with the consumer namespace you are using to query
    the data. When this query is passed to the producer from this consumer, the `current_namespace`
    variable will have the namespace of this consumer. Hence, the materialized view
    will filter the records just from this consumer based on the join condition from
    the school table.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当您从视图 `v_student_lmsactivities_and_score` 中选择时，您将只看到与用于查询数据的消费者命名空间相关联的数据。当此查询从消费者传递到生产者时，`current_namespace`
    变量将具有此消费者的命名空间。因此，物化视图将根据与学校表的连接条件仅过滤来自此消费者的记录。
- en: For a detailed description of how you can set up and test multiple consumers,
    you can refer to the blog [“Implementing Multi-tenant Patterns in Amazon Redshift
    Using Data Sharing”](https://oreil.ly/YXYbF).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 要详细了解如何设置和测试多个消费者，请参考博客 [“在 Amazon Redshift 中使用数据共享实现多租户模式”](https://oreil.ly/YXYbF)。
- en: Using Role-Level Security
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用角色级安全性
- en: Instead of using database views defined on the producer, you can use *row-level
    security* (RLS), which is built on the foundation of [role-based access control
    (RBAC)](https://oreil.ly/dNIsy) to restrict rows for each consumer. RLS allows
    you to control which users or roles can access specific records of data within
    tables based on security policies that are defined at the database object level.
    This RLS capability in Amazon Redshift enables you to dynamically filter existing
    rows of data in a table.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是使用在生产者上定义的数据库视图，你可以使用建立在 [基于角色的访问控制（RBAC）](https://oreil.ly/dNIsy) 基础上的*行级安全*（RLS），以限制每个消费者的行。RLS
    允许你控制哪些用户或角色可以根据在数据库对象级别定义的安全策略访问特定记录的数据。Amazon Redshift 中的这种 RLS 能力使你能够动态过滤表格中现有的数据行。
- en: Using the previous example, assume the school table still has the `consumer_namespace`
    field but all tables are shared with all consumers. The following RLS policy in
    [Example 7-17](#rls_create_policy_grant_select) can be defined and will force
    a join to the school table to ensure that only schools where the `consumer_namespace`
    = `current_namespace` are returned.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前的示例，假设 school 表仍然具有 `consumer_namespace` 字段，但所有表格都与所有消费者共享。可以定义如 [Example 7-17](#rls_create_policy_grant_select)
    中所示的以下 RLS 策略，并强制在与 school 表进行连接时仅返回 `consumer_namespace` = `current_namespace`
    的学校。
- en: Example 7-17\. Creating row-level security policy
  id: totrans-166
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 7-17\. 创建行级安全策略
- en: '[PRE17]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Next, you can attach this policy, as shown in [Example 7-18](#rls_attach_policy),
    to any table containing the `school_id` field and any user who is associated to
    the database role school will have this policy applied and see only their data.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你可以像在 [Example 7-18](#rls_attach_policy) 中展示的那样，将此策略附加到包含 `school_id` 字段的任何表格，并且任何关联到数据库角色
    school 的用户都将应用此策略，并且只能看到他们自己的数据。
- en: Example 7-18\. Associating policy on object to role
  id: totrans-169
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 7-18\. 将策略关联到对象角色
- en: '[PRE18]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Bridge model
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 桥接模型
- en: In the *bridge model*, you store data for each tenant in its own schema in a
    database with a similar set of tables. You create datashares for each schema and
    share them with the corresponding consumer so the query workloads on each schema
    can be routed to consumers. This is an appealing balance between the silo and
    pool model, providing both data isolation and reuse of ETL code across different
    schemas. Using a bridge model without data sharing, queries from all users are
    directed to a single data warehouse. With Amazon Redshift, you can create up to
    9,900 schemas, so if your use case requires more than this limit, you can consider
    creating more databases. For more information, see [Quotas and Limits in Amazon
    Redshift](https://oreil.ly/_qd3j). [Figure 7-11](#data_sharing_bridge_model) illustrates
    the bridge model.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在*桥接模型*中，你可以将每个租户的数据存储在其自己的架构中，这些架构与具有类似表格集合的数据库相似。你为每个架构创建数据共享，并将其与相应的消费者共享，以便将每个架构的查询工作负载路由到消费者。这是在独立模型和池模型之间寻求平衡的一种吸引人方法，既提供了数据隔离，又在不同架构之间复用了
    ETL 代码。在 Amazon Redshift 中，你可以创建高达 9,900 个架构，因此，如果你的使用情况需要超过此限制，可以考虑创建更多数据库。有关更多信息，请参阅
    [Amazon Redshift 中的配额和限制](https://oreil.ly/_qd3j)。[Figure 7-11](#data_sharing_bridge_model)
    说明了桥接模型。
- en: '![Bridge model multi-tenant architecture with data sharing compared to the
    single data warehouse approach](assets/ardg_0711.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![桥接模型多租户架构与数据共享相比单一数据仓库方法](assets/ardg_0711.png)'
- en: Figure 7-11\. Bridge model multi-tenant architecture with data sharing compared
    to the single data warehouse approach
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-11\. 桥接模型多租户架构与数据共享相比单一数据仓库方法
- en: Creating database schemas and tables in the producer
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建生产者中的数据库架构和表格
- en: Let’s continue using the previous use case. As you did in the pool model, the
    first step is to create the database schema and tables. Log in to the producer
    and create separate schemas for each tenant. For example, you can create two schemas,
    `learnschema_school1` and `learnschema_school2`, to store student data from two
    different schools, and the same tables you created in [Example 3-1](ch03.html#creating_sis_data_model)
    under each schema. To maximize ETL code reuse, ensure the data models are the
    same across all schemas.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用之前的用例。就像在池模型中所做的那样，第一步是在生产者中创建数据库架构和表格。登录到生产者并为每个租户创建单独的架构。例如，你可以创建两个架构，`learnschema_school1`
    和 `learnschema_school2`，用于存储来自两所不同学校的学生数据，并在每个架构下创建与 [Example 3-1](ch03.html#creating_sis_data_model)
    中相同的表格。为了最大化 ETL 代码的复用性，请确保所有架构中的数据模型保持一致。
- en: Creating datashares in the producer and granting usage to the consumer
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在生产者中创建数据共享并授予消费者使用权限
- en: To create datashares in a bridge model, create two datashares, `learnshare-school1`
    and `learnshare-school2`, and add all the tables in the respective schema for
    school1 and school2 to each of the datashares. Then grant access to the corresponding
    consumers in the same account or a different account for the consumers to access
    the data.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 要在桥接模型中创建数据共享，创建两个数据共享，`learnshare-school1`和`learnshare-school2`，并将学校1和学校2的各自模式中的所有表添加到各自的数据共享中。然后，为消费者授予访问相同帐户或不同帐户中相应消费者数据的访问权限。
- en: Create two datashares, `learnshare-school1` and `learnshare-school2`, to share
    the database objects under the two schemas to the respective consumers as shown
    in [Example 7-19](#create_datashare_bridge).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 创建两个数据共享，`learnshare-school1`和`learnshare-school2`，以共享两个模式下的数据库对象给各自的消费者，如[示例 7-19](#create_datashare_bridge)所示。
- en: Example 7-19\. Creating datashares
  id: totrans-180
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-19。创建数据共享
- en: '[PRE19]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Alter the datashare and add the schema(s) for respective tenants and the respective
    tables to be shared with the consumer using the scripts in [Example 7-20](#alter_datashare_bridge).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 修改数据共享并添加各租户的模式及相应要共享的表，使用[示例 7-20](#alter_datashare_bridge)中的脚本。
- en: Example 7-20\. Adding objects to datashares
  id: totrans-183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-20。向数据共享添加对象
- en: '[PRE20]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now grant usage on the datashare for the first school `learnshare-school1` to
    the namespace of the consumer data warehouse for school1, as in [Example 7-21](#grant_usage_bridge).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，授予第一个学校`learnshare-school1`的数据共享使用权限，使其能够访问学校1的消费者数据仓库的命名空间，如[示例 7-21](#grant_usage_bridge)所示。
- en: Example 7-21\. Allowing access to datashare
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-21。允许访问数据共享
- en: '[PRE21]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: To access consumer data of school1, log into the data warehouse for the first
    school and create a database referencing the datashare using script in [Example 7-22](#consumer_createdb_bridge).
    You can also view the datashares from the `SVV_DATASHARES` system view, or the
    command `SHOW DATASHARES`. If you want to view the list of objects in each datashare,
    you can view the details by querying the `SVV_DATASHARE_OBJECTS` system view.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问学校1的消费者数据，请登录第一个学校的数据仓库，并使用[示例 7-22](#consumer_createdb_bridge)中的脚本引用数据共享创建数据库。您还可以从`SVV_DATASHARES`系统视图查看数据共享，或使用`SHOW
    DATASHARES`命令。如果要查看每个数据共享中的对象列表，可以通过查询`SVV_DATASHARE_OBJECTS`系统视图查看详细信息。
- en: Example 7-22\. Creating local database from remote datashare
  id: totrans-189
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-22。从远程数据共享创建本地数据库
- en: '[PRE22]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the bridge model, since the database objects for the respective schools are
    organized under each schema, and the datashare contains only the respective schema
    for the school, a consumer can access only the database objects relevant for that
    school. In this example, school1 will be restricted to querying data from `learnschema_school1`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在桥接模型中，由于各学校的数据库对象都组织在各自的模式下，并且数据共享只包含各学校的相应模式，因此消费者只能访问与该学校相关的数据库对象。在此示例中，学校1将限制仅从`learnschema_school1`查询数据。
- en: Silo model
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 筒仓模型
- en: The third option is to store data for each tenant in separate databases within
    a data warehouse if you want to have distinct data models and separate monitoring,
    management, and security footprints—the *silo model*. Amazon Redshift supports
    cross-database queries across databases, which allows you to simplify data organization.
    You can store common or granular datasets used across all tenants in a centralized
    database and use the cross-database query capability to join relevant data for
    each tenant.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个选项是在数据仓库中为每个租户存储数据于单独的数据库中，如果您希望具有不同的数据模型和单独的监控、管理和安全足迹——*筒仓模型*。Amazon Redshift支持跨数据库查询，允许您简化数据组织。您可以将所有租户使用的通用或粒度数据集存储在集中式数据库中，并使用跨数据库查询功能来连接每个租户的相关数据。
- en: The steps to create a datashare in a silo model are similar to the bridge model;
    however, unlike the bridge model (where datashare is for each schema), the silo
    model has a datashare created for each database. [Figure 7-12](#data_sharing_silo_model)
    illustrates the architecture of the silo model.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 创建筒仓模型中的数据共享的步骤与桥接模型类似；但与桥接模型不同（其中数据共享是为每个模式），筒仓模型为每个数据库创建一个数据共享。[图 7-12](#data_sharing_silo_model)展示了筒仓模型的架构。
- en: '![Silo Model multi-tenant architecture with data sharing compared to the single
    data warehouse approach](assets/ardg_0712.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![筒仓模型多租户架构与单一数据仓库方法相比](assets/ardg_0712.png)'
- en: Figure 7-12\. Silo model multi-tenant architecture with data sharing compared
    to the single data warehouse approach
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-12。与单一数据仓库方法相比的筒仓模型多租户架构
- en: Creating databases and datashares in the producer
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在生产者中创建数据库和数据共享
- en: 'Again, let’s continue using the previous use case. To create datashares for
    the silo model in the producer, complete the following steps:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 继续使用之前的用例。为生产者的silo模型创建datashare，请完成以下步骤：
- en: Log in to the producer as an admin user and create separate databases for each
    tenant, as in [Example 7-23](#createdb_silo).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 作为管理员用户登录到生产者并为每个租户创建单独的数据库，如[示例 7-23](#createdb_silo)。
- en: Example 7-23\. Creating databases
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-23\. 创建数据库
- en: '[PRE23]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Log in again to the producer database `learndb_school1` with the user ID for
    the first school and create the schema `learnschema`, as in [Example 7-24](#createschema_silo).
    Similarly, you can log in to the producer database `learndb_school2` with the
    user ID for the second school and create the schema `learnschema`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 再次登录到生产者数据库`learndb_school1`，使用第一所学校的用户ID创建模式`learnschema`，如[示例 7-24](#createschema_silo)。类似地，您可以使用第二所学校的用户ID登录到生产者数据库`learndb_school2`并创建模式`learnschema`。
- en: Example 7-24\. Creating schema
  id: totrans-203
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-24\. 创建模式
- en: '[PRE24]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Then, using the scripts in [Example 3-1](ch03.html#creating_sis_data_model),
    create the tables for the student information data model in each database, storing
    the student data for each respective school. One benefit of this strategy is that
    because the schema and table names are identical, the ETL process can be reused
    with only the connection parameter of the database name being changed.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用[示例 3-1](ch03.html#creating_sis_data_model)中的脚本，在每个数据库中为学生信息数据模型创建表，存储各自学校的学生数据。这种策略的一个好处是，因为架构和表名相同，ETL过程可以仅通过更改数据库名称的连接参数进行重用。
- en: Creating datashares in the producer and granting usage to the consumer
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在生产者中创建datashare并授予消费者使用权
- en: Next, create the datashares like you did in the [“Bridge model”](#bridge_model),
    this time connecting to each database separately. For the first school, you could
    execute the script in [Example 7-25](#create_datashare_silo_school1).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建datashare，就像在[“桥模型”](#bridge_model)中所做的那样，这次连接到每个数据库单独。对于第一所学校，您可以在[示例 7-25](#create_datashare_silo_school1)中执行脚本。
- en: Example 7-25\. Setting up datashare for the first school
  id: totrans-208
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-25\. 为第一所学校设置datashare
- en: '[PRE25]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: For the second school, you could execute this script in [Example 7-26](#create_datashare_silo_school2).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二所学校，您可以在[示例 7-26](#create_datashare_silo_school2)中执行此脚本。
- en: Example 7-26\. Setting up datashare for the second school
  id: totrans-211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-26\. 为第二所学校设置datashare
- en: '[PRE26]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: External Data Sharing with AWS ADX Integration
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与AWS ADX集成的外部数据共享
- en: For some users, sharing data within an account or between accounts is sufficient
    for intra-organization collaboration, but for inter-organization collaboration
    and monetization use cases, you can use ADX. With ADX, you can share data from
    Amazon S3 or directly query data from Amazon Redshift data warehouses through
    a datashare.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些用户来说，在账户内或账户之间共享数据已足够进行组织内协作，但对于跨组织协作和货币化用例，您可以使用ADX。通过ADX，您可以通过datashare从Amazon
    S3共享数据或直接从Amazon Redshift数据仓库查询数据。
- en: '*AWS Data Exchange* (ADX) is a data marketplace where data providers can host
    their data products for subscribers to access on a subscription basis. ADX hosts
    data products from over three hundred providers and provides subscription-based
    access for data as files, APIs, or Amazon Redshift datashares. Subscribers can
    access the data directly through data lakes, applications, analytics, and machine
    learning models that use the data. As an AWS service, ADX is secure and compliant,
    integrated with AWS and third-party tools and services, and offers consolidated
    billing and subscription management.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '*AWS数据交换* (ADX) 是一个数据市场，数据提供者可以在订阅基础上托管其数据产品，供订阅者访问。ADX托管来自三百多个提供者的数据产品，并为数据提供文件、API或Amazon
    Redshift datashare的订阅式访问。订阅者可以通过数据湖、应用程序、分析和使用数据的机器学习模型直接访问数据。作为AWS服务，ADX安全合规，与AWS和第三方工具和服务集成，提供统一的计费和订阅管理。'
- en: With its integration for Amazon Redshift, you can license access to your Amazon
    Redshift data through ADX. When you subscribe to a product with ADX datashares,
    ADX automatically adds you as a data consumer on all of its datashares included
    with the product. You can automatically generate invoices and collect payments
    centrally and automatically disburse through AWS Marketplace Entitlement Service.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 通过其与Amazon Redshift的集成，您可以通过ADX许可访问Amazon Redshift数据。当您订阅带有ADX datashare的产品时，ADX会自动将您添加为该产品中包含的所有datashare的数据消费者。您可以自动生成发票，并通过AWS
    Marketplace Entitlement Service集中和自动收取支付。
- en: Providers can license data in Amazon Redshift at a granular level, such as schemas,
    tables, views, and UDFs. You can use the same ADX datashare across multiple ADX
    products. Any objects added to the ADX datashare are available to consumers. Producers
    can view all AWS Data Exchange datashares managed by ADX on their behalf using
    Amazon Redshift API operations, SQL commands, and the Amazon Redshift console.
    Consumers who subscribe to a product of ADX datashares have read-only access to
    the objects in the datashares.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 提供者可以在Amazon Redshift上以细粒度的级别许可数据，如模式、表、视图和UDF。您可以在多个ADX产品中使用同一ADX数据共享。添加到ADX数据共享的任何对象都可供消费者使用。生产者可以使用Amazon
    Redshift API操作、SQL命令和Amazon Redshift控制台查看由ADX代表其管理的所有AWS Data Exchange数据共享。订阅具有ADX数据共享产品的消费者对数据共享中的对象具有只读访问权限。
- en: An *AWS Data Exchange datashare* is a unit of licensing for sharing your data
    through ADX. AWS manages billing and payments associated with subscriptions to
    ADX and use of Amazon Redshift data sharing. Approved data providers can add ADX
    datashares to ADX products. When you subscribe to a product with ADX datashares,
    you get access to the datashares in the product. We will cover more details on
    how ADX integration with Amazon Redshift works in [“External Data Sharing with
    AWS ADX Integration”](#External-Sharing-Amazon-ADX-integration). Data producers
    who are approved providers for ADX datashares can add ADX datashares and license
    data as a product through ADX.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '*AWS Data Exchange数据共享* 是通过ADX分享数据的许可单位。AWS负责管理与ADX订阅和使用Amazon Redshift数据共享相关的计费和付款。批准的数据提供者可以将ADX数据共享添加到ADX产品中。当您订阅具有ADX数据共享的产品时，您可以访问产品中的数据共享。我们将更详细地介绍ADX与Amazon
    Redshift集成的工作方式在[“通过AWS ADX集成进行外部数据共享”](#External-Sharing-Amazon-ADX-integration)中。获得批准的ADX数据共享提供者可以通过ADX将ADX数据共享添加并许可为产品。'
- en: When you subscribe to a product with AWS Data Exchange datashares, ADX automatically
    adds you as a data consumer on all ADX datashares included with the product. ADX
    also removes you from ADX datashares when your subscription ends. ADX integrates
    with AWS billing to provide unified billing, invoicing, payment collection, and
    payment distribution for paid products with ADX datashares. To register as an
    ADX data provider, see [Getting Started as a Provider](https://oreil.ly/iokOZ).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当您订阅具有AWS Data Exchange数据共享的产品时，ADX会自动将您添加为该产品中包含的所有ADX数据共享的数据消费者。当您的订阅结束时，ADX也会将您从ADX数据共享中移除。ADX与AWS计费集成，为具有ADX数据共享的付费产品提供统一的计费、发票、付款收集和付款分发。要注册为ADX数据提供者，请参阅[作为提供者入门](https://oreil.ly/iokOZ)。
- en: If you are a consumer with an active ADX subscription (also known as subscribers
    on ADX), you can find, subscribe to, and query granular, up-to-date data in Amazon
    Redshift without the need to extract, transform, and load the data.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是具有活动ADX订阅（也称为ADX订户）的消费者，则无需提取、转换和加载数据即可在Amazon Redshift中查找、订阅和查询细粒度、最新的数据。
- en: If you want to consume third-party producer data, you can browse the AWS Data
    Exchange catalog to discover and subscribe to datasets in Amazon Redshift. After
    your ADX subscription is active, you can create a database from the datashare
    in their data warehouse and query the data in Amazon Redshift.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想使用第三方生产者数据，您可以浏览AWS Data Exchange目录，发现并订阅Amazon Redshift中的数据集。在您的ADX订阅激活后，您可以在他们的数据仓库中从数据共享创建数据库，并在Amazon
    Redshift中查询数据。
- en: As a subscriber, you can directly use data from providers without any further
    processing, without need for an ETL process. Because you don’t have to do any
    processing, the data is always current and can be used directly in your Amazon
    Redshift queries. ADX for Amazon Redshift takes care of managing all entitlements
    and payments for you, with all charges billed to your AWS account.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 作为订阅者，您可以直接使用来自提供者的数据，无需进一步处理，无需ETL过程。因为您无需进行任何处理，数据始终是当前的，并可以直接用于您的Amazon Redshift查询中。ADX为Amazon
    Redshift管理所有授权和付款，所有费用都计入您的AWS账户。
- en: Publishing a Data Product
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发布数据产品
- en: To publish a data product in Amazon Redshift using ADX, you can create ADX datashares
    that connect to your Amazon Redshift data warehouses. To add ADX datashares to
    products on ADX, you must be a registered ADX provider.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Amazon Redshift中使用ADX发布数据产品，您可以创建连接到您的Amazon Redshift数据仓库的ADX数据共享。要将ADX数据共享添加到ADX产品中，您必须是注册的ADX提供者。
- en: Once you are registered as a provider, you can create AWS Data Exchange datashares
    for Amazon Redshift to publish as a data product in data exchange. When you subscribe
    to a product containing datashares, you are granted read-only access to the tables,
    views, schemas, and user-defined functions that a data provider adds to the datashare.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦注册为提供者，您可以创建AWS Data Exchange数据共享以将Amazon Redshift发布为数据交换中的数据产品。当您订阅包含数据共享的产品时，您将被授予只读访问权限，以访问数据提供者添加到数据共享的表、视图、模式和用户定义函数。
- en: Let’s walk through how you can share the student materialized view as a data
    product through data exchange. The first step is to create a data exchange datashare,
    and you can create this datashare either using the console as shown in [Figure 7-13](#create_dataexchange_datashare)
    or using scripts.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看如何通过数据交换将学生的材料化视图作为数据产品共享。第一步是创建一个数据交换数据共享，你可以按照[图 7-13](#create_dataexchange_datashare)中所示使用控制台或脚本创建此数据共享。
- en: '![Create a data exchange datashare](assets/ardg_0713.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![创建数据交换数据共享](assets/ardg_0713.png)'
- en: Figure 7-13\. Create a data exchange datashare
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-13\. 创建数据交换数据共享
- en: Then you add the database objects for the datashare; in this case, choose `mv_student_lmsactivities_and_score`
    (see [Figure 7-14](#add_dataexchange_datashare_objects)).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 然后添加数据共享的数据库对象；在这种情况下，选择`mv_student_lmsactivities_and_score`（参见[图 7-14](#add_dataexchange_datashare_objects)）。
- en: '![Add data exchange datashare objects](assets/ardg_0714.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![添加数据交换数据共享对象](assets/ardg_0714.png)'
- en: Figure 7-14\. Add data exchange datashare objects
  id: totrans-231
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-14\. 添加数据交换数据共享对象
- en: Once you create the datashare and add the database objects to it, you can select
    the datashare `learnshare_adx` and create a dataset on AWS Data Exchange (see
    [Figure 7-15](#create_dataset_on_adx)). This datashare will then be listed in
    AWS Data Exchange for consumers to subscribe to the dataset.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了数据共享并添加了数据库对象，你可以选择数据共享`learnshare_adx`并在AWS Data Exchange上创建一个数据集（参见[图 7-15](#create_dataset_on_adx)）。这个数据共享将在AWS
    Data Exchange上列出，供消费者订阅数据集。
- en: '![Creating ADX Dataset from Redshift Datashare](assets/ardg_0715.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![从Redshift数据共享创建ADX数据集](assets/ardg_0715.png)'
- en: Figure 7-15\. Creating ADX Dataset from Redshift Datashare
  id: totrans-234
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-15\. 从Redshift数据共享创建ADX数据集
- en: Follow the steps to create the dataset, and finalize the datashare version.
    Now you can create a data product from the dataset (see [Figure 7-16](#create_product_from_dataset)).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 按照步骤创建数据集，并完成数据共享版本。现在你可以从数据集创建数据产品（参见[图 7-16](#create_product_from_dataset)）。
- en: '![Create product from dataset](assets/ardg_0716.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![从数据集创建产品](assets/ardg_0716.png)'
- en: Figure 7-16\. Create product from dataset
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-16\. 从数据集创建产品
- en: For detailed steps, see the online documentation on how to [publish a data product
    containing Amazon Redshift datasets](https://oreil.ly/QyO4p).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解详细步骤，请参阅有关如何[发布包含Amazon Redshift数据集的数据产品](https://oreil.ly/QyO4p)的在线文档。
- en: Note that you need to register as a marketplace seller to publish data products.
    If you would like to provide paid products and are eligible to do so, you must
    submit your tax and banking information.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您需要注册成为市场销售商才能发布数据产品。如果您希望提供付费产品并且符合条件，必须提交税务和银行信息。
- en: Subscribing to a Published Data Product
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 订阅已发布的数据产品
- en: If you want to consume data products from third-party producers, you can use
    an AWS Data Exchange subscription to get access to the data. If you are a subscriber
    with an active ADX subscription, you can browse the ADX catalog on the ADX console
    to discover products containing ADX datashares (see [Figure 7-17](#adx_browse_data_products)).
    After getting your ADX subscription active, you can create a database from the
    datashare in their data warehouse and query the data in Amazon Redshift.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想从第三方生产商那里获取数据产品，可以使用AWS Data Exchange订阅来访问数据。如果你是一个有着活跃ADX订阅的订阅者，可以在ADX控制台上浏览ADX目录，发现包含ADX数据共享的产品（参见[图 7-17](#adx_browse_data_products)）。在ADX订阅激活后，可以在他们的数据仓库中从数据共享创建数据库，并在Amazon
    Redshift中查询数据。
- en: '![Browse data products on ADX](assets/ardg_0717.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![在ADX上浏览数据产品](assets/ardg_0717.png)'
- en: Figure 7-17\. Browse data products on ADX
  id: totrans-243
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-17\. 在ADX上浏览数据产品
- en: After you subscribe to a product that contains AWS Data Exchange datashares,
    create a database from the datashare within your data warehouse. You can then
    query the data in Amazon Redshift directly without extracting, transforming, and
    loading the data. With ADX datashares added to an ADX product, consumers automatically
    have access to a product’s datashares when their subscription starts and retain
    their access as long as their subscription is active.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 订阅包含 AWS 数据交换数据共享的产品后，在您的数据仓库中创建来自数据共享的数据库。然后，您可以直接在 Amazon Redshift 中查询数据，无需提取、转换和加载数据。将
    ADX 数据共享添加到 ADX 产品后，消费者在订阅开始时自动获得对产品数据共享的访问，并在其订阅有效期内保持访问权限。
- en: For more information, see the online documentation on [working with AWS Data
    Exchange datashares as a consumer](https://oreil.ly/-Gtit).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多信息，请参阅关于 [作为消费者使用 AWS 数据交换数据共享](https://oreil.ly/-Gtit) 的在线文档。
- en: Considerations When Using AWS Data Exchange for Amazon Redshift
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 AWS 数据交换服务（AWS Data Exchange）用于 Amazon Redshift 时的注意事项
- en: 'When using AWS Data Exchange for Amazon Redshift, consider the following:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AWS 数据交换服务（AWS Data Exchange）用于 Amazon Redshift 时，请考虑以下内容：
- en: Both producers and consumers must use the RA3 node type to use Amazon Redshift
    datashares. Producers must use the RA3 node types or serverless with both the
    producer and consumer data warehouses encrypted.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产者和消费者必须使用 RA3 节点类型才能使用 Amazon Redshift 数据共享（datashares）。生产者必须使用 RA3 节点类型或者使用无服务器方式，同时生产者和消费者数据仓库必须加密。
- en: You must be registered as an ADX provider to list products on ADX, including
    products that contain ADX datashares. For more information, see [Getting Started
    as a Provider](https://oreil.ly/vFwMO).
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您必须注册为 ADX 提供者才能在 ADX 上列出产品，包括包含 ADX 数据共享的产品。欲了解更多信息，请参阅 [作为提供者入门](https://oreil.ly/vFwMO)。
- en: You don’t need to be a registered ADX provider to find, subscribe to, and query
    Amazon Redshift data through ADX.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不需要注册为 ADX 提供者即可查找、订阅和查询通过 ADX 访问的 Amazon Redshift 数据。
- en: To control access to your data through ADX datashares, you have to have the
    Publicly Accessible setting turned on. This doesn’t mean that your datashare is
    public or even that the consumer’s data warehouse is public, but it means they
    are allowed to make it public. To alter an ADX datashare, turn off the Publicly
    Accessible setting using `ALTER DATASHARE SET PUBLICACCESSIBLE FALSE` command.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要控制通过 ADX 数据共享访问您的数据，必须打开“公开访问”设置。这并不意味着您的数据共享是公开的，或者消费者的数据仓库是公开的，但这意味着他们被允许将其公开。要更改
    ADX 数据共享，请使用 `ALTER DATASHARE SET PUBLICACCESSIBLE FALSE` 命令关闭“公开访问”设置。
- en: Producers can’t manually add or remove consumers from ADX datashares because
    access to the datashares is granted based on having an active subscription to
    an ADX product that contains the ADX datashares.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产者不能手动添加或移除 ADX 数据共享的消费者，因为对数据共享的访问是基于订阅包含 ADX 数据共享的 ADX 产品而授予的。
- en: Producers can’t view the SQL queries that consumers run. They can only view
    metadata, such as the number of queries or the objects consumers query, through
    Amazon Redshift tables that only the producer can access. Producers can use this
    information to understand how their subscribers are using their product and inform
    their decisions based on data usage patterns.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产者无法查看消费者运行的 SQL 查询。他们只能通过只有生产者可以访问的 Amazon Redshift 表查看元数据，例如查询的数量或消费者查询的对象。生产者可以利用这些信息了解订阅者如何使用其产品，并根据数据使用模式做出决策。
- en: We recommend that you don’t delete an ADX datashare shared to other AWS accounts
    using the `DROP DATASHARE` statement. If you do, the AWS accounts that have access
    to the datashare will lose access. This action is irreversible. Performing this
    type of alteration can breach data product terms in ADX.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们建议您不要使用 `DROP DATASHARE` 语句删除共享给其他 AWS 帐户的 ADX 数据共享（datashare）。如果这样做，可以访问该数据共享的
    AWS 帐户将失去访问权限。此操作是不可逆转的。执行此类更改可能违反 ADX 数据产品条款。
- en: For cross-region data sharing, you can create ADX datashares to share licensed
    data.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要进行跨区域数据共享，您可以创建 ADX 数据共享以共享许可的数据。
- en: We recommend that you make your datashares publicly accessible. If you don’t,
    subscribers on AWS Data Exchange with publicly accessible consumer data warehouses
    won’t be able to use your datashare.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议您将您的数据共享（datashares）设置为公开访问。如果不这样做，AWS 数据交换的订阅者无法使用您的数据共享，即使他们的消费者数据仓库是公开访问的。
- en: Query from the Data Lake and Unload to the Data Lake
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据湖（Data Lake）查询并卸载到数据湖
- en: You may have use cases where you want to share data that has been curated in
    the data warehouse with external applications. Because Amazon Redshift is integrated
    with the data lake, you can take a data warehouse-first approach to store the
    data in your Data Warehouse first, and offload data to the data lake as required.
    Since Amazon Redshift supports decoupling of storage and compute, it enables you
    to store large volumes of data up to 128TB per node within the data warehouse.
    So, for OLAP workloads, you can store all your data in your data warehouse. When
    you want to share data in your Amazon Redshift data warehouse with other services
    like Amazon SageMaker, you can use the `UNLOAD` option to offload the data from
    your Amazon Redshift local tables to Amazon S3\. You can directly convert to a
    recommended format like Parquet or ORC while unloading to Amazon S3, and share
    with other services.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能有使用情况，想要将在数据仓库中策划的数据与外部应用程序共享。因为Amazon Redshift与数据湖集成，你可以采取数据仓库优先的方法，先将数据存储在你的数据仓库中，根据需要将数据卸载到数据湖中。由于Amazon
    Redshift支持存储和计算的解耦，它可以在数据仓库中每个节点最多存储128TB的大容量数据。因此，对于OLAP工作负载，你可以将所有数据存储在你的数据仓库中。当你想要与Amazon
    Redshift数据仓库中的其他服务（如Amazon SageMaker）共享数据时，可以使用`UNLOAD`选项，将数据从Amazon Redshift本地表卸载到Amazon
    S3中。在卸载到Amazon S3时，可以直接转换为推荐的格式如Parquet或ORC，并与其他服务共享。
- en: For the general syntax of the `UNLOAD` command, refer to the [documentation
    for the UNLOAD command](https://oreil.ly/N9z_r). Using the running example, if
    you want to share the student learning management engagement with partners or
    users who use other services to access data, then you can unload the student activities
    data using the `UNLOAD` command, as shown in [Example 7-27](#unload_example).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`UNLOAD`命令的一般语法，请参考[UNLOAD命令文档](https://oreil.ly/N9z_r)。使用运行示例，如果你想要与使用其他服务访问数据的合作伙伴或用户共享学生学习管理参与情况，那么你可以使用`UNLOAD`命令卸载学生活动数据，如[示例 7-27](#unload_example)所示。
- en: Example 7-27\. `UNLOAD` example
  id: totrans-260
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-27\. `UNLOAD`示例
- en: '[PRE27]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: You can also use `INSERT INTO SELECT` query to load the results into existing
    external table on external catalogs, as in [Example 7-28](#insert_into_external),
    for AWS Glue, AWS Lake Formation, or an Apache Hive metastore. Use the same AWS
    IAM role used for the `CREATE EXTERNAL SCHEMA` command to interact with external
    catalogs and Amazon S3\. For detailed steps on using the insert into external
    table command, you can refer to the documentation on [inserting results of a `SELECT`
    query into an external table](https://oreil.ly/cGyyl).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用`INSERT INTO SELECT`查询将结果加载到现有的外部表中，这些表位于外部目录，如[示例 7-28](#insert_into_external)所示，适用于AWS
    Glue、AWS Lake Formation或Apache Hive元存储。使用与`CREATE EXTERNAL SCHEMA`命令相同的AWS IAM角色与外部目录和Amazon
    S3交互。有关使用插入到外部表命令的详细步骤，可以参考[将`SELECT`查询结果插入到外部表中的文档](https://oreil.ly/cGyyl)。
- en: Example 7-28\. Writing data to external table
  id: totrans-263
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 7-28\. 将数据写入外部表
- en: '[PRE28]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Amazon DataZone to Discover and Share Data
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amazon DataZone 用于发现和共享数据
- en: A data warehouse typically means building a centralized data store by transferring
    detailed transactional data from multiple sources systems and consolidating data
    into a single source of truth. The detailed data is transformed by applying business
    rules and stored in a format that is aggregated and stored for fast query performance.
    A relatively new architecture has evolved for data management around decentralized
    data management and governance. This is the data mesh architecture, which you
    read about in [“Data Mesh”](ch01.html#data_mesh). Data mesh embraces decentralized
    ownership of data and is intended to enable easy access to data without having
    to move or copy data in a central data store.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库通常指通过将来自多个来源系统的详细事务数据转移并将数据合并到一个单一的真实数据源来构建集中式数据存储。详细数据通过应用业务规则进行转换，并以聚合的格式存储，以实现快速查询性能。围绕去中心化数据管理和治理，数据管理的相对较新架构已经发展。这就是数据网格架构，你可以在[“数据网格”](ch01.html#data_mesh)中了解更多。数据网格采纳了数据的去中心化所有权，旨在实现无需移动或复制数据即可轻松访问数据的目标。
- en: 'Data producers who are subject matter experts create data assets and define
    the data catalog, add business definitions for easy consumption, and organize
    as data domains. They then register data products in a data catalog for consumers
    to search and access the data relevant to their business needs. As a refresher,
    the four key concepts of data mesh architecture are:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 数据生产者是专业领域专家，创建数据资产并定义数据目录，为便于使用添加业务定义，并按数据领域组织。然后在数据目录中注册数据产品，以便消费者搜索和访问与其业务需求相关的数据。作为提醒，数据网格架构的四个关键概念是：
- en: Domain-oriented ownership of data
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面向域的数据所有权
- en: Federated data governance
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联合数据治理
- en: Self-service data infrastructure
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自助数据基础设施
- en: Data as a product thinking
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据作为产品思维
- en: In the next section, you’ll see how Amazon DataZone components can enable key
    capabilities that constitute a data mesh architecture.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，您将看到Amazon DataZone组件如何实现构成数据网格架构的关键能力。
- en: Use Cases for a Data Mesh Architecture with Amazon DataZone
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Amazon DataZone的数据网格架构用例
- en: There are many use cases for a data mesh architecture, especially in organizations
    that have multiple lines of business or business units and subsidiaries that require
    data sharing across business units. Here are a few examples.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 数据网格架构有许多用例，特别适用于具有多条业务线或需要跨业务部门共享数据的组织。以下是一些示例。
- en: As part of the modernization strategy, a large financial organization embarked
    on a journey to migrate their legacy on-premises workloads to AWS Cloud, including
    managed services such as Amazon Redshift and Amazon S3\. They chose to build a
    modern data platform on AWS Cloud that serves as the central data store for analytics,
    research, and data science. In addition, this platform was also built to serve
    for governance, regulatory, and financial reports. With the initial design to
    store data for all businesses in a centralized data store and a central AWS account,
    they ran into limits and complexities in making data accessible.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 作为现代化战略的一部分，一家大型金融组织着手将其遗留的本地工作负载迁移到AWS云上，包括Amazon Redshift和Amazon S3等托管服务。他们选择在AWS云上构建现代数据平台，作为分析、研究和数据科学的中央数据存储。此外，该平台还用于治理、监管和财务报告。最初设计是将所有业务数据存储在中央数据存储和中央AWS账户中，但在使数据可访问方面遇到了限制和复杂性。
- en: To address the growing pains and needs of a large data footprint, they decentralized
    and delegated ownership of the data stores and associated management functions
    to their respective business units. The data mesh architecture allowed them to
    keep data of the respective business units in their own accounts, yet enable a
    seamless access across the business unit accounts in a secure manner. They reorganized
    the AWS account structure to have separate accounts for each of the business units
    wherein business data and dependent applications were co-located in their respective
    AWS accounts in Amazon Redshift and Amazon S3\. With this decentralized model,
    the business units independently managed the responsibility of hydration, curation,
    and security of their data.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决大型数据存储的成长痛点和需求，他们将数据存储和相关管理功能的所有权分散并委托给各自的业务部门。数据网格架构使他们能够在各自的账户中保留各业务部门的数据，同时以安全的方式实现跨业务部门账户的无缝访问。他们重新组织了AWS账户结构，为每个业务部门设置了单独的账户，在亚马逊Redshift和亚马逊S3中的相应AWS账户中共同定位了业务数据和依赖应用程序。通过这种分散化模型，业务部门独立管理其数据的水合、策展和安全责任。
- en: An investment banking organization that had multiple LOBs and corporate functions
    needed an architecture to freely share data across the enterprise while managing
    the risk of unauthorized access. They took a two-pronged approach to addressing
    this requirement. First, by defining data products, which are curated by people
    who understand the data and its management requirements, permissible uses, and
    limitations. And second, by implementing a data mesh architecture, which allowed
    them to align their data technology to those data products.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 一家投资银行组织拥有多个业务部门和公司职能，需要一种架构来在企业内自由共享数据，同时管理未经授权访问的风险。他们采取了双管齐下的方法来解决这一需求。首先，通过定义数据产品，由了解数据及其管理需求、允许使用和限制的人员策展。其次，通过实施数据网格架构，使他们能够将其数据技术与这些数据产品对齐。
- en: A healthcare organization can create a data product that provides real-time
    patient monitoring data, which can be used by various departments such as emergency
    services, patient care, and research. In a school system, where student data is
    stored in a student information system, the IT department can be the producer
    of data and the individual schools would be subscribers of the data relevant to
    the students in their school. You can build a data mesh architecture to enable
    teachers, students, and administrators to collaborate and share data securely,
    embracing a producer–consumer model. A retail company might have separate domains
    for sales, inventory, customer data, and marketing. Each domain can have its own
    data team responsible for collecting, storing, and analyzing data specific to
    that domain. Adopting a data mesh architecture will allow each domain to own and
    manage its data, enabling them to make data-driven decisions independently.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗机构可以创建一个数据产品，提供实时患者监控数据，各部门如急诊服务、患者护理和研究都可以使用。在学校系统中，学生数据存储在学生信息系统中，IT部门可以是数据的生产者，各个学校将订阅与其学生相关的数据。您可以构建数据网格架构，使教师、学生和管理员能够安全地协作和共享数据，采用生产者-消费者模型。零售公司可能为销售、库存、客户数据和营销设立单独的领域。每个领域可以有自己的数据团队负责收集、存储和分析特定领域的数据。采用数据网格架构将使每个领域能够拥有和管理自己的数据，从而能够独立做出数据驱动的决策。
- en: These are just a few examples of how data mesh architecture can be applied in
    practice. The main goal is to decentralize data management, empower domain teams,
    and create a scalable and sustainable data ecosystem within organizations.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是数据网格架构实际应用的几个例子。主要目标是分散数据管理，赋予领域团队权力，并在组织内创建可伸缩和可持续的数据生态系统。
- en: Key Capabilities and Use Cases for Amazon DataZone
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊数据区的关键能力和使用案例
- en: '[Amazon DataZone](https://aws.amazon.com/datazone) is a data management service
    that embraces the data mesh architecture and enables data producers to publish
    data products and make them available to the business data catalog through a web
    interface. Once data products are published, users have a streamlined way to search
    for data. With the Amazon DataZone catalog, you can make data visible with business
    context to find and understand data quickly. You can create business use cases
    based on groupings of teams, analytics tools, and data assets to simplify access
    to AWS analytics tools. With the automated publish/subscribe workflow, you can
    adjust data ownership to protect data between producers and consumers.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '[亚马逊数据区](https://aws.amazon.com/datazone)是一项数据管理服务，采用数据网格架构，使数据生产者能够发布数据产品，并通过Web界面将其提供给业务数据目录。一旦数据产品发布，用户可以通过简化的方式搜索数据。使用亚马逊数据区目录，您可以使数据在业务背景下可见，快速找到并理解数据。您可以基于团队、分析工具和数据资产的分组创建业务用例，以简化访问AWS分析工具。通过自动化的发布/订阅工作流，您可以调整数据所有权以保护生产者和消费者之间的数据。'
- en: You can set up security policies to ensure that the people with the right permissions
    get access to your data. With Amazon DataZone, you have federated data governance
    where the data owners and subject matter experts of that dataset can enforce security
    and access controls on their relevant data assets. You can extend governance controls
    setup in the AWS Glue Data Catalog, IAM, and Lake Formation. Amazon DataZone supports
    data access and data sharing across AWS services like Amazon Redshift, Amazon
    Athena, AWS Glue, AWS Lake Formation, and Amazon QuickSight.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以设置安全策略，确保具有正确权限的人员可以访问您的数据。使用亚马逊数据区，您可以实现联合数据治理，数据集的数据所有者和主题专家可以对其相关数据资产实施安全和访问控制。您可以扩展在AWS
    Glue数据目录、IAM和Lake Formation中设置的治理控制。亚马逊数据区支持通过Amazon Redshift、Amazon Athena、AWS
    Glue、AWS Lake Formation和Amazon QuickSight等AWS服务进行数据访问和数据共享。
- en: Amazon DataZone Integrations with Amazon Redshift and Other AWS Services
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊数据区与亚马逊Redshift及其他AWS服务的集成
- en: 'Amazon DataZone by itself does not store any data, and it acts as a metadata
    hub to enable ease of data access across siloed datasets. For data access, Amazon
    DataZone has to integrate with existing AWS services that store, access, and control
    data. At the time of writing this book, it supports three types of integrations
    with other AWS services:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '[亚马逊数据区](https://aws.amazon.com/datazone)本身不存储任何数据，它作为元数据中心，实现跨数据集的数据访问便利化。为了数据访问，亚马逊数据区必须与存储、访问和控制数据的现有AWS服务集成。在编写本书时，它支持与其他AWS服务的三种集成类型：'
- en: Producer data sources
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者数据源
- en: From a producer perspective, Amazon DataZone integrates with data stored in
    Amazon S3 data lake or Amazon Redshift. You can publish data assets to the Amazon
    DataZone catalog from the data stored in Amazon S3 and Amazon Redshift tables
    and views. You can also manually publish objects from AWS Glue Data Catalog to
    the Amazon DataZone catalog.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 从生产者的角度看，亚马逊数据区集成了存储在亚马逊S3数据湖或亚马逊Redshift中的数据。您可以将数据资产发布到亚马逊数据区目录，从存储在亚马逊S3和亚马逊Redshift表格和视图中的数据。您还可以手动将AWS
    Glue数据目录中的对象发布到亚马逊数据区目录中。
- en: Consumer tools
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者工具
- en: You can access data assets using Amazon Redshift query editors or Amazon Athena,
    through external tables in Amazon Redshift.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过亚马逊Redshift查询编辑器或亚马逊Athena访问数据资产，通过亚马逊Redshift中的外部表格。
- en: Access control and fulfillment
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 访问控制和履行
- en: With Amazon DataZone, you can grant access to AWS Lake Formation-managed AWS
    Glue tables and Amazon Redshift tables and views. Additionally, Amazon DataZone
    connects standard events related to your actions to Amazon EventBridge. You can
    use these standard events to integrate with other AWS services or third-party
    solutions for custom integrations.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 使用亚马逊数据区，您可以授予对由AWS Lake Formation管理的AWS Glue表格和亚马逊Redshift表格和视图的访问权限。此外，亚马逊数据区将与您的操作相关的标准事件连接到亚马逊EventBridge。您可以使用这些标准事件与其他AWS服务或第三方解决方案进行自定义集成。
- en: Components and Capabilities of Amazon DataZone
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊数据区的组件和能力
- en: 'AWS introduced the concept of `` domain` `` in Amazon DataZone to help organize
    data assets and resources associated with these assets. Amazon DataZone domains
    provide you the ﬂexibility to reﬂect your organization’s business areas and entities
    including data assets, data sources, metadata, business glossaries, and even associated
    AWS accounts. There are four key components of Amazon DataZone that enables secure
    data access across business domains using data products published to the central
    catalog:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: AWS引入了“`domain`”的概念，用于帮助组织与这些资产相关的数据资产和资源。亚马逊数据区域域提供了灵活性，以反映您组织的业务领域和实体，包括数据资产、数据来源、元数据、业务术语表以及关联的AWS账户。亚马逊数据区的四个关键组件使得通过发布到中央目录的数据产品来跨业务领域安全访问数据变得可能：
- en: Business data catalog
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商业数据目录
- en: Projects
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目
- en: Governance and access control
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 治理和访问控制
- en: Data portal
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据门户
- en: We discuss these components next, and they are part of the domain you create,
    as shown in [Figure 7-18](#datazone_components).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来讨论这些组件，它们是您创建的域的一部分，如[图 7-18](#datazone_components)所示。
- en: '![Amazon DataZone components](assets/ardg_0718.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![亚马逊数据区组件](assets/ardg_0718.png)'
- en: Figure 7-18\. Amazon DataZone components
  id: totrans-299
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-18\. 亚马逊数据区组件
- en: To initially set up Amazon DataZone and its data portal, you will create a domain
    that will serve as the root domain. Within the data portal, domain administrators
    can create additional domains. These components work together to provide capabilities
    to enable you to build and operate a data mesh architecture with decentralized
    data governance; these are discussed in the next sections.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 要最初设置亚马逊数据区（Amazon DataZone）及其数据门户，您将创建一个作为根域的域。在数据门户内，域管理员可以创建额外的域。这些组件共同工作，提供功能，使您能够构建和操作具有分散数据治理的数据网格架构；这些将在接下来的章节中讨论。
- en: Business data catalog
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 商业数据目录
- en: The core component of Amazon DataZone is a metadata catalog with business-friendly
    descriptions. The catalog is built when a data producer publishes the data product
    and can grow as new products are ready for consumption. This catalog can be from
    data across disparate data sources. Datasets are published to the catalog, which
    consumers can access through the Amazon DataZone portal, as shown in [Figure 7-24](#datazone_catalog_search),
    to search for your desired data.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊数据区的核心组件是一个带有商业友好描述的元数据目录。当数据生产者发布数据产品时，该目录会被构建，并且随着新产品准备就绪而增长。该目录可以来自不同数据源的数据。数据集发布到目录后，消费者可以通过亚马逊数据区门户（如[图 7-24](#datazone_catalog_search)所示）搜索所需数据。
- en: Amazon DataZone uses ML to automatically suggest business terms while cataloging
    data assets. This automation reduces the manual work required to add searchable
    business terms to technical data.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊数据区使用机器学习自动在编目数据资产时建议商业术语。此自动化减少了添加可搜索业务术语到技术数据所需的手动工作。
- en: Projects
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 项目
- en: Amazon DataZone introduces data projects for teams to collaborate and get access
    to data assets. With projects, a group of users within your organization can collaborate
    on various business use cases that involve publishing, discovering, subscribing
    to, and consuming data assets in the Amazon DataZone catalog. Instead of relying
    on individual user credentials, you use projects as an identity principal to receive
    access grants to underlying resources. Each project has set of access controls
    applied to it so that only authorized individuals, groups, and roles can access
    the project and the data assets that this project subscribes to, and can use only
    those tools that are defined by the project permissions. Projects are tied to
    a project profile with specific capabilities to behave as a consumer or a producer
    or both. You can use data projects to manage and monitor data assets across projects
    through usage auditing capabilities.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon DataZone为团队引入数据项目，以便协作并获取访问数据资产。通过项目，组织内的一组用户可以在Amazon DataZone目录中发布、发现、订阅和使用涉及的各种业务用例。您使用项目作为身份主体来接收对底层资源的访问授予，而不是依赖于个人用户凭据。每个项目都有一组应用于其的访问控制，以便只有经授权的个人、组和角色可以访问该项目及该项目订阅的数据资产，并且只能使用项目权限定义的工具。项目与具有特定能力的项目配置文件相关联，可作为消费者或生产者或两者行为。您可以使用数据项目通过使用审计能力来管理和监控跨项目的数据资产。
- en: 'With data projects, you can create and access business use case groupings of
    data, people, and tools that teams can use to collaborate while consuming data.
    Some of the components that are available in the project view are:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据项目，您可以创建和访问数据、人员和工具的业务用例分组，团队可以使用这些分组协作。项目视图中可用的一些组件包括：
- en: Subscribed data
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 已订阅数据
- en: This includes all subscriptions including approved, pending, and granted subscription
    requests.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括所有已批准、待处理和已授予的订阅请求。
- en: Publishing
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 发布
- en: This includes all published data, subscription requests, publishing jobs, and
    all agreements.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括所有已发布的数据、订阅请求、发布作业和所有协议。
- en: Members
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 成员
- en: Includes the members of this project and their respective roles.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 包括此项目的成员及其各自的角色。
- en: Settings
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 设置
- en: Provides details of the project like ID, Account, VPC, and the project capabilities.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 提供项目的详细信息，如ID、账户、VPC和项目的能力。
- en: Members of the project can collaborate, exchange data, and share artifacts securely,
    and only those who are explicitly added to the project are able to access the
    data and analytics tools within it. Projects manage the ownership of data assets
    produced in accordance with policies applied by data stewards, decentralizing
    data ownership through federated governance.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 项目成员可以安全地协作、交换数据和共享工件，只有明确添加到项目中的人员才能访问其中的数据和分析工具。项目通过数据监管人员施加的策略管理生成的数据资产的所有权，通过联邦治理去中心化数据所有权。
- en: Data governance and access control
  id: totrans-316
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据治理和访问控制
- en: The automated workflow allows consumers to request access to a data product
    they find in the business catalog. This request is routed to the data producers
    or data owners for approval. When a producer approves the request, the consumer
    gets notified and can access the data without any manual intervention. Data producers
    can streamline auditing to monitor who is using each dataset, and monitor usage
    and costs across projects and LOBs. You can find the sample steps to publish and
    subscribe in the next section.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化工作流程允许消费者请求访问他们在业务目录中找到的数据产品。此请求将路由到数据生产者或数据所有者以进行批准。当生产者批准请求时，消费者将收到通知，并可以在无需任何手动干预的情况下访问数据。数据生产者可以简化审计以监控谁正在使用每个数据集，并跨项目和LOB（业务线）监控使用和成本。您可以在下一节中找到发布和订阅的示例步骤。
- en: Data portal
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据门户
- en: The portal is a personalized homepage outside of the console and provides self-service
    capability where consumers can search for data in the catalog. The data portal
    is the primary way users access Amazon DataZone and is a browser-based web application
    where you can catalog, discover, govern, share, and analyze data. This enables
    cross-functional collaboration while working with data and analytics tools using
    existing credentials from your identity provider.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 门户是控制台之外的个性化主页，提供自助服务功能，消费者可以在目录中搜索数据。数据门户是用户访问Amazon DataZone的主要方式，是一个基于浏览器的Web应用程序，您可以在其中编目、发现、管理、共享和分析数据。这使得用户能够在使用现有身份提供者的凭据时，使用数据和分析工具进行跨部门协作。
- en: With this portal you can access personalized views for data assets. In [Figure 7-19](#datazone_catalog_personalized_view),
    you see the various state of the subscriptions requested in the workflow. You
    can analyze data without having to sign in to the AWS Management Console or understand
    the underlying AWS analytics services.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 使用该门户，你可以访问数据资产的个性化视图。在[图 7-19](#datazone_catalog_personalized_view)中，你可以看到工作流程中请求的各种订阅状态。你可以分析数据，无需登录AWS管理控制台或了解底层AWS分析服务。
- en: '![Personalized view of data products in various states of subscriptions](assets/ardg_0719.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![不同订阅状态下的数据产品个性化视图](assets/ardg_0719.png)'
- en: Figure 7-19\. Personalized view of data products in various states of subscriptions
  id: totrans-322
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-19\. 不同订阅状态下的数据产品个性化视图
- en: Getting Started with Amazon DataZone
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon DataZone入门
- en: Adopting a data mesh architecture is not just about technology; it requires
    a mindset change. You have to organize your team and implement processes in your
    organization to move toward a producer–consumer model. Domains enable an easier
    transition by providing a mechanism to instill organizational discipline for teams
    that are producing and cataloging the data in the business data catalog. Any data
    producer can publish a data asset in the catalog to a particular domain that governs
    the data and control access of consumers who can access the domain. A domain can
    have multiple projects associated with each business use case and in which people
    collaborate and access data.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 采用数据网格架构不仅仅是技术问题；它需要一种心态的转变。你必须组织你的团队，并在你的组织中实施流程，向生产者-消费者模型迈进。域通过提供一种机制来为在业务数据目录中产生和编目数据的团队灌输组织纪律，从而实现更简单的过渡。任何数据生产者都可以将数据资产发布到管理数据的特定域的目录中，并控制可以访问该域的消费者的访问权限。一个域可以与每个业务用例相关联，其中人们可以协作和访问数据。
- en: This section takes you through creating the Amazon DataZone root domain and
    obtaining the data portal URL. It then takes you through the basic workflows for
    data producers and data consumers. For detailed steps to set up Amazon DataZone,
    refer to the [“Getting started” documentation](https://oreil.ly/QzAOG). This includes
    the following steps.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将带你创建Amazon DataZone的根域，并获取数据门户的URL。然后，将带你通过数据生产者和数据消费者的基本工作流程。详细设置Amazon
    DataZone的步骤，请参阅[“入门文档”](https://oreil.ly/QzAOG)。具体步骤如下。
- en: 'Step 1: Create the domain and data portal'
  id: totrans-326
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '步骤 1: 创建域和数据门户'
- en: To start with Amazon DataZone, the first step is to create a domain. A domain
    is a collection of Amazon DataZone objects, such as data assets, projects, associated
    AWS accounts, and data sources. Domains are containers where you and your team
    can create all related Amazon DataZone entities, including metadata assets. You
    can publish a data asset to the catalog with a particular domain that governs
    the data, and control access for associated AWS accounts and resources that can
    access that domain.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用Amazon DataZone，第一步是创建一个域。域是Amazon DataZone对象的集合，如数据资产、项目、相关的AWS账户和数据源。域是你和你的团队可以创建所有相关Amazon
    DataZone实体的容器，包括元数据资产。你可以使用特定的域将数据资产发布到目录，并控制可以访问该域的相关AWS账户和资源的访问权限。
- en: 'Step 2: Create a producer project'
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '步骤 2: 创建生产者项目'
- en: To create and publish a data product as a producer, you need to create a project
    under which the data product and related assets will be organized. When you create
    a project, you specify the project profile and the data source connection details.
    The project profile determines the capabilities of the project and whether the
    project serves as a producer, consumer, or both; the connection details are for
    the data source. So, before you create a project, you need to create a project
    profile and an AWS Glue connection. You can create a project profile by choosing
    the Catalog Management menu and selecting the Project and Accounts tab.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 要作为生产者创建和发布数据产品，你需要创建一个项目，该项目将组织数据产品和相关资产。创建项目时，你需要指定项目配置文件和数据源连接详细信息。项目配置文件确定项目的能力，以及项目是作为生产者、消费者还是两者兼而有之；连接详细信息用于数据源。因此，在创建项目之前，你需要创建一个项目配置文件和一个AWS
    Glue连接。你可以通过选择“目录管理”菜单并选择“项目和账户”选项卡来创建项目配置文件。
- en: For a data warehouse producer, you need to enter additional information like
    the Amazon Redshift cluster name and the AWS Glue connection details. If you do
    not already have an AWS Glue connection, you can create a Glue connection to the
    datasource and specify the connection details in the project. You will be publishing
    data you produce to the catalog from the project, and consumers will access data
    through the project as well.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据仓库生产者，您需要输入额外的信息，如亚马逊Redshift集群名称和AWS Glue连接详细信息。如果您还没有AWS Glue连接，您可以创建一个Glue连接到数据源，并在项目中指定连接详细信息。您将从项目发布您生成的数据到目录，并且消费者也将通过项目访问数据。
- en: To create a project, navigate to the Amazon DataZone data portal using the data
    portal URL and log in using your single sign-on (SSO) or AWS credentials. Here
    you can go to the My Projects menu, and click the + sign to create a new project,
    as shown in [Figure 7-20](#data_zone_catalog_createproject). If you’re an Amazon
    DataZone administrator, you can obtain the data portal URL by accessing the Amazon
    DataZone console in the AWS account where the Amazon DataZone root domain was
    created.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建项目，请使用数据门户网址导航至亚马逊数据区（Amazon DataZone）数据门户，并使用您的单一登录（SSO）或AWS凭据登录。在这里，您可以转到“我的项目”菜单，并点击+号以创建新项目，如[图 7-20](#data_zone_catalog_createproject)所示。如果您是亚马逊数据区管理员，您可以通过访问亚马逊数据区控制台（位于创建亚马逊数据区根域的AWS账户中）获取数据门户网址。
- en: '![Create projects with specific data domain](assets/ardg_0720.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![使用特定数据域创建项目](assets/ardg_0720.png)'
- en: Figure 7-20\. Create projects with specific data domain
  id: totrans-333
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-20\. 使用特定数据域创建项目
- en: You can also view all the data projects by choosing “Browse all projects.” The
    list of projects will be as shown in [Figure 7-21](#data_zone_catalog_dataprojects).
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过选择“浏览所有项目”查看所有数据项目。项目列表如[图 7-21](#data_zone_catalog_dataprojects)所示。
- en: '![Browse projects with specific data domain](assets/ardg_0721.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![使用特定数据域浏览项目](assets/ardg_0721.png)'
- en: Figure 7-21\. List projects under specific data domain
  id: totrans-336
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-21\. 在特定数据域下列出项目
- en: 'Step 3: Produce data for publishing in Amazon DataZone'
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3步：为在亚马逊数据区发布数据而生成数据
- en: Before publishing a data asset to the data catalog, you need to create the data
    objects and data you want to share with your consumers. From the producer project
    you created in the previous step, you click on “Query data—Amazon Redshift” under
    Analytical Tools, as shown in [Figure 7-22](#datazone_create_data), and log in
    to the Amazon Redshift cluster to create the data tables and set up the data.
    This will take you to Amazon Redshift Query Editor V2, and you log in to the data
    warehouse using the “Federated user” option. Here you can create the database
    objects and the data. If you have tables already, you can choose to include those
    when you publish the data product.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据资产发布到数据目录之前，您需要创建要与消费者共享的数据对象和数据。从您在上一步创建的生产者项目中，您点击“分析工具”下的“查询数据 - 亚马逊Redshift”，如[图 7-22](#datazone_create_data)所示，并登录到亚马逊Redshift集群以创建数据表并设置数据。这将带您进入亚马逊Redshift查询编辑器V2，并使用“联合用户”选项登录数据仓库。在这里，您可以创建数据库对象和数据。如果已经有表格，您可以选择在发布数据产品时包含这些表格。
- en: '![Create the data product in producer](assets/ardg_0722.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![在生产者中创建数据产品](assets/ardg_0722.png)'
- en: Figure 7-22\. Create the data product in producer
  id: totrans-340
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-22\. 在生产者中创建数据产品
- en: 'Step 4: Publish a data product to the catalog'
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第4步：向目录发布数据产品
- en: When producers have the data product ready, they can publish to the business
    data catalog for consumers to search and subscribe. To publish, you will choose
    the producer project and choose “Publish data.” Publishing is done through a job
    with a publishing agreement. You can create a publishing agreement from the project
    from which you want to publish the data product by selecting the Publishing tab
    and choosing Publishing Agreements under this. The publish process is triggered
    through a job, and you can monitor the job as well. In our student example, when
    producers of the Student Performance data product are ready, they can publish
    to the catalog, as shown in [Figure 7-23](#data_zone_catalog_publish). For detailed
    steps to publish data, refer to the documentation on [publishing data in Amazon
    DataZone](https://oreil.ly/ykTGV).
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 当生产者准备好数据产品后，他们可以发布到业务数据目录，供消费者搜索和订阅。要发布，您将选择生产者项目并选择“发布数据”。发布通过具有发布协议的作业完成。您可以通过选择发布选项卡并在其中选择发布协议来从希望发布数据产品的项目创建发布协议。发布过程通过作业触发，并且您也可以监控该作业。在我们的学生示例中，当学生绩效数据产品的生产者准备好后，他们可以发布到目录中，如[图7-23](#data_zone_catalog_publish)所示。有关发布数据的详细步骤，请参阅[在Amazon
    DataZone发布数据](https://oreil.ly/ykTGV)的文档。
- en: '![Publish Student Performance data product](assets/ardg_0723.png)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![发布学生绩效数据产品](assets/ardg_0723.png)'
- en: Figure 7-23\. Publish Student Performance data product
  id: totrans-344
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-23\. 发布学生绩效数据产品
- en: 'Step 5: Create a consumer project'
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤5：创建消费者项目
- en: For a consumer to subscribe to the underlying data product, again the projects
    act as an identity principal that receives access grants to underlying resources,
    without relying on individual user credentials. For a consumer to subscribe to
    the data produced by a producer, you need to create a consumer project with a
    consumer profile. For the consumer profile, you will add the capability data warehouse
    Consumer Capability while creating the consumer profile. When the user identifies
    a dataset in the catalog using the portal, the user needs to select the consumer
    project before requesting access for the dataset. Amazon DataZone will validate
    the request against the set of access controls and authorize only individuals,
    groups, and roles who can access the project and the data assets.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让消费者订阅底层数据产品，项目再次作为一个身份主体，接收对底层资源的访问授权，而不依赖于个人用户凭据。要让消费者订阅生产者生成的数据，您需要创建一个带有消费者配置文件的消费者项目。在消费者配置文件中，您将在创建消费者配置文件时添加数据仓库消费者能力。当用户通过门户在目录中识别数据集时，用户需要在请求数据集访问之前选择消费者项目。Amazon
    DataZone将根据访问控制集验证请求，并仅授权能够访问项目和数据资产的个人、组和角色。
- en: 'Step 6: Discovering and consuming data in Amazon DataZone'
  id: totrans-347
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤6：在Amazon DataZone中发现和消费数据
- en: Once you publish a data asset to a domain, subscribers can discover and request
    a subscription to this data asset using the Amazon DataZone portal. When consumers
    wants to subscribe to a data product, they begin with searching for and browsing
    the catalog to find an asset they want, as shown in [Figure 7-24](#datazone_catalog_search).
    Consumers select the consumer project and search for a data product by entering
    key words in the search box. Amazon DataZone will search through all the published
    catalogs and return the list of data products matching the key words. Search lists
    return results based on the cataloged data. Consumers can select their desired
    dataset and learn more about it in the business glossary. After you confirm your
    selected dataset, you can request access and start your analysis.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将数据资产发布到一个领域，订阅者可以使用Amazon DataZone门户发现并请求订阅此数据资产。当消费者想订阅数据产品时，他们首先需要在目录中搜索并浏览他们想要的资产，如[图7-24](#datazone_catalog_search)所示。消费者选择消费者项目并在搜索框中输入关键词以搜索数据产品。Amazon
    DataZone将搜索所有已发布的目录，并返回与关键词匹配的数据产品列表。搜索列表根据编目的数据返回结果。消费者可以选择他们想要的数据集，并在业务词汇表中了解更多信息。确认所选数据集后，您可以请求访问并开始分析。
- en: '![Search for data in the business data catalog](assets/ardg_0724.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![在业务数据目录中搜索数据](assets/ardg_0724.png)'
- en: Figure 7-24\. Search for data in the business data catalog
  id: totrans-350
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-24\. 在业务数据目录中搜索数据
- en: 'You choose to subscribe to the data asset by submitting a subscription request:
    click the Subscribe button as shown in [Figure 7-25](#data_zone_catalog_subscribe)
    and include justification and the reason for the request. The subscription approver,
    as defined in the publishing agreement, then reviews the access request. They
    can either approve or reject the request. For detailed steps, you can refer to
    the documentation on [discovering and consuming data](https://oreil.ly/7EF48).'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择通过提交订阅请求订阅数据资产：按照[图 7-25](#data_zone_catalog_subscribe) 中显示的订阅按钮，并包括请求的理由和原因。根据发布协议定义的订阅批准人员随后审查访问请求。他们可以批准或拒绝请求。有关详细步骤，请参阅[发现和使用数据](https://oreil.ly/7EF48)中的文档。
- en: '![Subscribe to the Student Performance data product](assets/ardg_0725.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![订阅学生表现数据产品](assets/ardg_0725.png)'
- en: Figure 7-25\. Subscribe to the Student Performance data product
  id: totrans-353
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-25\. 订阅学生表现数据产品
- en: 'Step 7: Approve access to a published data asset as a producer'
  id: totrans-354
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 7：作为生产者批准对发布数据资产的访问
- en: A producer can approve access to a request by a consumer through the producer
    project. The producer can view all the subscription requests pending approval
    by navigating to the producer project and choosing the Subscription Requests tab
    under the Publishing tab. Here the producer can approve and also specify the reason
    for approval. This information is recorded for future tracking of who granted
    approval and details of the approval request.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者可以通过生产者项目批准消费者的请求访问。生产者可以通过导航到生产者项目并在发布选项卡下选择订阅请求选项卡，查看所有待批准的订阅请求。在这里，生产者可以批准并指定批准原因。这些信息将记录下来，以便将来跟踪授予批准的人员和批准请求的详细信息。
- en: 'Step 8: Analyze a published data asset as a consumer'
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 8：作为消费者分析发布的数据资产
- en: Once approved, a subscriber can view the approval status using the consumer
    project, and use either Amazon Athena or the Amazon Redshift query editor to view
    the data, depending on the type of the data source and where the data resides.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获得批准，订阅者可以使用消费者项目查看批准状态，并根据数据源类型和数据所在位置，使用 Amazon Athena 或 Amazon Redshift
    查询编辑器查看数据。
- en: Before you begin setting up Amazon DataZone for your data mesh, complete the
    procedures described in the [Setting Up section in the documentation](https://oreil.ly/4Z4vm).
    If you are using a brand-new AWS account, you must [configure permissions for
    the Amazon DataZone management console](https://oreil.ly/5hOJb). If you are using
    an AWS account that has existing AWS Glue Data Catalog objects, you must also
    [configure data lake permissions to Amazon DataZone](https://oreil.ly/bnllj).
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始设置 Amazon DataZone 用于您的数据网格之前，请完成[文档中的设置部分](https://oreil.ly/4Z4vm)中描述的步骤。如果您使用全新的
    AWS 账户，则必须[配置 Amazon DataZone 管理控制台的权限](https://oreil.ly/5hOJb)。如果您使用具有现有 AWS
    Glue Data Catalog 对象的 AWS 账户，您还必须[将数据湖权限配置为 Amazon DataZone](https://oreil.ly/bnllj)。
- en: Security in Amazon DataZone
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon DataZone 中的安全性
- en: As with other AWS services, the AWS shared responsibility model applies to data
    protection in Amazon DataZone. Amazon DataZone provides security features to consider
    as you develop and implement your own security policies. You can use these best
    practice guidelines for your security solution, but we encourage you to adopt
    these practices based on your environment and security requirements. For detailed
    security configuration, refer to the documentation in the [User Guide for security
    in Amazon DataZone](https://oreil.ly/rIDBL).
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他 AWS 服务一样，AWS 的责任共享模型适用于 Amazon DataZone 中的数据保护。Amazon DataZone 提供了安全功能，您在制定和实施自己的安全策略时需要考虑这些功能。您可以使用这些最佳实践指南作为您的安全解决方案，但我们鼓励根据您的环境和安全需求采用这些实践。有关详细的安全配置，请参阅[Amazon
    DataZone 安全用户指南](https://oreil.ly/rIDBL)中的文档。
- en: Using Lake Formation-based authorization
  id: totrans-361
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用基于 Lake Formation 的授权
- en: Amazon DataZone uses the Lake Formation permissions model to grant access privileges.
    Once a project subscribes to an asset, that asset needs to be managed by Lake
    Formation. Adding the Amazon S3 bucket in which the data is stored to the Lake
    Formation location is part of switching the permissions model.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon DataZone 使用 Lake Formation 权限模型来授予访问权限。一旦项目订阅了资产，该资产需要由 Lake Formation
    进行管理。将存储数据的 Amazon S3 存储桶添加到 Lake Formation 位置是切换权限模型的一部分。
- en: Amazon DataZone abstracts the process of sharing data between data producers
    and consumers through AWS Lake Formation and automates this process, normally
    done manually. For Amazon DataZone–managed assets, fulfillment of data access
    to the underlying tables according to the policies applied by data publishers
    is taken care of without the need for an admin or data movement.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon DataZone 通过 AWS Lake Formation 抽象化数据生产者和消费者之间的数据共享过程，并自动化这一过程，通常需要手动完成。对于由
    Amazon DataZone 管理的资产，根据数据发布者应用的策略来履行对底层表的数据访问，无需管理员或数据迁移即可完成。
- en: Encryption
  id: totrans-364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加密
- en: Amazon DataZone encrypts service metadata by default with an AWS KMS key that
    AWS owns and manages for you. You can also encrypt the metadata stored in the
    Amazon DataZone data catalog using keys that you manage with AWS KMS. Amazon DataZone
    uses Transport Layer Security (TLS) and client-side encryption for encryption
    in transit. Communication with Amazon DataZone is always done over HTTPS so your
    data is always encrypted in transit.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon DataZone 默认使用 AWS KMS 密钥对服务元数据进行加密，由 AWS 拥有和管理。您还可以使用 AWS KMS 管理的密钥对存储在
    Amazon DataZone 数据目录中的元数据进行加密。Amazon DataZone 在传输中使用传输层安全性（TLS）和客户端端到端加密进行加密。与
    Amazon DataZone 的通信始终通过 HTTPS 进行，因此您的数据始终在传输过程中得到加密保护。
- en: Implement least privilege access
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实施最小特权访问
- en: A typical use case for Amazon DataZone will require sharing data across business
    groups within your organization. Since the basic assumption of a data mesh architecture
    with Amazon DataZone is a decentralized governance, it is more important to maintain
    the principle of least privileged access when granting permissions. You analyze
    who the producer and consumer of data is and what permissions they need to the
    Amazon DataZone resources and accordingly assign privileges through your administrators.
    You enable specific actions that you want to allow on those resources. Therefore,
    you should grant only the permissions that are required to perform a task. Implementing
    least privilege access is fundamental in reducing security risk and the impact
    that could result from errors or malicious intent.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon DataZone 的典型用例是在您的组织内跨业务组共享数据。由于 Amazon DataZone 数据网格架构的基本假设是分散治理，因此在授予权限时保持最小特权访问原则更为重要。您需分析数据的生产者和消费者是谁，以及他们对
    Amazon DataZone 资源需要哪些权限，并通过管理员相应地分配权限。您应该仅授予执行任务所需的权限。实施最小特权访问是降低安全风险和由错误或恶意意图可能导致的影响的基础。
- en: Use IAM roles
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 IAM 角色
- en: Communication between producer and consumer in Amazon DataZone is done through
    IAM roles similar to access between AWS services. Both producer and client applications
    must have valid credentials, and it is recommended to use an IAM role to manage
    temporary credentials for your producer and client applications to access Amazon
    DataZone resources.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon DataZone 中生产者和消费者之间的通信通过 IAM 角色进行，类似于 AWS 服务之间的访问。生产者和客户端应用程序都必须具有有效的凭证，建议使用
    IAM 角色来管理您的生产者和客户端应用程序访问 Amazon DataZone 资源的临时凭证。
- en: Storing AWS credentials directly in a client application or in an Amazon S3
    bucket is not recommended. These are long-term credentials that are not automatically
    rotated and could have a significant business impact if they are compromised.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 不建议将 AWS 凭证直接存储在客户端应用程序中或 Amazon S3 存储桶中。这些是长期凭证，不会自动轮换，如果被泄露可能会对业务产生重大影响。
- en: For more details on security, you can refer to [Data Protection in Amazon DataZone](https://oreil.ly/tPE-E).
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 关于安全性的更多细节，请参阅[Amazon DataZone 中的数据保护](https://oreil.ly/tPE-E)。
- en: Summary
  id: totrans-372
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter discussed how Amazon Redshift data sharing enables seamless data
    sharing within and across your organizational boundaries with built-in governance
    and access controls. You learned how to make data available securely to your business
    users using data sharing to analyze data with the tool of their choice to make
    timely decisions. The ability to share data without moving data eliminates potential
    errors in the ETL process and maintains data integrity of your source data that
    your users use to make key business decisions.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了如何通过 Amazon Redshift 数据共享在组织边界内和跨组织边界内实现无缝数据共享，并具备内置治理和访问控制。您学习了如何利用数据共享安全地向业务用户提供数据，让他们使用自己选择的工具分析数据以做出及时决策。通过数据共享而无需移动数据，消除了在
    ETL 过程中可能出现的错误，保持了源数据的数据完整性，这些数据是您的用户用来做出关键业务决策的基础。
- en: You learned various use cases of data sharing including workload isolation,
    cross-departmental collaboration, and Analytics as a Service, and to improve agility
    of development. You created three types of multi-tenant models with various levels
    of isolation for the student information dataset. Finally, you learned about Amazon
    DataZone and how you can use this service to discover and share data with a decentralized
    data governance model.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 您学习了数据共享的各种用例，包括工作负载隔离、跨部门协作以及作为服务的分析，以及提高开发灵活性。您创建了三种多租户模型，用于学生信息数据集的不同隔离级别。最后，您了解了亚马逊数据区（Amazon
    DataZone）及如何使用该服务来实现去中心化数据治理模型。
- en: In the next chapter, we’ll cover how you secure and govern the data in your
    analytics environment. We will go in detail about the various access controls
    you can apply to components of Amazon Redshift, giving you both broad and fine-grained
    control. Finally, we’ll cover how to set access controls on external services
    you may consume in Amazon Redshift such as data in your data lake, operational
    databases, streaming data, and other AWS services like AWS Lambda and Amazon SageMaker.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将介绍如何在您的分析环境中保护和治理数据。我们将详细讨论您可以应用于Amazon Redshift组件的各种访问控制，为您提供广泛和细粒度的控制。最后，我们将介绍如何设置对Amazon
    Redshift中可能使用的外部服务的访问控制，例如数据湖中的数据、运营数据库、流数据，以及AWS Lambda和Amazon SageMaker等其他AWS服务。
