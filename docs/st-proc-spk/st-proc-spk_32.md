# 第二十六章：性能调优

分布式流应用程序的性能特征通常受其运行中的内部和外部因素之间复杂关系的制约。

外部因素与应用程序执行环境绑定，如构成集群的主机及连接它们的网络。每个主机提供诸如 CPU、内存和存储等资源，具有特定的性能特征。例如，我们可能有磁盘通常速度较慢但提供低成本存储的磁盘，或者提供高成本每存储单位较快访问的快速固态驱动器（SSD）阵列。或者我们可能正在使用云存储，其性能受网络容量和可用互联网连接的限制。同样，数据生产者通常不受流应用程序控制之外。

在内部因素方面，我们考虑实施的算法复杂性、分配给应用程序的资源以及决定应用程序行为的特定配置。

在本章中，我们首先努力深入了解 Spark Streaming 的性能因素。然后，我们调查几种可以应用于调优现有作业性能的策略。

# Spark Streaming 的性能平衡

在 Spark Streaming 中进行性能调优有时可能会很复杂，但始终始于批处理间隔和批处理时间的简单平衡。我们可以将批处理时间视为完成所有接收数据及相关簿记处理所需的时间成本，而批处理间隔则是我们分配的预算。就像财务类比一样，一个健康的应用程序将在分配的预算内完成其处理成本。虽然在一些特定时刻压力增大时可能会超出预算，但我们必须看到从长期来看，我们的平衡是得以保持的。一个长期超出这种时间预算平衡的应用程序将导致系统性失败，通常由于资源耗尽导致应用程序崩溃。

## 批处理间隔与处理延迟之间的关系

一般来说，流应用程序的一个重要限制是数据摄入不会停止。在 Spark Streaming 中，数据摄入是在固定的间隔内发生的，并且没有任何方法可以随意关闭它。因此，如果在新的批处理间隔开始时作业队列还没有空，新数据又被插入系统中，Spark Streaming 需要在处理新数据之前完成先前作业的处理。

只有一个作业在运行时，我们可以看到以下情况：

+   如果批处理时间仅暂时大于批处理间隔，但一般情况下，Spark 能够在批处理间隔内处理一个批次，Spark Streaming 最终将赶上并清空作业（RDD）队列。

+   另一方面，如果迟延是系统性的，并且集群平均需要超过一个批处理间隔来处理一个微批次，Spark Streaming 将在每个批处理间隔上平均接受更多数据，而无法从其存储管理中删除。最终，集群将耗尽资源并崩溃。

然后，我们需要考虑当那些多余数据积累稳定一段时间后会发生什么。默认情况下，代表输入到系统的数据的 RDD 被放置在集群机器的内存中。在那个内存中，原始数据——源 RDD——需要复制，这意味着随着数据被输入到系统中，在每个块间隔上逐渐为了容错性创建第二个副本。因此，暂时的时间内，直到处理该 RDD 的数据，该数据在系统执行者的内存中存在两个副本。在接收者模型中，因为数据始终在接收者上存在一个副本，所以这台机器承担了大部分的内存压力。

## 一个作业失败的最后时刻

最终，如果我们在系统中某个地方添加了太多的数据，我们最终会溢出几个执行者的内存。在接收者模型中，这可能是接收者执行者因为`OutOfMemoryError`而崩溃。接下来发生的是集群中的另一台机器将被指定为新的接收者，并开始接收新数据。因为那个接收者内存中的一些块由于崩溃而丢失，它们现在只存在于集群中的单一副本中，这意味着在处理这些数据之前会触发对这些数据的重复。因此，集群中现有的执行者将承受先前的内存压力——在崩溃期间丢失的数据没有固有的缓解。少数执行者将忙于复制数据，而一个新的执行者将再次接受数据。但请记住，如果在崩溃之前我们的集群包含 *N* 个执行者，现在由 *N* - *1* 个执行者组成，并且在处理相同的数据摄入节奏时可能较慢——更不用说大多数执行者现在忙于数据复制而不是像往常一样的处理。我们在崩溃之前观察到的批处理时间现在只能更高，并且特别是高于批处理间隔。

总之，平均批处理时间高于批处理间隔可能会在整个集群中引发级联崩溃。因此，在考虑批处理间隔作为集群正常运行期间可能要执行的所有操作的时间预算时，保持 Spark 的平衡非常重要。

###### 注意

通过将`spark.streaming.concurrent.jobs`设置为比您的 Spark 配置中的值大的值，您可以取消仅允许一个作业在给定时间执行的约束。然而，这可能存在风险，因为它可能会导致资源竞争，并且可能会使调试是否系统中有足够的资源来处理摄入数据变得更加困难。

## 深入探讨：调度延迟和处理延迟

许多因素可能会影响批处理时间。当然，首要的约束是要在数据上执行的分析——作业本身的逻辑。该计算的运行时间可能取决于数据的大小，也可能不取决于数据中的值。

这种纯计算时间在*处理延迟*的名义下被考虑进去，它是运行作业所花时间和设置作业所花时间之间的差异。

另一方面，*调度延迟*考虑的是在获取作业定义（通常是一个*闭包*），序列化它并发送到需要处理它的执行器所需的时间。自然地，这种任务的分发意味着一些开销——并非全部用于计算的时间，因此明智的做法是不要将我们的工作负载分解为太多的小作业，并调整并行性，使其与我们集群上的执行器数量相匹配。最后，*调度延迟*还考虑了作业迟到，如果我们的 Spark Streaming 集群在其队列中积累了作业。它正式定义为作业（RDD）进入作业队列和 Spark Streaming 实际开始计算之间的时间。

影响调度延迟的另一个重要因素是地域设置，特别是`spark.locality.wait`，它规定在向数据相关任务的最本地放置等待多长时间之前升级到下一个地域级别。以下是地域级别：

`PROCESS_LOCAL`

同一进程的 Java 虚拟机（JVM）。这是最高的地域级别。

`NODE_LOCAL`

同一执行器机器。

`NO_PREF`

无地域偏好。

`RACK_LOCAL`

同一服务器机架。

`ANY`

这是最低的地域级别，通常是由于无法获取任何上面级别的地域而导致的。

## 处理时间中的检查点影响

还有其他因素可能出乎意料地会影响批处理时间，特别是检查点。如第二十四章中讨论的那样，检查点是在处理有状态流时必需的保障，以避免在故障恢复时发生数据丢失。它使用中间计算值在磁盘上进行存储，以便在故障发生时，不需要重新计算从数据源以来看到的流中的值所依赖的数据，而只需从最后一个检查点的时间开始重新计算。检查点操作由 Spark 结构化地编程为周期性作业，因此，制作检查点所花费的时间实际上被视为处理延迟的一部分，而不是调度延迟。

对于有状态流的常规检查点，通常在语义上和保护数据大小方面，检查点的持续时间可能远远超过批处理间隔的时间。检查点的持续时间长达 10 个批处理间隔并不罕见。因此，在确保平均批处理时间小于批处理间隔时，有必要考虑检查点。检查点对平均批处理时间的贡献如下：

<math alttext="StartFraction c h e c k p o i n t i n g d e l a y Over b a t c h i n t e r v a l EndFraction asterisk c h e c k p o i n t i n g d u r a t i o n" display="block"><mrow><mfrac><mrow><mi>c</mi><mi>h</mi><mi>e</mi><mi>c</mi><mi>k</mi><mi>p</mi><mi>o</mi><mi>i</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>d</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>y</mi></mrow> <mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>a</mi><mi>l</mi></mrow></mfrac> <mo>*</mo> <mrow><mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>c</mi> <mi>k</mi> <mi>p</mi> <mi>o</mi> <mi>i</mi> <mi>n</mi> <mi>t</mi> <mi>i</mi> <mi>n</mi> <mi>g</mi> <mi>d</mi> <mi>u</mi> <mi>r</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi></mrow></mrow></math>

这应该添加到非检查点作业期间观察到的平均计算时间中，以了解真实批处理时间的概念。或者，另一种处理方式是计算在我们的预算（批处理间隔和批处理时间之间的差异）中没有检查点的剩余时间，并在函数中调整检查点间隔：

<math alttext="c h e c k p o i n t i n g d e l a y greater-than-or-equal-to c h e c k p o i n t i n g d u r a t i o n slash left-parenthesis b a t c h i n t e r v a l minus b a t c h p r o c e s s i n g t i m e Superscript asterisk Baseline right-parenthesis" display="block"><mrow><mrow><mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>c</mi> <mi>k</mi> <mi>p</mi> <mi>o</mi> <mi>i</mi> <mi>n</mi> <mi>t</mi> <mi>i</mi> <mi>n</mi> <mi>g</mi> <mi>d</mi> <mi>e</mi> <mi>l</mi> <mi>a</mi> <mi>y</mi></mrow> <mo>≥</mo> <mrow><mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>c</mi> <mi>k</mi> <mi>p</mi> <mi>o</mi> <mi>i</mi> <mi>n</mi> <mi>t</mi> <mi>i</mi> <mi>n</mi> <mi>g</mi> <mi>d</mi> <mi>u</mi> <mi>r</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi></mrow> <mo>/</mo> <mo>(</mo> <mrow><mi>b</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>i</mi> <mi>n</mi> <mi>t</mi> <mi>e</mi> <mi>r</mi> <mi>v</mi> <mi>a</mi> <mi>l</mi></mrow> <mo>-</mo> <msup><mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi>p</mi><mi>r</mi><mi>o</mi><mi>c</mi><mi>e</mi><mi>s</mi><mi>s</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi></mrow> <mo>*</mo></msup> <mo>)</mo></mrow></math>

当*标记批处理时间的测量时，不使用检查点。

# 影响作业性能的外部因素

最后，如果所有这些因素都已考虑进去，但您仍然注意到作业处理延迟出现波动，我们确实需要注意的另一个方面是集群上的变化条件。

例如，我们集群中共存的其他系统可能会影响我们共享的处理资源：已知 Hadoop 分布式文件系统（HDFS）在其较旧版本中存在有限制并发磁盘写入的错误。¹ 因此，我们可能正在以非常稳定的速率运行集群，同时，一个可能与 Spark 无关的不同作业可能需要大量使用磁盘。这可能会影响以下内容：

+   数据在可靠接收模型中的接收，在使用写前日志（WAL）时

+   检查点时间

+   我们流处理中涉及将数据保存到磁盘的操作。

为了通过磁盘使用减轻作业受外部影响的问题，我们可以采取以下措施：

+   使用 Alluxio 等分布式内存缓存

+   将结构化的小数据保存在 NoSQL 数据库中，而不是保存在文件中，以减少磁盘压力。

+   避免将更多磁盘密集型应用与 Spark 放置在一起，除非绝对必要

磁盘访问只是可能影响我们通过资源共享与集群的作业的一种潜在瓶颈。另一种可能性可能是网络饥饿，或者更普遍地说，存在无法通过我们的资源管理器监视和调度的工作负载。

# 如何提高性能？

在前一节中，我们讨论了可以影响 Spark Streaming 作业性能的内在和外在因素。

假设我们处于这样一种情况：我们开发了一个作业，并观察到某些影响性能和因此作业稳定性的问题。采取的第一步将是深入了解我们作业的不同性能指标，也许可以使用“使用流式 UI 理解作业性能”中概述的技术。

我们将这些信息作为比较基准，并指导使用以下的一个或多个不同策略。

# 调整批处理间隔

经常提到的一个策略是延长批处理间隔。这种方法可能有助于改善一些并行性和资源使用问题。例如，如果我们将批处理间隔从一分钟增加到五分钟，那么我们每五分钟只需序列化一次作业中的组件任务，而不是每分钟一次，从而减少五倍。

尽管如此，我们流的批次将表示通过“线上”看到的五分钟数据，而不是一分钟数据，因为大多数不稳定性问题是由于我们的资源分配不足以支持我们流的吞吐量所导致的，批处理间隔对于这种不平衡可能改变很少。更重要的是，我们希望实现的批处理间隔在我们的分析中通常具有很高的语义值；例如，正如我们在第二十一章中看到的，它限制了我们可以在聚合流上创建的窗口和滑动间隔。只有在最后一种情况下，我们才应该考虑改变这些分析语义以适应处理约束。

一种更具吸引力的策略是减少一般的低效率，例如使用快速序列化库或实现具有更好性能特性的算法。我们还可以通过增加或替换我们的分布式文件系统为内存缓存，如[Alluxio](https://www.alluxio.com/)，来加快磁盘写入速度。当这些措施不足以满足需求时，我们应该考虑通过调整块间隔来增加集群资源，从而通过相应增加使用的分区数来将流分布到更多执行器上。

# 通过固定速率节流来限制数据入口

如果绝对不能获取更多资源，我们需要考虑减少必须处理的数据元素数量。

自版本 1.3 起，Spark 包含了一个固定速率的限流功能，允许其接受最大数量的元素。我们可以通过在 Spark 配置中添加 `spark.streaming.receiver.maxRate` 来设置每秒元素的值。请注意，对于基于接收器的消费者，此限制在块创建时生效，并且如果达到了限制，它将简单地拒绝从数据源读取更多元素。

对于 Kafka 直连器，有一个专门的配置 `spark.streaming.kafka.maxRatePerPartition`，设置每个分区中主题的最大速率限制，以记录每秒。在使用此选项时，请注意总速率将如下：

<math display="block"><mrow><mrow><mi>m</mi> <mi>a</mi> <mi>x</mi> <mi>R</mi> <mi>a</mi> <mi>t</mi> <mi>e</mi> <mi>P</mi> <mi>e</mi> <mi>r</mi> <mi>P</mi> <mi>a</mi> <mi>r</mi> <mi>t</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi></mrow> <mo>*</mo> <mrow><mi>p</mi> <mi>a</mi> <mi>r</mi> <mi>t</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>s</mi> <mi>p</mi> <mi>e</mi> <mi>r</mi> <mi>t</mi> <mi>o</mi> <mi>p</mi> <mi>i</mi> <mi>c</mi></mrow> <mo>*</mo> <mrow><mi>b</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>i</mi> <mi>n</mi> <mi>t</mi> <mi>e</mi> <mi>r</mi> <mi>v</mi> <mi>a</mi> <mi>l</mi></mrow></mrow></math>

请注意，这种行为本身并不包括任何信号传递；Spark 只会在批次间隔结束时允许有限数量的元素，并在下一个批次间隔开始时继续读取新元素。这对将数据馈送到 Spark 的系统有影响：

+   如果这是一个拉取式系统，例如 Kafka、Flume 等，输入系统可以计算读取的元素数量，并以自定义方式管理溢出数据。

+   如果输入系统更加朴素地是一个缓冲区（文件缓冲区、TCP 缓冲区），它将在几个块间隔后溢出（因为我们的流比限流的吞吐量大），并且会定期刷新（删除）。

由于 Spark 中的限流机制，可以表现出读取元素时的一些“抖动”，因为 Spark 会读取每个元素，直到底层的 TCP 或文件缓冲区，用作“延迟”元素的队列，达到容量并整体刷新。这样做的效果是输入流被分隔成大量处理元素的间隔，其中夹杂着定期大小的“空洞”（丢失的元素）（例如，一个 TCP 缓冲区）。

# 回压

我们描述的基于队列的系统通过固定速率限流存在一个缺点，即使我们整个流水线都不易理解效率低下的原因。事实上，我们考虑了一个*数据源*（例如 TCP 套接字），它由*从外部服务器读取数据*（例如 HTTP 服务器）组成，进入*本地系统级队列*（TCP 缓冲区），然后 Spark 将此数据传送到*应用级缓冲区*（Spark Streaming 的 RDD）。除非我们使用与 Spark Streaming 接收器绑定的监听器，否则很难检测和诊断系统是否拥挤，以及拥挤发生在哪里。

如果外部服务器意识到我们的 Spark Streaming 集群拥塞，它可以决定根据该信号做出反应，并使用自己的方法延迟或选择要发送到 Spark 的入站元素。更重要的是，它可以使拥塞信息沿着流向上传回其依赖的数据生产者，调用管道的每个部分意识到并帮助处理拥塞。这还允许任何监控系统更好地查看拥塞在我们系统中的发生位置，从而有助于资源管理和调优。

*上游流动*、*量化信号*关于拥塞的信息被称为*背压*。这是一个连续的信号，明确表示了在特定时刻我们期望系统（这里是我们的 Spark Streaming 集群）处理多少元素。与节流相比，背压信号有一个优势，因为它被设置为动态信号，根据元素的流入以及 Spark 队列的状态而变化。因此，如果没有拥塞，它不会影响系统，并且不需要调整任意限制，避免配置错误（如果限制过于严格，则资源未充分利用；如果限制过于宽松，则会溢出）的相关风险。

此方法自 Spark 1.5 版本起可用，简言之，可提供动态节流。

# 动态节流

在 Spark Streaming 中，默认使用*比例积分微分*（PID）控制器来动态调节节流，它通过观察错误信号来调节，这个错误信号是指最新批处理间隔内的*摄入速率*（以每秒元素数计）与*处理速率*之间的差异。我们可以将这个错误视为当前时刻进入 Spark 的元素数与离开 Spark 的元素数之间的不平衡（“即时”被调整为完整批处理间隔）。

然后，PID 控制器旨在通过考虑以下因素来调节*下一个*批处理间隔中的摄入元素数：

+   比例项（此时的错误）

+   积分或“历史”项（过去所有错误的总和；这里指队列中未处理元素的数量）

+   导数或“速度”项（过去元素数量减少的速率）

然后，PID 试图计算一个理想数，具体取决于这三个因素。

在 Spark 中，基于背压的动态节流可以通过在 Spark 配置中将`spark.streaming.backpressure.enabled`设置为`true`来启用。另一个变量`spark.streaming.backpressure.initialRate`决定了节流初始应预期的每秒处理元素数。您应将其设置为略高于流吞吐量的最佳估计，以允许算法“预热”。

###### 注意

关注反压来处理管道系统中的拥塞问题受到了[反应流规范](http://www.reactive-streams.org/)的启发，这是一个与实现无关的 API，旨在实现一个关于这种方法优势的宣言，得到了包括 Netflix、Lightbend 和 Twitter 在内的多个行业参与者的支持。

## 调整反压 PID

PID 调优是一个成熟且广泛的主题，超出了本书的范围，但 Spark Streaming 用户应该对其用途有直觉。*比例项*有助于处理当前错误的快照，*积分项*帮助系统处理到目前为止累积的错误，*导数项*帮助系统避免在系统快速修正时过冲或在面对流元素吞吐量急剧增加时欠修正。

PID 的每个术语都有一个附加的权重因子，介于 0 和 1 之间，适合经典的 PID 实现。以下是您需要在 Spark 配置中设置的参数：

```
spark.streaming.backpressure.pid.proportional
spark.streaming.backpressure.pid.integral
spark.streaming.backpressure.pid.derived
```

默认情况下，Spark 实现了一个比例-积分控制器，比例权重为 1，积分权重为 0.2，导数权重为 0。这在 Spark Streaming 应用程序中提供了一个合理的默认值，其中流的吞吐量相对于批处理间隔变化比较慢，并且更容易解释：Spark 的目标是不超过最后一个处理速率，并且在每个批次中有一个用于处理五分之一迟到元素的“缓冲区”。然而，请注意，如果面对变化快速且吞吐量不规则的流，您可能需要考虑使用非零导数项。

## 自定义速率估算器

PID 估算器并非是我们可以在 Spark 中实现的唯一速率估算器。它是`RateEstimator` trait 的一个实现，可以通过将`spark.streaming.backpressure.rateEstimator`的值设置为您的类名来交换特定的实现。请记住，您需要在 Spark 类路径中包含相关类；例如，通过`spark-submit`的`--jars`参数。

`RateEstimator` trait 是一个可序列化的 trait，需要一个单独的方法：

```
  def compute(
      time: Long,
      elements: Long,
      processingDelay: Long,
      schedulingDelay: Long): Option[Double]
}
```

此函数应返回流连接到此`RateEstimator`应每秒摄取的记录数的估计值，考虑到最新批次的大小和完成时间的更新。您可以自由贡献替代实现。

## 替代动态处理策略的注意事项

在 Spark 中，动态或静态的节流表达在`InputDStream`类中，这包括接收模型的`ReceiverInputDStream`和 Kafka 直接接收器的`DirectKafkaInputDStream`。目前，这些实现都有一种简单的处理多余元素的方式：它们既不从输入源读取（`ReceiverInputDStream`），也不从主题消费（`DirectKafkaInputDStream`）。

但是，在`InputDStream`接收到的背压信号的应用程序生命周期内，可以合理地提出几种可能的替代实现。我们可以想象诸如取第一个、最大的或最小的元素，或者是一个随机样本的策略。

不幸的是，这些类的`rateController: RateController`成员是`protected[streaming]`的，但该成员具有一个`getLatestRate`函数，该函数允许 DStream 实现在任何时刻接收到相关限制。因此，任何自定义 DStream 的实现都可以从速率控制的非公开但开放源代码的方法中汲取灵感，以更好地处理拥塞情况。

# 缓存

在 Spark Streaming 中，缓存是一种功能，当良好地操作时，可以显著加快应用程序执行的计算。这似乎是违反直觉的，因为在作业运行之前，表示计算输入中存储的数据的基础 RDD 实际上被复制了两次。

然而，在你的应用程序的生命周期内，可能存在一个非常长的流水线，将你的计算从这些基础 RDD 到一些非常精细和结构化的数据表示，通常涉及键-值元组。在应用程序执行的计算结束时，你可能正在考虑将计算输出的某些部分分发到各种输出：例如数据存储或数据库，如 Cassandra。这种分发通常涉及查看在上一批次间隔期间计算的数据，并找出应将输出数据的哪些部分放在哪里。

对于这种情况的典型用例是查看结构化输出数据的 RDD 中的键（计算中的最后一个 DStream），以确定根据这些键将计算结果放置在 Spark 之外的确切位置。另一个用例是仅查找上一批次接收到的 RDD 中的某些特定元素。事实上，你的 RDD 实际上可能是依赖于不仅是最后一批数据，而是从应用程序启动以来接收的许多先前事件的计算输出。你的流水线的最后一步可能总结了系统的状态。在那个输出结构化结果的 RDD 上查找，我们可能正在寻找通过某些标准的某些元素，将新结果与先前值进行比较，或者将数据分发给不同的组织实体，列举几种情况。

例如，想象一下异常检测。您可能会对值（定期监视的用户或元素）计算一些指标或特征。其中一些特征可能会显示出一些问题或需要生成一些警报。为了将这些输出到警报系统，您需要在当前查看的数据 RDD 中找到通过某些标准的元素。为此，您将会*迭代*结果 RDD。除了警报外，您可能还希望发布应用程序的状态，例如，用于提供数据可视化或仪表板，以通知您正在调查的系统的更一般特征。

这个思维实验的要点是设想在输出 DStream 上计算涉及到为管道最终结果的每个 RDD 进行多次操作，尽管它非常结构化且可能从输入数据中减少了大小。为此，在多次迭代发生之前使用缓存来存储该最终 RDD 非常有用。

当你在缓存的 RDD 上进行多次迭代时，第一次迭代与非缓存版本花费的时间相同，而每个后续迭代只需花费少量时间。这是因为虽然 Spark Streaming 的基础数据被缓存在系统中，但在应用程序定义的潜在非常长的流水线中，需要逐步从该基础数据中恢复中间步骤。在处理数据时，每次迭代都需要检索详细数据，如下所示：

```
dstream.foreachRDD{ (rdd)  =>
  rdd.cache()
  keys.foreach{ (key) =>
    rdd.filter(elem=> key(elem) == key).saveAsFooBar(...)
  }
  rdd.unpersist()
}
```

因此，如果您的 DStream 或对应的 RDD 被多次使用，将它们缓存会显著加快处理速度。但非常重要的是不要过度使用 Spark 的内存管理，并假设 DStream 的 RDD 在批处理间隔后会自然地从缓存中移除。在每个 DStream 的 RDD 迭代结束时，请务必考虑取消持久化 RDD，以便让它从缓存中移除。

否则，Spark 将需要进行相对聪明的计算，以尝试理解应保留哪些数据片段。这种特定的计算可能会减慢应用程序的结果或限制其可访问的内存。

最后要考虑的一点是，不应过度使用`cache`操作。如果缓存数据没有足够多次使用，`cache`操作的成本可能超过其带来的好处。总结一下，`cache`是一个提升性能的函数，应谨慎使用。

# 预测执行

Apache Spark 处理流或批处理执行中的落后作业时，使用 *推测执行*。该机制利用了 Spark 处理将同一任务同时放入每个工作节点的队列的特点。因此，估计每个工作节点完成一个任务应该需要大致相同的时间。如果不是这种情况，通常是由于以下两个原因之一：

+   我们的数据集可能受到数据倾斜的影响，其中少数任务集中了大部分的计算。在某些情况下这是正常的，³ 但在大多数情况下是一个不好的情况，我们需要通过重新分配输入（例如通过洗牌）来改善。

+   或者某个特定执行器由于硬件故障或者共享集群中的负载过载而运行缓慢。

如果 Spark 检测到异常长的执行时间并且有可用资源，它可以重新启动当前运行缓慢的任务到另一个节点。这个推测任务（假设原始任务出了问题）将要么首先完成并取消旧任务，要么在前者返回后立即被取消。总体来说，“乌龟和兔子”的竞争能够实现更好的完成时间和资源利用。

推测执行响应四个配置参数，详见表 26-1。

表 26-1\. 推测执行配置参数

| 选项 | 默认 | 含义 |
| --- | --- | --- |
| `spark.speculation` | `false` | *如果设置为“true”，则执行任务的推测执行* |
| `spark.speculation.interval` | `100ms` | *Spark 检测任务进行推测的频率* |
| `spark.speculation.multiplier` | `1.5` | *任务比中位数慢多少倍才考虑进行推测* |
| `spark.speculation.quantile` | `0.75` | *特定阶段启用推测执行前完成的任务比例* |

¹ 您可以参考 [HDFS-7489](https://issues.apache.org/jira/browse/HDFS-7489) 来了解这些微妙的并发问题的一个示例。

² Alluxio 最初名为 Tachyon，是 Spark 代码库的一部分，这表明它的功能与 Spark 数据处理非常互补。

³ 例如，在异常检测推断中，探测到异常值的执行器有时还需要额外的警报工作，这是常规节点职责的额外负担。
